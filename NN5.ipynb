{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9529d1ba",
   "metadata": {},
   "source": [
    "# Project covering neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9acacf",
   "metadata": {},
   "source": [
    "# -------------------------------------------NN1------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62913f70",
   "metadata": {},
   "source": [
    "## MLP CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88a85c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def linear_derivative(x):\n",
    "    return 1\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x>0).astype(float)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - np.tanh(x)**2\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x/np.sum(exp_x, axis = 1, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "class MLPNoBackprop:\n",
    "    #####################################################################################################################\n",
    "    #----------------------------------------FRIST CHECKPOINT -----------------------------------------------------------\n",
    "    #####################################################################################################################\n",
    "    def __init__(self, layer_sizes,\n",
    "                 hidden_activation='sigmoid',\n",
    "                 output_activation='linear',\n",
    "                 weights_initialize_function ='uniform'):\n",
    "        self.weights = [0] * (len(layer_sizes)-1)\n",
    "        self.biases = [0] * (len(layer_sizes)-1)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.bounds = {\n",
    "            'uniform': {i: (0, 1) for i in range(len(layer_sizes) - 1)},  \n",
    "            'he': {\n",
    "                i: (-math.sqrt(6 / layer_sizes[i]), math.sqrt(6 / layer_sizes[i]))\n",
    "                for i in range(len(layer_sizes) - 1)\n",
    "            },\n",
    "            'xavier': {\n",
    "                i: (-math.sqrt(6 / (layer_sizes[i] + layer_sizes[i + 1])), \n",
    "                    math.sqrt(6 / (layer_sizes[i] + layer_sizes[i + 1])))\n",
    "                for i in range(len(layer_sizes) - 1)\n",
    "            }\n",
    "        }\n",
    "            \n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            low, high = self.bounds[weights_initialize_function][i] \n",
    "            self.weights[i] = np.random.uniform(low, high,(layer_sizes[i],layer_sizes[i+1]))\n",
    "            self.biases[i] = np.zeros((layer_sizes[i+1], ))\n",
    "        self.functions = {\n",
    "            'linear': linear,\n",
    "            'sigmoid': sigmoid,\n",
    "            'relu': relu,\n",
    "            'tanh': tanh,\n",
    "            'softmax': softmax\n",
    "        }\n",
    "        self.hidden_activation = self.functions[hidden_activation]\n",
    "        self.output_activation = self.functions[output_activation]\n",
    "        \n",
    "        self.derivatives ={\n",
    "            'linear': linear_derivative,\n",
    "            'sigmoid': sigmoid_derivative,\n",
    "            'relu': relu_derivative,\n",
    "            'tanh': tanh_derivative,\n",
    "            'softmax': softmax\n",
    "        }\n",
    "        \n",
    "        self.hidden_derivative = self.derivatives[hidden_activation]\n",
    "        self.output_derivative = self.derivatives[output_activation]\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Performs the foraward pass in a neural network\n",
    "        \n",
    "        Parameters:\n",
    "        X - numpy.ndarray \n",
    "            input data matrix (can be a vector or a matrix)\n",
    "            \n",
    "        Returns:\n",
    "        actiations : list\n",
    "            a list of activations from the hidden layers and output layer\n",
    "        \"\"\"\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1,-1)\n",
    "        activation = X\n",
    "        activations = [activation]\n",
    "        for i in range(len(self.weights)-1):\n",
    "            z = activation @ self.weights[i] + self.biases[i]\n",
    "            activation = self.hidden_activation(z)\n",
    "            activations.append(activation)\n",
    "        z = activation @ self.weights[-1] + self.biases[-1]\n",
    "        activation = self.output_activation(z)\n",
    "        activations.append(activation)\n",
    "        return activations\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        return activation from output layer after performing a forward pass\n",
    "        \n",
    "        Parameters:\n",
    "        X - numpy.ndarray\n",
    "            input data matrix (can be a vector or a matrix)\n",
    "        \n",
    "        Returns:\n",
    "        numpy.ndarray\n",
    "            The activation of the output layer, representing the network's prediction\n",
    "        \"\"\"\n",
    "        return self.forward(X)[-1]\n",
    "        \n",
    "    def set_weights_and_biases(self, layer_idx, W, b):\n",
    "        \"\"\"\n",
    "        Allows to manually set weights and biases for layer with index equal to layer_indx\n",
    "\n",
    "        Parameters: \n",
    "        layer_indx: int\n",
    "        index of the layer for which weights and biases should be set\n",
    "        W: numpy.ndarray\n",
    "            Weight matrix\n",
    "        b: numpy.ndarray\n",
    "            Bias vector for specified layer\n",
    "        \"\"\"\n",
    "        self.weights[layer_idx] = W\n",
    "        self.biases[layer_idx] = b\n",
    "\n",
    "    \n",
    "    def mse(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "         Computes the Mean Squared Error (MSE) between true and predicted values.\n",
    "\n",
    "        Parameters:\n",
    "        y_true - numpy.ndarray\n",
    "            The ground truth (actual) values.\n",
    "        y_pred - numpy.ndarray\n",
    "            The predicted values.\n",
    "        Returns:\n",
    "        float\n",
    "        The mean squared error\n",
    "        \"\"\"\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "###########################################################################################################################    \n",
    "#--------------------------------------------- SECOND CHECKPOINT ----------------------------------------------------------    \n",
    "###########################################################################################################################    \n",
    "    \n",
    "    def backward(self, X, Y_true):\n",
    "        \"\"\"\n",
    "        Computes gradients of weights and biases using backpropagation for regression.\n",
    "\n",
    "        Parameters:\n",
    "        X : numpy.ndarray\n",
    "            Input data.\n",
    "        Y_true : numpy.ndarray\n",
    "            True target values.\n",
    "\n",
    "        Returns:\n",
    "        list\n",
    "            Gradients of weights.\n",
    "        list\n",
    "            Gradients of biases.\n",
    "        \"\"\"\n",
    "        weights_backprop=[]\n",
    "        biases_backprop=[]\n",
    "        activations = self.forward(X)\n",
    "        n = len(Y_true)\n",
    "        error = 2/n * (activations[-1] - Y_true)\n",
    "        delta = error * self.output_derivative(activations[-2] @ self.weights[-1] + self.biases[-1])\n",
    "        last_gradient_descent = activations[-2].T @ delta\n",
    "        weights_backprop.insert(0, last_gradient_descent)\n",
    "        biases_backprop.insert(0, np.sum(delta, axis=0, keepdims=True))\n",
    "        for i in range(len(self.weights) -2, -1, -1):\n",
    "            delta = (delta @ self.weights[i+1].T) * self.hidden_derivative(activations[i] @ self.weights[i] + self.biases[i])\n",
    "            gradient = activations[i].T @ delta\n",
    "            weights_backprop.insert(0, gradient)\n",
    "            biases_backprop.insert(0,  np.sum(delta, axis=0, keepdims=True))\n",
    "        \n",
    "        return weights_backprop, biases_backprop\n",
    "    \n",
    "             \n",
    "    \n",
    "    def SGD(self, X, Y_true, epochs, learning_rate):\n",
    "        \"\"\"\n",
    "        Trains the model using stochastic gradient descent.\n",
    "\n",
    "        Parameters:\n",
    "        X : numpy.ndarray\n",
    "            Input features.\n",
    "        Y_true : numpy.ndarray\n",
    "            Target labels.\n",
    "        epochs : int\n",
    "            Number of epochs.\n",
    "        learning_rate : float\n",
    "            Learning rate.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            shuffle_idx = np.random.permutation(n_samples)\n",
    "            X_shuffled = X[shuffle_idx]\n",
    "            Y_shuffled = Y_true[shuffle_idx]\n",
    "            for i in range(n_samples):\n",
    "                w, b = self.backward(X_shuffled, Y_shuffled)\n",
    "                for l in range(len(self.weights)):\n",
    "                    new_weight = self.weights[l] - learning_rate * w[l]\n",
    "                    new_bias = self.biases[l] - learning_rate * b[l]\n",
    "                    self.set_weights_and_biases(l, new_weight, new_bias)\n",
    "\n",
    "            \n",
    "\n",
    "    def mini_batch_GD(self, X, Y_true, batch_size, epochs, learning_rate):\n",
    "        \"\"\"\n",
    "        Trains the model using mini-batch gradient descent.\n",
    "\n",
    "        Parameters:\n",
    "        X : numpy.ndarray\n",
    "            Input features.\n",
    "        Y_true : numpy.ndarray\n",
    "            Target labels.\n",
    "        batch_size : int\n",
    "            Size of the mini-batch.\n",
    "        epochs : int\n",
    "            Number of epochs.\n",
    "        learning_rate : float\n",
    "            Learning rate.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            shuffle_idx = np.random.permutation(n_samples)\n",
    "            X_shuffled = X[shuffle_idx]\n",
    "            Y_shuffled = Y_true[shuffle_idx]\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                X_batch = X_shuffled[i:i+batch_size]\n",
    "                Y_batch = Y_shuffled[i:i+batch_size]\n",
    "                w, b = self.backward(X_batch, Y_batch)\n",
    "                for l in range(len(self.weights)):\n",
    "                    new_weight = self.weights[l] - learning_rate * w[l]\n",
    "                    new_bias = self.biases[l] - learning_rate * b[l]\n",
    "                    self.set_weights_and_biases(l, new_weight, new_bias)\n",
    "            if epoch % 10 == 0:    \n",
    "                loss = self.mse(Y_true, self.predict(X)[-1])\n",
    "                print(f\"Epoka {epoch}: Loss = {loss:.9f}\")    \n",
    "\n",
    "#######################################################################################################################\n",
    "#-------------------------------------------THIRD CHECKOPINT ---------------------------------------------------------\n",
    "######################################################################################################################\n",
    "    \n",
    "    def momentum(self, X, Y_true, epochs, learning_rate, Lambda, batch_size):\n",
    "        \"\"\"\n",
    "        Trains the model using momentum-based gradient descent.\n",
    "\n",
    "        Parameters:\n",
    "        X : numpy.ndarray\n",
    "            Input features.\n",
    "        Y_true : numpy.ndarray\n",
    "            Target labels.\n",
    "        epochs : int\n",
    "            Number of epochs.\n",
    "        learning_rate : float\n",
    "            Learning rate.\n",
    "        Lambda : float\n",
    "            Momentum coefficient.\n",
    "        batch_size : int\n",
    "            Size of the mini-batch.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        momentum_weights = [0] * (len(self.layer_sizes)-1)\n",
    "        momentum_biases = [0] * (len(self.layer_sizes)-1)\n",
    "        for i in range(len(self.layer_sizes)-1):\n",
    "            momentum_weights[i] = np.zeros((self.layer_sizes[i], self.layer_sizes[i+1]))\n",
    "            momentum_biases[i] = np.zeros((self.layer_sizes[i+1], )) \n",
    "        for epoch in range(epochs):\n",
    "            shuffle_idx = np.random.permutation(n_samples)\n",
    "            X_shuffled = X[shuffle_idx]\n",
    "            Y_shuffled = Y_true[shuffle_idx]\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                X_batch = X_shuffled[i:i+batch_size]\n",
    "                Y_batch = Y_shuffled[i:i+batch_size]\n",
    "                w, b = self.backward(X_batch, Y_batch)\n",
    "                for l in range(len(self.weights)):\n",
    "                    momentum_weights[l] = Lambda * momentum_weights[l] + learning_rate * w[l]\n",
    "                    momentum_biases[l] = Lambda * momentum_biases[l] + learning_rate * b[l].squeeze()            \n",
    "                    self.weights[l] -= momentum_weights[l]\n",
    "                    self.biases[l] -= momentum_biases[l]\n",
    "            if epoch % 10 == 0:\n",
    "                loss = self.mse(self.predict(X), Y_true)  \n",
    "                print(f\"Epoka {epoch}: Loss = {loss:.9f}\")                      \n",
    "    \n",
    "        \n",
    "    \n",
    "    def RMSprop(self, X, Y_true, epochs, learning_rate, beta, epsilon, batch_size):\n",
    "        \"\"\"\n",
    "        Trains the model using RMSprop optimization.\n",
    "\n",
    "        Parameters:\n",
    "        X : numpy.ndarray\n",
    "            Input features.\n",
    "        Y_true : numpy.ndarray\n",
    "            Target labels.\n",
    "        epochs : int\n",
    "            Number of epochs.\n",
    "        learning_rate : float\n",
    "            Learning rate.\n",
    "        beta : float\n",
    "            Decay rate for moving average.\n",
    "        epsilon : float\n",
    "            Small constant for numerical stability.\n",
    "        batch_size : int\n",
    "            Size of the mini-batch.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        v_weights = [np.zeros((self.layer_sizes[i], self.layer_sizes[i+1])) for i in range(len(self.layer_sizes)-1)]\n",
    "        v_biases = [np.zeros((self.layer_sizes[i+1],)) for i in range(len(self.layer_sizes)-1)]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            shuffle_idx = np.random.permutation(n_samples)\n",
    "            X_shuffled = X[shuffle_idx]\n",
    "            Y_shuffled = Y_true[shuffle_idx]\n",
    "\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                X_batch = X_shuffled[i:i + batch_size]\n",
    "                Y_batch = Y_shuffled[i:i + batch_size]\n",
    "                w, b = self.backward(X_batch, Y_batch)\n",
    "\n",
    "                for l in range(len(self.weights)):\n",
    "                    v_weights[l] = beta * v_weights[l] + (1 - beta) * (w[l] ** 2)\n",
    "                    v_biases[l] = beta * v_biases[l] + (1 - beta) * (b[l] ** 2)\n",
    "                    self.weights[l] -= (learning_rate / (np.sqrt(v_weights[l]) + epsilon)) * w[l]\n",
    "                    self.biases[l] -= ((learning_rate / (np.sqrt(v_biases[l]) + epsilon)) * b[l]).squeeze()\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                loss = self.mse(self.predict(X), Y_true)\n",
    "                print(f\"Epoka {epoch}: Loss = {loss:.9f}\")\n",
    "                \n",
    "####################################################################################################################\n",
    "#-------------------------------------------FOURTH CHECKPOINT ------------------------------------------------------\n",
    "####################################################################################################################\n",
    "\n",
    "    def predict_classification(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class labels for the given input data X.\n",
    "\n",
    "        Parameters:\n",
    "        X : numpy.ndarray\n",
    "            Input features.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        probabilities = self.forward(X)[-1]\n",
    "        return np.argmax(probabilities, axis=1).reshape(-1,1)\n",
    "   \n",
    "    \n",
    "    def one_hot_encoding(self, Y_true):\n",
    "        \"\"\"\n",
    "        Converts class labels into one-hot encoded vectors.\n",
    "\n",
    "        Parameters:\n",
    "        Y_true : numpy.ndarray\n",
    "            Class labels.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray\n",
    "            One-hot encoded labels.\n",
    "        \"\"\"\n",
    "        num_classes = np.max(Y_true) + 1\n",
    "        one_hot = np.zeros((Y_true.shape[0], num_classes))\n",
    "        for i in range(Y_true.shape[0]):\n",
    "            one_hot[i, Y_true[i]] = 1\n",
    "        return one_hot    \n",
    "    \n",
    "    def backward_classification(self, X, Y_true):\n",
    "        \"\"\"\n",
    "        Computes gradients using backpropagation for classification tasks.\n",
    "\n",
    "        This implementation assumes that the output layer uses the softmax activation function\n",
    "        and the loss function is cross-entropy. In this case, the derivative simplifies to \n",
    "        (softmax_output - one_hot_encoded_labels), which is used directly for the output layer gradient.\n",
    "\n",
    "        Parameters:\n",
    "        X : numpy.ndarray\n",
    "            Input features.\n",
    "        Y_true : numpy.ndarray\n",
    "            One-hot encoded true labels.\n",
    "\n",
    "        Returns:\n",
    "        list\n",
    "            Gradients of weights for each layer.\n",
    "        list\n",
    "            Gradients of biases for each layer.\n",
    "        \"\"\"\n",
    "        weights_backprop = []\n",
    "        biases_backprop =[]\n",
    "        activations = self.forward(X)\n",
    "        n = len(Y_true)\n",
    "#         if self.output_activation == 'softmax':\n",
    "        delta = (activations[-1] - Y_true)\n",
    "#         else:\n",
    "#             error = -Y_true/activations[-1] \n",
    "#             delta = error * self.output_derivative(activations[-2] @ self.weights[-1] + self.biases[-1])\n",
    "        last_gradient_descent = activations[-2].T @ delta\n",
    "        weights_backprop.insert(0, last_gradient_descent)\n",
    "        biases_backprop.insert(0, np.sum(delta, axis=0, keepdims=True))\n",
    "        for i in range(len(self.weights) -2, -1, -1):\n",
    "            delta = (delta @ self.weights[i+1].T) * self.hidden_derivative(activations[i] @ self.weights[i] + self.biases[i])\n",
    "            gradient = activations[i].T @ delta\n",
    "            weights_backprop.insert(0, gradient)\n",
    "            biases_backprop.insert(0,  np.sum(delta, axis=0, keepdims=True))\n",
    "        \n",
    "        return weights_backprop, biases_backprop\n",
    "    \n",
    "    \n",
    "    def classifiaction_train(self, X, Y_true, epochs, learning_rate, batch_size):\n",
    "        \"\"\"\n",
    "        Trains the model for classification using mini-batch gradient descent.\n",
    "\n",
    "        Parameters:\n",
    "        X : numpy.ndarray\n",
    "            Input features.\n",
    "        Y_true : numpy.ndarray\n",
    "            True class labels.\n",
    "        epochs : int\n",
    "            Number of training epochs.\n",
    "        learning_rate : float\n",
    "            Learning rate for gradient descent.\n",
    "        batch_size : int\n",
    "            Size of the mini-batch.\n",
    "        \"\"\"\n",
    "        Y = Y_true\n",
    "        Y_true = self.one_hot_encoding(Y_true)\n",
    "        n_samples = X.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            shuffle_idx = np.random.permutation(n_samples)\n",
    "            X_shuffled = X[shuffle_idx]\n",
    "            Y_shuffled = Y_true[shuffle_idx]            \n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                X_batch = X_shuffled[i:i+batch_size]\n",
    "                Y_batch = Y_shuffled[i:i+batch_size]\n",
    "                w, b = self.backward_classification(X_batch, Y_batch)\n",
    "                for l in range(len(self.weights)):\n",
    "                    new_weight = self.weights[l] - learning_rate * w[l]\n",
    "                    new_bias = self.biases[l] - learning_rate * b[l]\n",
    "                    self.set_weights_and_biases(l, new_weight, new_bias)\n",
    "            if epoch % 10 == 0:\n",
    "                loss = self.f1_score(Y, self.predict_classification(X))\n",
    "                print(f\"Epoka {epoch}: Loss = {loss:.9f}\")     \n",
    "\n",
    "    \n",
    "    def cross_entropy_loss(self, y_true, y_pred):\n",
    "        return -np.sum(y_true * np.log(y_pred + 1e-9)) / y_true.shape[0]\n",
    "    \n",
    "    \n",
    "    def f1_score(self, y_true, y_pred):\n",
    "        unique_classes = np.unique(y_true)\n",
    "        f1_scores =[]\n",
    "        for cls in unique_classes:\n",
    "            tp = np.sum((y_pred == cls)&(y_true==cls))\n",
    "            fp = np.sum((y_pred == cls)& (y_true!=cls))\n",
    "            fn = np.sum((y_pred != cls)& (y_true == cls))\n",
    "            \n",
    "            precision = tp / (tp+fp) if (tp+fp) > 0 else 0\n",
    "            recall = tp/(tp+fn) if (tp+fn)>0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            f1_scores.append(f1)\n",
    "        return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd93b98",
   "metadata": {},
   "source": [
    "## Loading csv fiels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05ade9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepsL_train = pd.read_csv('steps-large-training.csv')\n",
    "stepsL_test = pd.read_csv('steps-large-test.csv')\n",
    "squareS_train = pd.read_csv('square-simple-training.csv')\n",
    "squareS_test = pd.read_csv('square-simple-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5ca005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.481354</td>\n",
       "      <td>-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.033264</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.076403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.419785</td>\n",
       "      <td>-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.108398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         x   y\n",
       "0           1 -1.481354 -80\n",
       "1           2  1.033264  80\n",
       "2           3 -0.076403   0\n",
       "3           4 -1.419785 -80\n",
       "4           5 -0.108398   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepsL_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ca7cc",
   "metadata": {},
   "source": [
    "## splitting data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb6c621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stepsL_train = np.array(stepsL_train[['x']])\n",
    "Y_stepsL_train = np.array(stepsL_train[['y']])\n",
    "X_stepsL_test = np.array(stepsL_test[['x']])\n",
    "Y_stepsL_test = np.array(stepsL_test[['y']])\n",
    "X_squareS_train = np.array(squareS_train[['x']])\n",
    "Y_squareS_train = np.array(squareS_train[['y']])\n",
    "X_squareS_test = np.array(squareS_test[['x']])\n",
    "Y_squareS_test = np.array(squareS_test[['y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d3deb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4813543 ],\n",
       "       [ 1.03326405],\n",
       "       [-0.07640313],\n",
       "       ...,\n",
       "       [ 0.81091671],\n",
       "       [ 0.64431837],\n",
       "       [ 0.72881634]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_stepsL_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9a956",
   "metadata": {},
   "source": [
    "## Steps dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9a7aff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_stepsL_train,  Y_stepsL_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5105c",
   "metadata": {},
   "source": [
    "## Squares dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e0dabe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_squareS_train, Y_squareS_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fe568",
   "metadata": {},
   "source": [
    "## MLP for steps dataset (one hidden layer with 10 neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948169d9",
   "metadata": {},
   "source": [
    "### first attempt with random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00ff7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_steps = MLPNoBackprop(layer_sizes = [1, 10, 1])\n",
    "y_stepsL_pred = mlp_steps.predict(X_stepsL_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "683f1113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7100.4523024504215\n"
     ]
    }
   ],
   "source": [
    "mse_error_steps1 = mlp_steps.mse(Y_stepsL_train, y_stepsL_pred)\n",
    "print(mse_error_steps1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b690d5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.83207528]\n",
      " [4.00019317]\n",
      " [3.01619731]\n",
      " ...\n",
      " [3.8155419 ]\n",
      " [3.67163045]\n",
      " [3.74516189]]\n"
     ]
    }
   ],
   "source": [
    "print(y_stepsL_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05821e2",
   "metadata": {},
   "source": [
    "### manually setting weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1441fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13f1c76a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6ab39940ec449cb43f72a991787c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=10.0, description='W_0_0', max=600.0, min=-600.0), FloatSlider(value=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_plot(W_0_0, W_0_1, W_0_2, W_0_3, W_0_4, W_0_5, W_0_6, W_0_7, W_0_8, W_0_9,\n",
    "                b_0_0, b_0_1, b_0_2, b_0_3, b_0_4, b_0_5, b_0_6, b_0_7, b_0_8, b_0_9,\n",
    "                W_1_0, W_1_1, W_1_2, W_1_3, W_1_4, W_1_5, W_1_6, W_1_7, W_1_8, W_1_9,\n",
    "                b_1):\n",
    "    W_0 = np.array([[W_0_0, W_0_1, W_0_2, W_0_3, W_0_4, W_0_5, W_0_6, W_0_7, W_0_8, W_0_9]])\n",
    "    b_0 = np.array([b_0_0, b_0_1, b_0_2, b_0_3, b_0_4, b_0_5, b_0_6, b_0_7, b_0_8, b_0_9])\n",
    "    W_1 = np.array([[W_1_0], [W_1_1], [W_1_2], [W_1_3], [W_1_4], [W_1_5], [W_1_6], [W_1_7], [W_1_8], [W_1_9]])\n",
    "    b_1 = np.array([b_1])\n",
    "\n",
    "    mlp_steps.set_weights_and_biases(0, W_0, b_0)\n",
    "    mlp_steps.set_weights_and_biases(1, W_1, b_1)\n",
    "\n",
    "\n",
    "    y_stepsL_pred = mlp_steps.predict(X_stepsL_train)\n",
    "    mse_value = mlp_steps.mse(Y_stepsL_train, y_stepsL_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(X_stepsL_train, Y_stepsL_train, label='True Data', color='blue', alpha=0.5)\n",
    "    plt.scatter(X_stepsL_train, y_stepsL_pred, label=f'Predicted Data (MSE: {mse_value:.4f})', color='red')\n",
    "    plt.legend()\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Interactive MLP Regression')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "widgets_list = [\n",
    "    widgets.FloatSlider(value=10, min=-600, max=600, step=0.1, description=f'W_0_{i}') for i in range(10)\n",
    "] + [\n",
    "    widgets.FloatSlider(value=0, min=-600, max=600, step=0.1, description=f'b_0_{i}') for i in range(10)\n",
    "] + [\n",
    "    widgets.FloatSlider(value=-10, min=-600, max=600, step=0.1, description=f'W_1_{i}') for i in range(10)\n",
    "] + [\n",
    "    widgets.FloatSlider(value=0, min=-600, max=600, step=0.1, description=f'b_1')\n",
    "]\n",
    "\n",
    "interactive_plot = interactive(update_plot, **{f'W_0_{i}': widgets_list[i] for i in range(10)} |\n",
    "                                              {f'b_0_{i}': widgets_list[i+10] for i in range(10)} |\n",
    "                                              {f'W_1_{i}': widgets_list[i+20] for i in range(10)} |\n",
    "                                              {'b_1': widgets_list[30]})\n",
    "\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c10d2e",
   "metadata": {},
   "source": [
    "## weights from sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8691d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.527777568129963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_22808\\3951724984.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "W_0 = np.array([[300.3,501.1,472.5,600.0,500.1,399.9,403.6,463.9,500.0,500.0]])\n",
    "b_0 = np.array([150.0,-250.5,-506.5,-306.1,-375.3,-600.0,-303.1,-346.5,-530.0,-536.1])\n",
    "mlp_steps.set_weights_and_biases(0, W_0, b_0)\n",
    "\n",
    "W_1 = np.array([[83.8],[85.7],[-25.9],[-10.4],[-33.6],[77.0],[25.8],[11.0],[-0.3],[28.2]])\n",
    "b_1 = np.array([-82.0])\n",
    "mlp_steps.set_weights_and_biases(1, W_1, b_1)\n",
    "\n",
    "y_stepsL_pred =mlp_steps.predict(X_stepsL_train)\n",
    "mse_value = mlp_steps.mse(Y_stepsL_train, y_stepsL_pred)\n",
    "print(mse_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb46ce6",
   "metadata": {},
   "source": [
    "## mse on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baea0692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.507656780160088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_22808\\3951724984.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "y_stepsL_pred =mlp_steps.predict(X_stepsL_test)\n",
    "mse_value = mlp_steps.mse(Y_stepsL_test, y_stepsL_pred)\n",
    "print(mse_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4db03c",
   "metadata": {},
   "source": [
    "# MLP for squares dataset(one hidden layer with 5 neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a3b9e",
   "metadata": {},
   "source": [
    "## random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "329412b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp_square= MLPNoBackprop(layer_sizes = [1,5,1], hidden_activation='relu')\n",
    "y_squareS_pred = mlp_square.predict(X_squareS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da22cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10044.097081377582\n"
     ]
    }
   ],
   "source": [
    "mse_error_square1 = mlp_square.mse(Y_squareS_train, y_squareS_pred)\n",
    "print(mse_error_square1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d88b1",
   "metadata": {},
   "source": [
    "## silders for weights and biases manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0da1bf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(over='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd9f77d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7f6084138a432f91160fb5070a850b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=10.0, description='W_0_0', max=600.0, min=-600.0), FloatSlider(value=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_plot(W_0_0, W_0_1, W_0_2, W_0_3, W_0_4,\n",
    "                b_0_0, b_0_1, b_0_2, b_0_3, b_0_4,\n",
    "                W_1_0, W_1_1, W_1_2, W_1_3, W_1_4,\n",
    "                b_1):\n",
    "\n",
    "    W_0 = np.array([[W_0_0, W_0_1, W_0_2, W_0_3, W_0_4]])\n",
    "    b_0 = np.array([b_0_0, b_0_1, b_0_2, b_0_3, b_0_4])\n",
    "    W_1 = np.array([[W_1_0], [W_1_1], [W_1_2], [W_1_3], [W_1_4]])\n",
    "    b_1 = np.array([b_1])\n",
    "\n",
    "   \n",
    "    mlp_square.set_weights_and_biases(0, W_0, b_0)\n",
    "    mlp_square.set_weights_and_biases(1, W_1, b_1)\n",
    "\n",
    "\n",
    "    y_squareS_pred = mlp_square.predict(X_squareS_train)\n",
    "    mse_value = mlp_square.mse(Y_squareS_train, y_squareS_pred)\n",
    "\n",
    "   \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(X_squareS_train, Y_squareS_train, label='True Data', color='blue', alpha=0.5)\n",
    "    plt.scatter(X_squareS_train, y_squareS_pred, label=f'Predicted Data (MSE: {mse_value:.4f})', color='red')\n",
    "    plt.legend()\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Interactive MLP Regression for Square')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "widgets_list = [\n",
    "    widgets.FloatSlider(value=10, min=-600, max=600, step=0.1, description=f'W_0_{i}') for i in range(5)\n",
    "] + [\n",
    "    widgets.FloatSlider(value=0, min=-600, max=600, step=0.1, description=f'b_0_{i}') for i in range(5)\n",
    "] + [\n",
    "    widgets.FloatSlider(value=-10, min=-600, max=600, step=0.1, description=f'W_1_{i}') for i in range(5)\n",
    "] + [\n",
    "    widgets.FloatSlider(value=0, min=-600, max=600, step=0.1, description='b_1')\n",
    "]\n",
    "\n",
    "\n",
    "interactive_plot = interactive(update_plot, **{f'W_0_{i}': widgets_list[i] for i in range(5)} |\n",
    "                                              {f'b_0_{i}': widgets_list[i+5] for i in range(5)} |\n",
    "                                              {f'W_1_{i}': widgets_list[i+10] for i in range(5)} |\n",
    "                                              {'b_1': widgets_list[15]})\n",
    "\n",
    "interactive_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "defd52e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479.7992090448728\n"
     ]
    }
   ],
   "source": [
    "W_0 = np.array([[297,41,-204,9.9,-121]])\n",
    "b_0 = np.array([30, 0.02, -97.8, 0.3,13])\n",
    "mlp_square.set_weights_and_biases(0, W_0, b_0)\n",
    "\n",
    "W_1 = np.array([[0.11],[64.14],[0.96],[-251.3],[-0.13]])\n",
    "b_1 = np.array([-113])\n",
    "mlp_square.set_weights_and_biases(1, W_1, b_1)\n",
    "\n",
    "y_squareS_pred =mlp_square.predict(X_squareS_train)\n",
    "mse_value = mlp_square.mse(Y_squareS_train, y_squareS_pred)\n",
    "print(mse_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc29d7f",
   "metadata": {},
   "source": [
    "### now on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "326f2d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415.87483547679824\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp_square.predict(X_squareS_test)\n",
    "mse = mlp_square.mse(Y_squareS_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96fcbc9",
   "metadata": {},
   "source": [
    "# ------------------------------------------NN2------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58bbb9",
   "metadata": {},
   "source": [
    "Now we are working on this datastets: square-simple, steps-small, multimodal-large  \n",
    "I have to implement backpropagation  \n",
    "The squares set has already been loaded  \n",
    "X_squareS_train = np.array(squareS_train[['x']])  \n",
    "Y_squareS_train = np.array(squareS_train[['y']])  \n",
    "X_squareS_test = np.array(squareS_test[['x']])  \n",
    "Y_squareS_test = np.array(squareS_test[['y']])  \n",
    "  \n",
    "Let's load steps and multimodal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8497f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepsS_train = pd.read_csv('steps-small-training.csv')\n",
    "stepsS_test = pd.read_csv('steps-small-test.csv')\n",
    "multimodalL_train = pd.read_csv('multimodal-large-training.csv')\n",
    "multimodalL_test = pd.read_csv('multimodal-large-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12fe75",
   "metadata": {},
   "source": [
    "### spliting into target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb6f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stepsS_train = np.array(stepsS_train[['x']])\n",
    "Y_stepsS_train = np.array(stepsS_train[['y']])\n",
    "X_stepsS_test = np.array(stepsS_test[['x']])\n",
    "Y_stepsS_test = np.array(stepsS_test[['y']])\n",
    "X_multimodalL_train = np.array(multimodalL_train[['x']])\n",
    "Y_multimodalL_train = np.array(multimodalL_train[['y']])\n",
    "X_multimodalL_test = np.array(multimodalL_test[['x']])\n",
    "Y_multimodalL_test = np.array(multimodalL_test[['y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a695d2",
   "metadata": {},
   "source": [
    "### now lets normalize our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0988e083",
   "metadata": {},
   "source": [
    "#### squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27fc9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_squareS_train_normalized = (X_squareS_train- np.mean(X_squareS_train))/(np.std(X_squareS_train))\n",
    "Y_squareS_train_normalized = (Y_squareS_train- np.mean(Y_squareS_train))/(np.std(Y_squareS_train))\n",
    "X_squareS_test_normalized = (X_squareS_test- np.mean(X_squareS_train))/(np.std(X_squareS_train))\n",
    "Y_squareS_test_normalized = (Y_squareS_test- np.mean(Y_squareS_train))/(np.std(Y_squareS_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41812972",
   "metadata": {},
   "source": [
    "#### steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0424efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stepsS_train_normalized = (X_stepsS_train- np.mean(X_stepsS_train))/(np.std(X_stepsS_train))\n",
    "Y_stepsS_train_normalized = (Y_stepsS_train- np.mean(Y_stepsS_train))/(np.std(Y_stepsS_train))\n",
    "X_stepsS_test_normalized = (X_stepsS_test- np.mean(X_stepsS_train))/(np.std(X_stepsS_train))\n",
    "Y_stepsS_test_normalized = (Y_stepsS_test- np.mean(Y_stepsS_train))/(np.std(Y_stepsS_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae98544",
   "metadata": {},
   "source": [
    "### multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5e58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multimodalL_train_normalized = (X_multimodalL_train- np.mean(X_multimodalL_train))/(np.std(X_multimodalL_train))\n",
    "Y_multimodalL_train_normalized = (Y_multimodalL_train- np.mean(Y_multimodalL_train))/(np.std(Y_multimodalL_train))\n",
    "X_multimodalL_test_normalized = (X_multimodalL_test- np.mean(X_multimodalL_train))/(np.std(X_multimodalL_train))\n",
    "Y_multimodalL_test_normalized = (Y_multimodalL_test- np.mean(Y_multimodalL_train))/(np.std(Y_multimodalL_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b82b74",
   "metadata": {},
   "source": [
    "# MLP FOR SQUARES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d03aa5",
   "metadata": {},
   "source": [
    "## SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9db349c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wykonania: 387.783271 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_squares = MLPNoBackprop(layer_sizes = [1, 5, 5, 1])\n",
    "start_time = time.time()\n",
    "mlp_squares.SGD(X_squareS_train_normalized, Y_squareS_train_normalized, 10000, 0.05)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "335ace79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08657051246166983\n"
     ]
    }
   ],
   "source": [
    "Ypred_normalized = mlp_squares.predict(X_squareS_test_normalized)\n",
    "Ypred = (Ypred_normalized * np.std(Y_squareS_train)) + np.mean(Y_squareS_train)\n",
    "print(mlp_squares.mse(Ypred, Y_squareS_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706dfbc",
   "metadata": {},
   "source": [
    "## mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4806d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wykonania: 68.477309 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_squares2 = MLPNoBackprop(layer_sizes = [1, 5, 5, 1])\n",
    "start_time = time.time()\n",
    "mlp_squares2.mini_batch_GD(X_squareS_train_normalized, Y_squareS_train_normalized, 5, 10000, 0.05)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dc646a21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2430205529022203\n"
     ]
    }
   ],
   "source": [
    "Ypred_normalized2 = mlp_squares2.predict(X_squareS_test_normalized)\n",
    "Ypred2 = (Ypred_normalized2 * np.std(Y_squareS_train)) + np.mean(Y_squareS_train)\n",
    "print(mlp_squares2.mse(Ypred2, Y_squareS_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4957da",
   "metadata": {},
   "source": [
    "### lepszy wynik dla SGD ale dużo dłuższy czas wykonywania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b9746",
   "metadata": {},
   "source": [
    "# MLP FOR STEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e95b95",
   "metadata": {},
   "source": [
    "## SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d8211a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wykonania: 393.438124 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_steps = MLPNoBackprop(layer_sizes = [1, 10, 10, 1], weights_initialize_function ='uniform')\n",
    "start_time = time.time()\n",
    "mlp_steps.SGD(X_stepsS_train_normalized, Y_stepsS_train_normalized, 55000, 0.015)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "36dd1bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.560564624776615\n"
     ]
    }
   ],
   "source": [
    "Ypred_normalized = mlp_steps.predict(X_stepsS_train_normalized)\n",
    "Ypred = (Ypred_normalized * np.std(Y_stepsS_train)) + np.mean(Y_stepsS_train)\n",
    "mse_value = mlp_steps.mse(Ypred, Y_stepsS_train)\n",
    "print(mse_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d26816d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_stepsS_train, Y_stepsS_train, label='True Data', color='blue', alpha=0.5)\n",
    "plt.scatter(X_stepsS_train, Ypred, label=f'Predicted Data (MSE: {mse_value:.4f})', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Interactive MLP Regression for Square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dfa7fe",
   "metadata": {},
   "source": [
    "## mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "be137d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wykonania: 62.462466 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_steps2 = MLPNoBackprop(layer_sizes = [1, 10, 10, 1])\n",
    "start_time = time.time()\n",
    "mlp_steps2.mini_batch_GD(X_stepsS_train_normalized, Y_stepsS_train_normalized, 4, 52000, 0.06)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bb401967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5753910567929217\n"
     ]
    }
   ],
   "source": [
    "Ypred_normalized2 = mlp_steps2.predict(X_stepsS_train_normalized)\n",
    "Ypred2 = (Ypred_normalized2 * np.std(Y_stepsS_train)) + np.mean(Y_stepsS_train)\n",
    "mse_value = mlp_steps2.mse(Ypred2, Y_stepsS_train)\n",
    "print(mse_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3ae6979d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_stepsS_train, Y_stepsS_train, label='True Data', color='blue', alpha=0.5)\n",
    "plt.scatter(X_stepsS_train, Ypred2, label=f'Predicted Data (MSE: {mse_value:.4f})', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Interactive MLP Regression for Square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c50d4",
   "metadata": {},
   "source": [
    "# MLP FOR MULTIMODAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b57e21bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_multimodalL_train, Y_multimodalL_train, label='True Data', color='blue', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Interactive MLP Regression for Square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "95f06d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wykonania: 44460.318400 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_multimodal = MLPNoBackprop(layer_sizes = [1, 26, 1], hidden_activation='tanh')\n",
    "start_time = time.time()\n",
    "mlp_multimodal.SGD(X_multimodalL_train_normalized, Y_multimodalL_train_normalized, 100, 0.01)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "68c53924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.56316593008948\n"
     ]
    }
   ],
   "source": [
    "Ypred_normalized = mlp_multimodal.predict(X_multimodalL_test_normalized)\n",
    "Ypred = (Ypred_normalized * np.std(Y_multimodalL_train)) + np.mean(Y_multimodalL_train)\n",
    "print(mlp_steps.mse(Ypred, Y_multimodalL_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "516511fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFNCAYAAAAKBrb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABlkUlEQVR4nO3deXxU1fn48c+TnbBENpXFJLZaZQuIuP3auoFad0Vsa8etapFQW6rit1pq1Wq6SlvUBqFWqzLVWkqtVbQKarVWW8FCVKhLJYRNxABhCZBlnt8fdxKy3DszSWaf5/16zSuZe+/cOTOTzHPPOc85R1QVY4wxxqS/rEQXwBhjjDHxYUHfGGOMyRAW9I0xxpgMYUHfGGOMyRAW9I0xxpgMYUHfGGOMyRAW9I2JIhF5V0ROTnQ5MpmI3C8it8bgvCIiD4nINhH5d7TPb0w8WNA3SUdEqkVkUoTHviwi18S6TB7P/TsRuavtNlUdpaovR/l5SkVEReStDtsHiUiDiFS32eb63onIySISEJFdIrJTRN4Tka97PF/ExyYjVZ2mqnfG4NRfAE4DhqvqsdE4oYhcLSL/Db7Pm0XkGRHpG41zG+PGgr7JaCKSnegydEFvERnd5v7XgDVdePxGVe0D9AO+C/xGREZGcOz1wWOP6E6hQxGRnGifM4ZKgGpV3d3VB7q9ThE5CfgRcImq9gVGAE/0uJRRKJtJXxb0TVITkStF5B8icnewWXWNiJwZ3FcBfBG4L1grvS+4/UgReUFEtgZrqV9uc77fichcEVksIruBU0TkbBH5j4jsEJF1InJ7hzJ8QUT+KSLbg/uvFJGpgA/4v+Bz/zV4bLWITBKRoSKyR0QGtDnPUSLyqYjkBu9fJSKrg6/rbyJSEubteBS4os39y4FHuvqequNJYBvgFfTbHrsY2AqUBcudJSI3i8j/RKRWRJ7o8DovF5G1wX23tm19EJHbRWShiCwQkR3AlSJSJCK/FZFNIrJBRO5quRgTkcNE5O8iUhd87/4Q3C4i8ksR+SS4r6rlgqhjC4yIfENEPgz+PTwlIkPb7FMRmSYiHwQ/h1+LiHR8H0TkauAB4ITg531HhOf+poh8AHzg8vYeA7yuqv8JvtdbVfVhVd0ZfPzA4Dl3iMi/ReROEflHcF9L609Om+drbfUSkc+KyIvBz+BTEfGLyAFtjq0Wke+KSBWwW0RyROT4Nn/nK8W6qdKTqtrNbkl1A6qBScHfrwQagW8A2UA5sBGQ4P6XgWvaPLY3sA74OpADjAc+BUYF9/8OqAM+j3PRWwCcDIwJ3i8DNgMXBI8vBnYClwC5wEBgXJtz3RWi7C8C32iz7+fA/cHfLwA+xKnd5QDfB/7p8X6UAhr8uS74PowA3gMm4dQ+Oz1/h3OcDKwP/p4FXBh8X4+I4NjzgABwVHDbd4A3gOFAPjAPeCy4bySwC6cpPA+4O/g8Le/J7cH7FwTP3Qt4MniO3sCBwL+Ba4PHPwbMavNZfSG4/QxgOXAAIMH3Y0jHzwU4FefzHx8s673AK21eqwJPB89TDGwBvuTxOVwJ/KPN/UjO/QIwAOjlcr4vAnuAO3D+HvM77H8cp+bfGxgNbGh5/jZ/Ezltjn+Z4P8CcBhOV0Q+MBh4BfhVh7+TFcAhwc9gGFALnBV8r08L3h+c6O8Du0X3ZjV9kwrWqupvVLUZeBgYAhzkcew5OEHwIVVtUtW3gD8BU9oc8xdVfU1VA6q6V1VfVtW3g/ercALNScFjfcASVX1MVRtVtVZVV0RY7t/jXCwQrD1+NbgN4Frgx6q6WlWbcJp5x4Wp7a9nf6C/gq7X8oeKyHacQHUbcJmqvhfm2D3An4EbNFgjDZZ9lqquV9V9OIF8SrDWOQX4q6r+Q1UbgB/gBKe2XlfVJ1U1gNN9cCbwHVXdraqfAL/Eea/AuUAoAYYGP6t/tNneFzgS5wJwtapucnkdPuBBVX0rWNZbcGrrpW2O+YmqblfVGuAlYJzHe9Kdc/9YnRr8no4PVtVXgck4Fw3PALUi8gsRyQ62dFwE/CD4vryD87cfEVX9UFVfUNV9qroF+AX7/6Zb3KOq64JluxRYrKqLg/8HLwDLcC4CTBqxoG9Swcctv6hqffDXPh7HlgDHBZsotwcDlw84uM0x69o+QESOE5GXRGSLiNQB04BBwd2HAP/rZrkX4gSBocCJOMHv1TblnNOmjFtxaqzDwpzzEZwa5yXAgi6WZ6OqHqCqA1R1nKo+Hu5YnKB8D06ttkUJ8Oc2ZV8NNONciA2lzfsb/LxqO5y77ftfgtOCsqnN+ebh1PgB/g/nffm3OCMjrgqe90XgPuDXwGYRmS8i/Vxex1BgbZvy7AqWp+37/HGb3+vx/tvqzrnXdXxQW6r6rKqei9MacD7OZ3sNTu08p8Pj13Y6gQcROVBEHg92l+zA+VsZ1OGwjp/DxR3+b76Ac4Ft0ogFfZPqOtYi1wF/Dwa3llsfVS0P8ZjfA08Bh6hqEXA/TqBpOd9nI3zu9jtVtwPPA1/GSbp7TFVbHrMOpwm7bTl7qeo/Q50Tp9XibOAjVY04CHRXsAb7XWCMiFwQ3LwOOLND2QtUdQOwCafZHwAR6YXTJdLutG1+XwfsAwa1OVc/VR0VfP6PVfUbqjoUp4WhUkQOC+67R1WPBkYBnwNucnkJG3ECWkt5egfLs6Fbb0jXzx3RMqbB2vVSnC6h0TjdDE04F50titv83pJMWNhmW9sL2x8Hn7tMVfvh1OQ75ip0/Bwe7fCZ9lbVn0RSfpM6LOibVLcZ+Eyb+08DnxORy0QkN3g7RkRGhDhHX2Crqu4VkWNxAnQLPzBJRL4cTHYaKCLjPJ7bze9xEu4uYn/TPjgXFreIyCiAYDLbxWHOhTqZ46fi1Aa95IpIQZtbj7Kzg830s3Ga6lvKXtHSFSEig0Xk/OC+hcC5IvL/RCQPp7+6U2Jcm3Nvwrkwmi0i/cRJEvysOJntiMjFItJyEbENJ1A1Bz/T48RJitwN7MVpbejo98DXRWSciOTjdKP8S1Wru/l2RO3cInK+iHxVRPqL41icJvg3gl1Zi4DbRaRQnFEWrUmcwSb7DcClwe6Aq2h/cdoXJ7diu4gMw/2CqK0FOJ/bGcHzFYgzdHN4mMeZFGNB36S6OTj9ydtE5B51Mp9Px+kT3ojTdPtTnIQmL9OBH4rITpzA1jpsKtjPexZwI04T/ApgbHD3b4GRwebQJz3O/RRwOLBZVVe2Oe+fg+V6PNj8+g5O33ZYqrpMVUN1OSzG6Ytvud0eyXnDeBAoFpFzcd7zp4Dng+/ZG8BxwbK9C3wLJwltE04S5Cc4tXkvl+Mk/a3CCewL2d+sfAzwLxHZFXzOGaq6Bqfb4TfB49fiNKvf3fHEwdrzrTgtJJtwAuNXOx7XHVE49zacBNUPgJYm+J+rqj+4/zqcroaPcZITH+rw+G/gBPNanNaOtq1Ed+DkCtTh5AssCvNa1uF0L3wPp5VhXfDcFiPSTEsGtDHGRJ2I9AG2A4cHg7XpJhG5Eic7/wuJLotJXXYVZ4yJKhE5N9gk3Run9v02zhAxY0yCWdA3xkTb+ThdKxtxuja+qtakaExSsOZ9Y4wxJkNYTd8YY4zJEBb0jTHGmAyR9qsrDRo0SEtLSxNdDGOMMSYuli9f/qmqDnbbl/ZBv7S0lGXLliW6GMYYY0xciIjnbJ3WvG+MMcZkCAv6xhhjTIawoG+MMcZkCAv6xhhjTIawoG+MMcZkCAv6xhhjTIawoG+MMcZkCAv6kfL7obQUsrKcn35/uEcYY4wxSSXtJ+eJCr8frrgCmpud+2vXOvcBfL7ElcsYY4zpAqvpR+Laa/cH/BbNzc52Y4wxJkVY0I/E7t1d226MMcYkIQv6PWV9+8YYY1KEBf2emjEj0SUwxhhjImJBv6dqaxNdAmOMMSYiFvQjMXBgoktgjDHG9JgF/UjMmeO9r6AgfuUwxhhjesCCfiR8Pujd233f3r2WzGeMMSYlWNCPVH29975Zs+JXDmOMMaabLOhHqrjYe9/atfErhzHGGNNNFvQjVVHhvS87O37lMMYYY7rJgn6kQs2x33GKXmOMMSYJWdDvipIS733Tp8evHMYYY0w3WNDvilBN/PPnx68cxhhjTDdY0O8Ka+I3xpj0Mn06ZGWBSOhb375pMTw7J9EFMMYYYxJi2DDYuDGyY3ftgksvhddeg8rK2JYrhqymb4wxJvNMmhR5wG9r7tyUrvVb0O+qUMPzUvSPwBhjMsr06bB0afcf31LrHzYsemWKEwv6XRWq795m5jPGmOQ2aZJTW4+GjRuhf//onCtOLOh3VahhezU18SuHMcaYrvH7e1bDd7N9e0rV+C3od1WoYXsDBsSvHMaY1OT3w6BBaZ8lnpSuvTY259240fnsUuBzs6DfVT4f9OmT6FIYY1JNy9CwSy+F2lrv41r6i0VSqgaZ9Px+2L079DETJ4Lq/tvEiV17jksvdboPkpgF/e7w+sMJ9Y9sjMlc06c7/ciqXXtcSw1y1KjYlKstv99pZQg1Vr1Pn5SozbqaMSP0/vJyWLKk/bYlS7oe/JcuTeoZWhMa9EXkQRH5RETeabNtgIi8ICIfBH/2b7PvFhH5UETeE5Ez4lnWyy93EvdFoFrdV9wLIMw5zk9VVTxLZoxJevPm9ejhumoVKsI6Gdb6PRTJLSuLTscXFsKNN7Y5+fTpzo5LL3VaGULZvTs1s9b9fjREpayePGRuZbv3rbAQcnOD79vSJdxHOQEgkss2nTs3os+nb1+YPTtqrzIyqpqwG3AiMB54p822nwE3B3+/Gfhp8PeRwEogHzgU+B+QHe45jj76aO2pyy5r296jegkLtBlpvzF4W0NJ6928PNW77+7x0xtjUll5uet3RXdugTa33eTrJSzo9ulWMLL1XN06wciRiX5nQ7r7btVBg1RFVNdQEvI97cr7WM3QsO9ZAHQFIyM6n4jqDTdE97UDy9Qr7nrtiNcNKO0Q9N8DhgR/HwK8F/z9FuCWNsf9DTgh3PmjEfTz8zt/UM0en2Az0mnzZZf1uAjGmFQ0cmT3AmoXLwLq6B1R4LqXcm0iq2fBvu0tSXWsqHlV0gKg91Le5ZddR6+IAn81QyM6X16e6sqV0Xv9oYJ+MvbpH6SqmwCCPw8Mbh8GrGtz3PrgtphraOi8rYYS12Nr6ZzB/+ijCWjCMcYk1vTpsGpVyEO0za07JHjrx278XEoAIYCwj1wuwc9zTGrdFkD4JnPJJtD6uB5Lwmb+2bOd79wW9zId8XiHP2Ug36LrU+oWUU8NQ0N+bgIUs5HqCMJUQ0PsBhZ0lIxB34vb36jrey4iU0VkmYgs27JlS4+fOC+v87bvUcE+Ou8oYhuX0DnR5Uc/wvr6jckkYSaAUeDXlJOF8mvKaQ6Gpp5eAAiQRxN+LuV0lrbbHpVA39bGjUmVrb5wIXz/+/vvP8ckvslc19e9m0JmMKfbz1XKhogD/72ET+z717+c8secVxNAvG6kQPN+x6ai/U08vV13fMJA1+MnTepxUYwxqWDixJDNv6H6kS9hgTYg0Wl+7+Yt0OGWCs38K1eqHnRQ+/fRq+xd7ccPdfuEAyJq6o+kGyEK4UpVNeWa958Crgj+fgXwlzbbvyoi+SJyKHA48O94FOiRR+Cyy5yMzrb64j50bxDuWaJLl1ozvzGZQJcu9axVt9TwH8N9qe7H8JFHAB8LaGxT++9uC0BXKBBgfwtEFsrzTIzLc/fUnXfC5s377/+IWSFbNv6Q5ev0nd5CBHr1gpwI1qE9kG1UMTJsjf+bzA1b43///fDP11PiXBQkhog8BpwMDAI2A7cBTwJPAMVADXCxqm4NHj8LuApoAr6jqs+Ge44JEybosmXLYlF85y/DhQJZHn8CAwfCp5/GpjjGmCTg96OXXuoZcAJAdpvvh6wsCATCn/al3Emc1Oh9MdETLRcVlZS79nFXM4xiNno/d3l5wpeb7dOn/RQqAcS7vNnZ0NQU3QJkZTkV9lBEWPhEgIsv7rwrN9fpSg43ajISIrJcVSe4FrPnp+8+Vb1EVYeoaq6qDlfV36pqrapOVNXDgz+3tjm+QlU/q6pHRBLwY27gQM9dHfv1W8Z+bt1qffvGpLOGm7xrmC2BFZy4M2kS/Oc/kTUkn9ywxMlB7+osceH07o0sWECWKieurGTaNBgypP0hpWygmRArjM6fH90ydVFVFdTX778ftg996tToF6Jt9qAXVaa8OJ3Bg527LXGhJW+sZXtMebX7p8stGn36nhYs8PwfrW4zXh+csZigmpWletttsSuSMSaxQvXvNoOC6ogRqn/8Yw+fqFevnnVGZ2c732EeVq5UnTJl/+Hh+sgTqW05QbXJY4hezHMQJk6M6L1/aWS5Dh2q2qePMyS8Tx/VoUNVp02LTjFIsT791OFz75MDOIT9K+6J7G/16dULVqyIcbmMMQlR82M/6lHPb6nlX3aZM5JvypQePll9fedwcsAB7scOHAgLFrQ/tqkp5HdYWRn88Y9www3Ofa8chFYJmp534UL461/bb/PqXgVCr5TaU0uWOF0dHl2/LU5aNZd5OdMZORKOPBJGjoTx452HxlpC+/TjIaZ9+gClpbB2bafNDUNKGLCjul0fkwjk58Ohh4YdvmuMSUGb8ksZ0tD5+0CB55nIXV9Ywquvxr9cPXXOOfDMM9CMeNcUE5SwNGGCU5EKBJshLsGPH++cChYsCHmxEzVhAr8CiyYv4JkiH8XFMHmyc6EVnadO0j79tFBR4UzS3FZhIXk/r+CYYzqvX9HQAGvWxGk8pjEmbqqq4GCXgN/Cf1lqBnyAp592ApLXpGRAyLntY+mjj5z8iJbbHGaETnaMR8CHsNV2AS76yxU8ONHP7bdHL+CHY0G/p3w+J4mlbVJfr14AnHSSM+SjZdGLnBwnYUMVfvKTBJXXGBMTYebi4ZFH4lOOWHn0UbhVKkIP30tAE3/Ld2pzs3PzGjIdd5WVYWv7NDfDlVfGpTgtLOhHy549+3+vrYXLLuO6VdPZvdtp0s/Pd3Y1Njp/Bx98kJhiGmNio/DJFF1yNkJlZbD3Iu9asgBN35wRvwIFHXqo872qGj7GhhpxFRPTpoU/pqkpPksnB1nQj4ZZs9qPFwFQZdAf53JFrp9AAPbudf4oW4J/Q4MN3TMmnXznk9CTwaSDW2915qv3kl0X/1p2Y6PTw5qT43zH7qSP98Fzuj/tbrdUVkY2xHLVqrgFfgv60VBT47nrvj3XEAg4zfsA+/Y5AX/QIFi0KE7lM8bEVFUVDA949+dL795xLE3slJXBz4bOSaoZ+urq4IgjnLV/pvXzk88+9wPLy+PXn99WS0Z/OKtWxWUdAwv60VBc7LkrN7CXPn2crptAwOnf79ULCgps6J4x6aKyEgIeX6cKMG9eXMsTS8fN8XkOSwRn2GI8FRXBhg1Oa+qs3bPIp7HzQQMHJnbGwEife+nS2JYDC/rRUVHhuUtw+pwGDXJuQ4c64zJ794bt2+NWQmNMDL38MmQRYi7dRNQwY8SZX8C9ri9A/zvi169fVeVUolq6T4c1e7S2JGhkQTuRDsKPcTKkBf1oCPMPPXw4HHigMydESYnT1B8IeM+jYYxJHVVVsG6d9/507Off1sd76F6fffELsIsWOZPanH46fKU5RLDMDjGFcLxUVkYW+GfNimkxLOjHwS0bpjN6tHNFumOH83P0aBg3LtElM8b01J13wuS9fu9+7nhnjMfB7u+FGboXJzU1TvP+qFHww6YQiZTNzfEslrdIAn+IHLFosKAfLSH+sY9dPo+cHBg7Fs491/mZk+PMwGSMSW2vvgq/DMxw/TJViH/GeBwU35Ic3RXFxU4iH0BRnXciZUyn3u2qcBn9IXLEosGCfrSE+McWDTBzJvTvD+vXOz9nzozfDEzGmNhpbISBHhPCCKRVf36ymTwZtm1zbiGFyLtKCK85+gsLY15Wm3s/mkLNDJHm77MxmWrkSHh3dYi129P0f1/F/TUrOGvcxUlVldO3f9sdKfgZ+P1OH35NjVPDr6iIykWizb2fDBK0ApUxJrZ+vDPE2u1p2J/fovkA99e2u2BgXCceKyuD2w/3p2bCpM8H1dVOZnd1dVxahSzox8uM+E9PaYyJraoqOGf9/Z413nTsz2+Rc98cArl57bY1kMdPh87he9+L84yjoTLew87Nm1ks6EdTqGSR4DjRhQvh5JPh8MOdn7banjGpa9GiMGu3p3N/vs9H1kMPUtunhADQRDa5NDB9/SyOfMsfl7lwqqrg9ttBXZY3bxXJ/PcZxIJ+NIVJwFi4EL7zHVi92hm6t3q1c98CvzGpKcajq5Kfz8fd/SvYl1VIDs0IMKRhLXdunkr/xbHt0qyqgrvvhlMXheheyctL7Ex8SciCfjT5fN5NSSL85Cewe7czXK+gwPm5e7cts2tMqtq5E/ZS4LpPCty3p5tvfTyLXoH2C471CtTzrY9jO8lMZSW89x58/m337hUA+vaNaRlSkQX9aPPKElVl/H/9rYG+tnb/BcCaNfEtojGm56qqYOVK2I3HYjppsshOOEMa3ZvWD/bYHg1VVc6oN9Uw3Stbt8asDKnKgn60hejXv3XPLHbscFbh3bfP+bljh+WZGJOKFi1yLtq9xuhnTMDJcp/iViU7Zsl8ixY535urV4c5MMYT3aQiC/rRFqJff1hgLY2NzugMEednY6O1QBmTimpq4KsBv/eKcxkScCTgPsVtljbHbPnwv/8dNm1yvj930cf7wGSblCcJWNCPNp/Pc2yuAL9mOqrQ1OQ0TeXlQX5+fItojOm54mIoXzfLtXlZkcwJOB6tm/W9BsYs0XHNGqeVJScHXuc49wb+kSPTe/REN1nQjwWPsbkCTNV5FBQ4iz5lBd/9vXvjVzRjTHRMngyD6t2jmqCZE3AqKmjKzuu0OXfPDs6ui00G/549+5fTPZWX3dta3nsvJs+d6izox0KIf/YsAqg62fsFBc4f7c6dcZ7IwhjTY2Vl0Fw0wH1nGs/E14nPR0Ne5z7KPBqZ9GJsMvh79XK+P3NzIRuPFfSSZWW9JGNBPwG+0uxvTfLv3dtZGjJWfV/GmNjJad6X6CIkhYI97kmLfbfHpn3/0EOdLtIL94RoSch2TzDMdBb040xw1n1uaHCap/budfr0M36SD2NSTM2P/eiuXe47MyVzP2h9lnvS4nqJTTLjkUc6laU7Gmd5j9GfOjUmz53qLOjHSojmvWGBtag62fsNDbB2rdPEb4xJDVVVUFgRIuBkSOZ+i4+yDuuUTKfAe3pYTLouVaFfPxiuIWpLNhOfKwv6sRJioY0A2ag6mae5uU4z1apVcSybMaZHFi2CgbtDBJxMydwP+mJz52Q6AU7h5Zh0XTY0wIknwif5HhdXodZByXAW9GMlRDJfNs3k5Dh5JqpQWAgffxzHshljemTFCtiU6xFwBg7MnMz9oCx1T5rLpjkmXZfFxU4i32tnV9CQW9h+Z2Fhxl10dYUF/VgKcbX5dMMkevd2avo2ZM+Y1LJ9O9x7cAV7s9oHnL1ZhWm9nK6XUJOKxqKnY/Jk2LYNXhnu4y9nz2dr3xIUoWFICcyfn3EXXV1hQT+WPK42BZioS1v79QMBOOig+BbNGNN9BxwAzxzgo6J0Ph/nlxBA2Jhbwq/HWcDp6Kr86I/VLyuDmTOhf394tr+Pe26o5u2VAfI2Vtv7H4YF/VgK88d34R4/WVlOwP/c5+JUJmNMj40bB6NHw6uH+DhzRDWnnhRg5pRqdp6boQHHo1VTgIPvjf5Y/aoqJ69iyEt+frGolNt+mEXZeaXgj+1yvtFWVQW33w5XXeX8jMd8LRb0E0SAXzTPoHdvp9Zw8MGJLpExJlKTJzuJuGPHwrnnOj9zcpztGSlEH3ruppqoBrOqKrj7bjh10XSmvnIZB9StRVSdYVBTp6ZM4G95Hdu2wfDhzs+774594LegH2sTJ3ruGqC1FBc72fsbNtisfMakirIyuGuEnzseLuWOO7O44+FS7hrhp6ws0SVLkBBrjmzrWxzVDP5Fi2DSJ36++Pb9znTHbdXXw6zYzAIYbYsWOd0T/fs7U7K3/B7ridos6MfakiUhdxcWwsknw2c+Y7PyGZMy/H6K75rq1DJRDqhbS/FdqVPLjIk5c9iX3T6xsSG3kKUTK6KawV9TA+e9MatzwG97QAqoqXEmGGqrqCj2xbegHw8eV8D1vQZy8slOn348PmxjTJTMmuXUKttKoVpmTPh8PH3+/kz67UUl/PXc+fyj2BfVDP7iYiiqWxv6gBRQXAx1de231dXFvvgW9ONhzhxnbF4bLdeoY952agbx+LCNMdGhaz2Cjtf2DHH4bT7+UFbBtr7FFNXVcMoLszhyuT+quQ5hz5UiY/Rbhh1u2+aM4Gr5PdZ5IaLq0USSJiZMmKDLli1LdDGcZr8ZM6C2tt3mRrK5Nv9hqkb7ePBBMrdP0JgUUVUFo8blkO02IU12tpOkk6n8fgLXTCVr7/5WkEBBIVkPRHcoo4p4zw2QQjGtZRRCTY1T6Zs8OToxQESWq+oE130W9OOoTx/YvbvT5h305qCCXdx1F9x4YwLKZYyJ2O23w213pEfQibrSUvfWjpISqK6O3vNIiOmAMvn9DwoV9K15P55cAj5AX3bTpw/ce2+cy2OM6bKaGqgr8phtM9PnfPdITFJLWEoaFvSTRK9eGbcapzEpqbgY/CM7T8HbkGtzvnslJtUWFkd3SLLXKqYhVjc1Dgv6SeLMbX4GDEh0KYwx4YweDbM/9nHHsP1T8K7PLuE/5TYFLxWdF8BpyC1k8Rcqojsk+ctf7rwtNzcj1z3oqpxEF8A4s/P9ctdVzL09w78wjEkB77wDxx8Pr2/08dxAH0VFMHQofK4/HJfowiWaz8dD8+ErK2dRVFdDXVExSydW8OEoH+uj1cLv98PDD7ffJgLXXGMXXRGwoB9PffrArl2uu3rRwGmnxbk8xpguq6lx1s04bcX+wPZC/wqerbGAA7DpFB+3jfPRv//+bXXbojgk2W2OBFVYvDhKT5DekrZ5X0SqReRtEVkhIsuC2waIyAsi8kHwZ/9w50kq998fcvfzV/htKl5jktzZdX7Of7r9bHznPz2Vs+syeDa+NiZPhuGv+Ln2x6X84I4srv1xKcNfieJYfa+kQEsWjEjSBv2gU1R1XJuhBzcDS1X1cGBp8H7qCNH0JMAl78xi7tz4FccY03Xnvj6LvKb2Nc28pnrOfT2DZ+Nr44Bn/Hzr7akMaVhLFsqQhrV86+2pHPBMzy+Kqqpgez+PJgOb3SwiyR70OzofaOnMeRi4IHFF6ab8fM9dQ5vW8sYbcSyLMabL8j52r1F6bc80/X46i4Lm9hdFBc319Ptpzy6KWlale+r4zsmCFNrIiUglc9BX4HkRWS4iU4PbDlLVTQDBnwcmrHTd9dvfhtztMZTfGJMkGg62mmYoRXXuFz/9PLZHqmVVuo+O9/HXc+ezvWj/HP/Mt5ETkUrmoP95VR0PnAl8U0ROjPSBIjJVRJaJyLItW7bEroTdEeYP8zdrJ1m/fqaaNMnJQm57y83N7JXbkkxVFfy9z1md1ndTgLPOSkCJkk9dkfvFz8e5PRur33ZVurfH+PjVd6q57dYAN0yutoDfBUkb9FV1Y/DnJ8CfgWOBzSIyBCD48xOPx85X1QmqOmHw4MHxKnKPCXBiw1LevN6+5DNKS7BfurTzvqYmuPRSZ+SHBf+EW7QIxm1Y3GkKXgHLHg/a8d0KGmi/wNg+cnl0RM/G6idqVbp0k5RBX0R6i0jflt+B04F3gKeAK4KHXQH8JTEl7KGJEz13CeB78er4lcUk1rBh7sG+o9270UsvhenTY18m42nFChhYb9njoRQX4zI3vvDxx877112TJ8ORy/18+xel3HZHFt/+RWnUV/DLBEkZ9IGDgH+IyErg38Azqvoc8BPgNBH5ADgteD/1LFkScnc+++JUEJNQeXmwcWPEhwugc++3Gn8Cbd/uNFO7siqnY9Ys8rSh3aZ8Grh+yyzWr+/+acve9vONN6cyYKczVHLAzrV8482plL1t/w9dkZRBX1U/UtWxwdsoVa0Ibq9V1YmqenjwZ+rOVl9e3qlf0GSQ/v2hsbHLDxOUPZdexcKFMSiTCeuAA2DOQRXs6TDv/t5syx5v5dHicYiu9ZqbLCINN80ip6H9qICchnoabrKhkl2RlEE/I1RWht5vzbjpbfv2bj+0gAaOu3iYBf4EGDcOqkb7+G7/+azLcubd31xQwjPnW/Z4K48WD0W4cE/3a+W5m9wvJry2G3cW9BPIq6YvAPPmxbEkJq6mT+9RK48Aw9lI1rftwjDeRo+GI5b5uXnHLIYFavg4t5gf96lAL7GA36qiAu2U6ghZKDO3dr9Wvj3bfUUyr+3GnQX9BPp9vxBN/IFAPIti4un++12+EvdToJ48lNAXhudtmh/1opnQ5DE/P902laGNzmxzQxvX8tNtU5HHrF+5lc+H11/ugN3dr5XnNu/t0nbjzoJ+Av3jkjBN/Cb9+P2oetfzFfg15fRmH1lh2gOyaY5y4Uw4J/1tFvkdZpvLb67npL9Zv3Jb4rGufXO/7tfKe+M+c5nXduPOgn4Che22tyzt9DNjhmctX4EqRjIjq5I//tFZOOy9QyZ6hv5msrn88hiV07gauHttl7ZnrL3ute+GnXtt8rEEs6CfQGVlYQ6YOtUCfzrx+9HaWs/dDWQzjnf52c9gyhRn25E1S9jZd6jrDHDZNHPjo6Ms8MdJVZVzoeUqy2N7pvKYT7xXYHfYHGYv0qeP+3aPVgXjzoJ+gslE75oc9fXO2tEm9fn98PWvh6zlf52H+cIX4MYb2+/rt2MDEhzi2fK3IsFbGauY+eioWJXatDF3LmR5dKlIwLpaItWtRcX8ftjnMn9JTg7MmdPjMmUSC/oJtnDaEl7NDxH411qzYVqYNSvkuPyd9OHV4T5efdXjgGD1yG361zGsYvbsqJTShPDGG1CX7VGrtNpmex7vRy0Duzda1ev/p6jIhkp2kQX9BLvvPvhGyRI2ZJd4H2RN/ClPQ1y8KTAj936eeab75//Zz7C+0hgLkX9pOpozh33ktdukwB/lyzQ0uD8kFPWY8Ee3pu78bIliQT/BPvoItm2DH/et8K7tT5sWzyKZGAiId59vLQPZfYEvfI5HCAs+mdTtvlITmeOPh6JmjyBjwac9n4/Hel/d7jtNgKv0AS7a1/VKzL6cQtft9QU2Rr+rLOgnWFYW7NoF9+8I0UTVk7krTVLIUvc+XwVu7z+H738//Dkk2/3CQYBJLCXnCb/V9mNo+nTYmesRZGze/U4u2PtEp+6ofBq5s25G107k95Pf6J4YaNOZdJ0F/QQTgT17IvjjtSb+1BVibGYtA2n+SoS1/IcfDjlZz/9tn8Xcud0poIlE2dt++jZv77wjL8/m3XdR1Ow+UsVru6dZszwTYPvssxaWrrKgn2DbtjkJqNnZEAg1T9vVttxuSpo+HZ071/WTraeQ2/vPobw8wnP5fEiW97/scF3LSy91q5QmEjNmkOWWpZ+ba8lkLkLNOtmlFqkQSxbXD7IWlq6yoJ9gjY3Od0avXvDbnGne/fr79lltPwXpvPmuX34K3DF8Pk1f7mJf/rXXeu4S4PoPbT7+mPGaY8FjTLpxp8CiRV14QIgFfJ470VpYusqCfoINHuy0DmZnww35YTKxZnSxL8wkXojx25tO8XV9McXKSvCY20GAq5vn2+p7JqkJ8PTTXXhARYWzdHEbivCvo6fxTJG1sHSVBf0E+9a3oKnJqe0PGBCmiT/EbG4mOXnN4NZMNjNnRjAro5slSzx3ZdPMT37SjXOa8LzG4tsY/S77738jP7ZqjI/bh85nY66zlPGmvBJuOeRR7vlcpeVPdoMF/QS78Ua44w7o3dtZYn1B7xBN/ACTJsWpZCYa/t37ZNcpdBcOmNqjIXqhfPBBbM6b8ebMca7O28rNtRnhvHhcDO2kj+vkel4WLYJ1X/Rx5ohqTjg2wFePr+a5AT7efRcmT45SWTOIBf0kcOONUF0NO3bAFbsqkfx874OXLo1buUwPTZ/OCbtfbNd2o8BrvSby8sWxG1T/k53TbeheLPh88NBDUFLiDLspKXHuWxKfuzlzaCSn0+Y89nFpVuT5SUNe8vPrZ0pZUZXFX1aW8v+q/RQVwaGHdrOlLMNZ0E9Gv/1t6P1W209+fn8wa799PV+AwwIfdr0vv4NQY/av1bldS5QykfP5nCv0QMD5aQHfm8/HruyiTpsLaORHRLimiN/P11+fygF1axGUg/et5Y5NU7m6l59x46Jb3ExhQT+JVFXB7bfDVUt9oZv4rbaf9Jq+6b2E7kH7anpeQ5k6NeSY/foHbKSHSbwDPMbkH9wQ4Zois2aR11jfblNeYz1n/WOWNe13kwX9JFFVBXff7YzbHz6c0EHfJL3sOu+ky9reUcg+qqz0vKgQYPqGWZbFb1Kfxxj9gfVRuHDOUBb0k8SiRdC/v3PLyoI3J5SHDvw9bR82CaHA38+I0tji3r09dxVTY1n8JvV5pOeLpe13mwX9JFFT46wS2eLZsytDD9+bPz/2hTIxcfhtUeoHnjfP88KwiWzefTc6T2Mcrd1vVzk/LVkyDioqoLDDYjuFhTbtcQ9Y0E8SxcVQV9d+m/+MR71r+83ek76YBAvRCrNVBkavWTJEElkuTdy911qDoqVj99u2bc59C/yhydChrkNW6/sPjewEPp9TwWk7YmL+fEug7AEL+kli8mTni2TbNicxeNs2WHKgDyTER2RN/ElJ597vOfXuk6dEd0x3qH79adxvQSlKOna/tfxuoyTCyM3t9DcqwLYduZHlnPj9MGuW0xRaXOzU8C3g94gF/SRRVgYzZzpfJOvXOz9nzgSZ5j3XOnPnWuBPSt7ZGMf8MspfWB5D9wCyUAtKUdKx+w2c+yHWgjHg+QYNba7hvvvCPNbvh6lTYe1aUHV+Tp1qa5D0kAX9JFJW5tT4i4ud/5VFi6BqWiUhl2G7//74FdD0WNQzjkMM3QMLStFSXAyH/dvPd35Vym13ZPGdX5Vy2L/9Ng1sOB5v0Cf5xWzYEOaxs2ZBffvhetTX03BThGP8jSsL+knEs99wWojZ21TtyjeJ1Pw4zp9FiKF7AF+osb+NaLgq389XluyfJOaAurV8ZclUrsq39zekigr2ZnVcLAc+yjmMYcPCPNbjijV3U411W/WABf0k0u1+wxDLrZr4GnzrtZ5BeBfeQ+xiQYDz/2W1omgonjeL/Ob2tc785nqK59n7G5LPx/ZRJ7RrjRLghN1LeaAgTNekRyvBtr7F1m3VAxb0k0hNDWzcCL/7Hdxzj/Nz48bgBW+IMdns3m21/WTg91PQ7L62ugKvXDIvNs/rsdQuwIBd1r4fFV79JNZ/EtbBq152Teb7zAthhh2fdRba4ZENuYUsnVhhb3sPWNBPIrt2wd/+Bnv3Qt++zs+//c3ZzrwwAWOW1TgSrek676l3Ac7+fYyyjpcsoVk6L2wCUN9rQGyeM9N4dd5bp354HsOLJdDsncHv98PDD7dbu0IR/jP2Cv5R7LO3vQcs6CeRjz5ykrFbErJbfv/oI5xhKn36eD/YLn0TLnu799S7Mdev88ImEDK533RBzbUVNOTaJDHd4vFH2Ey2dwa/SxKfoBz+3mK2bbMldXvCgn4SqatzlovMzYV9+5yfhx7aZtKeUJn6dumb1Hblu68tHi05O7a6bs/ftdWSnnqoqgq+v9rH46fOZ3tRCYrwae8Sar5vk8RExGWEiQLVBUd4Z/B7VGL676xh5kxbUrcnLOgnkWHDnIl5Bg2CggKneX/Dhjbjg30+Z/ieuDQi19TYmP1ECpFTEQC23RbdSXk6saSnmFm0CCZ94ue8N2ZRVFdDXVExi79QwYP7LOBHpLKS//Ua2SmZ77N7V/HT3R7fWfn5rpulIN8Cfg9Z0E8i110Hn34K//sfNDQ4o/H27oVevdpM91lZCY8+2rmpX9Um60mghqumec7C97fPlFN8S4wDREUF+7I7Do0S3v/cWdbz00NDXvLz1RfbD9f76otTGfKSJc9G6jP73nNN5rtgs0cy3969rpvVY7uJnGfQF5HFIlIax7JkvClT4IQTnK7CffucYH/66TB+fIdhez4f7NnjfpK5c+NSVtNebsMuz33D/hxinoVo8flYcdQV7bKdBWXsfx62sfo99JWV7mu6f2WlJc9GKivgnszntT0U667qmVA1/d8Bz4vILBHJjVN5Ml7fvvD//p/zc8cOePPNNsP22gq14M6kSTEto+maeDVHHrVhcbtsZ4BegXrO+scs+6LsgaId7k0lXtuNC49kPs1y2R6mtdK6q3rGM+ir6hPAUUA/YJmIzBSRG1pucSthhmkZtrdzpxPXN2+Gp55y5uNvJ1Ra9tKl1syfgfI+dg9CB+6roTIOjQ3pamtv93wJr+3GhUcy35LPTu18QRpieHJTdr51V/VQuD79RmA3kA/07XAzMfDRR073/J49TlJfS2xfvrxDs9bUqaFPNHeuTdiTaTyS+eqyB/DGG3EuSxp5Tw9zDVjv6WGJKE5qqqzk3xPKaZZsFGiWbP49oZynz6zsXHMPBFxPocBjk35rA5V6KFSf/peAFUAhMF5Vb1PVO1pu8Spgpqmrcybfy8lxgn9ODgwYAE1NHZq1Kivds/jbmjEjpmU1++3Jdp8xcXdBbIfqtVNRQYPkddrct3kbZ26zC8DuOna3+4xyx+5+OQGlSV3zxlSy6PyHqSsqIUsDHPHBYr5Q4+9SzX3JgT4bo99DoWr6s4CLVfVmVa0PcZyJomHDnMz9lsDf1OQ09RcWuvTrT5sW+mS1tVbbj4OaH/vJDTR22t5ENlt/EOOhem35fDRndU6/ySHA9zbbBWB3ZeOeP+O13bg7u87P+U+3HwVx/tNTObuuzXdUmG5JG6Pfc6IaamHO1DdhwgRdtmxZoosRsYUL4etfdwJ/Xp7T0tXU5IzdP+88l+T8ggIn1d9Lnz7OVYOJme0HlHJA3dpO23cVDKTPnk/jWhYV8Rw6KGn+vx4r9p5GR8PQUvI2df4/2T2ohN5bqp07OTmhk5Tt/Y6IiCxX1Qlu+2ycfpJpGbaXne0E/pwcp6u2Xz+Pv/ff/jb0CXftsqS+GCuqc2+f7L3XfZa8WPLq8AnTEWRMzHklmhZ+unZ/vlKIgN/cK76rVKYrC/pJaPhwuOwyGDrUSehbswbWrQPXBotIpgG1sfsxtafDpDgt6ooSkHE00COHwGu7CatxSEmXthsPnhl4wgd3hO6GVGD++Hk29DQKLOgnoeJieOcdZ5heSyLr3r2wciXMnu3ygIkTu/wcCxfCySfD4Yc7Pz1XuzIhffil6fRyWU63iWx2fDcBi7HMmeP0C7XRmJXHn06aY1+Y3bTjC52XeA0UFJL3c1tsp0sqKjq9j+BMInXS38JPdPSPEp+N0Y8C69NPQlVVcNxxTqAXad+sP2gQbNni8qD8fKc/wIsqVVVO0v9TTznj/zuOjDn0ULj8cmcFK0uWiUyT5JDjktDVTBbZmqBEL7+fhptmkbuphm19i1k6sYJ/FPvYts0Sobqq5sd+Drp1KvnN+3OZFaH24mkMesImP+gq7/wIQSae6swx4rofhh6sHHccPPlkLEuYHqxPP8WUlTnJe9C5H7+21mMaygcf9DyfinDxxfD5zzuHbdrkPhR2zRq44w445hiPFgXTiVcGdxbuY43jwufjR1OrefSMR8nKgilPXsYdD5cy6RO/1ZS6qN9PZ7UL+ODUTHOeX5ygEqU2766SYs+AD/ApA/n4Y5uCNxpSLuiLyJdE5D0R+VBEbk50eWLFawi+Ktx1l8sOn8+1mV8BVeXuhaWct8vfejERSkODUyO88cYuFTkjNeO9Vngi2SIx0eGVpOm13YSW9/MKAgXtc2DCdZUocIPMISvLqbCYnkmpoC8i2cCvgTOBkcAlIjIysaWKjVB5Vy++6LFjyRJn6d3gNH6Kk7WdBZSwlke5lHs08kz+++6zvv5wVh90svta4WeEmTExxmyRmOjYlT+gS9tNGD4fWQ/Mh5ISp2ZTUuLcD5OQ7MdHTo7nZH2mC1Iq6APHAh+q6keq2gA8Dpyf4DLFxAUXeO8LOey+shKamtjbZ2CnvrMsYDpzuYTIansNDfDtb0d0aEZ65mt+Rmxe2u59VuCdgyZy2HOJ7e+1RWKiw6vFLdxkmCYEnw+qq50lwsEZqpSf73m401oJjY3O7KSmZ1It6A8D1rW5vz64Le2Ul0Oux9qGzc3h+7byd9W6bs8CfkTktb1Nm+CccyI+PKOc+thV5HTYJsBhm19NRHHal8NjeJTXduPOa66FRMzBkFb8fgLXTIW1a52IHiIJuQYnD0DV6XY0PZNqQd9rYqz2B4lMFZFlIrJsi2uqe/IrK4OTTnLf16sXrqumVVU5E/vkdZ5+vZ1i1pKb631R0dEzz1hin5sC3L+ovLbHVUWFM3dzGw25hdRca8PMusJrroWEzMGQRhpumkXW3vCzuyvwPZy/2ZwcyzOKhlQL+uuBQ9rcHw5s7HiQqs5X1QmqOmHw4MFxK1y0zZ7tfG/n5Djd9Lm5zsx8JSV0WjXtxhvhqKOc7Y2NTrarFwE2XjCdhgbn6vnss8OX5Yc/tMzZtv41I8kT4nw+ar4/n097l6AI24tKePzU+Xx/tc8+xy7Y8d0K9nWYfGlfdmFi5mBII7mbIu9meowIJiAzEUu1oP8mcLiIHCoiecBXgacSXKaYKStzZucbPNgZn19Y6MzQt2qVc2upfV9+OfziF+2TXGYwp3MTSJAAgxbe37oYz9NPOxP/5HRsq25jxw731oVMdUTljKSf2vbBfT4Wf6GCrX2K6VdXw6QXZ1Hymt8+xy4ovsXH5jvns71o/8XT5jvnU3yLBaKeqO0dWUtJ28qL5VFEiaqm1A04C3gf+B8wK9zxRx99tKayadNUjzxSdfhw1awsVRFVp34e/vYJA0MfMHBgu+e64YbQh3/2s6orVybojUgyAY83KQBad+zERBdPVVXvP3GB7s0pbFe+3VKo3+y/wD5Hk1ALJy/w/B9q+790CQtaNw0ZkuhSpw5gmXrExFSr6aOqi1X1c6r6WVVN+za28nI47DD45BOnJt+VCRRnMIdAqPpobW27xXhmz4YDDnA/NCvLaWWwafzD6/evJYkuAuAM28tvat9vWqj1/GjbtfY5moQ6/DYfocKPAs8zsV3TvvXnR0fKBf1MU1bm5GRB15u3HsNHJdM8m/kBuH9/Mz/Ab34D/ft3fq6sLCfB9umnrW8fcJ1DPNT2RPAanteX3Xz+97byokmcsjL46IxrXb+bFPiUA/gS+y+eCwos6EeLBf0UUFYGQ4Y4v2dlObdI/fuySqS83PsAVZgxo/XulCkwfz4cfPD+wF9Q4OQUWG3fUVXlTMXqxmt7IngO2wMu2XF/fAtjTAd3l1by+6JyZxx+m1sVIzmQbe2OPeQQlxOYbrGgnyK+9S0nCEfaxF9UBH/8IzzyCE4GXqgp/mpr29X2p0yB555zmvoPPNC5ZWU5z3/QQZ1HDmSacMuAJo2KCs9LkKwkujgxmemNN+DGgkqy0Ha3cbzb6dhTT01AAdOUBf0UceON+2eqDBX0RZwV+l55xQnerebMCd0/MG1au7tlZU7tPicH9u1zhgsOHw69e3ctryAdffHZWZ6N+M1FSbRufZipTY1JJBEnVymS46Zbb1TUWNBPIY884tTejz7a6XcvKnKCcF6e0wQ/ciQ88YRzBd1p+VSfr1Ngb2fXLpg0qd2mU0/dPy9Ar17w3nuwYoXzj5rJc/IP2rPWdbsCOb+eE9/CGJOijj8+sgrEscfactDRJJrm1bYJEybosmXLEl2M5DFokNOc72XBgtYaYlUVfO978N//wrp1zgRB+flOc39jI/zsZx1aEzJEQLJcm8cDZJGl7kvtJor3+uUgaf6/b5JbVRWMH+9MK+6lsBBef92CfleJyHJVneC2z2r6mWZOmJpom9aAsjL40Y+gqclpUSgsdH6vqYHNm+EHP4hxWZPQf/7f9BBJfLYEmDGRKiuDr30t9DE//KEF/GizoJ9pwvXz7trVLqmvrMzpzz/wQGdWvt27Ye9eqK93mvszrZm/7PV5nv35jUNK4lqWnqr5cYokJJq09cgj7tOA5+TADTfYML1YsKCfiXr3Dr3/yivbBf5hw2DNGqdJv61AAP7v/6JfvGSW5VGbVyDv58k3V1TzAe6JhQL0/lHkqy0aEytPP+3kKp10kjMR2UknwWOP2SJfsWJBPxPNmxd6f1MTXH11693rrtu/8mXHbuA1a2yynlZJmC2fc5/3Ggz9d7knJJo2/H4oLXXGrJaWtrsYNtEzZQq8/DJ88IHzMxNzheLFgn4m8vlg4sTQx+zb1/oFN2VK6MV4pk6NYtmSWFUV7MN93eKG3DCtJ4kS4kIkeeYOTFKTJsGll+5f833tWueP3QK/SWEW9DPVkiXOxP6hXHll66+HH+59WKYMjvjgDj85Lv8xzQj5D4VpPUlS1q/vYfp0WLq08/b6ephl3SImddmQvUwXbkL/8nKorGThQrj4Yu/D0vzPCIBPCks50GWM/s78gfTd+2kCShSZ5qwcsj2GEtZn96awaVecS5QCcnK8x5K1TI1pTJKyIXum+4IT7YfqY8uEda6rqmCwx6Q8ffZtjXNpumbblKme/fq9mnfHtSwpI9TgcY81DYxJBRb0M124vn1wpv/De/r+nJz0T+Z783q/Z+BsHJLcQWDQE5WJLkLqyc523axAzbXJN0rDmEhZ0M90S5bA0KGhj9m+HSZNYsoUZ0a+joqK0n/lvckvz3D9ZwmQnEP1Ogp4/Kt7bc90H07q3DqiwFsDJvLgvuQbpWFMpOw/3sCGDc7E/aEsXcr3SvwMHgyDBztz/ffu7TQCHHQQvPBCetf2Dwi4T10skJRD9Tpa47J2uQJbxpySiOIkvWv2VvJAbjlNZKNAE9k8VFDO5D5LqKlJdOmM6T4L+sbxbuflLDsqnj2Dc85xZujr08eZxv8zn3GC/8CBsGhRHMppuuWw5yrZPGZiu8AvwIEfvG5D0Fxs2AB3DamkZGgTh5Yoh5U0cceBlWzfbl36JrVZ0Df7havt19ZyZ+10evWCQw91Vt/Lznam5R03jrStAVVVQX1WH9d9XjPeJaMBn37YaWx+1t56Gm6yIWgdDRvmdGU1NzszUao6o/V69YLJkxNdOmO6z4K+2S+C2v6gP87llhI/Is5c/L16wQknOM396VoDeukbfvIC9Z22N0kOOfelzlK6uZvcr8q8tmey665zJqbs189JVN2507l/0022AIxJbRb0TXvhJuwBrnhrBkccASNGOF+Gf/qTs3DGu++mZ7/+pf+eQa7LnPt7ND8l+vNb7Mwb0KXtmWzKFGfp6KFDIS/PCfS/+Y0tAGNSX4jJVU1GqgwO7wqRjp+zvZbzzoPvfQ82bgxuy4GXXoKPP4Zf/zq9akMDcE/i60NqjXH3mk8hE+ZZ6I4pU2wOeJN+rKZvOqushAULQh5yyE+nk5/vBIzGRmdF3h07YMWK/dcN6SCdWi68JhFK9smFjDHRY0HfuPP5Qi7Be+yyuTz2zijq652gHwg4P3fvhueei2M5YyydRiTU9nZPutiVb837xmQKC/rG27x5zvg8FwKMYhWLA5MQofWmCp98Et9ixtKQl9JnONvfz6igKavzKoG9GnfYsD1jMoQFfePN54OHHvLcLcDpLOUrAT+BwP5Fd5qa4lO8ePjKylmeS9A2F6XOcD2Aw2/zUZ/Tt9P2nECjrRxnTIawoG9C8/k85yEHJ/A/zGXttqmmT1940Q734WwK5Pw6dYbrgZNc2bfBPSlR17ovJmSMSS8W9E14U6eG3J2DtjbvgzOpSbrMxd94sHs/uAwcmFLD9VoExGshGUvhNyYTWNA34UWQjn+vTkfEGbrXq5czfC/VVVXBT/pVUC+F7bYHCgphTmrV8luIui8ZK6j16xuTASzom8iEmLRHgHLu56sBP6rOonw1NanfxH/nnfD59x+il9ajOE369eRxb9n8lKzlA3ySX+K6XQBmzIhrWYwx8WdB30QmTG0/C+VXzEDEGb7X1OQEzVT2zScncaouRaD11osGxr7lndyY7PyjKjqtttdCa937+40x6cOCvolcmAl7BlHLsqZRBAJO4H/hhTiVK0ZOalraqadbgttT1c5zU7OFwhgTHRb0TeR8vrDN/GWs4jkm0dzszNC3cGH8imfCsxXiIuD3Q2kpZGU5Py3XwaQRC/qmayorwwb+03FqwiLwk5/EqVxRlur5CF7SaU2EmPD7ndEqa9c6Y0/XrnXuW+A3acKCvum6ykoYGHpimvuYTp8+8NFHcSpTlF17LaxjaKf+bwVk4sREFMnEw6xZUN9hGeX6epu8yKQNC/qme0IMWXOy+efS1OS0kKaaqiq49I3pHMLGdn36inMhwJIliSpaVOzEfU0Fr+0ZpcZ9MibP7cakmBT8SjZJIcyQNQGq6/un5Ox8ixY5Fy1uSXzD2ZSIIkXVd/vNo7HDv34jWXy337wElSiJFLtPxuS53ZgUY0HfdF+Yvv1BbOcP2yal3NC9IS/5PeenE88Bb6nj09N9TCt4hHVZJQQQ1mWVMK3gET493TL7qaiAwvaTMVFY6Gw3Jg2Iaup/iYUyYcIEXbZsWaKLkb5GjYJVqzx3KzDkIOXjj+NXpJ6q7VvKwF3uc9ErICn+P1NVBd/8ppNvsWePM4PiZz4Dv/61JfoBTtLerFlOk35xsRPwU3QyJpOZRGS5qk5w3WdB3/SYeM/brsASJnLQyiUpE1BUskLX6NPgf6aqyunGaIlrkydbwG9h741JdaGCfk68C2PS0MSJsNR9whoBJrGUu6/ww8O+lPjy3Jk3gH4uq9EpICG6NFJJWZkFMjdVVXD33dC/PwwfDtu2OfdnzrT3y6QH69M3PbdkCRxwgGfdWIAZK77OB3ck/1jnqipodl+ThqbsgogWH0opNhFNO4sWOQG/f3/nLWn5fdGiRJfMmOiwoG+iY9u2kIuz5tHImX+5Nm7F6Y6qKrjqKihq3uq6PyewL84lijGbiKaTmhooKmq/rajIRuyZ9GFB30TPxIkhc9t7Ne+G6dPjVpyumjsXRvzHO+BJug3bsoloOikuhrq69tvq6mzEnkkfFvRN9CxZgubme+4WQO9P3rHgeQv9/C5wOVkuly5N5KTfsC2biKaTyZOdfvxt25xFo1p+tzULTLqwoG+iKuuh3xLIzfM+QAMwaVL8CtQFt346g2wCrvuE5rQbttVwsHv1taloQJxLkjzKypykvf79Yf1656cl8Zl0knRBX0RuF5ENIrIieDurzb5bRORDEXlPRM5IZDmNB5+PrIceDJnUx9KlSRf4Fy6EgXivJ+9W+091fz2hgqYslwu0HTsyul+/rAxuvx0efND5aQHfpJOkC/pBv1TVccHbYgARGQl8FRgFfAmoFJHsRBbSePD5+MOA8tBhcunSpAos4VYDlOz0+1N7psjHvvy+nbbnBBozul/fmHSWrEHfzfnA46q6T1XXAB8Cxya4TMbDyxdXsivcAi5XXRWfwkSg7B3vCxAFJ6s9zRQXQ+Ee95EKrHWfkdAYk9qSNehfJyJVIvKgiPQPbhsGrGtzzPrgNpOEpk+HW/rPC13bb2hwpvFNAr/ad22I+fZJv/H5OMlpO3Ld++8VkqolxhgTHQkJ+iKyRETecbmdD8wFPguMAzYBs1se5nIq15giIlNFZJmILNuyZUssXoIJo6wMmr8SQeLbqlUJ799fuBD6stt1n0LIhYVSWVmZ99LHApnZxG+TFZk0l9Rz74tIKfC0qo4WkVsAVPXHwX1/A25X1ddDncPm3k+cqirYPHYSk1gacuIeIKHz2Z98Mrz0d/G8qkz1BXZCyYR1BiLWMllR27kLCgth/vy0G7lh0luoufeTrnlfRIa0uXsh8E7w96eAr4pIvogcChwO/Dve5TORKyuDs3KWUMPQ8LnvCaztb9iQsKdOuK19Qsw6k4bJiyHZZEUmAyRd0Ad+JiJvi0gVcApwPYCqvgs8AawCngO+qaoes6SbZFLKhvBBP4HZ/BXbvWcJDNtCkeL+clyF52ejXosQpCubrMhkgKQL+qp6maqOUdUyVT1PVTe12Vehqp9V1SNU9dlEltNEZtAg52clYYbwAVx9dayL00lVFUz+dL53cC8piWdx4u4fxT62yUDXfVv7pPdr78Rrrl2bg9ekkaQL+ia9zJzp/PwWlTxP6Ln52bcv7rX9RYsgmxA12nSbereD4mJYlPflTp+LAu/pYYkoUuJUVDh9+G0VFqb934DJLBb0TUzdeCMMHuz8/iWWhA/8ca7tD3kpxEVGVlbaJ3BNngynNyzu1NIhwPG7X8ys7HWfj5rvz2d7UQmKsL2ohJrvWxKfSS9Jnb0fDZa9n3jl5fCb3+xfp74ZCX21OXIkvPtuzMs1ezZcfFMpxdp5IhoFpLw8LcfndxSQLO9phktKoLo6ruVJlKoquPtuZ779oiJndb1t22zufZN6Uip736Sf8vL2ieBh+/dXrYp5DXP2bLjtNhiuIZK0MiDgA+wZFKLPOoNm5vvgDj+/erKUX92TxQ33lHLiej/9+ztdQMakCwv6JubKyuDgg/ffj6h///LLYxr4770XfOIn4PEvIGmewNfWcyeGyODPypBhe34/5/356wzYuRZBOaBuLec/+XW+UOO35H2TVizom7g466z297/EktAPCATgsstiFvhP/djPr3ddSY5bEl+GJW89UxSizzqQIcP2ZswgVxvbbcoJNHLmszMsed+kFQv6Ji7Ky/cP32sRtravGpPEvqoqmLNvGjk0ddoXQDJuBrbiYtiQ7d6ysaVXhrR41Lovq9x7Xy2TJ8e5LMbEkAV9ExdlZTB3bvu+/S+xhAbCNB/v2xfVRXmqquCrX4U+7HLdL2hGBXxwMvjvKqygnvbD1QII/zjgLI9HZQ5L4jPpxIK+iZspU+DCC9sv8vJ1HmYvuaEfuGpV1AL/zJmwerX3/nSfgc9NWRm8d7SPx/KvaNfykoVy7se/zYxhewPdJygSj+3GpCoL+iaubr3VCfoizu1x8XEVD4WfrW/Vqqg8/wsvwApCXEBIJoZ9OOkkuFif6HTRk6sNMGNGQsoUV1/uPEFRIDcP5sxJSHGMiRUL+iauyspg6ND9tX1VeAxf+P596HFt//LL4TkmUcYq73Wap03r0XOkqsmToW+De7+2V3932vD7CTz0cLu/iQDCM0OupmpMZnX1mPRnQd/E3VlnQZ8+7bdFNFvfqlXOzCnd5PfD6eGW+c2Qsfkdheq3VkjvJv5Zs8ja2351vSyU8RsXZ+qfg0ljFvRN3JWXO0Gm42SQYYfxAWzf3q3Af+ONsDgQevneTBqb72ZXvke/NqR3E7/HQPwhTTW88Uacy2JMjFnQN3FXVgb33Qd5efu3iUBODrzNyPDN/Nu3w7BhET/f7Nnwy1+GruUrZNTYfDc/OmiO93ufzk38HgPxN+cVZ2qKh0ljFvRNQpSVwZgxTt9+Tg7k5kJTE4zlXT7lgPCBf+PGiGr8VVXwwx/CfzR0PoBAxg3V6+jZ/t6vP61X6KioYG92++GKe6SQ2QMrOP74BJXJmBixoG8S5uabnRq+KjQ07N9+INtoJCf8CbZvD5vcN3cu/HGHd/IeBAPaxIkRljp9ZWqAqxrj494x81mfXUIAYV1WCTMK5/Pm4T7KyxNdOmOiy4K+SZgpU+CUU9o387e4kt9FVrsMMYZ/9mzYOc/PaWGS9wRgSQT5BGlu+nSoxb1ff7f0cd2eDhYtgvUn+rjrmmpOPSnAeWXVrBzlY8QIm5jHpB8L+iahZs+GU0/tPDz+MXz8OtxqfC1WrXJOMGl/ot6NN8KYmZN4VC8NP+GO1fIBJ8B9r/cc11aWXN2Xthn8NTXOUroHHwwnnwznnw9nnNG+9cmYdCHaMYU6zUyYMEGXLVuW6GKYEKqqYMIEaG521tlp6xL8+IkgcLfR9i861OMUkKFDYcOGLpw9vR15JLz23iAG4pK4V1IC1dVxL1Os/euY6UxYPp8sbSYg2Sw7eiq//3+V9O8Pt9+e6NIZ03UislxVJ7jti6Dj1JjYKitzZoT7+987B/3HcJLLuhL4Iz4uJ8cCfgennAL939vqvjMd15idPp1jl81t/ZvJ1maOXTaXHXVw0EIbpG/SjzXvm6QwezaMHu2+7zF8+FhAAzlRyyJXgN/9LkpnSx/l5fBJvvsQtqaiAXEuTRzMn9/pIlGASf+bb/35Ji1Z0DdJoawsdAx+DB/5NFIVyTj+MBSQiRMzfoiem7IyeObzFTRI5+zK7O21TrZfOmludt0sAfftxqQ6C/omaZSVwQ03hD5mXKTj+F20PEbKyy1bP4TXSnw0FvTttF3AGQOZLgl9fr/n31EgK8ySz8akKAv6JqnMng2XXRb6mAPZ1uUavwIycqQzKYBNqB5ScTEU7vHo14f0mZJ3xgzPhZeePGhqvEtjTFxY0DdJ55FH4I9/hIIC72PG8S4+FrCD3ii43poQAgiUlCALFsC778aj+Clv8mTYlOverw+g6TIlb4jX8d3edmFo0lNGZu83Njayfv169u7dm+iiGA+jRsEbb8Ann3h2uwLj+SdvhjxPv35tZutdvTqaRUwLBQUFDB8+nNzc3NZtZWUwe0wFN7zVtaGSqUbxHunRhaUdjEkpGRn0169fT9++fSktLUVsRY2kt3UrrFsHjY1de9xBB8Ehh8SmTOlAVamtrWX9+vUceuih7fbtPNcHb13q/eBJk9I6L+K66xJdAmNiIyOD/t69ey3gp5ABA5wbQH09rF8PO3d2XpoXnC6BoUP3H2+8iQgDBw5ky5YtnfZNngyf3jGQwS6T9AigS0NPbZz0wiQjTpkSp3IYE2cZGfQBC/gpqrAQPve5RJcifXj9H5SVwU1D5/CzjWnaxO+RxAfQTHbmfjGatGeJfAlQW1vLuHHjGDduHAcffDDDhg1rvd8QpQm/Tz75ZI444gjKyso48sgjue6669i+fXvYx/3oRz+KyvOb1HfcnDDzGLRZ6yDVeCUjKvBwvmXum/RlQT8BBg4cyIoVK1ixYgXTpk3j+uuvb72fl5dHU1NTVJ7H7/dTVVVFVVUV+fn5nH/++WEfY0HftAjVxN3SxJ+OHj3eMvdN+rJWrAhUVTnLb9bUOGOYJ0+O/pKbV155JQMGDOA///kP48ePp2/fvvTp04eZM2cCMHr0aJ5++mlKS0tZsGAB99xzDw0NDRx33HFUVlaSne09mUheXh4/+9nPOOyww1i5ciVjx47lggsuYN26dezdu5cZM2YwdepUbr75Zvbs2cO4ceMYNWoUfr/f9TiTOXbSm37sTnQxok4RxGWmhwBZlsRn0prV9MOoqoK774Zt22D4cOfn3Xc726Pt/fffZ8mSJcyePdvzmNWrV/OHP/yB1157jRUrVpCdnY0/ghnSsrOzGTt2LP/9738BePDBB1m+fDnLli3jnnvuoba2lp/85Cf06tWLFStWtJ7T7TiTOR46dl7U1jtIFjU/9rsGfIAsApbEZ9Ka1fTDWLTIGefdMta75eeiRdGv7V988cUha+wAS5cuZfny5RxzzDEA7NmzhwMPPDCi87ddRvmee+7hz3/+MwDr1q3jgw8+YODAgZ0eE+lxJj2d8hsf74z9EaNZ1S7xTYF3GIlWRf//INZ6/2iWZxLf5vwSDo5raYyJL6vph1FTA0VF7bcVFcVmldHevXu3/p6Tk0OgzTqzLRMJqSpXXHFFaw7Ae++9x+0RLPrd3NzM22+/zYgRI3j55ZdZsmQJr7/+OitXruSoo45ynago0uNM+iorg9/d8C5vd5j2WIDDsqr54I7Um4d/wK61rtsVeO3sivgWxpg4s6AfRnEx1NW131ZX52yPpdLSUt566y0A3nrrLdasWQPAxIkTWbhwIZ988gkAW7duZe1a9y+xFo2Njdxyyy0ccsghlJWVUVdXR//+/SksLOS///0vb7zxRuuxubm5NAZnwQl1nMkcs2fD4LzdnWrHvQL1HPvkLBYuTEixuqWqCmdqZhcBhMNvs5UXTXqzoB/G5MlOP/62bRAI7P998uTYPu9FF13E1q1bGTduHHPnzuVzwcHpI0eO5K677uL000+nrKyM0047jU2bNrmew+fzUVZWxujRo9m9ezd/+ctfAPjSl75EU1MTZWVl3HrrrRx//PGtj5k6dSplZWX4fL6Qx5nMcnCDe9PW8MBatn1tesoE/t+d7ifLoz9f0JTrqjCmq0TdpjVLIxMmTNBly5a127Z69WpGjBgR8Tnikb1vTKJE8v/QMLSUvE3ezeK/zSvnmn3JPdRt9mz4xsy+9GOX6/6GISXkbayOb6GMiQERWa6qE9z2WSJfBMrKLMibzJb38woCl17mWksW4KqGuVx+eSWPPBL/skVq9my4wSPgK85rNCbdWfO+MSY8n89zmBs4gf/YR6dz443xK1JXPbwpzAyCPuvPN+nPgr4xJiKNQ0o89wkwnbn84hdw+eXxK1OkFi6ESaT4IkHGRIEFfWNMRPJ+XhFyoh4BVjCKRx8lqWr8N94YvhIvffrEpzDGJJgFfWNMZHw+pM1cEh0JUMYqVjCKX/zC6UNPtIUL4d57IdQ6Vgpw//3xKpIxCWVB3xgTuXnzQu5uCfz3Mp2ZM52pqxM1nK+qCr79bWhshHuZ7nmcZGdbf77JGBb0jTGR8/mgvDzkIQJ8k7ncy3Q2bIAvfzlMP//06ZCdDSLhb9O9gzc4gb68HA4+GMaPh02b4Dkm8U3muvfni8DDD4d71cakDQv6CZKdnc24ceMYPXo0F198MfX19d0+15VXXsnCYHXqmmuuYdWqVZ7Hvvzyy/zzn//s8nOUlpby6aefum4fM2YMY8aMYeTIkXz/+99n3759Ic+1fft2Kiu7PqZbVTn11FPZsWMHACLCZZdd1rq/qamJwYMHc8455wCwefNmzjnnHMaOHcvIkSM566yzAKiurqZXr16MGzeu9fZIhGPNFi5ciIjQMvfDSy+91O48BQUFPPnkkwC8+OKLjB8/ntGjR3PFFVe4Lpncncdv27aNCy+8kLKyMo499ljeeecdwFkb4ZRTTmHEiBGMGjWKOXPmtD7PzJkzefHFFyN9q0OrrISJE8P273+TuQQQntVJPPqoE1+3SH9UpN2NuXOdma8iMXfu/guAnByYPp2qKrj4Yhg0yAn0998PmzdDczNcgp/TPRL4FODRR62WbzKLqqb17eijj9aOVq1a1WlbSAsWqJaUqIo4Pxcs6NrjXfTu3bv196997Ws6e/bsdvubmpoiPtcVV1yhf/zjHyM69rbbbtOf//znEZ+7RUlJiW7ZsiXk9p07d+oll1yil19+echzrVmzRkeNGtXlMjz99NP6ne98p/V+7969ddy4cVpfX6+qqosXL9axY8fq2WefraqqU6dO1V/96letx69cubJHz79jxw794he/qMcdd5y++eabnfbX1tZq//79dffu3drc3KzDhw/X9957T1VVb731Vn3ggQdCnj/Sx8+cOVNvv/12VVVdvXq1nnrqqaqqunHjRl2+fHlrWQ8//HB99913VVW1urpaTzvtNNfn7fL/Q4vsbFUIewt0uEXymEhvLedsBr2X8k6H1NEn5GONSUfAMvWIiQmp6YvIxSLyrogERGRCh323iMiHIvKeiJzRZvvRIvJ2cN89IhKf0Td+P0ydCmvXOl8Va9c69yNYzjZSX/ziF/nwww95+eWXOeWUU/ja177GmDFjaG5u5qabbuKYY46hrKyMecH+VFXluuuuY+TIkZx99tmt8/ADnHzyya210Oeee47x48czduxYJk6cSHV1Nffffz+//OUvGTduHK+++ipbtmzhoosu4phjjuGYY47htddeA6C2tpbTTz+do446imuvvbbdCn1e+vTpw/3338+TTz7J1q1b2bVrFxMnTmT8+PGMGTOmdRrgm2++mf/973+MGzeOm266yfO4jvx+P+eff367bWeeeSbPPPMMAI899hiXXHJJ675NmzYxfPjw1vtlPZxh6dZbb+X//u//KCgocN2/cOFCzjzzTAoLC6mtrSU/P791+uTTTjuNP/3pTyHPH+njV61axcSJEwE48sgjqa6uZvPmzQwZMoTx48cD0LdvX0aMGMGGDRsAKCkpoba2lo8//rhH70E7ETaLS4dbNLWcM4v9LQttb309JuNpeawxGcfraiCWN2AEcATwMjChzfaRwEogHzgU+B+QHdz3b+AEnP/VZ4EzI3muHtf0S0rcawolJZGfw0VLTb+xsVHPO+88rays1JdeekkLCwv1o48+UlXVefPm6Z133qmqqnv37tWjjz5aP/roI/3Tn/6kkyZN0qamJt2wYYMWFRW11vRPOukkffPNN/WTTz7R4cOHt56rtrZWVTvX9C+55BJ99dVXVVV17dq1euSRR6qq6re+9S294447VNWpYQNha/otxo4dq2+88YY2NjZqXV2dqqpu2bJFP/vZz2ogEOhU0/Y6rqPi4mLdsWNHu/dw5cqVetFFF+mePXt07Nix+tJLL7XW9J977jktKirSk08+We+66y7dsGGDqjo1/YKCAh07dmzr7ZVXXlFV1auvvtq1Fv/WW2/p5MmT273HHZ1yyin617/+VVVVA4GAFhcXtx737W9/W0ePHt3pMd15/C233KLXX3+9qqr+61//0uzsbF22bFm7c61Zs0YPOeSQ1vdVVfWaa67RhQsXdnrebtf0VVVHjoxqzT2utzatbcakE0LU9BMyDa+qrganT7aD84HHVXUfsEZEPgSOFZFqoJ+qvh583CPABTjBP7a81tDt4dq6e/bsYdy4cYBT07/66qv55z//ybHHHsuhhx4KwPPPP09VVVVrf31dXR0ffPABr7zyCpdccgnZ2dkMHTqUU089tdP533jjDU488cTWcw0YMMC1HEuWLGmXA7Bjxw527tzJK6+8wqJFiwA4++yz6d+/f8SvTYOtAqrK9773PV555RWysrLYsGEDmzdvdj3e7biDD26/svnWrVvp27dvu21lZWVUV1fz2GOPtfbZtzjjjDP46KOPeO6553j22Wc56qijWvu/P/vZz7JixYpOZXnggQc6bQsEAlx//fX87ne/83zNmzZt4u233+aMM5zGKRHh8ccf5/rrr2ffvn2cfvrp5OR4/7t15fE333wzM2bMYNy4cYwZM4ajjjqq3bl37drFRRddxK9+9Sv69evXuv3AAw9k48aNnmXolnffhVGjIEQeSdIKMxLBmHSUbHPvDwPart+6PritMfh7x+2uRGQqMBWguKdr4BYXO036btt7oFevXq5Bp3ebcdCqyr333tsaCFosXrzY7YKpHVUNeww4Ae3111+nV69enfZ1pwdl586dVFdX87nPfQ6/38+WLVtYvnw5ubm5lJaWsnfv3k6PifS4nJwcAoEAWVnte6XOO+88Zs6cycsvv0xtbW27fQMGDOBrX/saX/va1zjnnHN45ZVXOProo7v8mt555x1OPvlkAD7++GPOO+88nnrqKSZMcHqnnnjiCS688EJyc3NbH3fCCSfw6quvAs4F3Pvvv+/5HF15fL9+/XjooYcA53M+9NBDWy/uGhsbueiii/D5fEzusBTk3r17XT/nHnv3Xae764ornOy5HurYkRSTZviJEy2Bz2SkmPXpi8gSEXnH5XZ+qIe5bNMQ212p6nxVnaCqEwYPHtzVordXUQGFhe23FRY622PsjDPOYO7cua3r27///vvs3r2bE088kccff5zm5mY2bdrESy+91OmxJ5xwAn//+99Zs2YN4NSSwenr3blzZ+txp59+Ovfdd1/r/ZYLkRNPPBF/MG/h2WefZdu2bWHLu2vXLqZPn84FF1xA//79qaur48ADDyQ3N5eXXnqJtcGLp45l8DquoyOOOIKPPvqo0/arrrqKH/zgB4wZM6bd9hdffLF1VMTOnTv53//+162LwKKiIj799FOqq6uprq7m+OOPbxfwoXM+AdCaa7Fv3z5++tOfMm3aNM/n6Mrjt2/fTkNwtpkHHniAE088kX79+qGqXH311YwYMYIbbrih03O8//77jB49usuvPyI+HzQ1hR3O10JD3J5nIlkoWSg1DHU9pkfKy2HJkp6exZiUFLOgr6qTVHW0y809S8uxHjikzf3hwMbg9uEu22PP54P586GkxBkmVFLi3I9DLeGaa65h5MiRrcO2rr32Wpqamrjwwgs5/PDDGTNmDOXl5Zx00kmdHjt48GDmz5/P5MmTGTt2LF/5ylcAOPfcc/nzn//cmsh3zz33sGzZMsrKyhg5ciT3B2cmu+2223jllVcYP348zz//fMhgecoppzB69GiOPfZYiouLWxMOfT4fy5YtY8KECfj9fo488kgABg4cyOc//3lGjx7NTTfd5HlcR2effTYvv/xyp+3Dhw9nxowZnbYvX76cCRMmUFZWxgknnMA111zDMcccA9CaSNhyu+eee1rf845LMYdTXV3NunXrOn0OP//5zxkxYgRlZWWce+65rd0wy5Yt45prrun241evXs2oUaM48sgjefbZZ1uH5r322ms8+uijvPjii62va/HixYDTAvDhhx+2u1CJicpKp8c8mGjYUUvQrmJka2DvePsSS2hpZCplQ6f9bzOye8E/JwcWLHDKaEyGkpb+14Q8ucjLwExVXRa8Pwr4PXAsMBRYChyuqs0i8ibwLeBfwGLgXlVdHO45JkyYoB2/xCNZP9wkn02bNnH55ZfzwgsvJLooKefPf/4zb731FnfeeWenfSn7/+D3w7XXwu7d4Y/t08cZwG9N+iYDiMhyVXW9wk/UkL0LRWQ9Tjb+MyLyNwBVfRd4AlgFPAd8U1VbOgnLgQeAD3Gy+mOfxGeSypAhQ/jGN77ROjmPiVxTUxM3JtMqONHg88GuXZHl6u/caQHfGBJc048Hq+kbE5r9PxiTXpKupp8M0v1ix5hI2P+BMZklI4N+QUEBtbW19oVnMpqqUltb6znDoDEm/STbOP24GD58OOvXr2fLli2JLooxCVVQUNBuqmJjTHrLyKCfm5vbOpmJMcYYkykysnnfGGOMyUQW9I0xxpgMYUHfGGOMyRBpP05fRLYA7pO5d90g4NMonSuZ2etMP5nyWu11phd7nd1ToqquC8+kfdCPJhFZ5jXhQTqx15l+MuW12utML/Y6o8+a940xxpgMYUHfGGOMyRAW9LtmfqILECf2OtNPprxWe53pxV5nlFmfvjHGGJMhrKZvjDHGZAgL+iGIyMUi8q6IBETEM7NSRKpF5G0RWSEiy7yOS1ZdeJ1fEpH3RORDEbk5nmWMBhEZICIviMgHwZ/9PY5Lyc8z3OcjjnuC+6tEZHwiytlTEbzOk0WkLvj5rRCRHySinD0lIg+KyCci8o7H/nT5PMO9znT5PA8RkZdEZHXw+3aGyzGx/0xV1W4eN2AEcATwMjAhxHHVwKBElzeWrxPIBv4HfAbIA1YCIxNd9i6+zp8BNwd/vxn4abp8npF8PsBZwLOAAMcD/0p0uWP0Ok8Gnk50WaPwWk8ExgPveOxP+c8zwteZLp/nEGB88Pe+wPuJ+B+1mn4IqrpaVd9LdDliLcLXeSzwoap+pKoNwOPA+bEvXVSdDzwc/P1h4ILEFSXqIvl8zgceUccbwAEiMiTeBe2hdPg7jIiqvgJsDXFIOnyekbzOtKCqm1T1reDvO4HVwLAOh8X8M7WgHx0KPC8iy0VkaqILEyPDgHVt7q+n8x9ssjtIVTeB8w8IHOhxXCp+npF8PunwGUb6Gk4QkZUi8qyIjIpP0eIuHT7PSKXV5ykipcBRwL867Ir5Z5qRS+u2JSJLgINdds1S1b9EeJrPq+pGETkQeEFE/hu8ek0aUXid4rIt6YZ+hHqdXThN0n+eLiL5fFLiMwwjktfwFs40pLtE5CzgSeDwWBcsAdLh84xEWn2eItIH+BPwHVXd0XG3y0Oi+plmfNBX1UlROMfG4M9PROTPOE2QSRUkovA61wOHtLk/HNjYw3NGXajXKSKbRWSIqm4KNpl94nGOpP88XUTy+aTEZxhG2NfQ9otUVReLSKWIDFLVdJvDPR0+z7DS6fMUkVycgO9X1UUuh8T8M7Xm/R4Skd4i0rfld+B0wDULNcW9CRwuIoeKSB7wVeCpBJepq54Crgj+fgXQqYUjhT/PSD6fp4DLgxnCxwN1Ld0dKSTs6xSRg0VEgr8fi/M9Vxv3ksZeOnyeYaXL5xl8Db8FVqvqLzwOi/lnmvE1/VBE5ELgXmAw8IyIrFDVM0RkKPCAqp4FHAT8Ofg3mQP8XlWfS1ihuyGS16mqTSJyHfA3nAzqB1X13QQWuzt+AjwhIlcDNcDFAOnweXp9PiIyLbj/fmAxTnbwh0A98PVElbe7InydU4ByEWkC9gBf1WBqdCoRkcdwMtcHich64DYgF9Ln84SIXmdafJ7A54HLgLdFZEVw2/eAYojfZ2oz8hljjDEZwpr3jTHGmAxhQd8YY4zJEBb0jTHGmAxhQd8YY4zJEBb0jTHGmAxhQd8YEzXBlcTWiMiA4P3+wfsliS6bMcaCvjEmilR1HTAXZ04Egj/nq+raxJXKGNPCxukbY6IqONXocuBB4BvAUcEV8YwxCWYz8hljokpVG0XkJuA54HQL+MYkD2veN8bEwpnAJmB0ogtijNnPgr4xJqpEZBxwGnA8cH1wRUNjTBKwoG+MiZrgSmJzcdYKrwF+Dtyd2FIZY1pY0DfGRNM3gBpVfSF4vxI4UkROSmCZjDFBlr1vjDHGZAir6RtjjDEZwoK+McYYkyEs6BtjjDEZwoK+McYYkyEs6BtjjDEZwoK+McYYkyEs6BtjjDEZwoK+McYYkyH+P+v4daHJpM+ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_multimodalL_test, Y_multimodalL_test, label='True Data', color='blue', alpha=0.5)\n",
    "plt.scatter(X_multimodalL_test, Ypred, label=f'Predicted Data (MSE: {mse_value:.4f})', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Interactive MLP Regression for Square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ea6c143f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wykonania: 828.908015 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_multimodal2 = MLPNoBackprop(layer_sizes = [1, 26, 1], hidden_activation='tanh')\n",
    "start_time = time.time()\n",
    "mlp_multimodal2.mini_batch_GD(X_multimodalL_train_normalized, Y_multimodalL_train_normalized, 10, 13000, 0.001)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "01c4f45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.46038932023373\n"
     ]
    }
   ],
   "source": [
    "Ypred_normalized2 = mlp_multimodal2.predict(X_multimodalL_test_normalized)\n",
    "Ypred2 = (Ypred_normalized2 * np.std(Y_multimodalL_train)) + np.mean(Y_multimodalL_train)\n",
    "print(mlp_steps.mse(Ypred2, Y_multimodalL_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cfd164b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_multimodalL_test, Y_multimodalL_test, label='True Data', color='blue', alpha=0.5)\n",
    "plt.scatter(X_multimodalL_test, Ypred2, label=f'Predicted Data (MSE: {mse_value:.4f})', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Interactive MLP Regression for Square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a6425",
   "metadata": {},
   "source": [
    "# ----------------------------------------NN3--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0561d",
   "metadata": {},
   "source": [
    "### Now I have to implement two improvements to gradient-based learning: Momentum and gradient normalization using RMSprop I will be working on these datasets: square-large, steps-large and multimodal-large   Steps-large and Multimodal-Large have been already loaded. \n",
    "\n",
    "\n",
    "stepsL_train = pd.read_csv('steps-large-training.csv')  \n",
    "stepsL_test = pd.read_csv('steps-large-test.csv')  \n",
    "X_stepsL_train = np.array(stepsL_train[['x']])  \n",
    "Y_stepsL_train = np.array(stepsL_train[['y']])  \n",
    "X_stepsL_test = np.array(stepsL_test[['x']])  \n",
    "Y_stepsL_test = np.array(stepsL_test[['y']])  \n",
    "  \n",
    "  \n",
    "multimodalL_train = pd.read_csv('multimodal-large-training.csv')  \n",
    "multimodalL_test = pd.read_csv('multimodal-large-test.csv')  \n",
    "X_multimodalL_train = np.array(multimodalL_train[['x']])  \n",
    "Y_multimodalL_train = np.array(multimodalL_train[['y']])  \n",
    "X_multimodalL_test = np.array(multimodalL_test[['x']])  \n",
    "Y_multimodalL_test = np.array(multimodalL_test[['y']])  \n",
    "  \n",
    "### multimodal-large have been additionaly normalised\n",
    "X_multimodalL_train_normalized = (X_multimodalL_train-   np.mean(X_multimodalL_train))/(np.std(X_multimodalL_train))  \n",
    "Y_multimodalL_train_normalized = (Y_multimodalL_train-   np.mean(Y_multimodalL_train))/(np.std(Y_multimodalL_train))  \n",
    "X_multimodalL_test_normalized = (X_multimodalL_test-   np.mean(X_multimodalL_train))/(np.std(X_multimodalL_train))  \n",
    "Y_multimodalL_test_normalized = (Y_multimodalL_test-   np.mean(Y_multimodalL_train))/(np.std(Y_multimodalL_train))  \n",
    "\n",
    "### now i have to load square-large dataset and normalize it, just like the steps-large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7a6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "squareL_train =pd.read_csv('square-large-training.csv')\n",
    "squareL_test = pd.read_csv('square-large-test.csv')\n",
    "X_squareL_train = np.array(squareL_train[['x']])\n",
    "Y_squareL_train = np.array(squareL_train[['y']])\n",
    "X_squareL_test = np.array(squareL_test[['x']])\n",
    "Y_squareL_test =np.array(squareL_test[['y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114bc12c",
   "metadata": {},
   "source": [
    "### now lets normalize square-large and steps-large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6669f138",
   "metadata": {},
   "source": [
    "#### square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbfcbd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_squareL_train_normalized = (X_squareL_train- np.mean(X_squareL_train))/(np.std(X_squareL_train))\n",
    "Y_squareL_train_normalized = (Y_squareL_train- np.mean(Y_squareL_train))/(np.std(Y_squareL_train))\n",
    "X_squareL_test_normalized = (X_squareL_test- np.mean(X_squareL_train))/(np.std(X_squareL_train))\n",
    "Y_squareL_test_normalized = (Y_squareL_test- np.mean(Y_squareL_train))/(np.std(Y_squareL_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c7a0e",
   "metadata": {},
   "source": [
    "#### steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afdae01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stepsL_train_normalized = (X_stepsL_train- np.mean(X_stepsL_train))/(np.std(X_stepsL_train))\n",
    "Y_stepsL_train_normalized =(Y_stepsL_train - np.mean(Y_stepsL_train))/(np.std(Y_stepsL_train))\n",
    "X_stepsL_test_normalized = (X_stepsL_test - np.mean(X_stepsL_train))/(np.std(X_stepsL_train))\n",
    "Y_stepsL_test_normalized =(Y_stepsL_test - np.mean(Y_stepsL_train))/(np.std(Y_stepsL_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c388f45",
   "metadata": {},
   "source": [
    "## MLP for square_large trained using sgd with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "032ffb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22621232fd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X_squareL_train, Y_squareL_train, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86693a",
   "metadata": {},
   "source": [
    "#### miało być sgd ale dałam batcha 10 bo strasznie długo się liczyło"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736beb95",
   "metadata": {},
   "source": [
    "## momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "96f69264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 0.448105630\n",
      "Epoka 10: Loss = 0.006118061\n",
      "Epoka 20: Loss = 0.001042717\n",
      "Epoka 30: Loss = 0.000729126\n",
      "Epoka 40: Loss = 0.000586496\n",
      "Epoka 50: Loss = 0.000533271\n",
      "Epoka 60: Loss = 0.000520248\n",
      "Epoka 70: Loss = 0.000571519\n",
      "Epoka 80: Loss = 0.000470262\n",
      "Epoka 90: Loss = 0.000496940\n",
      "Epoka 100: Loss = 0.000503969\n",
      "Epoka 110: Loss = 0.000395058\n",
      "Epoka 120: Loss = 0.000472663\n",
      "Epoka 130: Loss = 0.000390923\n",
      "Epoka 140: Loss = 0.000463588\n",
      "Epoka 150: Loss = 0.000449806\n",
      "Epoka 160: Loss = 0.000330962\n",
      "Epoka 170: Loss = 0.000308071\n",
      "Epoka 180: Loss = 0.000533593\n",
      "Epoka 190: Loss = 0.000282947\n",
      "Epoka 200: Loss = 0.000280253\n",
      "Epoka 210: Loss = 0.000348157\n",
      "Epoka 220: Loss = 0.000250085\n",
      "Epoka 230: Loss = 0.000293016\n",
      "Epoka 240: Loss = 0.000311509\n",
      "Epoka 250: Loss = 0.000238481\n",
      "Epoka 260: Loss = 0.000245946\n",
      "Epoka 270: Loss = 0.000232444\n",
      "Epoka 280: Loss = 0.000212785\n",
      "Epoka 290: Loss = 0.000246781\n",
      "Epoka 300: Loss = 0.000290005\n",
      "Epoka 310: Loss = 0.000198222\n",
      "Epoka 320: Loss = 0.000307868\n",
      "Epoka 330: Loss = 0.000263964\n",
      "Epoka 340: Loss = 0.000233917\n",
      "Epoka 350: Loss = 0.000165786\n",
      "Epoka 360: Loss = 0.000228119\n",
      "Epoka 370: Loss = 0.000170296\n",
      "Epoka 380: Loss = 0.000201968\n",
      "Epoka 390: Loss = 0.000507492\n",
      "Epoka 400: Loss = 0.000151212\n",
      "Epoka 410: Loss = 0.000184202\n",
      "Epoka 420: Loss = 0.000143394\n",
      "Epoka 430: Loss = 0.000135247\n",
      "Epoka 440: Loss = 0.000156285\n",
      "Epoka 450: Loss = 0.000143725\n",
      "Epoka 460: Loss = 0.000176990\n",
      "Epoka 470: Loss = 0.000141765\n",
      "Epoka 480: Loss = 0.000192212\n",
      "Epoka 490: Loss = 0.000128693\n",
      "Epoka 500: Loss = 0.000113424\n",
      "Epoka 510: Loss = 0.000129397\n",
      "Epoka 520: Loss = 0.000111214\n",
      "Epoka 530: Loss = 0.000116503\n",
      "Epoka 540: Loss = 0.000102874\n",
      "Epoka 550: Loss = 0.000109118\n",
      "Epoka 560: Loss = 0.000139346\n",
      "Epoka 570: Loss = 0.000092700\n",
      "Epoka 580: Loss = 0.000088539\n",
      "Epoka 590: Loss = 0.000092535\n",
      "Epoka 600: Loss = 0.000084680\n",
      "Epoka 610: Loss = 0.000126731\n",
      "Epoka 620: Loss = 0.000089332\n",
      "Epoka 630: Loss = 0.000220218\n",
      "Epoka 640: Loss = 0.000120832\n",
      "Epoka 650: Loss = 0.000341238\n",
      "Epoka 660: Loss = 0.000075407\n",
      "Epoka 670: Loss = 0.000105126\n",
      "Epoka 680: Loss = 0.000074782\n",
      "Epoka 690: Loss = 0.000068675\n",
      "Epoka 700: Loss = 0.000069014\n",
      "Epoka 710: Loss = 0.000086136\n",
      "Epoka 720: Loss = 0.000070401\n",
      "Epoka 730: Loss = 0.000066666\n",
      "Epoka 740: Loss = 0.000105165\n",
      "Epoka 750: Loss = 0.000055453\n",
      "Epoka 760: Loss = 0.000053286\n",
      "Epoka 770: Loss = 0.000055900\n",
      "Epoka 780: Loss = 0.000058621\n",
      "Epoka 790: Loss = 0.000055603\n",
      "Epoka 800: Loss = 0.000045127\n",
      "Epoka 810: Loss = 0.000062643\n",
      "Epoka 820: Loss = 0.000056612\n",
      "Epoka 830: Loss = 0.000054639\n",
      "Epoka 840: Loss = 0.000050841\n",
      "Epoka 850: Loss = 0.000045592\n",
      "Epoka 860: Loss = 0.000055240\n",
      "Epoka 870: Loss = 0.000037051\n",
      "Epoka 880: Loss = 0.000077347\n",
      "Epoka 890: Loss = 0.000035468\n",
      "Epoka 900: Loss = 0.000031571\n",
      "Epoka 910: Loss = 0.000063589\n",
      "Epoka 920: Loss = 0.000029674\n",
      "Epoka 930: Loss = 0.000036288\n",
      "Epoka 940: Loss = 0.000027128\n",
      "Epoka 950: Loss = 0.000045267\n",
      "Epoka 960: Loss = 0.000026489\n",
      "Epoka 970: Loss = 0.000035337\n",
      "Epoka 980: Loss = 0.000024047\n",
      "Epoka 990: Loss = 0.000028817\n",
      "Epoka 1000: Loss = 0.000029397\n",
      "Epoka 1010: Loss = 0.000027964\n",
      "Epoka 1020: Loss = 0.000024145\n",
      "Epoka 1030: Loss = 0.000022443\n",
      "Epoka 1040: Loss = 0.000034421\n",
      "Epoka 1050: Loss = 0.000020117\n",
      "Epoka 1060: Loss = 0.000027830\n",
      "Epoka 1070: Loss = 0.000018774\n",
      "Epoka 1080: Loss = 0.000015935\n",
      "Epoka 1090: Loss = 0.000016887\n",
      "Epoka 1100: Loss = 0.000025737\n",
      "Epoka 1110: Loss = 0.000014889\n",
      "Epoka 1120: Loss = 0.000017397\n",
      "Epoka 1130: Loss = 0.000013852\n",
      "Epoka 1140: Loss = 0.000018690\n",
      "Epoka 1150: Loss = 0.000013247\n",
      "Epoka 1160: Loss = 0.000014761\n",
      "Epoka 1170: Loss = 0.000019245\n",
      "Epoka 1180: Loss = 0.000018527\n",
      "Epoka 1190: Loss = 0.000013811\n",
      "Epoka 1200: Loss = 0.000010278\n",
      "Epoka 1210: Loss = 0.000019692\n",
      "Epoka 1220: Loss = 0.000010860\n",
      "Epoka 1230: Loss = 0.000009336\n",
      "Epoka 1240: Loss = 0.000015747\n",
      "Epoka 1250: Loss = 0.000013062\n",
      "Epoka 1260: Loss = 0.000013522\n",
      "Epoka 1270: Loss = 0.000011551\n",
      "Epoka 1280: Loss = 0.000013868\n",
      "Epoka 1290: Loss = 0.000007847\n",
      "Epoka 1300: Loss = 0.000008024\n",
      "Epoka 1310: Loss = 0.000007890\n",
      "Epoka 1320: Loss = 0.000007441\n",
      "Epoka 1330: Loss = 0.000008877\n",
      "Epoka 1340: Loss = 0.000007447\n",
      "Epoka 1350: Loss = 0.000007030\n",
      "Epoka 1360: Loss = 0.000007656\n",
      "Epoka 1370: Loss = 0.000006886\n",
      "Epoka 1380: Loss = 0.000008163\n",
      "Epoka 1390: Loss = 0.000006521\n",
      "Epoka 1400: Loss = 0.000008722\n",
      "Epoka 1410: Loss = 0.000006927\n",
      "Epoka 1420: Loss = 0.000008309\n",
      "Epoka 1430: Loss = 0.000007252\n",
      "Epoka 1440: Loss = 0.000005504\n",
      "Epoka 1450: Loss = 0.000008740\n",
      "Epoka 1460: Loss = 0.000005175\n",
      "Epoka 1470: Loss = 0.000005994\n",
      "Epoka 1480: Loss = 0.000005895\n",
      "Epoka 1490: Loss = 0.000005208\n",
      "Epoka 1500: Loss = 0.000004872\n",
      "Epoka 1510: Loss = 0.000005595\n",
      "Epoka 1520: Loss = 0.000004886\n",
      "Epoka 1530: Loss = 0.000004693\n",
      "Epoka 1540: Loss = 0.000004788\n",
      "Epoka 1550: Loss = 0.000007214\n",
      "Epoka 1560: Loss = 0.000006153\n",
      "Epoka 1570: Loss = 0.000006614\n",
      "Epoka 1580: Loss = 0.000006202\n",
      "Epoka 1590: Loss = 0.000004658\n",
      "Epoka 1600: Loss = 0.000004846\n",
      "Epoka 1610: Loss = 0.000005695\n",
      "Epoka 1620: Loss = 0.000004955\n",
      "Epoka 1630: Loss = 0.000004147\n",
      "Epoka 1640: Loss = 0.000004445\n",
      "Epoka 1650: Loss = 0.000004560\n",
      "Epoka 1660: Loss = 0.000004806\n",
      "Epoka 1670: Loss = 0.000004860\n",
      "Epoka 1680: Loss = 0.000004344\n",
      "Epoka 1690: Loss = 0.000004319\n",
      "Epoka 1700: Loss = 0.000003889\n",
      "Epoka 1710: Loss = 0.000004285\n",
      "Epoka 1720: Loss = 0.000004031\n",
      "Epoka 1730: Loss = 0.000005282\n",
      "Epoka 1740: Loss = 0.000004353\n",
      "Epoka 1750: Loss = 0.000004097\n",
      "Epoka 1760: Loss = 0.000004825\n",
      "Epoka 1770: Loss = 0.000005423\n",
      "Epoka 1780: Loss = 0.000004496\n",
      "Epoka 1790: Loss = 0.000004105\n",
      "Epoka 1800: Loss = 0.000004138\n",
      "Epoka 1810: Loss = 0.000003841\n",
      "Epoka 1820: Loss = 0.000005289\n",
      "Epoka 1830: Loss = 0.000004943\n",
      "Epoka 1840: Loss = 0.000004135\n",
      "Epoka 1850: Loss = 0.000004513\n",
      "Epoka 1860: Loss = 0.000004167\n",
      "Epoka 1870: Loss = 0.000005138\n",
      "Epoka 1880: Loss = 0.000003530\n",
      "Epoka 1890: Loss = 0.000003666\n",
      "Epoka 1900: Loss = 0.000005215\n",
      "Epoka 1910: Loss = 0.000011176\n",
      "Epoka 1920: Loss = 0.000004485\n",
      "Epoka 1930: Loss = 0.000004411\n",
      "Epoka 1940: Loss = 0.000003795\n",
      "Epoka 1950: Loss = 0.000004297\n",
      "Epoka 1960: Loss = 0.000003641\n",
      "Epoka 1970: Loss = 0.000003533\n",
      "Epoka 1980: Loss = 0.000003704\n",
      "Epoka 1990: Loss = 0.000003943\n",
      "Epoka 2000: Loss = 0.000005859\n",
      "Epoka 2010: Loss = 0.000003542\n",
      "Epoka 2020: Loss = 0.000003674\n",
      "Epoka 2030: Loss = 0.000003437\n",
      "Epoka 2040: Loss = 0.000003769\n",
      "Epoka 2050: Loss = 0.000004140\n",
      "Epoka 2060: Loss = 0.000004089\n",
      "Epoka 2070: Loss = 0.000003689\n",
      "Epoka 2080: Loss = 0.000003452\n",
      "Epoka 2090: Loss = 0.000004078\n",
      "Epoka 2100: Loss = 0.000003866\n",
      "Epoka 2110: Loss = 0.000003636\n",
      "Epoka 2120: Loss = 0.000004167\n",
      "Epoka 2130: Loss = 0.000003853\n",
      "Epoka 2140: Loss = 0.000003423\n",
      "Epoka 2150: Loss = 0.000004086\n",
      "Epoka 2160: Loss = 0.000005054\n",
      "Epoka 2170: Loss = 0.000003700\n",
      "Epoka 2180: Loss = 0.000004085\n",
      "Epoka 2190: Loss = 0.000003190\n",
      "Epoka 2200: Loss = 0.000003364\n",
      "Epoka 2210: Loss = 0.000003909\n",
      "Epoka 2220: Loss = 0.000004325\n",
      "Epoka 2230: Loss = 0.000004735\n",
      "Epoka 2240: Loss = 0.000003597\n",
      "Epoka 2250: Loss = 0.000003080\n",
      "Epoka 2260: Loss = 0.000004064\n",
      "Epoka 2270: Loss = 0.000003333\n",
      "Epoka 2280: Loss = 0.000003151\n",
      "Epoka 2290: Loss = 0.000003272\n",
      "Epoka 2300: Loss = 0.000004029\n",
      "Epoka 2310: Loss = 0.000004469\n",
      "Epoka 2320: Loss = 0.000003306\n",
      "Epoka 2330: Loss = 0.000003098\n",
      "Epoka 2340: Loss = 0.000003098\n",
      "Epoka 2350: Loss = 0.000003333\n",
      "Epoka 2360: Loss = 0.000003155\n",
      "Epoka 2370: Loss = 0.000003112\n",
      "Epoka 2380: Loss = 0.000003061\n",
      "Epoka 2390: Loss = 0.000003684\n",
      "Epoka 2400: Loss = 0.000003148\n",
      "Epoka 2410: Loss = 0.000004093\n",
      "Epoka 2420: Loss = 0.000003406\n",
      "Epoka 2430: Loss = 0.000004639\n",
      "Epoka 2440: Loss = 0.000005507\n",
      "Epoka 2450: Loss = 0.000003258\n",
      "Epoka 2460: Loss = 0.000004056\n",
      "Epoka 2470: Loss = 0.000003504\n",
      "Epoka 2480: Loss = 0.000003080\n",
      "Epoka 2490: Loss = 0.000003680\n",
      "Epoka 2500: Loss = 0.000003822\n",
      "Epoka 2510: Loss = 0.000005529\n",
      "Epoka 2520: Loss = 0.000002973\n",
      "Epoka 2530: Loss = 0.000004642\n",
      "Epoka 2540: Loss = 0.000003432\n",
      "Epoka 2550: Loss = 0.000003586\n",
      "Epoka 2560: Loss = 0.000003913\n",
      "Epoka 2570: Loss = 0.000003256\n",
      "Epoka 2580: Loss = 0.000008660\n",
      "Epoka 2590: Loss = 0.000003386\n",
      "Epoka 2600: Loss = 0.000002909\n",
      "Epoka 2610: Loss = 0.000004210\n",
      "Epoka 2620: Loss = 0.000003423\n",
      "Epoka 2630: Loss = 0.000003005\n",
      "Epoka 2640: Loss = 0.000003264\n",
      "Epoka 2650: Loss = 0.000002950\n",
      "Epoka 2660: Loss = 0.000003367\n",
      "Epoka 2670: Loss = 0.000003353\n",
      "Epoka 2680: Loss = 0.000004998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 2690: Loss = 0.000004111\n",
      "Epoka 2700: Loss = 0.000003704\n",
      "Epoka 2710: Loss = 0.000002917\n",
      "Epoka 2720: Loss = 0.000003228\n",
      "Epoka 2730: Loss = 0.000003655\n",
      "Epoka 2740: Loss = 0.000003264\n",
      "Epoka 2750: Loss = 0.000003053\n",
      "Epoka 2760: Loss = 0.000003686\n",
      "Epoka 2770: Loss = 0.000002927\n",
      "Epoka 2780: Loss = 0.000002863\n",
      "Epoka 2790: Loss = 0.000002893\n",
      "Epoka 2800: Loss = 0.000003142\n",
      "Epoka 2810: Loss = 0.000003307\n",
      "Epoka 2820: Loss = 0.000003305\n",
      "Epoka 2830: Loss = 0.000003096\n",
      "Epoka 2840: Loss = 0.000003213\n",
      "Epoka 2850: Loss = 0.000002940\n",
      "Epoka 2860: Loss = 0.000002717\n",
      "Epoka 2870: Loss = 0.000003428\n",
      "Epoka 2880: Loss = 0.000003041\n",
      "Epoka 2890: Loss = 0.000004357\n",
      "Epoka 2900: Loss = 0.000003025\n",
      "Epoka 2910: Loss = 0.000004536\n",
      "Epoka 2920: Loss = 0.000002892\n",
      "Epoka 2930: Loss = 0.000004883\n",
      "Epoka 2940: Loss = 0.000003970\n",
      "Epoka 2950: Loss = 0.000003520\n",
      "Epoka 2960: Loss = 0.000002782\n",
      "Epoka 2970: Loss = 0.000004666\n",
      "Epoka 2980: Loss = 0.000002642\n",
      "Epoka 2990: Loss = 0.000003315\n",
      "Epoka 3000: Loss = 0.000003094\n",
      "Epoka 3010: Loss = 0.000003149\n",
      "Epoka 3020: Loss = 0.000004019\n",
      "Epoka 3030: Loss = 0.000002686\n",
      "Epoka 3040: Loss = 0.000003443\n",
      "Epoka 3050: Loss = 0.000003380\n",
      "Epoka 3060: Loss = 0.000002775\n",
      "Epoka 3070: Loss = 0.000003064\n",
      "Epoka 3080: Loss = 0.000004548\n",
      "Epoka 3090: Loss = 0.000002579\n",
      "Epoka 3100: Loss = 0.000002800\n",
      "Epoka 3110: Loss = 0.000003416\n",
      "Epoka 3120: Loss = 0.000005328\n",
      "Epoka 3130: Loss = 0.000003620\n",
      "Epoka 3140: Loss = 0.000003160\n",
      "Epoka 3150: Loss = 0.000003259\n",
      "Epoka 3160: Loss = 0.000002786\n",
      "Epoka 3170: Loss = 0.000002581\n",
      "Epoka 3180: Loss = 0.000002775\n",
      "Epoka 3190: Loss = 0.000002758\n",
      "Epoka 3200: Loss = 0.000002896\n",
      "Epoka 3210: Loss = 0.000005381\n",
      "Epoka 3220: Loss = 0.000002660\n",
      "Epoka 3230: Loss = 0.000002985\n",
      "Epoka 3240: Loss = 0.000003787\n",
      "Epoka 3250: Loss = 0.000003541\n",
      "Epoka 3260: Loss = 0.000003059\n",
      "Epoka 3270: Loss = 0.000002501\n",
      "Epoka 3280: Loss = 0.000005939\n",
      "Epoka 3290: Loss = 0.000002918\n",
      "Epoka 3300: Loss = 0.000002484\n",
      "Epoka 3310: Loss = 0.000002898\n",
      "Epoka 3320: Loss = 0.000003871\n",
      "Epoka 3330: Loss = 0.000002699\n",
      "Epoka 3340: Loss = 0.000002622\n",
      "Epoka 3350: Loss = 0.000002641\n",
      "Epoka 3360: Loss = 0.000002963\n",
      "Epoka 3370: Loss = 0.000003233\n",
      "Epoka 3380: Loss = 0.000002734\n",
      "Epoka 3390: Loss = 0.000002941\n",
      "Epoka 3400: Loss = 0.000006912\n",
      "Epoka 3410: Loss = 0.000002435\n",
      "Epoka 3420: Loss = 0.000003149\n",
      "Epoka 3430: Loss = 0.000002742\n",
      "Epoka 3440: Loss = 0.000005623\n",
      "Epoka 3450: Loss = 0.000002458\n",
      "Epoka 3460: Loss = 0.000002795\n",
      "Epoka 3470: Loss = 0.000002551\n",
      "Epoka 3480: Loss = 0.000002504\n",
      "Epoka 3490: Loss = 0.000002619\n",
      "Epoka 3500: Loss = 0.000003029\n",
      "Epoka 3510: Loss = 0.000003357\n",
      "Epoka 3520: Loss = 0.000002736\n",
      "Epoka 3530: Loss = 0.000002882\n",
      "Epoka 3540: Loss = 0.000002666\n",
      "Epoka 3550: Loss = 0.000002533\n",
      "Epoka 3560: Loss = 0.000003697\n",
      "Epoka 3570: Loss = 0.000003041\n",
      "Epoka 3580: Loss = 0.000003227\n",
      "Epoka 3590: Loss = 0.000003234\n",
      "Epoka 3600: Loss = 0.000003699\n",
      "Epoka 3610: Loss = 0.000002419\n",
      "Epoka 3620: Loss = 0.000002472\n",
      "Epoka 3630: Loss = 0.000002536\n",
      "Epoka 3640: Loss = 0.000003310\n",
      "Epoka 3650: Loss = 0.000002691\n",
      "Epoka 3660: Loss = 0.000002523\n",
      "Epoka 3670: Loss = 0.000004782\n",
      "Epoka 3680: Loss = 0.000002413\n",
      "Epoka 3690: Loss = 0.000002703\n",
      "Epoka 3700: Loss = 0.000002997\n",
      "Epoka 3710: Loss = 0.000002606\n",
      "Epoka 3720: Loss = 0.000003182\n",
      "Epoka 3730: Loss = 0.000003982\n",
      "Epoka 3740: Loss = 0.000002414\n",
      "Epoka 3750: Loss = 0.000002845\n",
      "Epoka 3760: Loss = 0.000002308\n",
      "Epoka 3770: Loss = 0.000002369\n",
      "Epoka 3780: Loss = 0.000004199\n",
      "Epoka 3790: Loss = 0.000002507\n",
      "Epoka 3800: Loss = 0.000002475\n",
      "Epoka 3810: Loss = 0.000002831\n",
      "Epoka 3820: Loss = 0.000003008\n",
      "Epoka 3830: Loss = 0.000003015\n",
      "Epoka 3840: Loss = 0.000002348\n",
      "Epoka 3850: Loss = 0.000002662\n",
      "Epoka 3860: Loss = 0.000002208\n",
      "Epoka 3870: Loss = 0.000003157\n",
      "Epoka 3880: Loss = 0.000002362\n",
      "Epoka 3890: Loss = 0.000003323\n",
      "Epoka 3900: Loss = 0.000002253\n",
      "Epoka 3910: Loss = 0.000002532\n",
      "Epoka 3920: Loss = 0.000002181\n",
      "Epoka 3930: Loss = 0.000002159\n",
      "Epoka 3940: Loss = 0.000002607\n",
      "Epoka 3950: Loss = 0.000003462\n",
      "Epoka 3960: Loss = 0.000003705\n",
      "Epoka 3970: Loss = 0.000003157\n",
      "Epoka 3980: Loss = 0.000002229\n",
      "Epoka 3990: Loss = 0.000002509\n",
      "Epoka 4000: Loss = 0.000002198\n",
      "Epoka 4010: Loss = 0.000002306\n",
      "Epoka 4020: Loss = 0.000003162\n",
      "Epoka 4030: Loss = 0.000002252\n",
      "Epoka 4040: Loss = 0.000002249\n",
      "Epoka 4050: Loss = 0.000002843\n",
      "Epoka 4060: Loss = 0.000002348\n",
      "Epoka 4070: Loss = 0.000002719\n",
      "Epoka 4080: Loss = 0.000002134\n",
      "Epoka 4090: Loss = 0.000003280\n",
      "Epoka 4100: Loss = 0.000002654\n",
      "Epoka 4110: Loss = 0.000002247\n",
      "Epoka 4120: Loss = 0.000002468\n",
      "Epoka 4130: Loss = 0.000002246\n",
      "Epoka 4140: Loss = 0.000002333\n",
      "Epoka 4150: Loss = 0.000002781\n",
      "Epoka 4160: Loss = 0.000002204\n",
      "Epoka 4170: Loss = 0.000002448\n",
      "Epoka 4180: Loss = 0.000002344\n",
      "Epoka 4190: Loss = 0.000002299\n",
      "Epoka 4200: Loss = 0.000002383\n",
      "Epoka 4210: Loss = 0.000002498\n",
      "Epoka 4220: Loss = 0.000002366\n",
      "Epoka 4230: Loss = 0.000002443\n",
      "Epoka 4240: Loss = 0.000002280\n",
      "Epoka 4250: Loss = 0.000002295\n",
      "Epoka 4260: Loss = 0.000002729\n",
      "Epoka 4270: Loss = 0.000002098\n",
      "Epoka 4280: Loss = 0.000002412\n",
      "Epoka 4290: Loss = 0.000002069\n",
      "Epoka 4300: Loss = 0.000002507\n",
      "Epoka 4310: Loss = 0.000002359\n",
      "Epoka 4320: Loss = 0.000002133\n",
      "Epoka 4330: Loss = 0.000002375\n",
      "Epoka 4340: Loss = 0.000002071\n",
      "Epoka 4350: Loss = 0.000002807\n",
      "Epoka 4360: Loss = 0.000002523\n",
      "Epoka 4370: Loss = 0.000002340\n",
      "Epoka 4380: Loss = 0.000002328\n",
      "Epoka 4390: Loss = 0.000002140\n",
      "Epoka 4400: Loss = 0.000002310\n",
      "Epoka 4410: Loss = 0.000002006\n",
      "Epoka 4420: Loss = 0.000003083\n",
      "Epoka 4430: Loss = 0.000002496\n",
      "Epoka 4440: Loss = 0.000002001\n",
      "Epoka 4450: Loss = 0.000002590\n",
      "Epoka 4460: Loss = 0.000002002\n",
      "Epoka 4470: Loss = 0.000002347\n",
      "Epoka 4480: Loss = 0.000003887\n",
      "Epoka 4490: Loss = 0.000002131\n",
      "Epoka 4500: Loss = 0.000002265\n",
      "Epoka 4510: Loss = 0.000002455\n",
      "Epoka 4520: Loss = 0.000004716\n",
      "Epoka 4530: Loss = 0.000002154\n",
      "Epoka 4540: Loss = 0.000004017\n",
      "Epoka 4550: Loss = 0.000002384\n",
      "Epoka 4560: Loss = 0.000004280\n",
      "Epoka 4570: Loss = 0.000002570\n",
      "Epoka 4580: Loss = 0.000002148\n",
      "Epoka 4590: Loss = 0.000003317\n",
      "Epoka 4600: Loss = 0.000002959\n",
      "Epoka 4610: Loss = 0.000002008\n",
      "Epoka 4620: Loss = 0.000002247\n",
      "Epoka 4630: Loss = 0.000002048\n",
      "Epoka 4640: Loss = 0.000002117\n",
      "Epoka 4650: Loss = 0.000001996\n",
      "Epoka 4660: Loss = 0.000002063\n",
      "Epoka 4670: Loss = 0.000002397\n",
      "Epoka 4680: Loss = 0.000001957\n",
      "Epoka 4690: Loss = 0.000002044\n",
      "Epoka 4700: Loss = 0.000002342\n",
      "Epoka 4710: Loss = 0.000002233\n",
      "Epoka 4720: Loss = 0.000002734\n",
      "Epoka 4730: Loss = 0.000001936\n",
      "Epoka 4740: Loss = 0.000002329\n",
      "Epoka 4750: Loss = 0.000002907\n",
      "Epoka 4760: Loss = 0.000002830\n",
      "Epoka 4770: Loss = 0.000002717\n",
      "Epoka 4780: Loss = 0.000002001\n",
      "Epoka 4790: Loss = 0.000002188\n",
      "Epoka 4800: Loss = 0.000002228\n",
      "Epoka 4810: Loss = 0.000002152\n",
      "Epoka 4820: Loss = 0.000001968\n",
      "Epoka 4830: Loss = 0.000002460\n",
      "Epoka 4840: Loss = 0.000001900\n",
      "Epoka 4850: Loss = 0.000001962\n",
      "Epoka 4860: Loss = 0.000003170\n",
      "Epoka 4870: Loss = 0.000003586\n",
      "Epoka 4880: Loss = 0.000001905\n",
      "Epoka 4890: Loss = 0.000002590\n",
      "Epoka 4900: Loss = 0.000002160\n",
      "Epoka 4910: Loss = 0.000002849\n",
      "Epoka 4920: Loss = 0.000002190\n",
      "Epoka 4930: Loss = 0.000003789\n",
      "Epoka 4940: Loss = 0.000002931\n",
      "Epoka 4950: Loss = 0.000002025\n",
      "Epoka 4960: Loss = 0.000002231\n",
      "Epoka 4970: Loss = 0.000002481\n",
      "Epoka 4980: Loss = 0.000002835\n",
      "Epoka 4990: Loss = 0.000002152\n",
      "Epoka 5000: Loss = 0.000001928\n",
      "Epoka 5010: Loss = 0.000001865\n",
      "Epoka 5020: Loss = 0.000001850\n",
      "Epoka 5030: Loss = 0.000001965\n",
      "Epoka 5040: Loss = 0.000002042\n",
      "Epoka 5050: Loss = 0.000003764\n",
      "Epoka 5060: Loss = 0.000002177\n",
      "Epoka 5070: Loss = 0.000002353\n",
      "Epoka 5080: Loss = 0.000001936\n",
      "Epoka 5090: Loss = 0.000002173\n",
      "Epoka 5100: Loss = 0.000004142\n",
      "Epoka 5110: Loss = 0.000002269\n",
      "Epoka 5120: Loss = 0.000001882\n",
      "Epoka 5130: Loss = 0.000001954\n",
      "Epoka 5140: Loss = 0.000001961\n",
      "Epoka 5150: Loss = 0.000002518\n",
      "Epoka 5160: Loss = 0.000001778\n",
      "Epoka 5170: Loss = 0.000002148\n",
      "Epoka 5180: Loss = 0.000001859\n",
      "Epoka 5190: Loss = 0.000002289\n",
      "Epoka 5200: Loss = 0.000002278\n",
      "Epoka 5210: Loss = 0.000002329\n",
      "Epoka 5220: Loss = 0.000001862\n",
      "Epoka 5230: Loss = 0.000001884\n",
      "Epoka 5240: Loss = 0.000002632\n",
      "Epoka 5250: Loss = 0.000002415\n",
      "Epoka 5260: Loss = 0.000001835\n",
      "Epoka 5270: Loss = 0.000002114\n",
      "Epoka 5280: Loss = 0.000005436\n",
      "Epoka 5290: Loss = 0.000001843\n",
      "Epoka 5300: Loss = 0.000001796\n",
      "Epoka 5310: Loss = 0.000001772\n",
      "Epoka 5320: Loss = 0.000003384\n",
      "Epoka 5330: Loss = 0.000001752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 5340: Loss = 0.000002165\n",
      "Epoka 5350: Loss = 0.000001859\n",
      "Epoka 5360: Loss = 0.000002248\n",
      "Epoka 5370: Loss = 0.000005205\n",
      "Epoka 5380: Loss = 0.000005218\n",
      "Epoka 5390: Loss = 0.000001824\n",
      "Epoka 5400: Loss = 0.000002064\n",
      "Epoka 5410: Loss = 0.000001779\n",
      "Epoka 5420: Loss = 0.000001993\n",
      "Epoka 5430: Loss = 0.000003311\n",
      "Epoka 5440: Loss = 0.000001725\n",
      "Epoka 5450: Loss = 0.000002415\n",
      "Epoka 5460: Loss = 0.000001996\n",
      "Epoka 5470: Loss = 0.000001755\n",
      "Epoka 5480: Loss = 0.000002064\n",
      "Epoka 5490: Loss = 0.000002021\n",
      "Epoka 5500: Loss = 0.000002341\n",
      "Epoka 5510: Loss = 0.000002145\n",
      "Epoka 5520: Loss = 0.000001705\n",
      "Epoka 5530: Loss = 0.000002189\n",
      "Epoka 5540: Loss = 0.000002200\n",
      "Epoka 5550: Loss = 0.000002413\n",
      "Epoka 5560: Loss = 0.000001821\n",
      "Epoka 5570: Loss = 0.000001859\n",
      "Epoka 5580: Loss = 0.000002358\n",
      "Epoka 5590: Loss = 0.000002491\n",
      "Epoka 5600: Loss = 0.000001677\n",
      "Epoka 5610: Loss = 0.000001686\n",
      "Epoka 5620: Loss = 0.000001776\n",
      "Epoka 5630: Loss = 0.000002968\n",
      "Epoka 5640: Loss = 0.000001784\n",
      "Epoka 5650: Loss = 0.000001887\n",
      "Epoka 5660: Loss = 0.000001737\n",
      "Epoka 5670: Loss = 0.000001748\n",
      "Epoka 5680: Loss = 0.000002233\n",
      "Epoka 5690: Loss = 0.000001952\n",
      "Epoka 5700: Loss = 0.000001669\n",
      "Epoka 5710: Loss = 0.000002468\n",
      "Epoka 5720: Loss = 0.000002895\n",
      "Epoka 5730: Loss = 0.000001748\n",
      "Epoka 5740: Loss = 0.000001761\n",
      "Epoka 5750: Loss = 0.000001910\n",
      "Epoka 5760: Loss = 0.000001976\n",
      "Epoka 5770: Loss = 0.000001774\n",
      "Epoka 5780: Loss = 0.000003475\n",
      "Epoka 5790: Loss = 0.000002414\n",
      "Epoka 5800: Loss = 0.000002526\n",
      "Epoka 5810: Loss = 0.000002226\n",
      "Epoka 5820: Loss = 0.000001754\n",
      "Epoka 5830: Loss = 0.000001945\n",
      "Epoka 5840: Loss = 0.000001686\n",
      "Epoka 5850: Loss = 0.000001687\n",
      "Epoka 5860: Loss = 0.000002286\n",
      "Epoka 5870: Loss = 0.000001811\n",
      "Epoka 5880: Loss = 0.000001769\n",
      "Epoka 5890: Loss = 0.000001769\n",
      "Epoka 5900: Loss = 0.000002113\n",
      "Epoka 5910: Loss = 0.000002596\n",
      "Epoka 5920: Loss = 0.000002558\n",
      "Epoka 5930: Loss = 0.000003576\n",
      "Epoka 5940: Loss = 0.000003193\n",
      "Epoka 5950: Loss = 0.000001802\n",
      "Epoka 5960: Loss = 0.000001894\n",
      "Epoka 5970: Loss = 0.000001803\n",
      "Epoka 5980: Loss = 0.000001764\n",
      "Epoka 5990: Loss = 0.000001718\n",
      "Epoka 6000: Loss = 0.000001823\n",
      "Epoka 6010: Loss = 0.000001612\n",
      "Epoka 6020: Loss = 0.000001582\n",
      "Epoka 6030: Loss = 0.000001717\n",
      "Epoka 6040: Loss = 0.000001735\n",
      "Epoka 6050: Loss = 0.000001873\n",
      "Epoka 6060: Loss = 0.000002698\n",
      "Epoka 6070: Loss = 0.000002611\n",
      "Epoka 6080: Loss = 0.000002067\n",
      "Epoka 6090: Loss = 0.000001594\n",
      "Epoka 6100: Loss = 0.000001617\n",
      "Epoka 6110: Loss = 0.000002856\n",
      "Epoka 6120: Loss = 0.000001830\n",
      "Epoka 6130: Loss = 0.000001937\n",
      "Epoka 6140: Loss = 0.000001855\n",
      "Epoka 6150: Loss = 0.000003691\n",
      "Epoka 6160: Loss = 0.000002397\n",
      "Epoka 6170: Loss = 0.000002275\n",
      "Epoka 6180: Loss = 0.000002243\n",
      "Epoka 6190: Loss = 0.000001536\n",
      "Epoka 6200: Loss = 0.000001954\n",
      "Epoka 6210: Loss = 0.000001774\n",
      "Epoka 6220: Loss = 0.000001787\n",
      "Epoka 6230: Loss = 0.000002029\n",
      "Epoka 6240: Loss = 0.000001684\n",
      "Epoka 6250: Loss = 0.000001523\n",
      "Epoka 6260: Loss = 0.000001918\n",
      "Epoka 6270: Loss = 0.000001740\n",
      "Epoka 6280: Loss = 0.000001731\n",
      "Epoka 6290: Loss = 0.000002003\n",
      "Epoka 6300: Loss = 0.000001705\n",
      "Epoka 6310: Loss = 0.000002647\n",
      "Epoka 6320: Loss = 0.000001735\n",
      "Epoka 6330: Loss = 0.000001542\n",
      "Epoka 6340: Loss = 0.000002025\n",
      "Epoka 6350: Loss = 0.000001730\n",
      "Epoka 6360: Loss = 0.000001929\n",
      "Epoka 6370: Loss = 0.000001595\n",
      "Epoka 6380: Loss = 0.000001627\n",
      "Epoka 6390: Loss = 0.000002093\n",
      "Epoka 6400: Loss = 0.000002003\n",
      "Epoka 6410: Loss = 0.000001546\n",
      "Epoka 6420: Loss = 0.000001554\n",
      "Epoka 6430: Loss = 0.000001947\n",
      "Epoka 6440: Loss = 0.000003141\n",
      "Epoka 6450: Loss = 0.000001500\n",
      "Epoka 6460: Loss = 0.000001537\n",
      "Epoka 6470: Loss = 0.000001796\n",
      "Epoka 6480: Loss = 0.000001498\n",
      "Epoka 6490: Loss = 0.000002566\n",
      "Epoka 6500: Loss = 0.000002343\n",
      "Epoka 6510: Loss = 0.000001600\n",
      "Epoka 6520: Loss = 0.000001892\n",
      "Epoka 6530: Loss = 0.000002761\n",
      "Epoka 6540: Loss = 0.000001467\n",
      "Epoka 6550: Loss = 0.000001759\n",
      "Epoka 6560: Loss = 0.000001588\n",
      "Epoka 6570: Loss = 0.000001482\n",
      "Epoka 6580: Loss = 0.000001932\n",
      "Epoka 6590: Loss = 0.000001533\n",
      "Epoka 6600: Loss = 0.000002160\n",
      "Epoka 6610: Loss = 0.000001807\n",
      "Epoka 6620: Loss = 0.000003175\n",
      "Epoka 6630: Loss = 0.000001559\n",
      "Epoka 6640: Loss = 0.000001666\n",
      "Epoka 6650: Loss = 0.000001728\n",
      "Epoka 6660: Loss = 0.000001546\n",
      "Epoka 6670: Loss = 0.000001499\n",
      "Epoka 6680: Loss = 0.000001861\n",
      "Epoka 6690: Loss = 0.000001983\n",
      "Epoka 6700: Loss = 0.000001445\n",
      "Epoka 6710: Loss = 0.000001621\n",
      "Epoka 6720: Loss = 0.000001495\n",
      "Epoka 6730: Loss = 0.000001897\n",
      "Epoka 6740: Loss = 0.000002122\n",
      "Epoka 6750: Loss = 0.000001902\n",
      "Epoka 6760: Loss = 0.000001781\n",
      "Epoka 6770: Loss = 0.000001647\n",
      "Epoka 6780: Loss = 0.000001544\n",
      "Epoka 6790: Loss = 0.000002175\n",
      "Epoka 6800: Loss = 0.000001487\n",
      "Epoka 6810: Loss = 0.000001815\n",
      "Epoka 6820: Loss = 0.000001509\n",
      "Epoka 6830: Loss = 0.000003437\n",
      "Epoka 6840: Loss = 0.000002241\n",
      "Epoka 6850: Loss = 0.000001583\n",
      "Epoka 6860: Loss = 0.000001557\n",
      "Epoka 6870: Loss = 0.000001519\n",
      "Epoka 6880: Loss = 0.000001546\n",
      "Epoka 6890: Loss = 0.000001477\n",
      "Epoka 6900: Loss = 0.000001953\n",
      "Epoka 6910: Loss = 0.000001632\n",
      "Epoka 6920: Loss = 0.000002103\n",
      "Epoka 6930: Loss = 0.000001466\n",
      "Epoka 6940: Loss = 0.000001420\n",
      "Epoka 6950: Loss = 0.000001837\n",
      "Epoka 6960: Loss = 0.000001419\n",
      "Epoka 6970: Loss = 0.000001424\n",
      "Epoka 6980: Loss = 0.000001585\n",
      "Epoka 6990: Loss = 0.000001840\n",
      "Epoka 7000: Loss = 0.000001570\n",
      "Epoka 7010: Loss = 0.000001804\n",
      "Epoka 7020: Loss = 0.000001793\n",
      "Epoka 7030: Loss = 0.000001712\n",
      "Epoka 7040: Loss = 0.000001473\n",
      "Epoka 7050: Loss = 0.000001433\n",
      "Epoka 7060: Loss = 0.000003344\n",
      "Epoka 7070: Loss = 0.000001722\n",
      "Epoka 7080: Loss = 0.000002625\n",
      "Epoka 7090: Loss = 0.000001384\n",
      "Epoka 7100: Loss = 0.000002110\n",
      "Epoka 7110: Loss = 0.000001374\n",
      "Epoka 7120: Loss = 0.000002265\n",
      "Epoka 7130: Loss = 0.000001489\n",
      "Epoka 7140: Loss = 0.000001426\n",
      "Epoka 7150: Loss = 0.000001703\n",
      "Epoka 7160: Loss = 0.000001375\n",
      "Epoka 7170: Loss = 0.000001659\n",
      "Epoka 7180: Loss = 0.000001905\n",
      "Epoka 7190: Loss = 0.000001838\n",
      "Epoka 7200: Loss = 0.000001444\n",
      "Epoka 7210: Loss = 0.000002088\n",
      "Epoka 7220: Loss = 0.000002046\n",
      "Epoka 7230: Loss = 0.000001433\n",
      "Epoka 7240: Loss = 0.000001416\n",
      "Epoka 7250: Loss = 0.000001871\n",
      "Epoka 7260: Loss = 0.000001423\n",
      "Epoka 7270: Loss = 0.000001439\n",
      "Epoka 7280: Loss = 0.000001381\n",
      "Epoka 7290: Loss = 0.000001865\n",
      "Epoka 7300: Loss = 0.000001786\n",
      "Epoka 7310: Loss = 0.000001549\n",
      "Epoka 7320: Loss = 0.000001574\n",
      "Epoka 7330: Loss = 0.000001506\n",
      "Epoka 7340: Loss = 0.000002025\n",
      "Epoka 7350: Loss = 0.000001455\n",
      "Epoka 7360: Loss = 0.000001454\n",
      "Epoka 7370: Loss = 0.000001572\n",
      "Epoka 7380: Loss = 0.000001613\n",
      "Epoka 7390: Loss = 0.000001619\n",
      "Epoka 7400: Loss = 0.000001393\n",
      "Epoka 7410: Loss = 0.000001440\n",
      "Epoka 7420: Loss = 0.000001398\n",
      "Epoka 7430: Loss = 0.000002130\n",
      "Epoka 7440: Loss = 0.000001747\n",
      "Epoka 7450: Loss = 0.000001479\n",
      "Epoka 7460: Loss = 0.000001548\n",
      "Epoka 7470: Loss = 0.000002243\n",
      "Epoka 7480: Loss = 0.000001568\n",
      "Epoka 7490: Loss = 0.000001629\n",
      "Epoka 7500: Loss = 0.000001305\n",
      "Epoka 7510: Loss = 0.000002212\n",
      "Epoka 7520: Loss = 0.000001455\n",
      "Epoka 7530: Loss = 0.000001781\n",
      "Epoka 7540: Loss = 0.000001478\n",
      "Epoka 7550: Loss = 0.000001402\n",
      "Epoka 7560: Loss = 0.000001398\n",
      "Epoka 7570: Loss = 0.000002012\n",
      "Epoka 7580: Loss = 0.000002818\n",
      "Epoka 7590: Loss = 0.000001571\n",
      "Epoka 7600: Loss = 0.000002723\n",
      "Epoka 7610: Loss = 0.000002026\n",
      "Epoka 7620: Loss = 0.000001692\n",
      "Epoka 7630: Loss = 0.000001427\n",
      "Epoka 7640: Loss = 0.000001323\n",
      "Epoka 7650: Loss = 0.000001461\n",
      "Epoka 7660: Loss = 0.000001440\n",
      "Epoka 7670: Loss = 0.000002154\n",
      "Epoka 7680: Loss = 0.000001616\n",
      "Epoka 7690: Loss = 0.000003402\n",
      "Epoka 7700: Loss = 0.000001347\n",
      "Epoka 7710: Loss = 0.000001269\n",
      "Epoka 7720: Loss = 0.000001985\n",
      "Epoka 7730: Loss = 0.000001346\n",
      "Epoka 7740: Loss = 0.000001604\n",
      "Epoka 7750: Loss = 0.000002384\n",
      "Epoka 7760: Loss = 0.000001614\n",
      "Epoka 7770: Loss = 0.000002115\n",
      "Epoka 7780: Loss = 0.000001357\n",
      "Epoka 7790: Loss = 0.000001520\n",
      "Epoka 7800: Loss = 0.000001850\n",
      "Epoka 7810: Loss = 0.000001364\n",
      "Epoka 7820: Loss = 0.000001315\n",
      "Epoka 7830: Loss = 0.000001689\n",
      "Epoka 7840: Loss = 0.000002311\n",
      "Epoka 7850: Loss = 0.000001516\n",
      "Epoka 7860: Loss = 0.000001418\n",
      "Epoka 7870: Loss = 0.000001521\n",
      "Epoka 7880: Loss = 0.000001274\n",
      "Epoka 7890: Loss = 0.000001397\n",
      "Epoka 7900: Loss = 0.000001285\n",
      "Epoka 7910: Loss = 0.000001262\n",
      "Epoka 7920: Loss = 0.000001366\n",
      "Epoka 7930: Loss = 0.000002328\n",
      "Epoka 7940: Loss = 0.000001325\n",
      "Epoka 7950: Loss = 0.000001375\n",
      "Epoka 7960: Loss = 0.000001305\n",
      "Epoka 7970: Loss = 0.000002094\n",
      "Epoka 7980: Loss = 0.000001526\n",
      "Epoka 7990: Loss = 0.000001433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 8000: Loss = 0.000001561\n",
      "Epoka 8010: Loss = 0.000001917\n",
      "Epoka 8020: Loss = 0.000001245\n",
      "Epoka 8030: Loss = 0.000001725\n",
      "Epoka 8040: Loss = 0.000001542\n",
      "Epoka 8050: Loss = 0.000001297\n",
      "Epoka 8060: Loss = 0.000001616\n",
      "Epoka 8070: Loss = 0.000001325\n",
      "Epoka 8080: Loss = 0.000001623\n",
      "Epoka 8090: Loss = 0.000001749\n",
      "Epoka 8100: Loss = 0.000003530\n",
      "Epoka 8110: Loss = 0.000001733\n",
      "Epoka 8120: Loss = 0.000001375\n",
      "Epoka 8130: Loss = 0.000001352\n",
      "Epoka 8140: Loss = 0.000001347\n",
      "Epoka 8150: Loss = 0.000001207\n",
      "Epoka 8160: Loss = 0.000001518\n",
      "Epoka 8170: Loss = 0.000001212\n",
      "Epoka 8180: Loss = 0.000001229\n",
      "Epoka 8190: Loss = 0.000001366\n",
      "Epoka 8200: Loss = 0.000001857\n",
      "Epoka 8210: Loss = 0.000001248\n",
      "Epoka 8220: Loss = 0.000001264\n",
      "Epoka 8230: Loss = 0.000001276\n",
      "Epoka 8240: Loss = 0.000001483\n",
      "Epoka 8250: Loss = 0.000001345\n",
      "Epoka 8260: Loss = 0.000001272\n",
      "Epoka 8270: Loss = 0.000003124\n",
      "Epoka 8280: Loss = 0.000001612\n",
      "Epoka 8290: Loss = 0.000001273\n",
      "Epoka 8300: Loss = 0.000001623\n",
      "Epoka 8310: Loss = 0.000001612\n",
      "Epoka 8320: Loss = 0.000001678\n",
      "Epoka 8330: Loss = 0.000003274\n",
      "Epoka 8340: Loss = 0.000001310\n",
      "Epoka 8350: Loss = 0.000001530\n",
      "Epoka 8360: Loss = 0.000001813\n",
      "Epoka 8370: Loss = 0.000002472\n",
      "Epoka 8380: Loss = 0.000001348\n",
      "Epoka 8390: Loss = 0.000001669\n",
      "Epoka 8400: Loss = 0.000001286\n",
      "Epoka 8410: Loss = 0.000002294\n",
      "Epoka 8420: Loss = 0.000001242\n",
      "Epoka 8430: Loss = 0.000001189\n",
      "Epoka 8440: Loss = 0.000001176\n",
      "Epoka 8450: Loss = 0.000001733\n",
      "Epoka 8460: Loss = 0.000001237\n",
      "Epoka 8470: Loss = 0.000003820\n",
      "Epoka 8480: Loss = 0.000001389\n",
      "Epoka 8490: Loss = 0.000001297\n",
      "Epoka 8500: Loss = 0.000003340\n",
      "Epoka 8510: Loss = 0.000001583\n",
      "Epoka 8520: Loss = 0.000001909\n",
      "Epoka 8530: Loss = 0.000001195\n",
      "Epoka 8540: Loss = 0.000001474\n",
      "Epoka 8550: Loss = 0.000001555\n",
      "Epoka 8560: Loss = 0.000001279\n",
      "Epoka 8570: Loss = 0.000001204\n",
      "Epoka 8580: Loss = 0.000001333\n",
      "Epoka 8590: Loss = 0.000001334\n",
      "Epoka 8600: Loss = 0.000001274\n",
      "Epoka 8610: Loss = 0.000001173\n",
      "Epoka 8620: Loss = 0.000001779\n",
      "Epoka 8630: Loss = 0.000001724\n",
      "Epoka 8640: Loss = 0.000002046\n",
      "Epoka 8650: Loss = 0.000001309\n",
      "Epoka 8660: Loss = 0.000002599\n",
      "Epoka 8670: Loss = 0.000001245\n",
      "Epoka 8680: Loss = 0.000001710\n",
      "Epoka 8690: Loss = 0.000001427\n",
      "Epoka 8700: Loss = 0.000001689\n",
      "Epoka 8710: Loss = 0.000001567\n",
      "Epoka 8720: Loss = 0.000001158\n",
      "Epoka 8730: Loss = 0.000001441\n",
      "Epoka 8740: Loss = 0.000001430\n",
      "Epoka 8750: Loss = 0.000001446\n",
      "Epoka 8760: Loss = 0.000001562\n",
      "Epoka 8770: Loss = 0.000002109\n",
      "Epoka 8780: Loss = 0.000001358\n",
      "Epoka 8790: Loss = 0.000001355\n",
      "Epoka 8800: Loss = 0.000001790\n",
      "Epoka 8810: Loss = 0.000001234\n",
      "Epoka 8820: Loss = 0.000001254\n",
      "Epoka 8830: Loss = 0.000001500\n",
      "Epoka 8840: Loss = 0.000001228\n",
      "Epoka 8850: Loss = 0.000001330\n",
      "Epoka 8860: Loss = 0.000001526\n",
      "Epoka 8870: Loss = 0.000001257\n",
      "Epoka 8880: Loss = 0.000002747\n",
      "Epoka 8890: Loss = 0.000001272\n",
      "Epoka 8900: Loss = 0.000001692\n",
      "Epoka 8910: Loss = 0.000001218\n",
      "Epoka 8920: Loss = 0.000001373\n",
      "Epoka 8930: Loss = 0.000002076\n",
      "Epoka 8940: Loss = 0.000001138\n",
      "Epoka 8950: Loss = 0.000001329\n",
      "Epoka 8960: Loss = 0.000001177\n",
      "Epoka 8970: Loss = 0.000001277\n",
      "Epoka 8980: Loss = 0.000001748\n",
      "Epoka 8990: Loss = 0.000001118\n",
      "Epoka 9000: Loss = 0.000001380\n",
      "Epoka 9010: Loss = 0.000001373\n",
      "Epoka 9020: Loss = 0.000001523\n",
      "Epoka 9030: Loss = 0.000001097\n",
      "Epoka 9040: Loss = 0.000001227\n",
      "Epoka 9050: Loss = 0.000001532\n",
      "Epoka 9060: Loss = 0.000001545\n",
      "Epoka 9070: Loss = 0.000001268\n",
      "Epoka 9080: Loss = 0.000002063\n",
      "Epoka 9090: Loss = 0.000001346\n",
      "Epoka 9100: Loss = 0.000001323\n",
      "Epoka 9110: Loss = 0.000001368\n",
      "Epoka 9120: Loss = 0.000001367\n",
      "Epoka 9130: Loss = 0.000001296\n",
      "Epoka 9140: Loss = 0.000001414\n",
      "Epoka 9150: Loss = 0.000001110\n",
      "Epoka 9160: Loss = 0.000001226\n",
      "Epoka 9170: Loss = 0.000001220\n",
      "Epoka 9180: Loss = 0.000001086\n",
      "Epoka 9190: Loss = 0.000001915\n",
      "Epoka 9200: Loss = 0.000001412\n",
      "Epoka 9210: Loss = 0.000001540\n",
      "Epoka 9220: Loss = 0.000001741\n",
      "Epoka 9230: Loss = 0.000001277\n",
      "Epoka 9240: Loss = 0.000001775\n",
      "Epoka 9250: Loss = 0.000001230\n",
      "Epoka 9260: Loss = 0.000001585\n",
      "Epoka 9270: Loss = 0.000001141\n",
      "Epoka 9280: Loss = 0.000001127\n",
      "Epoka 9290: Loss = 0.000001271\n",
      "Epoka 9300: Loss = 0.000001618\n",
      "Epoka 9310: Loss = 0.000001359\n",
      "Epoka 9320: Loss = 0.000001210\n",
      "Epoka 9330: Loss = 0.000001183\n",
      "Epoka 9340: Loss = 0.000001420\n",
      "Epoka 9350: Loss = 0.000001608\n",
      "Epoka 9360: Loss = 0.000001136\n",
      "Epoka 9370: Loss = 0.000001431\n",
      "Epoka 9380: Loss = 0.000001165\n",
      "Epoka 9390: Loss = 0.000001174\n",
      "Epoka 9400: Loss = 0.000001247\n",
      "Epoka 9410: Loss = 0.000001137\n",
      "Epoka 9420: Loss = 0.000001424\n",
      "Epoka 9430: Loss = 0.000001826\n",
      "Epoka 9440: Loss = 0.000001403\n",
      "Epoka 9450: Loss = 0.000001114\n",
      "Epoka 9460: Loss = 0.000001113\n",
      "Epoka 9470: Loss = 0.000001223\n",
      "Epoka 9480: Loss = 0.000001554\n",
      "Epoka 9490: Loss = 0.000001352\n",
      "Epoka 9500: Loss = 0.000001807\n",
      "Epoka 9510: Loss = 0.000001522\n",
      "Epoka 9520: Loss = 0.000001252\n",
      "Epoka 9530: Loss = 0.000001362\n",
      "Epoka 9540: Loss = 0.000001057\n",
      "Epoka 9550: Loss = 0.000001105\n",
      "Epoka 9560: Loss = 0.000001220\n",
      "Epoka 9570: Loss = 0.000001175\n",
      "Epoka 9580: Loss = 0.000001365\n",
      "Epoka 9590: Loss = 0.000001125\n",
      "Epoka 9600: Loss = 0.000001084\n",
      "Epoka 9610: Loss = 0.000001131\n",
      "Epoka 9620: Loss = 0.000001673\n",
      "Epoka 9630: Loss = 0.000001638\n",
      "Epoka 9640: Loss = 0.000001221\n",
      "Epoka 9650: Loss = 0.000001079\n",
      "Epoka 9660: Loss = 0.000001562\n",
      "Epoka 9670: Loss = 0.000002455\n",
      "Epoka 9680: Loss = 0.000001242\n",
      "Epoka 9690: Loss = 0.000001050\n",
      "Epoka 9700: Loss = 0.000001042\n",
      "Epoka 9710: Loss = 0.000001301\n",
      "Epoka 9720: Loss = 0.000002155\n",
      "Epoka 9730: Loss = 0.000001132\n",
      "Epoka 9740: Loss = 0.000002407\n",
      "Epoka 9750: Loss = 0.000001396\n",
      "Epoka 9760: Loss = 0.000001084\n",
      "Epoka 9770: Loss = 0.000003019\n",
      "Epoka 9780: Loss = 0.000001753\n",
      "Epoka 9790: Loss = 0.000001614\n",
      "Epoka 9800: Loss = 0.000001081\n",
      "Epoka 9810: Loss = 0.000001049\n",
      "Epoka 9820: Loss = 0.000001223\n",
      "Epoka 9830: Loss = 0.000001216\n",
      "Epoka 9840: Loss = 0.000001292\n",
      "Epoka 9850: Loss = 0.000001398\n",
      "Epoka 9860: Loss = 0.000001473\n",
      "Epoka 9870: Loss = 0.000001265\n",
      "Epoka 9880: Loss = 0.000001684\n",
      "Epoka 9890: Loss = 0.000001180\n",
      "Epoka 9900: Loss = 0.000001160\n",
      "Epoka 9910: Loss = 0.000001080\n",
      "Epoka 9920: Loss = 0.000001073\n",
      "Epoka 9930: Loss = 0.000001175\n",
      "Epoka 9940: Loss = 0.000001244\n",
      "Epoka 9950: Loss = 0.000002229\n",
      "Epoka 9960: Loss = 0.000001108\n",
      "Epoka 9970: Loss = 0.000001231\n",
      "Epoka 9980: Loss = 0.000001414\n",
      "Epoka 9990: Loss = 0.000001117\n",
      "Epoka 10000: Loss = 0.000001216\n",
      "Epoka 10010: Loss = 0.000001182\n",
      "Epoka 10020: Loss = 0.000001090\n",
      "Epoka 10030: Loss = 0.000001065\n",
      "Epoka 10040: Loss = 0.000001103\n",
      "Epoka 10050: Loss = 0.000001106\n",
      "Epoka 10060: Loss = 0.000000990\n",
      "Epoka 10070: Loss = 0.000000987\n",
      "Epoka 10080: Loss = 0.000002327\n",
      "Epoka 10090: Loss = 0.000001508\n",
      "Epoka 10100: Loss = 0.000001076\n",
      "Epoka 10110: Loss = 0.000001501\n",
      "Epoka 10120: Loss = 0.000001119\n",
      "Epoka 10130: Loss = 0.000001464\n",
      "Epoka 10140: Loss = 0.000001841\n",
      "Epoka 10150: Loss = 0.000001000\n",
      "Epoka 10160: Loss = 0.000001084\n",
      "Epoka 10170: Loss = 0.000001174\n",
      "Epoka 10180: Loss = 0.000001497\n",
      "Epoka 10190: Loss = 0.000001361\n",
      "Epoka 10200: Loss = 0.000001073\n",
      "Epoka 10210: Loss = 0.000001069\n",
      "Epoka 10220: Loss = 0.000000982\n",
      "Epoka 10230: Loss = 0.000002306\n",
      "Epoka 10240: Loss = 0.000001328\n",
      "Epoka 10250: Loss = 0.000001088\n",
      "Epoka 10260: Loss = 0.000001646\n",
      "Epoka 10270: Loss = 0.000001027\n",
      "Epoka 10280: Loss = 0.000001211\n",
      "Epoka 10290: Loss = 0.000001946\n",
      "Epoka 10300: Loss = 0.000001099\n",
      "Epoka 10310: Loss = 0.000001264\n",
      "Epoka 10320: Loss = 0.000001288\n",
      "Epoka 10330: Loss = 0.000001030\n",
      "Epoka 10340: Loss = 0.000001161\n",
      "Epoka 10350: Loss = 0.000000984\n",
      "Epoka 10360: Loss = 0.000001222\n",
      "Epoka 10370: Loss = 0.000001050\n",
      "Epoka 10380: Loss = 0.000001194\n",
      "Epoka 10390: Loss = 0.000001136\n",
      "Epoka 10400: Loss = 0.000000969\n",
      "Epoka 10410: Loss = 0.000000968\n",
      "Epoka 10420: Loss = 0.000001258\n",
      "Epoka 10430: Loss = 0.000001033\n",
      "Epoka 10440: Loss = 0.000001139\n",
      "Epoka 10450: Loss = 0.000002431\n",
      "Epoka 10460: Loss = 0.000001128\n",
      "Epoka 10470: Loss = 0.000002950\n",
      "Epoka 10480: Loss = 0.000001308\n",
      "Epoka 10490: Loss = 0.000001647\n",
      "Epoka 10500: Loss = 0.000001324\n",
      "Epoka 10510: Loss = 0.000001226\n",
      "Epoka 10520: Loss = 0.000001517\n",
      "Epoka 10530: Loss = 0.000001109\n",
      "Epoka 10540: Loss = 0.000001242\n",
      "Epoka 10550: Loss = 0.000001010\n",
      "Epoka 10560: Loss = 0.000001127\n",
      "Epoka 10570: Loss = 0.000000959\n",
      "Epoka 10580: Loss = 0.000001139\n",
      "Epoka 10590: Loss = 0.000001003\n",
      "Epoka 10600: Loss = 0.000001473\n",
      "Epoka 10610: Loss = 0.000000956\n",
      "Epoka 10620: Loss = 0.000001255\n",
      "Epoka 10630: Loss = 0.000001113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 10640: Loss = 0.000001217\n",
      "Epoka 10650: Loss = 0.000001442\n",
      "Epoka 10660: Loss = 0.000001173\n",
      "Epoka 10670: Loss = 0.000001345\n",
      "Epoka 10680: Loss = 0.000001030\n",
      "Epoka 10690: Loss = 0.000001761\n",
      "Epoka 10700: Loss = 0.000001431\n",
      "Epoka 10710: Loss = 0.000001756\n",
      "Epoka 10720: Loss = 0.000001154\n",
      "Epoka 10730: Loss = 0.000001787\n",
      "Epoka 10740: Loss = 0.000001069\n",
      "Epoka 10750: Loss = 0.000003038\n",
      "Epoka 10760: Loss = 0.000001617\n",
      "Epoka 10770: Loss = 0.000001126\n",
      "Epoka 10780: Loss = 0.000000936\n",
      "Epoka 10790: Loss = 0.000001412\n",
      "Epoka 10800: Loss = 0.000001329\n",
      "Epoka 10810: Loss = 0.000001161\n",
      "Epoka 10820: Loss = 0.000001010\n",
      "Epoka 10830: Loss = 0.000000947\n",
      "Epoka 10840: Loss = 0.000000981\n",
      "Epoka 10850: Loss = 0.000001157\n",
      "Epoka 10860: Loss = 0.000000918\n",
      "Epoka 10870: Loss = 0.000001043\n",
      "Epoka 10880: Loss = 0.000000968\n",
      "Epoka 10890: Loss = 0.000001127\n",
      "Epoka 10900: Loss = 0.000001384\n",
      "Epoka 10910: Loss = 0.000001383\n",
      "Epoka 10920: Loss = 0.000001077\n",
      "Epoka 10930: Loss = 0.000000928\n",
      "Epoka 10940: Loss = 0.000001131\n",
      "Epoka 10950: Loss = 0.000000931\n",
      "Epoka 10960: Loss = 0.000001022\n",
      "Epoka 10970: Loss = 0.000001081\n",
      "Epoka 10980: Loss = 0.000000916\n",
      "Epoka 10990: Loss = 0.000001420\n",
      "Epoka 11000: Loss = 0.000001095\n",
      "Epoka 11010: Loss = 0.000000917\n",
      "Epoka 11020: Loss = 0.000001388\n",
      "Epoka 11030: Loss = 0.000001361\n",
      "Epoka 11040: Loss = 0.000001044\n",
      "Epoka 11050: Loss = 0.000000931\n",
      "Epoka 11060: Loss = 0.000001014\n",
      "Epoka 11070: Loss = 0.000001130\n",
      "Epoka 11080: Loss = 0.000001197\n",
      "Epoka 11090: Loss = 0.000000905\n",
      "Epoka 11100: Loss = 0.000001165\n",
      "Epoka 11110: Loss = 0.000001581\n",
      "Epoka 11120: Loss = 0.000000980\n",
      "Epoka 11130: Loss = 0.000001326\n",
      "Epoka 11140: Loss = 0.000000996\n",
      "Epoka 11150: Loss = 0.000000999\n",
      "Epoka 11160: Loss = 0.000001088\n",
      "Epoka 11170: Loss = 0.000001021\n",
      "Epoka 11180: Loss = 0.000000897\n",
      "Epoka 11190: Loss = 0.000001437\n",
      "Epoka 11200: Loss = 0.000001081\n",
      "Epoka 11210: Loss = 0.000001082\n",
      "Epoka 11220: Loss = 0.000001552\n",
      "Epoka 11230: Loss = 0.000001128\n",
      "Epoka 11240: Loss = 0.000000937\n",
      "Epoka 11250: Loss = 0.000001143\n",
      "Epoka 11260: Loss = 0.000001003\n",
      "Epoka 11270: Loss = 0.000001797\n",
      "Epoka 11280: Loss = 0.000001224\n",
      "Epoka 11290: Loss = 0.000001098\n",
      "Epoka 11300: Loss = 0.000001023\n",
      "Epoka 11310: Loss = 0.000000932\n",
      "Epoka 11320: Loss = 0.000001223\n",
      "Epoka 11330: Loss = 0.000001098\n",
      "Epoka 11340: Loss = 0.000000892\n",
      "Epoka 11350: Loss = 0.000001189\n",
      "Epoka 11360: Loss = 0.000000972\n",
      "Epoka 11370: Loss = 0.000001403\n",
      "Epoka 11380: Loss = 0.000000934\n",
      "Epoka 11390: Loss = 0.000001613\n",
      "Epoka 11400: Loss = 0.000000964\n",
      "Epoka 11410: Loss = 0.000000909\n",
      "Epoka 11420: Loss = 0.000001041\n",
      "Epoka 11430: Loss = 0.000001176\n",
      "Epoka 11440: Loss = 0.000001125\n",
      "Epoka 11450: Loss = 0.000000885\n",
      "Epoka 11460: Loss = 0.000001243\n",
      "Epoka 11470: Loss = 0.000001004\n",
      "Epoka 11480: Loss = 0.000000912\n",
      "Epoka 11490: Loss = 0.000000904\n",
      "Epoka 11500: Loss = 0.000000868\n",
      "Epoka 11510: Loss = 0.000000993\n",
      "Epoka 11520: Loss = 0.000000983\n",
      "Epoka 11530: Loss = 0.000001108\n",
      "Epoka 11540: Loss = 0.000000952\n",
      "Epoka 11550: Loss = 0.000001225\n",
      "Epoka 11560: Loss = 0.000001049\n",
      "Epoka 11570: Loss = 0.000001350\n",
      "Epoka 11580: Loss = 0.000000960\n",
      "Epoka 11590: Loss = 0.000001180\n",
      "Epoka 11600: Loss = 0.000000870\n",
      "Epoka 11610: Loss = 0.000000892\n",
      "Epoka 11620: Loss = 0.000001037\n",
      "Epoka 11630: Loss = 0.000000937\n",
      "Epoka 11640: Loss = 0.000001035\n",
      "Epoka 11650: Loss = 0.000000985\n",
      "Epoka 11660: Loss = 0.000000904\n",
      "Epoka 11670: Loss = 0.000001174\n",
      "Epoka 11680: Loss = 0.000000943\n",
      "Epoka 11690: Loss = 0.000001033\n",
      "Epoka 11700: Loss = 0.000001161\n",
      "Epoka 11710: Loss = 0.000001051\n",
      "Epoka 11720: Loss = 0.000001590\n",
      "Epoka 11730: Loss = 0.000000875\n",
      "Epoka 11740: Loss = 0.000000880\n",
      "Epoka 11750: Loss = 0.000001274\n",
      "Epoka 11760: Loss = 0.000001248\n",
      "Epoka 11770: Loss = 0.000000919\n",
      "Epoka 11780: Loss = 0.000000969\n",
      "Epoka 11790: Loss = 0.000001526\n",
      "Epoka 11800: Loss = 0.000001710\n",
      "Epoka 11810: Loss = 0.000000960\n",
      "Epoka 11820: Loss = 0.000000865\n",
      "Epoka 11830: Loss = 0.000001264\n",
      "Epoka 11840: Loss = 0.000000911\n",
      "Epoka 11850: Loss = 0.000000953\n",
      "Epoka 11860: Loss = 0.000000923\n",
      "Epoka 11870: Loss = 0.000000951\n",
      "Epoka 11880: Loss = 0.000000970\n",
      "Epoka 11890: Loss = 0.000001426\n",
      "Epoka 11900: Loss = 0.000000954\n",
      "Epoka 11910: Loss = 0.000001338\n",
      "Epoka 11920: Loss = 0.000000885\n",
      "Epoka 11930: Loss = 0.000001381\n",
      "Epoka 11940: Loss = 0.000001171\n",
      "Epoka 11950: Loss = 0.000001564\n",
      "Epoka 11960: Loss = 0.000001063\n",
      "Epoka 11970: Loss = 0.000001398\n",
      "Epoka 11980: Loss = 0.000000841\n",
      "Epoka 11990: Loss = 0.000000946\n",
      "Epoka 12000: Loss = 0.000000992\n",
      "Epoka 12010: Loss = 0.000001283\n",
      "Epoka 12020: Loss = 0.000001391\n",
      "Epoka 12030: Loss = 0.000000846\n",
      "Epoka 12040: Loss = 0.000000995\n",
      "Epoka 12050: Loss = 0.000000893\n",
      "Epoka 12060: Loss = 0.000000860\n",
      "Epoka 12070: Loss = 0.000001053\n",
      "Epoka 12080: Loss = 0.000000829\n",
      "Epoka 12090: Loss = 0.000001025\n",
      "Epoka 12100: Loss = 0.000000987\n",
      "Epoka 12110: Loss = 0.000000811\n",
      "Epoka 12120: Loss = 0.000002028\n",
      "Epoka 12130: Loss = 0.000000864\n",
      "Epoka 12140: Loss = 0.000001757\n",
      "Epoka 12150: Loss = 0.000000926\n",
      "Epoka 12160: Loss = 0.000001039\n",
      "Epoka 12170: Loss = 0.000000898\n",
      "Epoka 12180: Loss = 0.000001255\n",
      "Epoka 12190: Loss = 0.000000913\n",
      "Epoka 12200: Loss = 0.000002286\n",
      "Epoka 12210: Loss = 0.000001115\n",
      "Epoka 12220: Loss = 0.000000869\n",
      "Epoka 12230: Loss = 0.000001155\n",
      "Epoka 12240: Loss = 0.000001018\n",
      "Epoka 12250: Loss = 0.000000849\n",
      "Epoka 12260: Loss = 0.000000811\n",
      "Epoka 12270: Loss = 0.000001088\n",
      "Epoka 12280: Loss = 0.000001414\n",
      "Epoka 12290: Loss = 0.000001005\n",
      "Epoka 12300: Loss = 0.000001414\n",
      "Epoka 12310: Loss = 0.000000815\n",
      "Epoka 12320: Loss = 0.000000923\n",
      "Epoka 12330: Loss = 0.000001169\n",
      "Epoka 12340: Loss = 0.000000951\n",
      "Epoka 12350: Loss = 0.000001012\n",
      "Epoka 12360: Loss = 0.000001000\n",
      "Epoka 12370: Loss = 0.000000905\n",
      "Epoka 12380: Loss = 0.000000805\n",
      "Epoka 12390: Loss = 0.000000818\n",
      "Epoka 12400: Loss = 0.000001903\n",
      "Epoka 12410: Loss = 0.000000934\n",
      "Epoka 12420: Loss = 0.000000866\n",
      "Epoka 12430: Loss = 0.000000918\n",
      "Epoka 12440: Loss = 0.000001055\n",
      "Epoka 12450: Loss = 0.000000881\n",
      "Epoka 12460: Loss = 0.000000866\n",
      "Epoka 12470: Loss = 0.000001039\n",
      "Epoka 12480: Loss = 0.000000848\n",
      "Epoka 12490: Loss = 0.000001001\n",
      "Epoka 12500: Loss = 0.000001280\n",
      "Epoka 12510: Loss = 0.000000849\n",
      "Epoka 12520: Loss = 0.000001079\n",
      "Epoka 12530: Loss = 0.000001675\n",
      "Epoka 12540: Loss = 0.000001030\n",
      "Epoka 12550: Loss = 0.000001023\n",
      "Epoka 12560: Loss = 0.000001188\n",
      "Epoka 12570: Loss = 0.000000993\n",
      "Epoka 12580: Loss = 0.000000884\n",
      "Epoka 12590: Loss = 0.000001060\n",
      "Epoka 12600: Loss = 0.000000830\n",
      "Epoka 12610: Loss = 0.000000955\n",
      "Epoka 12620: Loss = 0.000001071\n",
      "Epoka 12630: Loss = 0.000001012\n",
      "Epoka 12640: Loss = 0.000001118\n",
      "Epoka 12650: Loss = 0.000000807\n",
      "Epoka 12660: Loss = 0.000001053\n",
      "Epoka 12670: Loss = 0.000000832\n",
      "Epoka 12680: Loss = 0.000000832\n",
      "Epoka 12690: Loss = 0.000001004\n",
      "Epoka 12700: Loss = 0.000000938\n",
      "Epoka 12710: Loss = 0.000000943\n",
      "Epoka 12720: Loss = 0.000000799\n",
      "Epoka 12730: Loss = 0.000000805\n",
      "Epoka 12740: Loss = 0.000000845\n",
      "Epoka 12750: Loss = 0.000002187\n",
      "Epoka 12760: Loss = 0.000001222\n",
      "Epoka 12770: Loss = 0.000000787\n",
      "Epoka 12780: Loss = 0.000001094\n",
      "Epoka 12790: Loss = 0.000000904\n",
      "Epoka 12800: Loss = 0.000001145\n",
      "Epoka 12810: Loss = 0.000000833\n",
      "Epoka 12820: Loss = 0.000000772\n",
      "Epoka 12830: Loss = 0.000001257\n",
      "Epoka 12840: Loss = 0.000000894\n",
      "Epoka 12850: Loss = 0.000001098\n",
      "Epoka 12860: Loss = 0.000000777\n",
      "Epoka 12870: Loss = 0.000000933\n",
      "Epoka 12880: Loss = 0.000000827\n",
      "Epoka 12890: Loss = 0.000001027\n",
      "Epoka 12900: Loss = 0.000000844\n",
      "Epoka 12910: Loss = 0.000000825\n",
      "Epoka 12920: Loss = 0.000000834\n",
      "Epoka 12930: Loss = 0.000001225\n",
      "Epoka 12940: Loss = 0.000000907\n",
      "Epoka 12950: Loss = 0.000001476\n",
      "Epoka 12960: Loss = 0.000000916\n",
      "Epoka 12970: Loss = 0.000000874\n",
      "Epoka 12980: Loss = 0.000001037\n",
      "Epoka 12990: Loss = 0.000000869\n",
      "Epoka 13000: Loss = 0.000001022\n",
      "Epoka 13010: Loss = 0.000002133\n",
      "Epoka 13020: Loss = 0.000000930\n",
      "Epoka 13030: Loss = 0.000000838\n",
      "Epoka 13040: Loss = 0.000000766\n",
      "Epoka 13050: Loss = 0.000000806\n",
      "Epoka 13060: Loss = 0.000000913\n",
      "Epoka 13070: Loss = 0.000000841\n",
      "Epoka 13080: Loss = 0.000000850\n",
      "Epoka 13090: Loss = 0.000000787\n",
      "Epoka 13100: Loss = 0.000000881\n",
      "Epoka 13110: Loss = 0.000000749\n",
      "Epoka 13120: Loss = 0.000000743\n",
      "Epoka 13130: Loss = 0.000000860\n",
      "Epoka 13140: Loss = 0.000001332\n",
      "Epoka 13150: Loss = 0.000000864\n",
      "Epoka 13160: Loss = 0.000000959\n",
      "Epoka 13170: Loss = 0.000001197\n",
      "Epoka 13180: Loss = 0.000000880\n",
      "Epoka 13190: Loss = 0.000000774\n",
      "Epoka 13200: Loss = 0.000000810\n",
      "Epoka 13210: Loss = 0.000001141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 13220: Loss = 0.000001144\n",
      "Epoka 13230: Loss = 0.000000937\n",
      "Epoka 13240: Loss = 0.000000790\n",
      "Epoka 13250: Loss = 0.000001480\n",
      "Epoka 13260: Loss = 0.000000906\n",
      "Epoka 13270: Loss = 0.000001290\n",
      "Epoka 13280: Loss = 0.000000843\n",
      "Epoka 13290: Loss = 0.000000827\n",
      "Epoka 13300: Loss = 0.000000811\n",
      "Epoka 13310: Loss = 0.000000771\n",
      "Epoka 13320: Loss = 0.000000951\n",
      "Epoka 13330: Loss = 0.000000959\n",
      "Epoka 13340: Loss = 0.000000747\n",
      "Epoka 13350: Loss = 0.000000828\n",
      "Epoka 13360: Loss = 0.000000744\n",
      "Epoka 13370: Loss = 0.000000826\n",
      "Epoka 13380: Loss = 0.000001028\n",
      "Epoka 13390: Loss = 0.000001308\n",
      "Epoka 13400: Loss = 0.000000870\n",
      "Epoka 13410: Loss = 0.000001076\n",
      "Epoka 13420: Loss = 0.000000810\n",
      "Epoka 13430: Loss = 0.000000848\n",
      "Epoka 13440: Loss = 0.000000725\n",
      "Epoka 13450: Loss = 0.000000812\n",
      "Epoka 13460: Loss = 0.000001111\n",
      "Epoka 13470: Loss = 0.000001024\n",
      "Epoka 13480: Loss = 0.000000800\n",
      "Epoka 13490: Loss = 0.000000766\n",
      "Epoka 13500: Loss = 0.000000799\n",
      "Epoka 13510: Loss = 0.000000762\n",
      "Epoka 13520: Loss = 0.000000764\n",
      "Epoka 13530: Loss = 0.000001212\n",
      "Epoka 13540: Loss = 0.000000865\n",
      "Epoka 13550: Loss = 0.000001092\n",
      "Epoka 13560: Loss = 0.000000825\n",
      "Epoka 13570: Loss = 0.000000806\n",
      "Epoka 13580: Loss = 0.000001038\n",
      "Epoka 13590: Loss = 0.000000880\n",
      "Epoka 13600: Loss = 0.000001078\n",
      "Epoka 13610: Loss = 0.000000751\n",
      "Epoka 13620: Loss = 0.000000922\n",
      "Epoka 13630: Loss = 0.000000851\n",
      "Epoka 13640: Loss = 0.000000781\n",
      "Epoka 13650: Loss = 0.000001800\n",
      "Epoka 13660: Loss = 0.000000792\n",
      "Epoka 13670: Loss = 0.000000836\n",
      "Epoka 13680: Loss = 0.000000850\n",
      "Epoka 13690: Loss = 0.000000775\n",
      "Epoka 13700: Loss = 0.000000788\n",
      "Epoka 13710: Loss = 0.000001030\n",
      "Epoka 13720: Loss = 0.000001179\n",
      "Epoka 13730: Loss = 0.000001330\n",
      "Epoka 13740: Loss = 0.000001116\n",
      "Epoka 13750: Loss = 0.000001077\n",
      "Epoka 13760: Loss = 0.000001077\n",
      "Epoka 13770: Loss = 0.000000925\n",
      "Epoka 13780: Loss = 0.000000724\n",
      "Epoka 13790: Loss = 0.000000870\n",
      "Epoka 13800: Loss = 0.000000808\n",
      "Epoka 13810: Loss = 0.000001080\n",
      "Epoka 13820: Loss = 0.000000725\n",
      "Epoka 13830: Loss = 0.000000698\n",
      "Epoka 13840: Loss = 0.000001378\n",
      "Epoka 13850: Loss = 0.000001630\n",
      "Epoka 13860: Loss = 0.000000916\n",
      "Epoka 13870: Loss = 0.000001068\n",
      "Epoka 13880: Loss = 0.000000929\n",
      "Epoka 13890: Loss = 0.000000708\n",
      "Epoka 13900: Loss = 0.000000726\n",
      "Epoka 13910: Loss = 0.000001085\n",
      "Epoka 13920: Loss = 0.000001165\n",
      "Epoka 13930: Loss = 0.000000724\n",
      "Epoka 13940: Loss = 0.000000692\n",
      "Epoka 13950: Loss = 0.000000779\n",
      "Epoka 13960: Loss = 0.000000787\n",
      "Epoka 13970: Loss = 0.000001251\n",
      "Epoka 13980: Loss = 0.000001041\n",
      "Epoka 13990: Loss = 0.000000744\n",
      "Epoka 14000: Loss = 0.000001294\n",
      "Epoka 14010: Loss = 0.000000766\n",
      "Epoka 14020: Loss = 0.000000952\n",
      "Epoka 14030: Loss = 0.000001158\n",
      "Epoka 14040: Loss = 0.000001122\n",
      "Epoka 14050: Loss = 0.000000725\n",
      "Epoka 14060: Loss = 0.000001143\n",
      "Epoka 14070: Loss = 0.000000739\n",
      "Epoka 14080: Loss = 0.000000828\n",
      "Epoka 14090: Loss = 0.000001017\n",
      "Epoka 14100: Loss = 0.000000795\n",
      "Epoka 14110: Loss = 0.000000694\n",
      "Epoka 14120: Loss = 0.000000726\n",
      "Epoka 14130: Loss = 0.000000777\n",
      "Epoka 14140: Loss = 0.000001897\n",
      "Epoka 14150: Loss = 0.000000697\n",
      "Epoka 14160: Loss = 0.000000955\n",
      "Epoka 14170: Loss = 0.000000890\n",
      "Epoka 14180: Loss = 0.000000690\n",
      "Epoka 14190: Loss = 0.000000872\n",
      "Epoka 14200: Loss = 0.000000752\n",
      "Epoka 14210: Loss = 0.000000720\n",
      "Epoka 14220: Loss = 0.000001070\n",
      "Epoka 14230: Loss = 0.000000753\n",
      "Epoka 14240: Loss = 0.000000700\n",
      "Epoka 14250: Loss = 0.000001020\n",
      "Epoka 14260: Loss = 0.000000689\n",
      "Epoka 14270: Loss = 0.000000735\n",
      "Epoka 14280: Loss = 0.000000934\n",
      "Epoka 14290: Loss = 0.000000715\n",
      "Epoka 14300: Loss = 0.000000795\n",
      "Epoka 14310: Loss = 0.000000984\n",
      "Epoka 14320: Loss = 0.000000856\n",
      "Epoka 14330: Loss = 0.000001325\n",
      "Epoka 14340: Loss = 0.000000818\n",
      "Epoka 14350: Loss = 0.000000774\n",
      "Epoka 14360: Loss = 0.000000796\n",
      "Epoka 14370: Loss = 0.000000780\n",
      "Epoka 14380: Loss = 0.000000692\n",
      "Epoka 14390: Loss = 0.000000692\n",
      "Epoka 14400: Loss = 0.000000803\n",
      "Epoka 14410: Loss = 0.000000923\n",
      "Epoka 14420: Loss = 0.000001036\n",
      "Epoka 14430: Loss = 0.000000749\n",
      "Epoka 14440: Loss = 0.000000747\n",
      "Epoka 14450: Loss = 0.000001886\n",
      "Epoka 14460: Loss = 0.000000688\n",
      "Epoka 14470: Loss = 0.000001096\n",
      "Epoka 14480: Loss = 0.000000918\n",
      "Epoka 14490: Loss = 0.000000814\n",
      "Epoka 14500: Loss = 0.000000898\n",
      "Epoka 14510: Loss = 0.000000971\n",
      "Epoka 14520: Loss = 0.000001376\n",
      "Epoka 14530: Loss = 0.000000695\n",
      "Epoka 14540: Loss = 0.000002468\n",
      "Epoka 14550: Loss = 0.000000757\n",
      "Epoka 14560: Loss = 0.000000780\n",
      "Epoka 14570: Loss = 0.000000844\n",
      "Epoka 14580: Loss = 0.000000951\n",
      "Epoka 14590: Loss = 0.000000661\n",
      "Epoka 14600: Loss = 0.000000724\n",
      "Epoka 14610: Loss = 0.000000863\n",
      "Epoka 14620: Loss = 0.000000795\n",
      "Epoka 14630: Loss = 0.000000754\n",
      "Epoka 14640: Loss = 0.000000729\n",
      "Epoka 14650: Loss = 0.000000849\n",
      "Epoka 14660: Loss = 0.000001281\n",
      "Epoka 14670: Loss = 0.000000803\n",
      "Epoka 14680: Loss = 0.000000742\n",
      "Epoka 14690: Loss = 0.000000787\n",
      "Epoka 14700: Loss = 0.000000741\n",
      "Epoka 14710: Loss = 0.000000750\n",
      "Epoka 14720: Loss = 0.000000689\n",
      "Epoka 14730: Loss = 0.000000667\n",
      "Epoka 14740: Loss = 0.000000991\n",
      "Epoka 14750: Loss = 0.000000843\n",
      "Epoka 14760: Loss = 0.000000781\n",
      "Epoka 14770: Loss = 0.000000857\n",
      "Epoka 14780: Loss = 0.000000881\n",
      "Epoka 14790: Loss = 0.000000703\n",
      "Epoka 14800: Loss = 0.000000748\n",
      "Epoka 14810: Loss = 0.000001086\n",
      "Epoka 14820: Loss = 0.000000980\n",
      "Epoka 14830: Loss = 0.000001032\n",
      "Epoka 14840: Loss = 0.000001000\n",
      "Epoka 14850: Loss = 0.000000820\n",
      "Epoka 14860: Loss = 0.000001084\n",
      "Epoka 14870: Loss = 0.000000936\n",
      "Epoka 14880: Loss = 0.000000719\n",
      "Epoka 14890: Loss = 0.000000722\n",
      "Epoka 14900: Loss = 0.000000813\n",
      "Epoka 14910: Loss = 0.000001004\n",
      "Epoka 14920: Loss = 0.000000669\n",
      "Epoka 14930: Loss = 0.000001038\n",
      "Epoka 14940: Loss = 0.000001295\n",
      "Epoka 14950: Loss = 0.000000726\n",
      "Epoka 14960: Loss = 0.000000770\n",
      "Epoka 14970: Loss = 0.000000761\n",
      "Epoka 14980: Loss = 0.000000691\n",
      "Epoka 14990: Loss = 0.000000989\n",
      "Epoka 15000: Loss = 0.000000915\n",
      "Epoka 15010: Loss = 0.000000818\n",
      "Epoka 15020: Loss = 0.000000688\n",
      "Epoka 15030: Loss = 0.000000777\n",
      "Epoka 15040: Loss = 0.000000832\n",
      "Epoka 15050: Loss = 0.000000653\n",
      "Epoka 15060: Loss = 0.000000826\n",
      "Epoka 15070: Loss = 0.000000815\n",
      "Epoka 15080: Loss = 0.000000682\n",
      "Epoka 15090: Loss = 0.000001394\n",
      "Epoka 15100: Loss = 0.000000816\n",
      "Epoka 15110: Loss = 0.000000693\n",
      "Epoka 15120: Loss = 0.000001355\n",
      "Epoka 15130: Loss = 0.000000854\n",
      "Epoka 15140: Loss = 0.000000738\n",
      "Epoka 15150: Loss = 0.000000683\n",
      "Epoka 15160: Loss = 0.000000700\n",
      "Epoka 15170: Loss = 0.000000693\n",
      "Epoka 15180: Loss = 0.000000640\n",
      "Epoka 15190: Loss = 0.000000936\n",
      "Epoka 15200: Loss = 0.000000635\n",
      "Epoka 15210: Loss = 0.000000921\n",
      "Epoka 15220: Loss = 0.000000659\n",
      "Epoka 15230: Loss = 0.000000635\n",
      "Epoka 15240: Loss = 0.000000650\n",
      "Epoka 15250: Loss = 0.000001073\n",
      "Epoka 15260: Loss = 0.000000803\n",
      "Epoka 15270: Loss = 0.000000845\n",
      "Epoka 15280: Loss = 0.000000784\n",
      "Epoka 15290: Loss = 0.000002003\n",
      "Epoka 15300: Loss = 0.000000669\n",
      "Epoka 15310: Loss = 0.000000911\n",
      "Epoka 15320: Loss = 0.000000798\n",
      "Epoka 15330: Loss = 0.000000800\n",
      "Epoka 15340: Loss = 0.000001360\n",
      "Epoka 15350: Loss = 0.000001192\n",
      "Epoka 15360: Loss = 0.000000645\n",
      "Epoka 15370: Loss = 0.000000637\n",
      "Epoka 15380: Loss = 0.000000686\n",
      "Epoka 15390: Loss = 0.000000818\n",
      "Epoka 15400: Loss = 0.000000990\n",
      "Epoka 15410: Loss = 0.000001013\n",
      "Epoka 15420: Loss = 0.000000679\n",
      "Epoka 15430: Loss = 0.000000789\n",
      "Epoka 15440: Loss = 0.000000666\n",
      "Epoka 15450: Loss = 0.000000679\n",
      "Epoka 15460: Loss = 0.000000802\n",
      "Epoka 15470: Loss = 0.000000708\n",
      "Epoka 15480: Loss = 0.000000700\n",
      "Epoka 15490: Loss = 0.000000731\n",
      "Epoka 15500: Loss = 0.000000627\n",
      "Epoka 15510: Loss = 0.000001143\n",
      "Epoka 15520: Loss = 0.000000803\n",
      "Epoka 15530: Loss = 0.000001596\n",
      "Epoka 15540: Loss = 0.000000681\n",
      "Epoka 15550: Loss = 0.000000612\n",
      "Epoka 15560: Loss = 0.000000916\n",
      "Epoka 15570: Loss = 0.000000639\n",
      "Epoka 15580: Loss = 0.000001790\n",
      "Epoka 15590: Loss = 0.000000773\n",
      "Epoka 15600: Loss = 0.000000619\n",
      "Epoka 15610: Loss = 0.000000880\n",
      "Epoka 15620: Loss = 0.000000893\n",
      "Epoka 15630: Loss = 0.000000759\n",
      "Epoka 15640: Loss = 0.000001112\n",
      "Epoka 15650: Loss = 0.000000721\n",
      "Epoka 15660: Loss = 0.000000623\n",
      "Epoka 15670: Loss = 0.000000761\n",
      "Epoka 15680: Loss = 0.000000637\n",
      "Epoka 15690: Loss = 0.000000719\n",
      "Epoka 15700: Loss = 0.000000970\n",
      "Epoka 15710: Loss = 0.000000623\n",
      "Epoka 15720: Loss = 0.000000772\n",
      "Epoka 15730: Loss = 0.000000697\n",
      "Epoka 15740: Loss = 0.000000650\n",
      "Epoka 15750: Loss = 0.000000629\n",
      "Epoka 15760: Loss = 0.000000799\n",
      "Epoka 15770: Loss = 0.000000663\n",
      "Epoka 15780: Loss = 0.000001033\n",
      "Epoka 15790: Loss = 0.000000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 15800: Loss = 0.000002126\n",
      "Epoka 15810: Loss = 0.000000761\n",
      "Epoka 15820: Loss = 0.000000625\n",
      "Epoka 15830: Loss = 0.000000695\n",
      "Epoka 15840: Loss = 0.000000858\n",
      "Epoka 15850: Loss = 0.000000730\n",
      "Epoka 15860: Loss = 0.000000643\n",
      "Epoka 15870: Loss = 0.000000752\n",
      "Epoka 15880: Loss = 0.000001294\n",
      "Epoka 15890: Loss = 0.000000756\n",
      "Epoka 15900: Loss = 0.000000825\n",
      "Epoka 15910: Loss = 0.000000818\n",
      "Epoka 15920: Loss = 0.000000630\n",
      "Epoka 15930: Loss = 0.000000741\n",
      "Epoka 15940: Loss = 0.000000645\n",
      "Epoka 15950: Loss = 0.000001318\n",
      "Epoka 15960: Loss = 0.000001259\n",
      "Epoka 15970: Loss = 0.000000975\n",
      "Epoka 15980: Loss = 0.000001317\n",
      "Epoka 15990: Loss = 0.000000676\n",
      "Epoka 16000: Loss = 0.000000643\n",
      "Epoka 16010: Loss = 0.000001053\n",
      "Epoka 16020: Loss = 0.000000693\n",
      "Epoka 16030: Loss = 0.000000790\n",
      "Epoka 16040: Loss = 0.000001427\n",
      "Epoka 16050: Loss = 0.000000651\n",
      "Epoka 16060: Loss = 0.000000687\n",
      "Epoka 16070: Loss = 0.000000619\n",
      "Epoka 16080: Loss = 0.000000786\n",
      "Epoka 16090: Loss = 0.000000871\n",
      "Epoka 16100: Loss = 0.000000695\n",
      "Epoka 16110: Loss = 0.000000601\n",
      "Epoka 16120: Loss = 0.000000676\n",
      "Epoka 16130: Loss = 0.000000701\n",
      "Epoka 16140: Loss = 0.000000610\n",
      "Epoka 16150: Loss = 0.000000654\n",
      "Epoka 16160: Loss = 0.000000590\n",
      "Epoka 16170: Loss = 0.000000799\n",
      "Epoka 16180: Loss = 0.000000915\n",
      "Epoka 16190: Loss = 0.000000780\n",
      "Epoka 16200: Loss = 0.000000683\n",
      "Epoka 16210: Loss = 0.000000642\n",
      "Epoka 16220: Loss = 0.000000760\n",
      "Epoka 16230: Loss = 0.000000612\n",
      "Epoka 16240: Loss = 0.000000689\n",
      "Epoka 16250: Loss = 0.000000697\n",
      "Epoka 16260: Loss = 0.000001055\n",
      "Epoka 16270: Loss = 0.000000623\n",
      "Epoka 16280: Loss = 0.000000827\n",
      "Epoka 16290: Loss = 0.000000837\n",
      "Epoka 16300: Loss = 0.000000811\n",
      "Epoka 16310: Loss = 0.000000990\n",
      "Epoka 16320: Loss = 0.000000575\n",
      "Epoka 16330: Loss = 0.000000701\n",
      "Epoka 16340: Loss = 0.000001058\n",
      "Epoka 16350: Loss = 0.000000578\n",
      "Epoka 16360: Loss = 0.000000930\n",
      "Epoka 16370: Loss = 0.000000576\n",
      "Epoka 16380: Loss = 0.000000636\n",
      "Epoka 16390: Loss = 0.000000594\n",
      "Epoka 16400: Loss = 0.000000632\n",
      "Epoka 16410: Loss = 0.000000645\n",
      "Epoka 16420: Loss = 0.000000675\n",
      "Epoka 16430: Loss = 0.000000751\n",
      "Epoka 16440: Loss = 0.000000704\n",
      "Epoka 16450: Loss = 0.000001038\n",
      "Epoka 16460: Loss = 0.000000661\n",
      "Epoka 16470: Loss = 0.000000934\n",
      "Epoka 16480: Loss = 0.000000991\n",
      "Epoka 16490: Loss = 0.000000711\n",
      "Epoka 16500: Loss = 0.000000642\n",
      "Epoka 16510: Loss = 0.000000663\n",
      "Epoka 16520: Loss = 0.000000588\n",
      "Epoka 16530: Loss = 0.000001762\n",
      "Epoka 16540: Loss = 0.000000773\n",
      "Epoka 16550: Loss = 0.000000995\n",
      "Epoka 16560: Loss = 0.000000578\n",
      "Epoka 16570: Loss = 0.000001001\n",
      "Epoka 16580: Loss = 0.000001045\n",
      "Epoka 16590: Loss = 0.000000744\n",
      "Epoka 16600: Loss = 0.000000669\n",
      "Epoka 16610: Loss = 0.000000789\n",
      "Epoka 16620: Loss = 0.000000607\n",
      "Epoka 16630: Loss = 0.000000562\n",
      "Epoka 16640: Loss = 0.000000581\n",
      "Epoka 16650: Loss = 0.000000642\n",
      "Epoka 16660: Loss = 0.000000763\n",
      "Epoka 16670: Loss = 0.000000687\n",
      "Epoka 16680: Loss = 0.000000897\n",
      "Epoka 16690: Loss = 0.000000798\n",
      "Epoka 16700: Loss = 0.000000745\n",
      "Epoka 16710: Loss = 0.000000619\n",
      "Epoka 16720: Loss = 0.000000655\n",
      "Epoka 16730: Loss = 0.000000685\n",
      "Epoka 16740: Loss = 0.000000586\n",
      "Epoka 16750: Loss = 0.000000640\n",
      "Epoka 16760: Loss = 0.000000656\n",
      "Epoka 16770: Loss = 0.000000691\n",
      "Epoka 16780: Loss = 0.000000675\n",
      "Epoka 16790: Loss = 0.000000578\n",
      "Epoka 16800: Loss = 0.000000599\n",
      "Epoka 16810: Loss = 0.000000935\n",
      "Epoka 16820: Loss = 0.000000625\n",
      "Epoka 16830: Loss = 0.000000705\n",
      "Epoka 16840: Loss = 0.000001239\n",
      "Epoka 16850: Loss = 0.000000582\n",
      "Epoka 16860: Loss = 0.000000680\n",
      "Epoka 16870: Loss = 0.000000704\n",
      "Epoka 16880: Loss = 0.000000591\n",
      "Epoka 16890: Loss = 0.000000791\n",
      "Epoka 16900: Loss = 0.000000978\n",
      "Epoka 16910: Loss = 0.000001352\n",
      "Epoka 16920: Loss = 0.000000622\n",
      "Epoka 16930: Loss = 0.000000616\n",
      "Epoka 16940: Loss = 0.000000588\n",
      "Epoka 16950: Loss = 0.000000679\n",
      "Epoka 16960: Loss = 0.000000599\n",
      "Epoka 16970: Loss = 0.000000593\n",
      "Epoka 16980: Loss = 0.000000580\n",
      "Epoka 16990: Loss = 0.000000615\n",
      "Epoka 17000: Loss = 0.000000948\n",
      "Epoka 17010: Loss = 0.000000773\n",
      "Epoka 17020: Loss = 0.000000808\n",
      "Epoka 17030: Loss = 0.000001177\n",
      "Epoka 17040: Loss = 0.000000718\n",
      "Epoka 17050: Loss = 0.000000617\n",
      "Epoka 17060: Loss = 0.000000655\n",
      "Epoka 17070: Loss = 0.000000618\n",
      "Epoka 17080: Loss = 0.000000767\n",
      "Epoka 17090: Loss = 0.000000607\n",
      "Epoka 17100: Loss = 0.000000560\n",
      "Epoka 17110: Loss = 0.000001067\n",
      "Epoka 17120: Loss = 0.000000626\n",
      "Epoka 17130: Loss = 0.000000582\n",
      "Epoka 17140: Loss = 0.000000678\n",
      "Epoka 17150: Loss = 0.000000639\n",
      "Epoka 17160: Loss = 0.000000651\n",
      "Epoka 17170: Loss = 0.000000602\n",
      "Epoka 17180: Loss = 0.000000943\n",
      "Epoka 17190: Loss = 0.000000598\n",
      "Epoka 17200: Loss = 0.000000545\n",
      "Epoka 17210: Loss = 0.000001053\n",
      "Epoka 17220: Loss = 0.000001251\n",
      "Epoka 17230: Loss = 0.000000610\n",
      "Epoka 17240: Loss = 0.000000651\n",
      "Epoka 17250: Loss = 0.000000545\n",
      "Epoka 17260: Loss = 0.000000641\n",
      "Epoka 17270: Loss = 0.000000838\n",
      "Epoka 17280: Loss = 0.000000945\n",
      "Epoka 17290: Loss = 0.000000553\n",
      "Epoka 17300: Loss = 0.000000937\n",
      "Epoka 17310: Loss = 0.000000987\n",
      "Epoka 17320: Loss = 0.000000560\n",
      "Epoka 17330: Loss = 0.000000582\n",
      "Epoka 17340: Loss = 0.000000542\n",
      "Epoka 17350: Loss = 0.000000544\n",
      "Epoka 17360: Loss = 0.000000851\n",
      "Epoka 17370: Loss = 0.000000540\n",
      "Epoka 17380: Loss = 0.000000699\n",
      "Epoka 17390: Loss = 0.000001831\n",
      "Epoka 17400: Loss = 0.000000580\n",
      "Epoka 17410: Loss = 0.000000554\n",
      "Epoka 17420: Loss = 0.000000589\n",
      "Epoka 17430: Loss = 0.000000699\n",
      "Epoka 17440: Loss = 0.000000637\n",
      "Epoka 17450: Loss = 0.000000777\n",
      "Epoka 17460: Loss = 0.000000860\n",
      "Epoka 17470: Loss = 0.000000536\n",
      "Epoka 17480: Loss = 0.000000542\n",
      "Epoka 17490: Loss = 0.000000701\n",
      "Epoka 17500: Loss = 0.000000894\n",
      "Epoka 17510: Loss = 0.000000846\n",
      "Epoka 17520: Loss = 0.000000560\n",
      "Epoka 17530: Loss = 0.000000576\n",
      "Epoka 17540: Loss = 0.000000614\n",
      "Epoka 17550: Loss = 0.000000617\n",
      "Epoka 17560: Loss = 0.000000909\n",
      "Epoka 17570: Loss = 0.000000609\n",
      "Epoka 17580: Loss = 0.000000621\n",
      "Epoka 17590: Loss = 0.000000620\n",
      "Epoka 17600: Loss = 0.000000923\n",
      "Epoka 17610: Loss = 0.000000608\n",
      "Epoka 17620: Loss = 0.000000575\n",
      "Epoka 17630: Loss = 0.000000712\n",
      "Epoka 17640: Loss = 0.000000909\n",
      "Epoka 17650: Loss = 0.000000524\n",
      "Epoka 17660: Loss = 0.000000599\n",
      "Epoka 17670: Loss = 0.000000535\n",
      "Epoka 17680: Loss = 0.000000695\n",
      "Epoka 17690: Loss = 0.000000563\n",
      "Epoka 17700: Loss = 0.000000754\n",
      "Epoka 17710: Loss = 0.000000914\n",
      "Epoka 17720: Loss = 0.000000555\n",
      "Epoka 17730: Loss = 0.000000603\n",
      "Epoka 17740: Loss = 0.000000880\n",
      "Epoka 17750: Loss = 0.000000652\n",
      "Epoka 17760: Loss = 0.000000569\n",
      "Epoka 17770: Loss = 0.000000597\n",
      "Epoka 17780: Loss = 0.000000568\n",
      "Epoka 17790: Loss = 0.000000722\n",
      "Epoka 17800: Loss = 0.000000730\n",
      "Epoka 17810: Loss = 0.000000544\n",
      "Epoka 17820: Loss = 0.000000733\n",
      "Epoka 17830: Loss = 0.000000650\n",
      "Epoka 17840: Loss = 0.000001137\n",
      "Epoka 17850: Loss = 0.000000665\n",
      "Epoka 17860: Loss = 0.000000517\n",
      "Epoka 17870: Loss = 0.000000588\n",
      "Epoka 17880: Loss = 0.000000563\n",
      "Epoka 17890: Loss = 0.000000557\n",
      "Epoka 17900: Loss = 0.000000586\n",
      "Epoka 17910: Loss = 0.000000617\n",
      "Epoka 17920: Loss = 0.000000639\n",
      "Epoka 17930: Loss = 0.000000620\n",
      "Epoka 17940: Loss = 0.000000684\n",
      "Epoka 17950: Loss = 0.000000828\n",
      "Epoka 17960: Loss = 0.000000509\n",
      "Epoka 17970: Loss = 0.000000606\n",
      "Epoka 17980: Loss = 0.000000614\n",
      "Epoka 17990: Loss = 0.000000560\n",
      "Epoka 18000: Loss = 0.000000655\n",
      "Epoka 18010: Loss = 0.000000513\n",
      "Epoka 18020: Loss = 0.000000612\n",
      "Epoka 18030: Loss = 0.000000565\n",
      "Epoka 18040: Loss = 0.000000679\n",
      "Epoka 18050: Loss = 0.000000560\n",
      "Epoka 18060: Loss = 0.000000920\n",
      "Epoka 18070: Loss = 0.000000550\n",
      "Epoka 18080: Loss = 0.000000672\n",
      "Epoka 18090: Loss = 0.000000526\n",
      "Epoka 18100: Loss = 0.000000543\n",
      "Epoka 18110: Loss = 0.000000754\n",
      "Epoka 18120: Loss = 0.000000586\n",
      "Epoka 18130: Loss = 0.000000675\n",
      "Epoka 18140: Loss = 0.000001926\n",
      "Epoka 18150: Loss = 0.000000500\n",
      "Epoka 18160: Loss = 0.000000672\n",
      "Epoka 18170: Loss = 0.000000541\n",
      "Epoka 18180: Loss = 0.000000499\n",
      "Epoka 18190: Loss = 0.000000514\n",
      "Epoka 18200: Loss = 0.000000542\n",
      "Epoka 18210: Loss = 0.000000544\n",
      "Epoka 18220: Loss = 0.000000504\n",
      "Epoka 18230: Loss = 0.000000496\n",
      "Epoka 18240: Loss = 0.000000510\n",
      "Epoka 18250: Loss = 0.000000642\n",
      "Epoka 18260: Loss = 0.000000755\n",
      "Epoka 18270: Loss = 0.000000786\n",
      "Epoka 18280: Loss = 0.000000555\n",
      "Epoka 18290: Loss = 0.000000685\n",
      "Epoka 18300: Loss = 0.000000515\n",
      "Epoka 18310: Loss = 0.000000930\n",
      "Epoka 18320: Loss = 0.000000685\n",
      "Epoka 18330: Loss = 0.000000531\n",
      "Epoka 18340: Loss = 0.000000574\n",
      "Epoka 18350: Loss = 0.000000536\n",
      "Epoka 18360: Loss = 0.000000578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 18370: Loss = 0.000000527\n",
      "Epoka 18380: Loss = 0.000000545\n",
      "Epoka 18390: Loss = 0.000000608\n",
      "Epoka 18400: Loss = 0.000000554\n",
      "Epoka 18410: Loss = 0.000000633\n",
      "Epoka 18420: Loss = 0.000000641\n",
      "Epoka 18430: Loss = 0.000000519\n",
      "Epoka 18440: Loss = 0.000000550\n",
      "Epoka 18450: Loss = 0.000000826\n",
      "Epoka 18460: Loss = 0.000000748\n",
      "Epoka 18470: Loss = 0.000000569\n",
      "Epoka 18480: Loss = 0.000000532\n",
      "Epoka 18490: Loss = 0.000000511\n",
      "Epoka 18500: Loss = 0.000000577\n",
      "Epoka 18510: Loss = 0.000000547\n",
      "Epoka 18520: Loss = 0.000000606\n",
      "Epoka 18530: Loss = 0.000000656\n",
      "Epoka 18540: Loss = 0.000001160\n",
      "Epoka 18550: Loss = 0.000000585\n",
      "Epoka 18560: Loss = 0.000000680\n",
      "Epoka 18570: Loss = 0.000000959\n",
      "Epoka 18580: Loss = 0.000000548\n",
      "Epoka 18590: Loss = 0.000000711\n",
      "Epoka 18600: Loss = 0.000000535\n",
      "Epoka 18610: Loss = 0.000000889\n",
      "Epoka 18620: Loss = 0.000000521\n",
      "Epoka 18630: Loss = 0.000000568\n",
      "Epoka 18640: Loss = 0.000000600\n",
      "Epoka 18650: Loss = 0.000000511\n",
      "Epoka 18660: Loss = 0.000000766\n",
      "Epoka 18670: Loss = 0.000000796\n",
      "Epoka 18680: Loss = 0.000000694\n",
      "Epoka 18690: Loss = 0.000000670\n",
      "Epoka 18700: Loss = 0.000000563\n",
      "Epoka 18710: Loss = 0.000000481\n",
      "Epoka 18720: Loss = 0.000000503\n",
      "Epoka 18730: Loss = 0.000000526\n",
      "Epoka 18740: Loss = 0.000000499\n",
      "Epoka 18750: Loss = 0.000000526\n",
      "Epoka 18760: Loss = 0.000000630\n",
      "Epoka 18770: Loss = 0.000000520\n",
      "Epoka 18780: Loss = 0.000001089\n",
      "Epoka 18790: Loss = 0.000000522\n",
      "Epoka 18800: Loss = 0.000000980\n",
      "Epoka 18810: Loss = 0.000000556\n",
      "Epoka 18820: Loss = 0.000000639\n",
      "Epoka 18830: Loss = 0.000000538\n",
      "Epoka 18840: Loss = 0.000000554\n",
      "Epoka 18850: Loss = 0.000000617\n",
      "Epoka 18860: Loss = 0.000000501\n",
      "Epoka 18870: Loss = 0.000000480\n",
      "Epoka 18880: Loss = 0.000000474\n",
      "Epoka 18890: Loss = 0.000000613\n",
      "Epoka 18900: Loss = 0.000000893\n",
      "Epoka 18910: Loss = 0.000000581\n",
      "Epoka 18920: Loss = 0.000000672\n",
      "Epoka 18930: Loss = 0.000000991\n",
      "Epoka 18940: Loss = 0.000000580\n",
      "Epoka 18950: Loss = 0.000000561\n",
      "Epoka 18960: Loss = 0.000000493\n",
      "Epoka 18970: Loss = 0.000001083\n",
      "Epoka 18980: Loss = 0.000000532\n",
      "Epoka 18990: Loss = 0.000000515\n",
      "Epoka 19000: Loss = 0.000000766\n",
      "Epoka 19010: Loss = 0.000000632\n",
      "Epoka 19020: Loss = 0.000000736\n",
      "Epoka 19030: Loss = 0.000000546\n",
      "Epoka 19040: Loss = 0.000000635\n",
      "Epoka 19050: Loss = 0.000000531\n",
      "Epoka 19060: Loss = 0.000000867\n",
      "Epoka 19070: Loss = 0.000000672\n",
      "Epoka 19080: Loss = 0.000000493\n",
      "Epoka 19090: Loss = 0.000000984\n",
      "Epoka 19100: Loss = 0.000000516\n",
      "Epoka 19110: Loss = 0.000000631\n",
      "Epoka 19120: Loss = 0.000000940\n",
      "Epoka 19130: Loss = 0.000000528\n",
      "Epoka 19140: Loss = 0.000000526\n",
      "Epoka 19150: Loss = 0.000000631\n",
      "Epoka 19160: Loss = 0.000000621\n",
      "Epoka 19170: Loss = 0.000000583\n",
      "Epoka 19180: Loss = 0.000000575\n",
      "Epoka 19190: Loss = 0.000000656\n",
      "Epoka 19200: Loss = 0.000000471\n",
      "Epoka 19210: Loss = 0.000000594\n",
      "Epoka 19220: Loss = 0.000000479\n",
      "Epoka 19230: Loss = 0.000000504\n",
      "Epoka 19240: Loss = 0.000000470\n",
      "Epoka 19250: Loss = 0.000001106\n",
      "Epoka 19260: Loss = 0.000000874\n",
      "Epoka 19270: Loss = 0.000000937\n",
      "Epoka 19280: Loss = 0.000000468\n",
      "Epoka 19290: Loss = 0.000000675\n",
      "Epoka 19300: Loss = 0.000000583\n",
      "Epoka 19310: Loss = 0.000000460\n",
      "Epoka 19320: Loss = 0.000000496\n",
      "Epoka 19330: Loss = 0.000000460\n",
      "Epoka 19340: Loss = 0.000000666\n",
      "Epoka 19350: Loss = 0.000000472\n",
      "Epoka 19360: Loss = 0.000000696\n",
      "Epoka 19370: Loss = 0.000000685\n",
      "Epoka 19380: Loss = 0.000000772\n",
      "Epoka 19390: Loss = 0.000000713\n",
      "Epoka 19400: Loss = 0.000000912\n",
      "Epoka 19410: Loss = 0.000000485\n",
      "Epoka 19420: Loss = 0.000000506\n",
      "Epoka 19430: Loss = 0.000000602\n",
      "Epoka 19440: Loss = 0.000000459\n",
      "Epoka 19450: Loss = 0.000000456\n",
      "Epoka 19460: Loss = 0.000000575\n",
      "Epoka 19470: Loss = 0.000000562\n",
      "Epoka 19480: Loss = 0.000000580\n",
      "Epoka 19490: Loss = 0.000000558\n",
      "Epoka 19500: Loss = 0.000000841\n",
      "Epoka 19510: Loss = 0.000000478\n",
      "Epoka 19520: Loss = 0.000000659\n",
      "Epoka 19530: Loss = 0.000000513\n",
      "Epoka 19540: Loss = 0.000000577\n",
      "Epoka 19550: Loss = 0.000000812\n",
      "Epoka 19560: Loss = 0.000000614\n",
      "Epoka 19570: Loss = 0.000000574\n",
      "Epoka 19580: Loss = 0.000000491\n",
      "Epoka 19590: Loss = 0.000000660\n",
      "Epoka 19600: Loss = 0.000000615\n",
      "Epoka 19610: Loss = 0.000000687\n",
      "Epoka 19620: Loss = 0.000000626\n",
      "Epoka 19630: Loss = 0.000000893\n",
      "Epoka 19640: Loss = 0.000000488\n",
      "Epoka 19650: Loss = 0.000000576\n",
      "Epoka 19660: Loss = 0.000000522\n",
      "Epoka 19670: Loss = 0.000000455\n",
      "Epoka 19680: Loss = 0.000000527\n",
      "Epoka 19690: Loss = 0.000000611\n",
      "Epoka 19700: Loss = 0.000000633\n",
      "Epoka 19710: Loss = 0.000000500\n",
      "Epoka 19720: Loss = 0.000000663\n",
      "Epoka 19730: Loss = 0.000000492\n",
      "Epoka 19740: Loss = 0.000000463\n",
      "Epoka 19750: Loss = 0.000000552\n",
      "Epoka 19760: Loss = 0.000001056\n",
      "Epoka 19770: Loss = 0.000000506\n",
      "Epoka 19780: Loss = 0.000000650\n",
      "Epoka 19790: Loss = 0.000000817\n",
      "Epoka 19800: Loss = 0.000000532\n",
      "Epoka 19810: Loss = 0.000000843\n",
      "Epoka 19820: Loss = 0.000000900\n",
      "Epoka 19830: Loss = 0.000000578\n",
      "Epoka 19840: Loss = 0.000000490\n",
      "Epoka 19850: Loss = 0.000000474\n",
      "Epoka 19860: Loss = 0.000000551\n",
      "Epoka 19870: Loss = 0.000000576\n",
      "Epoka 19880: Loss = 0.000000740\n",
      "Epoka 19890: Loss = 0.000000487\n",
      "Epoka 19900: Loss = 0.000000526\n",
      "Epoka 19910: Loss = 0.000000568\n",
      "Epoka 19920: Loss = 0.000000599\n",
      "Epoka 19930: Loss = 0.000000526\n",
      "Epoka 19940: Loss = 0.000000460\n",
      "Epoka 19950: Loss = 0.000000525\n",
      "Epoka 19960: Loss = 0.000000457\n",
      "Epoka 19970: Loss = 0.000000456\n",
      "Epoka 19980: Loss = 0.000000478\n",
      "Epoka 19990: Loss = 0.000000874\n",
      "Epoka 20000: Loss = 0.000000543\n",
      "Epoka 20010: Loss = 0.000000579\n",
      "Epoka 20020: Loss = 0.000000679\n",
      "Epoka 20030: Loss = 0.000000495\n",
      "Epoka 20040: Loss = 0.000000460\n",
      "Epoka 20050: Loss = 0.000000473\n",
      "Epoka 20060: Loss = 0.000000532\n",
      "Epoka 20070: Loss = 0.000000543\n",
      "Epoka 20080: Loss = 0.000000611\n",
      "Epoka 20090: Loss = 0.000000580\n",
      "Epoka 20100: Loss = 0.000001844\n",
      "Epoka 20110: Loss = 0.000000532\n",
      "Epoka 20120: Loss = 0.000000497\n",
      "Epoka 20130: Loss = 0.000000452\n",
      "Epoka 20140: Loss = 0.000000494\n",
      "Epoka 20150: Loss = 0.000000588\n",
      "Epoka 20160: Loss = 0.000000440\n",
      "Epoka 20170: Loss = 0.000000437\n",
      "Epoka 20180: Loss = 0.000000516\n",
      "Epoka 20190: Loss = 0.000000537\n",
      "Epoka 20200: Loss = 0.000001053\n",
      "Epoka 20210: Loss = 0.000000464\n",
      "Epoka 20220: Loss = 0.000000436\n",
      "Epoka 20230: Loss = 0.000000536\n",
      "Epoka 20240: Loss = 0.000000591\n",
      "Epoka 20250: Loss = 0.000000802\n",
      "Epoka 20260: Loss = 0.000000450\n",
      "Epoka 20270: Loss = 0.000000456\n",
      "Epoka 20280: Loss = 0.000000502\n",
      "Epoka 20290: Loss = 0.000000467\n",
      "Epoka 20300: Loss = 0.000000882\n",
      "Epoka 20310: Loss = 0.000000543\n",
      "Epoka 20320: Loss = 0.000000466\n",
      "Epoka 20330: Loss = 0.000000494\n",
      "Epoka 20340: Loss = 0.000000612\n",
      "Epoka 20350: Loss = 0.000000546\n",
      "Epoka 20360: Loss = 0.000000706\n",
      "Epoka 20370: Loss = 0.000000457\n",
      "Epoka 20380: Loss = 0.000000480\n",
      "Epoka 20390: Loss = 0.000000443\n",
      "Epoka 20400: Loss = 0.000000515\n",
      "Epoka 20410: Loss = 0.000000441\n",
      "Epoka 20420: Loss = 0.000000527\n",
      "Epoka 20430: Loss = 0.000000616\n",
      "Epoka 20440: Loss = 0.000000736\n",
      "Epoka 20450: Loss = 0.000000438\n",
      "Epoka 20460: Loss = 0.000000793\n",
      "Epoka 20470: Loss = 0.000000425\n",
      "Epoka 20480: Loss = 0.000000463\n",
      "Epoka 20490: Loss = 0.000001279\n",
      "Epoka 20500: Loss = 0.000000429\n",
      "Epoka 20510: Loss = 0.000000442\n",
      "Epoka 20520: Loss = 0.000000427\n",
      "Epoka 20530: Loss = 0.000000463\n",
      "Epoka 20540: Loss = 0.000000441\n",
      "Epoka 20550: Loss = 0.000000628\n",
      "Epoka 20560: Loss = 0.000000667\n",
      "Epoka 20570: Loss = 0.000000438\n",
      "Epoka 20580: Loss = 0.000000426\n",
      "Epoka 20590: Loss = 0.000000443\n",
      "Epoka 20600: Loss = 0.000000509\n",
      "Epoka 20610: Loss = 0.000000451\n",
      "Epoka 20620: Loss = 0.000000487\n",
      "Epoka 20630: Loss = 0.000000437\n",
      "Epoka 20640: Loss = 0.000000481\n",
      "Epoka 20650: Loss = 0.000000914\n",
      "Epoka 20660: Loss = 0.000000481\n",
      "Epoka 20670: Loss = 0.000000423\n",
      "Epoka 20680: Loss = 0.000000890\n",
      "Epoka 20690: Loss = 0.000000607\n",
      "Epoka 20700: Loss = 0.000000539\n",
      "Epoka 20710: Loss = 0.000000453\n",
      "Epoka 20720: Loss = 0.000000528\n",
      "Epoka 20730: Loss = 0.000000629\n",
      "Epoka 20740: Loss = 0.000000445\n",
      "Epoka 20750: Loss = 0.000000442\n",
      "Epoka 20760: Loss = 0.000000459\n",
      "Epoka 20770: Loss = 0.000000854\n",
      "Epoka 20780: Loss = 0.000000500\n",
      "Epoka 20790: Loss = 0.000000487\n",
      "Epoka 20800: Loss = 0.000000765\n",
      "Epoka 20810: Loss = 0.000000714\n",
      "Epoka 20820: Loss = 0.000001044\n",
      "Epoka 20830: Loss = 0.000000463\n",
      "Epoka 20840: Loss = 0.000000426\n",
      "Epoka 20850: Loss = 0.000000591\n",
      "Epoka 20860: Loss = 0.000000558\n",
      "Epoka 20870: Loss = 0.000000549\n",
      "Epoka 20880: Loss = 0.000000638\n",
      "Epoka 20890: Loss = 0.000000442\n",
      "Epoka 20900: Loss = 0.000000638\n",
      "Epoka 20910: Loss = 0.000000528\n",
      "Epoka 20920: Loss = 0.000000443\n",
      "Epoka 20930: Loss = 0.000000458\n",
      "Epoka 20940: Loss = 0.000000771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 20950: Loss = 0.000000748\n",
      "Epoka 20960: Loss = 0.000000458\n",
      "Epoka 20970: Loss = 0.000000541\n",
      "Epoka 20980: Loss = 0.000000684\n",
      "Epoka 20990: Loss = 0.000000621\n",
      "Epoka 21000: Loss = 0.000000499\n",
      "Epoka 21010: Loss = 0.000000429\n",
      "Epoka 21020: Loss = 0.000000809\n",
      "Epoka 21030: Loss = 0.000000448\n",
      "Epoka 21040: Loss = 0.000000443\n",
      "Epoka 21050: Loss = 0.000000425\n",
      "Epoka 21060: Loss = 0.000000550\n",
      "Epoka 21070: Loss = 0.000000965\n",
      "Epoka 21080: Loss = 0.000000578\n",
      "Epoka 21090: Loss = 0.000000461\n",
      "Epoka 21100: Loss = 0.000000520\n",
      "Epoka 21110: Loss = 0.000000437\n",
      "Epoka 21120: Loss = 0.000000456\n",
      "Epoka 21130: Loss = 0.000000496\n",
      "Epoka 21140: Loss = 0.000000413\n",
      "Epoka 21150: Loss = 0.000000478\n",
      "Epoka 21160: Loss = 0.000000491\n",
      "Epoka 21170: Loss = 0.000000444\n",
      "Epoka 21180: Loss = 0.000000423\n",
      "Epoka 21190: Loss = 0.000000449\n",
      "Epoka 21200: Loss = 0.000001000\n",
      "Epoka 21210: Loss = 0.000000441\n",
      "Epoka 21220: Loss = 0.000000650\n",
      "Epoka 21230: Loss = 0.000000499\n",
      "Epoka 21240: Loss = 0.000000804\n",
      "Epoka 21250: Loss = 0.000001101\n",
      "Epoka 21260: Loss = 0.000000429\n",
      "Epoka 21270: Loss = 0.000000430\n",
      "Epoka 21280: Loss = 0.000000475\n",
      "Epoka 21290: Loss = 0.000000527\n",
      "Epoka 21300: Loss = 0.000000413\n",
      "Epoka 21310: Loss = 0.000000933\n",
      "Epoka 21320: Loss = 0.000000421\n",
      "Epoka 21330: Loss = 0.000000450\n",
      "Epoka 21340: Loss = 0.000000413\n",
      "Epoka 21350: Loss = 0.000000658\n",
      "Epoka 21360: Loss = 0.000000527\n",
      "Epoka 21370: Loss = 0.000000854\n",
      "Epoka 21380: Loss = 0.000000629\n",
      "Epoka 21390: Loss = 0.000000444\n",
      "Epoka 21400: Loss = 0.000000525\n",
      "Epoka 21410: Loss = 0.000000708\n",
      "Epoka 21420: Loss = 0.000000518\n",
      "Epoka 21430: Loss = 0.000000398\n",
      "Epoka 21440: Loss = 0.000000501\n",
      "Epoka 21450: Loss = 0.000000458\n",
      "Epoka 21460: Loss = 0.000000521\n",
      "Epoka 21470: Loss = 0.000000525\n",
      "Epoka 21480: Loss = 0.000000434\n",
      "Epoka 21490: Loss = 0.000000685\n",
      "Epoka 21500: Loss = 0.000000465\n",
      "Epoka 21510: Loss = 0.000000423\n",
      "Epoka 21520: Loss = 0.000001078\n",
      "Epoka 21530: Loss = 0.000000781\n",
      "Epoka 21540: Loss = 0.000000711\n",
      "Epoka 21550: Loss = 0.000000405\n",
      "Epoka 21560: Loss = 0.000001753\n",
      "Epoka 21570: Loss = 0.000000432\n",
      "Epoka 21580: Loss = 0.000000540\n",
      "Epoka 21590: Loss = 0.000000439\n",
      "Epoka 21600: Loss = 0.000001312\n",
      "Epoka 21610: Loss = 0.000000490\n",
      "Epoka 21620: Loss = 0.000000395\n",
      "Epoka 21630: Loss = 0.000000488\n",
      "Epoka 21640: Loss = 0.000000440\n",
      "Epoka 21650: Loss = 0.000000808\n",
      "Epoka 21660: Loss = 0.000000403\n",
      "Epoka 21670: Loss = 0.000000550\n",
      "Epoka 21680: Loss = 0.000000394\n",
      "Epoka 21690: Loss = 0.000000498\n",
      "Epoka 21700: Loss = 0.000000482\n",
      "Epoka 21710: Loss = 0.000000766\n",
      "Epoka 21720: Loss = 0.000000887\n",
      "Epoka 21730: Loss = 0.000000628\n",
      "Epoka 21740: Loss = 0.000000545\n",
      "Epoka 21750: Loss = 0.000000404\n",
      "Epoka 21760: Loss = 0.000000436\n",
      "Epoka 21770: Loss = 0.000000432\n",
      "Epoka 21780: Loss = 0.000000449\n",
      "Epoka 21790: Loss = 0.000000397\n",
      "Epoka 21800: Loss = 0.000000596\n",
      "Epoka 21810: Loss = 0.000000563\n",
      "Epoka 21820: Loss = 0.000000494\n",
      "Epoka 21830: Loss = 0.000000573\n",
      "Epoka 21840: Loss = 0.000000564\n",
      "Epoka 21850: Loss = 0.000000466\n",
      "Epoka 21860: Loss = 0.000000446\n",
      "Epoka 21870: Loss = 0.000000396\n",
      "Epoka 21880: Loss = 0.000000430\n",
      "Epoka 21890: Loss = 0.000000622\n",
      "Epoka 21900: Loss = 0.000000425\n",
      "Epoka 21910: Loss = 0.000000408\n",
      "Epoka 21920: Loss = 0.000000828\n",
      "Epoka 21930: Loss = 0.000000450\n",
      "Epoka 21940: Loss = 0.000000477\n",
      "Epoka 21950: Loss = 0.000000389\n",
      "Epoka 21960: Loss = 0.000000504\n",
      "Epoka 21970: Loss = 0.000000485\n",
      "Epoka 21980: Loss = 0.000000441\n",
      "Epoka 21990: Loss = 0.000000383\n",
      "Epoka 22000: Loss = 0.000000478\n",
      "Epoka 22010: Loss = 0.000000407\n",
      "Epoka 22020: Loss = 0.000001099\n",
      "Epoka 22030: Loss = 0.000000732\n",
      "Epoka 22040: Loss = 0.000000378\n",
      "Epoka 22050: Loss = 0.000000393\n",
      "Epoka 22060: Loss = 0.000000573\n",
      "Epoka 22070: Loss = 0.000000402\n",
      "Epoka 22080: Loss = 0.000000398\n",
      "Epoka 22090: Loss = 0.000000478\n",
      "Epoka 22100: Loss = 0.000000441\n",
      "Epoka 22110: Loss = 0.000000383\n",
      "Epoka 22120: Loss = 0.000000463\n",
      "Epoka 22130: Loss = 0.000000498\n",
      "Epoka 22140: Loss = 0.000000395\n",
      "Epoka 22150: Loss = 0.000000404\n",
      "Epoka 22160: Loss = 0.000000400\n",
      "Epoka 22170: Loss = 0.000000421\n",
      "Epoka 22180: Loss = 0.000000396\n",
      "Epoka 22190: Loss = 0.000000579\n",
      "Epoka 22200: Loss = 0.000000383\n",
      "Epoka 22210: Loss = 0.000000441\n",
      "Epoka 22220: Loss = 0.000000653\n",
      "Epoka 22230: Loss = 0.000000388\n",
      "Epoka 22240: Loss = 0.000000475\n",
      "Epoka 22250: Loss = 0.000000399\n",
      "Epoka 22260: Loss = 0.000000879\n",
      "Epoka 22270: Loss = 0.000000464\n",
      "Epoka 22280: Loss = 0.000000638\n",
      "Epoka 22290: Loss = 0.000000787\n",
      "Epoka 22300: Loss = 0.000000432\n",
      "Epoka 22310: Loss = 0.000000523\n",
      "Epoka 22320: Loss = 0.000000388\n",
      "Epoka 22330: Loss = 0.000000428\n",
      "Epoka 22340: Loss = 0.000000533\n",
      "Epoka 22350: Loss = 0.000000450\n",
      "Epoka 22360: Loss = 0.000000467\n",
      "Epoka 22370: Loss = 0.000000419\n",
      "Epoka 22380: Loss = 0.000000408\n",
      "Epoka 22390: Loss = 0.000000510\n",
      "Epoka 22400: Loss = 0.000000543\n",
      "Epoka 22410: Loss = 0.000000506\n",
      "Epoka 22420: Loss = 0.000000623\n",
      "Epoka 22430: Loss = 0.000000414\n",
      "Epoka 22440: Loss = 0.000000742\n",
      "Epoka 22450: Loss = 0.000000375\n",
      "Epoka 22460: Loss = 0.000000407\n",
      "Epoka 22470: Loss = 0.000000485\n",
      "Epoka 22480: Loss = 0.000000492\n",
      "Epoka 22490: Loss = 0.000000895\n",
      "Epoka 22500: Loss = 0.000000546\n",
      "Epoka 22510: Loss = 0.000000563\n",
      "Epoka 22520: Loss = 0.000000422\n",
      "Epoka 22530: Loss = 0.000000567\n",
      "Epoka 22540: Loss = 0.000000779\n",
      "Epoka 22550: Loss = 0.000000532\n",
      "Epoka 22560: Loss = 0.000000405\n",
      "Epoka 22570: Loss = 0.000000526\n",
      "Epoka 22580: Loss = 0.000000486\n",
      "Epoka 22590: Loss = 0.000000366\n",
      "Epoka 22600: Loss = 0.000000441\n",
      "Epoka 22610: Loss = 0.000000420\n",
      "Epoka 22620: Loss = 0.000001095\n",
      "Epoka 22630: Loss = 0.000000636\n",
      "Epoka 22640: Loss = 0.000000495\n",
      "Epoka 22650: Loss = 0.000000800\n",
      "Epoka 22660: Loss = 0.000000421\n",
      "Epoka 22670: Loss = 0.000000435\n",
      "Epoka 22680: Loss = 0.000000679\n",
      "Epoka 22690: Loss = 0.000001230\n",
      "Epoka 22700: Loss = 0.000000432\n",
      "Epoka 22710: Loss = 0.000000431\n",
      "Epoka 22720: Loss = 0.000000533\n",
      "Epoka 22730: Loss = 0.000000410\n",
      "Epoka 22740: Loss = 0.000000524\n",
      "Epoka 22750: Loss = 0.000000527\n",
      "Epoka 22760: Loss = 0.000000495\n",
      "Epoka 22770: Loss = 0.000000371\n",
      "Epoka 22780: Loss = 0.000000430\n",
      "Epoka 22790: Loss = 0.000000486\n",
      "Epoka 22800: Loss = 0.000000401\n",
      "Epoka 22810: Loss = 0.000000442\n",
      "Epoka 22820: Loss = 0.000000771\n",
      "Epoka 22830: Loss = 0.000000455\n",
      "Epoka 22840: Loss = 0.000000456\n",
      "Epoka 22850: Loss = 0.000000467\n",
      "Epoka 22860: Loss = 0.000000368\n",
      "Epoka 22870: Loss = 0.000000431\n",
      "Epoka 22880: Loss = 0.000000386\n",
      "Epoka 22890: Loss = 0.000000377\n",
      "Epoka 22900: Loss = 0.000000399\n",
      "Epoka 22910: Loss = 0.000000463\n",
      "Epoka 22920: Loss = 0.000000519\n",
      "Epoka 22930: Loss = 0.000000395\n",
      "Epoka 22940: Loss = 0.000000445\n",
      "Epoka 22950: Loss = 0.000000380\n",
      "Epoka 22960: Loss = 0.000000373\n",
      "Epoka 22970: Loss = 0.000000364\n",
      "Epoka 22980: Loss = 0.000000523\n",
      "Epoka 22990: Loss = 0.000000528\n",
      "Epoka 23000: Loss = 0.000000388\n",
      "Epoka 23010: Loss = 0.000000429\n",
      "Epoka 23020: Loss = 0.000000670\n",
      "Epoka 23030: Loss = 0.000000439\n",
      "Epoka 23040: Loss = 0.000000743\n",
      "Epoka 23050: Loss = 0.000000384\n",
      "Epoka 23060: Loss = 0.000000666\n",
      "Epoka 23070: Loss = 0.000000721\n",
      "Epoka 23080: Loss = 0.000000558\n",
      "Epoka 23090: Loss = 0.000000493\n",
      "Epoka 23100: Loss = 0.000000395\n",
      "Epoka 23110: Loss = 0.000000463\n",
      "Epoka 23120: Loss = 0.000000548\n",
      "Epoka 23130: Loss = 0.000000358\n",
      "Epoka 23140: Loss = 0.000000423\n",
      "Epoka 23150: Loss = 0.000000451\n",
      "Epoka 23160: Loss = 0.000000468\n",
      "Epoka 23170: Loss = 0.000000387\n",
      "Epoka 23180: Loss = 0.000000718\n",
      "Epoka 23190: Loss = 0.000000391\n",
      "Epoka 23200: Loss = 0.000000410\n",
      "Epoka 23210: Loss = 0.000000553\n",
      "Epoka 23220: Loss = 0.000000369\n",
      "Epoka 23230: Loss = 0.000000414\n",
      "Epoka 23240: Loss = 0.000000413\n",
      "Epoka 23250: Loss = 0.000000707\n",
      "Epoka 23260: Loss = 0.000000459\n",
      "Epoka 23270: Loss = 0.000000414\n",
      "Epoka 23280: Loss = 0.000000514\n",
      "Epoka 23290: Loss = 0.000000382\n",
      "Epoka 23300: Loss = 0.000000459\n",
      "Epoka 23310: Loss = 0.000000487\n",
      "Epoka 23320: Loss = 0.000000404\n",
      "Epoka 23330: Loss = 0.000000428\n",
      "Epoka 23340: Loss = 0.000000352\n",
      "Epoka 23350: Loss = 0.000000358\n",
      "Epoka 23360: Loss = 0.000000402\n",
      "Epoka 23370: Loss = 0.000000480\n",
      "Epoka 23380: Loss = 0.000000443\n",
      "Epoka 23390: Loss = 0.000000466\n",
      "Epoka 23400: Loss = 0.000000428\n",
      "Epoka 23410: Loss = 0.000000410\n",
      "Epoka 23420: Loss = 0.000000604\n",
      "Epoka 23430: Loss = 0.000000395\n",
      "Epoka 23440: Loss = 0.000000365\n",
      "Epoka 23450: Loss = 0.000000649\n",
      "Epoka 23460: Loss = 0.000000420\n",
      "Epoka 23470: Loss = 0.000000346\n",
      "Epoka 23480: Loss = 0.000000602\n",
      "Epoka 23490: Loss = 0.000000425\n",
      "Epoka 23500: Loss = 0.000000345\n",
      "Epoka 23510: Loss = 0.000000520\n",
      "Epoka 23520: Loss = 0.000000385\n",
      "Epoka 23530: Loss = 0.000000409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 23540: Loss = 0.000000365\n",
      "Epoka 23550: Loss = 0.000000517\n",
      "Epoka 23560: Loss = 0.000000370\n",
      "Epoka 23570: Loss = 0.000000477\n",
      "Epoka 23580: Loss = 0.000000425\n",
      "Epoka 23590: Loss = 0.000000546\n",
      "Epoka 23600: Loss = 0.000000456\n",
      "Epoka 23610: Loss = 0.000000405\n",
      "Epoka 23620: Loss = 0.000000468\n",
      "Epoka 23630: Loss = 0.000000602\n",
      "Epoka 23640: Loss = 0.000000415\n",
      "Epoka 23650: Loss = 0.000000341\n",
      "Epoka 23660: Loss = 0.000000699\n",
      "Epoka 23670: Loss = 0.000000361\n",
      "Epoka 23680: Loss = 0.000000401\n",
      "Epoka 23690: Loss = 0.000000390\n",
      "Epoka 23700: Loss = 0.000000376\n",
      "Epoka 23710: Loss = 0.000000391\n",
      "Epoka 23720: Loss = 0.000000517\n",
      "Epoka 23730: Loss = 0.000000354\n",
      "Epoka 23740: Loss = 0.000001011\n",
      "Epoka 23750: Loss = 0.000000458\n",
      "Epoka 23760: Loss = 0.000000440\n",
      "Epoka 23770: Loss = 0.000000340\n",
      "Epoka 23780: Loss = 0.000000568\n",
      "Epoka 23790: Loss = 0.000000372\n",
      "Epoka 23800: Loss = 0.000000768\n",
      "Epoka 23810: Loss = 0.000000650\n",
      "Epoka 23820: Loss = 0.000000424\n",
      "Epoka 23830: Loss = 0.000000475\n",
      "Epoka 23840: Loss = 0.000000450\n",
      "Epoka 23850: Loss = 0.000000436\n",
      "Epoka 23860: Loss = 0.000000346\n",
      "Epoka 23870: Loss = 0.000000562\n",
      "Epoka 23880: Loss = 0.000000350\n",
      "Epoka 23890: Loss = 0.000000588\n",
      "Epoka 23900: Loss = 0.000000481\n",
      "Epoka 23910: Loss = 0.000000392\n",
      "Epoka 23920: Loss = 0.000000343\n",
      "Epoka 23930: Loss = 0.000000358\n",
      "Epoka 23940: Loss = 0.000000334\n",
      "Epoka 23950: Loss = 0.000000354\n",
      "Epoka 23960: Loss = 0.000000378\n",
      "Epoka 23970: Loss = 0.000000348\n",
      "Epoka 23980: Loss = 0.000000436\n",
      "Epoka 23990: Loss = 0.000000393\n",
      "Epoka 24000: Loss = 0.000000334\n",
      "Epoka 24010: Loss = 0.000000377\n",
      "Epoka 24020: Loss = 0.000000356\n",
      "Epoka 24030: Loss = 0.000000454\n",
      "Epoka 24040: Loss = 0.000000733\n",
      "Epoka 24050: Loss = 0.000000364\n",
      "Epoka 24060: Loss = 0.000000371\n",
      "Epoka 24070: Loss = 0.000000340\n",
      "Epoka 24080: Loss = 0.000000399\n",
      "Epoka 24090: Loss = 0.000000349\n",
      "Epoka 24100: Loss = 0.000000364\n",
      "Epoka 24110: Loss = 0.000000361\n",
      "Epoka 24120: Loss = 0.000000452\n",
      "Epoka 24130: Loss = 0.000000395\n",
      "Epoka 24140: Loss = 0.000000430\n",
      "Epoka 24150: Loss = 0.000000358\n",
      "Epoka 24160: Loss = 0.000000517\n",
      "Epoka 24170: Loss = 0.000000387\n",
      "Epoka 24180: Loss = 0.000000331\n",
      "Epoka 24190: Loss = 0.000000357\n",
      "Epoka 24200: Loss = 0.000000377\n",
      "Epoka 24210: Loss = 0.000000328\n",
      "Epoka 24220: Loss = 0.000000344\n",
      "Epoka 24230: Loss = 0.000000537\n",
      "Epoka 24240: Loss = 0.000000472\n",
      "Epoka 24250: Loss = 0.000000446\n",
      "Epoka 24260: Loss = 0.000000337\n",
      "Epoka 24270: Loss = 0.000000356\n",
      "Epoka 24280: Loss = 0.000000505\n",
      "Epoka 24290: Loss = 0.000000659\n",
      "Epoka 24300: Loss = 0.000000454\n",
      "Epoka 24310: Loss = 0.000000373\n",
      "Epoka 24320: Loss = 0.000000336\n",
      "Epoka 24330: Loss = 0.000000404\n",
      "Epoka 24340: Loss = 0.000000353\n",
      "Epoka 24350: Loss = 0.000000351\n",
      "Epoka 24360: Loss = 0.000000332\n",
      "Epoka 24370: Loss = 0.000000428\n",
      "Epoka 24380: Loss = 0.000000535\n",
      "Epoka 24390: Loss = 0.000000992\n",
      "Epoka 24400: Loss = 0.000000965\n",
      "Epoka 24410: Loss = 0.000000497\n",
      "Epoka 24420: Loss = 0.000000332\n",
      "Epoka 24430: Loss = 0.000000402\n",
      "Epoka 24440: Loss = 0.000000345\n",
      "Epoka 24450: Loss = 0.000000371\n",
      "Epoka 24460: Loss = 0.000000381\n",
      "Epoka 24470: Loss = 0.000000369\n",
      "Epoka 24480: Loss = 0.000000438\n",
      "Epoka 24490: Loss = 0.000000321\n",
      "Epoka 24500: Loss = 0.000000384\n",
      "Epoka 24510: Loss = 0.000000347\n",
      "Epoka 24520: Loss = 0.000000563\n",
      "Epoka 24530: Loss = 0.000000332\n",
      "Epoka 24540: Loss = 0.000000433\n",
      "Epoka 24550: Loss = 0.000000349\n",
      "Epoka 24560: Loss = 0.000000336\n",
      "Epoka 24570: Loss = 0.000000344\n",
      "Epoka 24580: Loss = 0.000000362\n",
      "Epoka 24590: Loss = 0.000000345\n",
      "Epoka 24600: Loss = 0.000000336\n",
      "Epoka 24610: Loss = 0.000000343\n",
      "Epoka 24620: Loss = 0.000000629\n",
      "Epoka 24630: Loss = 0.000000362\n",
      "Epoka 24640: Loss = 0.000000411\n",
      "Epoka 24650: Loss = 0.000000399\n",
      "Epoka 24660: Loss = 0.000000404\n",
      "Epoka 24670: Loss = 0.000000403\n",
      "Epoka 24680: Loss = 0.000000400\n",
      "Epoka 24690: Loss = 0.000000350\n",
      "Epoka 24700: Loss = 0.000000321\n",
      "Epoka 24710: Loss = 0.000000354\n",
      "Epoka 24720: Loss = 0.000000466\n",
      "Epoka 24730: Loss = 0.000000379\n",
      "Epoka 24740: Loss = 0.000000495\n",
      "Epoka 24750: Loss = 0.000000314\n",
      "Epoka 24760: Loss = 0.000000407\n",
      "Epoka 24770: Loss = 0.000000665\n",
      "Epoka 24780: Loss = 0.000000529\n",
      "Epoka 24790: Loss = 0.000000381\n",
      "Epoka 24800: Loss = 0.000000322\n",
      "Epoka 24810: Loss = 0.000000475\n",
      "Epoka 24820: Loss = 0.000000402\n",
      "Epoka 24830: Loss = 0.000000348\n",
      "Epoka 24840: Loss = 0.000000337\n",
      "Epoka 24850: Loss = 0.000000337\n",
      "Epoka 24860: Loss = 0.000000420\n",
      "Epoka 24870: Loss = 0.000000339\n",
      "Epoka 24880: Loss = 0.000000353\n",
      "Epoka 24890: Loss = 0.000000728\n",
      "Epoka 24900: Loss = 0.000000475\n",
      "Epoka 24910: Loss = 0.000000592\n",
      "Epoka 24920: Loss = 0.000000601\n",
      "Epoka 24930: Loss = 0.000000402\n",
      "Epoka 24940: Loss = 0.000000375\n",
      "Epoka 24950: Loss = 0.000000323\n",
      "Epoka 24960: Loss = 0.000000497\n",
      "Epoka 24970: Loss = 0.000000417\n",
      "Epoka 24980: Loss = 0.000000347\n",
      "Epoka 24990: Loss = 0.000000324\n",
      "Epoka 25000: Loss = 0.000000603\n",
      "Epoka 25010: Loss = 0.000000357\n",
      "Epoka 25020: Loss = 0.000000471\n",
      "Epoka 25030: Loss = 0.000000362\n",
      "Epoka 25040: Loss = 0.000000324\n",
      "Epoka 25050: Loss = 0.000000318\n",
      "Epoka 25060: Loss = 0.000000405\n",
      "Epoka 25070: Loss = 0.000000640\n",
      "Epoka 25080: Loss = 0.000000375\n",
      "Epoka 25090: Loss = 0.000000372\n",
      "Epoka 25100: Loss = 0.000000315\n",
      "Epoka 25110: Loss = 0.000000434\n",
      "Epoka 25120: Loss = 0.000000574\n",
      "Epoka 25130: Loss = 0.000000487\n",
      "Epoka 25140: Loss = 0.000000486\n",
      "Epoka 25150: Loss = 0.000000366\n",
      "Epoka 25160: Loss = 0.000000441\n",
      "Epoka 25170: Loss = 0.000000408\n",
      "Epoka 25180: Loss = 0.000000369\n",
      "Epoka 25190: Loss = 0.000000311\n",
      "Epoka 25200: Loss = 0.000000443\n",
      "Epoka 25210: Loss = 0.000000405\n",
      "Epoka 25220: Loss = 0.000000375\n",
      "Epoka 25230: Loss = 0.000000426\n",
      "Epoka 25240: Loss = 0.000000318\n",
      "Epoka 25250: Loss = 0.000000383\n",
      "Epoka 25260: Loss = 0.000000320\n",
      "Epoka 25270: Loss = 0.000000357\n",
      "Epoka 25280: Loss = 0.000000362\n",
      "Epoka 25290: Loss = 0.000000347\n",
      "Epoka 25300: Loss = 0.000000328\n",
      "Epoka 25310: Loss = 0.000000329\n",
      "Epoka 25320: Loss = 0.000000635\n",
      "Epoka 25330: Loss = 0.000000379\n",
      "Epoka 25340: Loss = 0.000000427\n",
      "Epoka 25350: Loss = 0.000000399\n",
      "Epoka 25360: Loss = 0.000001203\n",
      "Epoka 25370: Loss = 0.000000315\n",
      "Epoka 25380: Loss = 0.000000638\n",
      "Epoka 25390: Loss = 0.000000345\n",
      "Epoka 25400: Loss = 0.000000471\n",
      "Epoka 25410: Loss = 0.000000316\n",
      "Epoka 25420: Loss = 0.000000340\n",
      "Epoka 25430: Loss = 0.000000346\n",
      "Epoka 25440: Loss = 0.000000378\n",
      "Epoka 25450: Loss = 0.000000874\n",
      "Epoka 25460: Loss = 0.000000441\n",
      "Epoka 25470: Loss = 0.000000505\n",
      "Epoka 25480: Loss = 0.000000324\n",
      "Epoka 25490: Loss = 0.000000323\n",
      "Epoka 25500: Loss = 0.000000306\n",
      "Epoka 25510: Loss = 0.000000304\n",
      "Epoka 25520: Loss = 0.000000332\n",
      "Epoka 25530: Loss = 0.000000371\n",
      "Epoka 25540: Loss = 0.000000323\n",
      "Epoka 25550: Loss = 0.000000347\n",
      "Epoka 25560: Loss = 0.000000651\n",
      "Epoka 25570: Loss = 0.000000321\n",
      "Epoka 25580: Loss = 0.000000551\n",
      "Epoka 25590: Loss = 0.000000362\n",
      "Epoka 25600: Loss = 0.000000677\n",
      "Epoka 25610: Loss = 0.000000357\n",
      "Epoka 25620: Loss = 0.000000310\n",
      "Epoka 25630: Loss = 0.000000327\n",
      "Epoka 25640: Loss = 0.000000448\n",
      "Epoka 25650: Loss = 0.000000339\n",
      "Epoka 25660: Loss = 0.000000331\n",
      "Epoka 25670: Loss = 0.000000383\n",
      "Epoka 25680: Loss = 0.000000367\n",
      "Epoka 25690: Loss = 0.000000384\n",
      "Epoka 25700: Loss = 0.000000320\n",
      "Epoka 25710: Loss = 0.000000359\n",
      "Epoka 25720: Loss = 0.000000319\n",
      "Epoka 25730: Loss = 0.000000431\n",
      "Epoka 25740: Loss = 0.000000358\n",
      "Epoka 25750: Loss = 0.000000322\n",
      "Epoka 25760: Loss = 0.000000325\n",
      "Epoka 25770: Loss = 0.000000366\n",
      "Epoka 25780: Loss = 0.000000322\n",
      "Epoka 25790: Loss = 0.000000462\n",
      "Epoka 25800: Loss = 0.000000322\n",
      "Epoka 25810: Loss = 0.000000314\n",
      "Epoka 25820: Loss = 0.000000334\n",
      "Epoka 25830: Loss = 0.000000360\n",
      "Epoka 25840: Loss = 0.000000311\n",
      "Epoka 25850: Loss = 0.000000419\n",
      "Epoka 25860: Loss = 0.000000314\n",
      "Epoka 25870: Loss = 0.000000296\n",
      "Epoka 25880: Loss = 0.000000327\n",
      "Epoka 25890: Loss = 0.000000349\n",
      "Epoka 25900: Loss = 0.000000362\n",
      "Epoka 25910: Loss = 0.000000380\n",
      "Epoka 25920: Loss = 0.000000312\n",
      "Epoka 25930: Loss = 0.000000390\n",
      "Epoka 25940: Loss = 0.000000368\n",
      "Epoka 25950: Loss = 0.000000355\n",
      "Epoka 25960: Loss = 0.000000575\n",
      "Epoka 25970: Loss = 0.000000526\n",
      "Epoka 25980: Loss = 0.000000408\n",
      "Epoka 25990: Loss = 0.000000321\n",
      "Epoka 26000: Loss = 0.000000386\n",
      "Epoka 26010: Loss = 0.000000338\n",
      "Epoka 26020: Loss = 0.000000319\n",
      "Epoka 26030: Loss = 0.000000533\n",
      "Epoka 26040: Loss = 0.000000498\n",
      "Epoka 26050: Loss = 0.000000302\n",
      "Epoka 26060: Loss = 0.000000382\n",
      "Epoka 26070: Loss = 0.000000453\n",
      "Epoka 26080: Loss = 0.000000453\n",
      "Epoka 26090: Loss = 0.000000425\n",
      "Epoka 26100: Loss = 0.000000740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 26110: Loss = 0.000000648\n",
      "Epoka 26120: Loss = 0.000000337\n",
      "Epoka 26130: Loss = 0.000000405\n",
      "Epoka 26140: Loss = 0.000000333\n",
      "Epoka 26150: Loss = 0.000000294\n",
      "Epoka 26160: Loss = 0.000000651\n",
      "Epoka 26170: Loss = 0.000000516\n",
      "Epoka 26180: Loss = 0.000000554\n",
      "Epoka 26190: Loss = 0.000000386\n",
      "Epoka 26200: Loss = 0.000000296\n",
      "Epoka 26210: Loss = 0.000000321\n",
      "Epoka 26220: Loss = 0.000000328\n",
      "Epoka 26230: Loss = 0.000000297\n",
      "Epoka 26240: Loss = 0.000000494\n",
      "Epoka 26250: Loss = 0.000000428\n",
      "Epoka 26260: Loss = 0.000000726\n",
      "Epoka 26270: Loss = 0.000000287\n",
      "Epoka 26280: Loss = 0.000000298\n",
      "Epoka 26290: Loss = 0.000000584\n",
      "Epoka 26300: Loss = 0.000000333\n",
      "Epoka 26310: Loss = 0.000000526\n",
      "Epoka 26320: Loss = 0.000000327\n",
      "Epoka 26330: Loss = 0.000000326\n",
      "Epoka 26340: Loss = 0.000000426\n",
      "Epoka 26350: Loss = 0.000000668\n",
      "Epoka 26360: Loss = 0.000000302\n",
      "Epoka 26370: Loss = 0.000000519\n",
      "Epoka 26380: Loss = 0.000000639\n",
      "Epoka 26390: Loss = 0.000000368\n",
      "Epoka 26400: Loss = 0.000000352\n",
      "Epoka 26410: Loss = 0.000000386\n",
      "Epoka 26420: Loss = 0.000000360\n",
      "Epoka 26430: Loss = 0.000000349\n",
      "Epoka 26440: Loss = 0.000000335\n",
      "Epoka 26450: Loss = 0.000000313\n",
      "Epoka 26460: Loss = 0.000000373\n",
      "Epoka 26470: Loss = 0.000000375\n",
      "Epoka 26480: Loss = 0.000000412\n",
      "Epoka 26490: Loss = 0.000000342\n",
      "Epoka 26500: Loss = 0.000000423\n",
      "Epoka 26510: Loss = 0.000000378\n",
      "Epoka 26520: Loss = 0.000000326\n",
      "Epoka 26530: Loss = 0.000000317\n",
      "Epoka 26540: Loss = 0.000000319\n",
      "Epoka 26550: Loss = 0.000000335\n",
      "Epoka 26560: Loss = 0.000000310\n",
      "Epoka 26570: Loss = 0.000000404\n",
      "Epoka 26580: Loss = 0.000000431\n",
      "Epoka 26590: Loss = 0.000000322\n",
      "Epoka 26600: Loss = 0.000000404\n",
      "Epoka 26610: Loss = 0.000000631\n",
      "Epoka 26620: Loss = 0.000000582\n",
      "Epoka 26630: Loss = 0.000000287\n",
      "Epoka 26640: Loss = 0.000000295\n",
      "Epoka 26650: Loss = 0.000000455\n",
      "Epoka 26660: Loss = 0.000000298\n",
      "Epoka 26670: Loss = 0.000000312\n",
      "Epoka 26680: Loss = 0.000000706\n",
      "Epoka 26690: Loss = 0.000000291\n",
      "Epoka 26700: Loss = 0.000000466\n",
      "Epoka 26710: Loss = 0.000000289\n",
      "Epoka 26720: Loss = 0.000000334\n",
      "Epoka 26730: Loss = 0.000000344\n",
      "Epoka 26740: Loss = 0.000000310\n",
      "Epoka 26750: Loss = 0.000000298\n",
      "Epoka 26760: Loss = 0.000000393\n",
      "Epoka 26770: Loss = 0.000000527\n",
      "Epoka 26780: Loss = 0.000000430\n",
      "Epoka 26790: Loss = 0.000000454\n",
      "Epoka 26800: Loss = 0.000000474\n",
      "Epoka 26810: Loss = 0.000000462\n",
      "Epoka 26820: Loss = 0.000000288\n",
      "Epoka 26830: Loss = 0.000000364\n",
      "Epoka 26840: Loss = 0.000000350\n",
      "Epoka 26850: Loss = 0.000000300\n",
      "Epoka 26860: Loss = 0.000000497\n",
      "Epoka 26870: Loss = 0.000000546\n",
      "Epoka 26880: Loss = 0.000000407\n",
      "Epoka 26890: Loss = 0.000000593\n",
      "Epoka 26900: Loss = 0.000000309\n",
      "Epoka 26910: Loss = 0.000000395\n",
      "Epoka 26920: Loss = 0.000000313\n",
      "Epoka 26930: Loss = 0.000000392\n",
      "Epoka 26940: Loss = 0.000000562\n",
      "Epoka 26950: Loss = 0.000000388\n",
      "Epoka 26960: Loss = 0.000000315\n",
      "Epoka 26970: Loss = 0.000000626\n",
      "Epoka 26980: Loss = 0.000000446\n",
      "Epoka 26990: Loss = 0.000000674\n",
      "Epoka 27000: Loss = 0.000000375\n",
      "Epoka 27010: Loss = 0.000000412\n",
      "Epoka 27020: Loss = 0.000000298\n",
      "Epoka 27030: Loss = 0.000000282\n",
      "Epoka 27040: Loss = 0.000000453\n",
      "Epoka 27050: Loss = 0.000000326\n",
      "Epoka 27060: Loss = 0.000000274\n",
      "Epoka 27070: Loss = 0.000000310\n",
      "Epoka 27080: Loss = 0.000000469\n",
      "Epoka 27090: Loss = 0.000000343\n",
      "Epoka 27100: Loss = 0.000000484\n",
      "Epoka 27110: Loss = 0.000000303\n",
      "Epoka 27120: Loss = 0.000000296\n",
      "Epoka 27130: Loss = 0.000000277\n",
      "Epoka 27140: Loss = 0.000000278\n",
      "Epoka 27150: Loss = 0.000000285\n",
      "Epoka 27160: Loss = 0.000000382\n",
      "Epoka 27170: Loss = 0.000000294\n",
      "Epoka 27180: Loss = 0.000000379\n",
      "Epoka 27190: Loss = 0.000000398\n",
      "Epoka 27200: Loss = 0.000000312\n",
      "Epoka 27210: Loss = 0.000000304\n",
      "Epoka 27220: Loss = 0.000000487\n",
      "Epoka 27230: Loss = 0.000000389\n",
      "Epoka 27240: Loss = 0.000001059\n",
      "Epoka 27250: Loss = 0.000000398\n",
      "Epoka 27260: Loss = 0.000000281\n",
      "Epoka 27270: Loss = 0.000000626\n",
      "Epoka 27280: Loss = 0.000000352\n",
      "Epoka 27290: Loss = 0.000000303\n",
      "Epoka 27300: Loss = 0.000000511\n",
      "Epoka 27310: Loss = 0.000000344\n",
      "Epoka 27320: Loss = 0.000000367\n",
      "Epoka 27330: Loss = 0.000000303\n",
      "Epoka 27340: Loss = 0.000000270\n",
      "Epoka 27350: Loss = 0.000000508\n",
      "Epoka 27360: Loss = 0.000000364\n",
      "Epoka 27370: Loss = 0.000000357\n",
      "Epoka 27380: Loss = 0.000000282\n",
      "Epoka 27390: Loss = 0.000000334\n",
      "Epoka 27400: Loss = 0.000000393\n",
      "Epoka 27410: Loss = 0.000000387\n",
      "Epoka 27420: Loss = 0.000000377\n",
      "Epoka 27430: Loss = 0.000000271\n",
      "Epoka 27440: Loss = 0.000000402\n",
      "Epoka 27450: Loss = 0.000000696\n",
      "Epoka 27460: Loss = 0.000000272\n",
      "Epoka 27470: Loss = 0.000000311\n",
      "Epoka 27480: Loss = 0.000000374\n",
      "Epoka 27490: Loss = 0.000000365\n",
      "Epoka 27500: Loss = 0.000000400\n",
      "Epoka 27510: Loss = 0.000000373\n",
      "Epoka 27520: Loss = 0.000000333\n",
      "Epoka 27530: Loss = 0.000000312\n",
      "Epoka 27540: Loss = 0.000000274\n",
      "Epoka 27550: Loss = 0.000000277\n",
      "Epoka 27560: Loss = 0.000000281\n",
      "Epoka 27570: Loss = 0.000000426\n",
      "Epoka 27580: Loss = 0.000000330\n",
      "Epoka 27590: Loss = 0.000000303\n",
      "Epoka 27600: Loss = 0.000000365\n",
      "Epoka 27610: Loss = 0.000000316\n",
      "Epoka 27620: Loss = 0.000000463\n",
      "Epoka 27630: Loss = 0.000000513\n",
      "Epoka 27640: Loss = 0.000000631\n",
      "Epoka 27650: Loss = 0.000000614\n",
      "Epoka 27660: Loss = 0.000000482\n",
      "Epoka 27670: Loss = 0.000000407\n",
      "Epoka 27680: Loss = 0.000000461\n",
      "Epoka 27690: Loss = 0.000000475\n",
      "Epoka 27700: Loss = 0.000000275\n",
      "Epoka 27710: Loss = 0.000000278\n",
      "Epoka 27720: Loss = 0.000000532\n",
      "Epoka 27730: Loss = 0.000000278\n",
      "Epoka 27740: Loss = 0.000000331\n",
      "Epoka 27750: Loss = 0.000000514\n",
      "Epoka 27760: Loss = 0.000000400\n",
      "Epoka 27770: Loss = 0.000000365\n",
      "Epoka 27780: Loss = 0.000000270\n",
      "Epoka 27790: Loss = 0.000000432\n",
      "Epoka 27800: Loss = 0.000000455\n",
      "Epoka 27810: Loss = 0.000000313\n",
      "Epoka 27820: Loss = 0.000000293\n",
      "Epoka 27830: Loss = 0.000000389\n",
      "Epoka 27840: Loss = 0.000000292\n",
      "Epoka 27850: Loss = 0.000000483\n",
      "Epoka 27860: Loss = 0.000000270\n",
      "Epoka 27870: Loss = 0.000000302\n",
      "Epoka 27880: Loss = 0.000000421\n",
      "Epoka 27890: Loss = 0.000000338\n",
      "Epoka 27900: Loss = 0.000000270\n",
      "Epoka 27910: Loss = 0.000000268\n",
      "Epoka 27920: Loss = 0.000000393\n",
      "Epoka 27930: Loss = 0.000000335\n",
      "Epoka 27940: Loss = 0.000000471\n",
      "Epoka 27950: Loss = 0.000000305\n",
      "Epoka 27960: Loss = 0.000000505\n",
      "Epoka 27970: Loss = 0.000000428\n",
      "Epoka 27980: Loss = 0.000000352\n",
      "Epoka 27990: Loss = 0.000000304\n",
      "Epoka 28000: Loss = 0.000000517\n",
      "Epoka 28010: Loss = 0.000000303\n",
      "Epoka 28020: Loss = 0.000000259\n",
      "Epoka 28030: Loss = 0.000000390\n",
      "Epoka 28040: Loss = 0.000000330\n",
      "Epoka 28050: Loss = 0.000000309\n",
      "Epoka 28060: Loss = 0.000000290\n",
      "Epoka 28070: Loss = 0.000000327\n",
      "Epoka 28080: Loss = 0.000000259\n",
      "Epoka 28090: Loss = 0.000000444\n",
      "Epoka 28100: Loss = 0.000000262\n",
      "Epoka 28110: Loss = 0.000000390\n",
      "Epoka 28120: Loss = 0.000000329\n",
      "Epoka 28130: Loss = 0.000000335\n",
      "Epoka 28140: Loss = 0.000000322\n",
      "Epoka 28150: Loss = 0.000000309\n",
      "Epoka 28160: Loss = 0.000000359\n",
      "Epoka 28170: Loss = 0.000000282\n",
      "Epoka 28180: Loss = 0.000000262\n",
      "Epoka 28190: Loss = 0.000000447\n",
      "Epoka 28200: Loss = 0.000000270\n",
      "Epoka 28210: Loss = 0.000000297\n",
      "Epoka 28220: Loss = 0.000000331\n",
      "Epoka 28230: Loss = 0.000000305\n",
      "Epoka 28240: Loss = 0.000000282\n",
      "Epoka 28250: Loss = 0.000000331\n",
      "Epoka 28260: Loss = 0.000000306\n",
      "Epoka 28270: Loss = 0.000000313\n",
      "Epoka 28280: Loss = 0.000000498\n",
      "Epoka 28290: Loss = 0.000000280\n",
      "Epoka 28300: Loss = 0.000000535\n",
      "Epoka 28310: Loss = 0.000000453\n",
      "Epoka 28320: Loss = 0.000000276\n",
      "Epoka 28330: Loss = 0.000000529\n",
      "Epoka 28340: Loss = 0.000000521\n",
      "Epoka 28350: Loss = 0.000000345\n",
      "Epoka 28360: Loss = 0.000000270\n",
      "Epoka 28370: Loss = 0.000000319\n",
      "Epoka 28380: Loss = 0.000000294\n",
      "Epoka 28390: Loss = 0.000000397\n",
      "Epoka 28400: Loss = 0.000000260\n",
      "Epoka 28410: Loss = 0.000000319\n",
      "Epoka 28420: Loss = 0.000000445\n",
      "Epoka 28430: Loss = 0.000000378\n",
      "Epoka 28440: Loss = 0.000000275\n",
      "Epoka 28450: Loss = 0.000000546\n",
      "Epoka 28460: Loss = 0.000000425\n",
      "Epoka 28470: Loss = 0.000000323\n",
      "Epoka 28480: Loss = 0.000000332\n",
      "Epoka 28490: Loss = 0.000000365\n",
      "Epoka 28500: Loss = 0.000000421\n",
      "Epoka 28510: Loss = 0.000000306\n",
      "Epoka 28520: Loss = 0.000000285\n",
      "Epoka 28530: Loss = 0.000000423\n",
      "Epoka 28540: Loss = 0.000000367\n",
      "Epoka 28550: Loss = 0.000000493\n",
      "Epoka 28560: Loss = 0.000000678\n",
      "Epoka 28570: Loss = 0.000000427\n",
      "Epoka 28580: Loss = 0.000000248\n",
      "Epoka 28590: Loss = 0.000000258\n",
      "Epoka 28600: Loss = 0.000000303\n",
      "Epoka 28610: Loss = 0.000000322\n",
      "Epoka 28620: Loss = 0.000000560\n",
      "Epoka 28630: Loss = 0.000000378\n",
      "Epoka 28640: Loss = 0.000000276\n",
      "Epoka 28650: Loss = 0.000000354\n",
      "Epoka 28660: Loss = 0.000000255\n",
      "Epoka 28670: Loss = 0.000000255\n",
      "Epoka 28680: Loss = 0.000000332\n",
      "Epoka 28690: Loss = 0.000000278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 28700: Loss = 0.000000384\n",
      "Epoka 28710: Loss = 0.000000285\n",
      "Epoka 28720: Loss = 0.000000279\n",
      "Epoka 28730: Loss = 0.000000476\n",
      "Epoka 28740: Loss = 0.000000310\n",
      "Epoka 28750: Loss = 0.000000269\n",
      "Epoka 28760: Loss = 0.000000275\n",
      "Epoka 28770: Loss = 0.000000261\n",
      "Epoka 28780: Loss = 0.000000349\n",
      "Epoka 28790: Loss = 0.000000254\n",
      "Epoka 28800: Loss = 0.000000267\n",
      "Epoka 28810: Loss = 0.000000282\n",
      "Epoka 28820: Loss = 0.000000272\n",
      "Epoka 28830: Loss = 0.000000316\n",
      "Epoka 28840: Loss = 0.000000371\n",
      "Epoka 28850: Loss = 0.000000324\n",
      "Epoka 28860: Loss = 0.000000353\n",
      "Epoka 28870: Loss = 0.000000270\n",
      "Epoka 28880: Loss = 0.000000263\n",
      "Epoka 28890: Loss = 0.000000243\n",
      "Epoka 28900: Loss = 0.000000561\n",
      "Epoka 28910: Loss = 0.000000342\n",
      "Epoka 28920: Loss = 0.000000299\n",
      "Epoka 28930: Loss = 0.000000253\n",
      "Epoka 28940: Loss = 0.000000271\n",
      "Epoka 28950: Loss = 0.000000271\n",
      "Epoka 28960: Loss = 0.000000299\n",
      "Epoka 28970: Loss = 0.000000336\n",
      "Epoka 28980: Loss = 0.000000299\n",
      "Epoka 28990: Loss = 0.000000256\n",
      "Epoka 29000: Loss = 0.000000306\n",
      "Epoka 29010: Loss = 0.000000265\n",
      "Epoka 29020: Loss = 0.000000248\n",
      "Epoka 29030: Loss = 0.000000271\n",
      "Epoka 29040: Loss = 0.000000334\n",
      "Epoka 29050: Loss = 0.000000289\n",
      "Epoka 29060: Loss = 0.000000398\n",
      "Epoka 29070: Loss = 0.000000551\n",
      "Epoka 29080: Loss = 0.000000266\n",
      "Epoka 29090: Loss = 0.000000437\n",
      "Epoka 29100: Loss = 0.000000328\n",
      "Epoka 29110: Loss = 0.000000286\n",
      "Epoka 29120: Loss = 0.000000558\n",
      "Epoka 29130: Loss = 0.000000295\n",
      "Epoka 29140: Loss = 0.000000347\n",
      "Epoka 29150: Loss = 0.000000468\n",
      "Epoka 29160: Loss = 0.000000241\n",
      "Epoka 29170: Loss = 0.000000306\n",
      "Epoka 29180: Loss = 0.000000268\n",
      "Epoka 29190: Loss = 0.000000244\n",
      "Epoka 29200: Loss = 0.000000356\n",
      "Epoka 29210: Loss = 0.000000263\n",
      "Epoka 29220: Loss = 0.000000330\n",
      "Epoka 29230: Loss = 0.000000280\n",
      "Epoka 29240: Loss = 0.000000450\n",
      "Epoka 29250: Loss = 0.000000265\n",
      "Epoka 29260: Loss = 0.000000649\n",
      "Epoka 29270: Loss = 0.000000335\n",
      "Epoka 29280: Loss = 0.000000359\n",
      "Epoka 29290: Loss = 0.000000303\n",
      "Epoka 29300: Loss = 0.000000245\n",
      "Epoka 29310: Loss = 0.000000250\n",
      "Epoka 29320: Loss = 0.000000409\n",
      "Epoka 29330: Loss = 0.000000548\n",
      "Epoka 29340: Loss = 0.000000379\n",
      "Epoka 29350: Loss = 0.000000302\n",
      "Epoka 29360: Loss = 0.000000430\n",
      "Epoka 29370: Loss = 0.000000258\n",
      "Epoka 29380: Loss = 0.000000269\n",
      "Epoka 29390: Loss = 0.000000251\n",
      "Epoka 29400: Loss = 0.000000453\n",
      "Epoka 29410: Loss = 0.000000240\n",
      "Epoka 29420: Loss = 0.000000252\n",
      "Epoka 29430: Loss = 0.000000305\n",
      "Epoka 29440: Loss = 0.000000481\n",
      "Epoka 29450: Loss = 0.000000297\n",
      "Epoka 29460: Loss = 0.000000287\n",
      "Epoka 29470: Loss = 0.000000278\n",
      "Epoka 29480: Loss = 0.000000317\n",
      "Epoka 29490: Loss = 0.000000307\n",
      "Epoka 29500: Loss = 0.000000271\n",
      "Epoka 29510: Loss = 0.000000335\n",
      "Epoka 29520: Loss = 0.000000315\n",
      "Epoka 29530: Loss = 0.000000339\n",
      "Epoka 29540: Loss = 0.000000238\n",
      "Epoka 29550: Loss = 0.000000387\n",
      "Epoka 29560: Loss = 0.000000594\n",
      "Epoka 29570: Loss = 0.000000344\n",
      "Epoka 29580: Loss = 0.000000293\n",
      "Epoka 29590: Loss = 0.000000315\n",
      "Epoka 29600: Loss = 0.000000252\n",
      "Epoka 29610: Loss = 0.000000316\n",
      "Epoka 29620: Loss = 0.000000294\n",
      "Epoka 29630: Loss = 0.000000260\n",
      "Epoka 29640: Loss = 0.000000249\n",
      "Epoka 29650: Loss = 0.000000445\n",
      "Epoka 29660: Loss = 0.000000258\n",
      "Epoka 29670: Loss = 0.000000262\n",
      "Epoka 29680: Loss = 0.000000316\n",
      "Epoka 29690: Loss = 0.000000234\n",
      "Epoka 29700: Loss = 0.000000287\n",
      "Epoka 29710: Loss = 0.000000317\n",
      "Epoka 29720: Loss = 0.000000384\n",
      "Epoka 29730: Loss = 0.000000242\n",
      "Epoka 29740: Loss = 0.000000288\n",
      "Epoka 29750: Loss = 0.000000276\n",
      "Epoka 29760: Loss = 0.000000239\n",
      "Epoka 29770: Loss = 0.000000275\n",
      "Epoka 29780: Loss = 0.000000369\n",
      "Epoka 29790: Loss = 0.000000511\n",
      "Epoka 29800: Loss = 0.000000247\n",
      "Epoka 29810: Loss = 0.000000406\n",
      "Epoka 29820: Loss = 0.000000289\n",
      "Epoka 29830: Loss = 0.000000460\n",
      "Epoka 29840: Loss = 0.000000275\n",
      "Epoka 29850: Loss = 0.000000244\n",
      "Epoka 29860: Loss = 0.000000455\n",
      "Epoka 29870: Loss = 0.000001059\n",
      "Epoka 29880: Loss = 0.000000440\n",
      "Epoka 29890: Loss = 0.000000257\n",
      "Epoka 29900: Loss = 0.000000315\n",
      "Epoka 29910: Loss = 0.000000382\n",
      "Epoka 29920: Loss = 0.000000339\n",
      "Epoka 29930: Loss = 0.000000358\n",
      "Epoka 29940: Loss = 0.000000294\n",
      "Epoka 29950: Loss = 0.000000290\n",
      "Epoka 29960: Loss = 0.000000288\n",
      "Epoka 29970: Loss = 0.000000235\n",
      "Epoka 29980: Loss = 0.000000300\n",
      "Epoka 29990: Loss = 0.000000243\n",
      "Czas wykonania: 224.760065 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_squareL = MLPNoBackprop(layer_sizes = [1, 15, 15, 1])\n",
    "start_time = time.time()\n",
    "mlp_squareL.momentum(X_squareL_train_normalized, Y_squareL_train_normalized, epochs = 30000, learning_rate=0.05, Lambda=0.9, batch_size=20)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "55ff3b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021961347516349906\n"
     ]
    }
   ],
   "source": [
    "ypred_normalized = mlp_squareL.predict(X_squareL_train_normalized)\n",
    "ypred = ypred_normalized *np.std(Y_squareL_train) +np.mean(Y_squareL_train)\n",
    "print(mlp_squareL.mse(ypred, Y_squareL_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0f2ff5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.372767564366863\n"
     ]
    }
   ],
   "source": [
    "ypred_normalized = mlp_squareL.predict(X_squareL_test_normalized)\n",
    "ypred = ypred_normalized *np.std(Y_squareL_train) +np.mean(Y_squareL_train)\n",
    "print(mlp_squareL.mse(ypred, Y_squareL_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d156a55a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2262bdf7d60>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X_squareL_test, Y_squareL_test, color='blue')\n",
    "plt.scatter(X_squareL_test, ypred, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78acc424",
   "metadata": {},
   "source": [
    "## RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "f0dc40bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 3.451318008\n",
      "Epoka 10: Loss = 2.246149374\n",
      "Epoka 20: Loss = 1.456686883\n",
      "Epoka 30: Loss = 1.038661921\n",
      "Epoka 40: Loss = 0.905552979\n",
      "Epoka 50: Loss = 0.870637164\n",
      "Epoka 60: Loss = 0.847226919\n",
      "Epoka 70: Loss = 0.826416661\n",
      "Epoka 80: Loss = 0.807997224\n",
      "Epoka 90: Loss = 0.792321370\n",
      "Epoka 100: Loss = 0.779026268\n",
      "Epoka 110: Loss = 0.767585774\n",
      "Epoka 120: Loss = 0.757112037\n",
      "Epoka 130: Loss = 0.748016758\n",
      "Epoka 140: Loss = 0.739814878\n",
      "Epoka 150: Loss = 0.731733978\n",
      "Epoka 160: Loss = 0.723874432\n",
      "Epoka 170: Loss = 0.716039791\n",
      "Epoka 180: Loss = 0.707957279\n",
      "Epoka 190: Loss = 0.699680014\n",
      "Epoka 200: Loss = 0.690955991\n",
      "Epoka 210: Loss = 0.681780506\n",
      "Epoka 220: Loss = 0.671963894\n",
      "Epoka 230: Loss = 0.661948328\n",
      "Epoka 240: Loss = 0.651207468\n",
      "Epoka 250: Loss = 0.640116147\n",
      "Epoka 260: Loss = 0.628624974\n",
      "Epoka 270: Loss = 0.616051640\n",
      "Epoka 280: Loss = 0.603034082\n",
      "Epoka 290: Loss = 0.589598373\n",
      "Epoka 300: Loss = 0.575757307\n",
      "Epoka 310: Loss = 0.561118530\n",
      "Epoka 320: Loss = 0.545686809\n",
      "Epoka 330: Loss = 0.529158536\n",
      "Epoka 340: Loss = 0.512083243\n",
      "Epoka 350: Loss = 0.494536516\n",
      "Epoka 360: Loss = 0.476133473\n",
      "Epoka 370: Loss = 0.457404834\n",
      "Epoka 380: Loss = 0.438487550\n",
      "Epoka 390: Loss = 0.418661034\n",
      "Epoka 400: Loss = 0.398003095\n",
      "Epoka 410: Loss = 0.377649210\n",
      "Epoka 420: Loss = 0.357293653\n",
      "Epoka 430: Loss = 0.336140751\n",
      "Epoka 440: Loss = 0.315788513\n",
      "Epoka 450: Loss = 0.295382988\n",
      "Epoka 460: Loss = 0.274878400\n",
      "Epoka 470: Loss = 0.254136818\n",
      "Epoka 480: Loss = 0.234221073\n",
      "Epoka 490: Loss = 0.214563806\n",
      "Epoka 500: Loss = 0.195778361\n",
      "Epoka 510: Loss = 0.178266271\n",
      "Epoka 520: Loss = 0.160835901\n",
      "Epoka 530: Loss = 0.144664034\n",
      "Epoka 540: Loss = 0.129734934\n",
      "Epoka 550: Loss = 0.116069322\n",
      "Epoka 560: Loss = 0.103461676\n",
      "Epoka 570: Loss = 0.092401764\n",
      "Epoka 580: Loss = 0.082920319\n",
      "Epoka 590: Loss = 0.075125652\n",
      "Epoka 600: Loss = 0.068974931\n",
      "Epoka 610: Loss = 0.063793359\n",
      "Epoka 620: Loss = 0.059609948\n",
      "Epoka 630: Loss = 0.056026024\n",
      "Epoka 640: Loss = 0.052944614\n",
      "Epoka 650: Loss = 0.050246155\n",
      "Epoka 660: Loss = 0.047835654\n",
      "Epoka 670: Loss = 0.045672335\n",
      "Epoka 680: Loss = 0.043593388\n",
      "Epoka 690: Loss = 0.041608308\n",
      "Epoka 700: Loss = 0.039772302\n",
      "Epoka 710: Loss = 0.038022714\n",
      "Epoka 720: Loss = 0.036279187\n",
      "Epoka 730: Loss = 0.034651770\n",
      "Epoka 740: Loss = 0.033106143\n",
      "Epoka 750: Loss = 0.031668283\n",
      "Epoka 760: Loss = 0.030269785\n",
      "Epoka 770: Loss = 0.028936912\n",
      "Epoka 780: Loss = 0.027667866\n",
      "Epoka 790: Loss = 0.026485513\n",
      "Epoka 800: Loss = 0.025290448\n",
      "Epoka 810: Loss = 0.024188918\n",
      "Epoka 820: Loss = 0.023150956\n",
      "Epoka 830: Loss = 0.022172392\n",
      "Epoka 840: Loss = 0.021220448\n",
      "Epoka 850: Loss = 0.020303816\n",
      "Epoka 860: Loss = 0.019443055\n",
      "Epoka 870: Loss = 0.018603123\n",
      "Epoka 880: Loss = 0.017808195\n",
      "Epoka 890: Loss = 0.017039178\n",
      "Epoka 900: Loss = 0.016298141\n",
      "Epoka 910: Loss = 0.015578965\n",
      "Epoka 920: Loss = 0.014909516\n",
      "Epoka 930: Loss = 0.014276767\n",
      "Epoka 940: Loss = 0.013682537\n",
      "Epoka 950: Loss = 0.013096855\n",
      "Epoka 960: Loss = 0.012555499\n",
      "Epoka 970: Loss = 0.012053552\n",
      "Epoka 980: Loss = 0.011545646\n",
      "Epoka 990: Loss = 0.011083155\n",
      "Epoka 1000: Loss = 0.010642172\n",
      "Epoka 1010: Loss = 0.010218280\n",
      "Epoka 1020: Loss = 0.009811894\n",
      "Epoka 1030: Loss = 0.009420374\n",
      "Epoka 1040: Loss = 0.009042821\n",
      "Epoka 1050: Loss = 0.008672635\n",
      "Epoka 1060: Loss = 0.008346590\n",
      "Epoka 1070: Loss = 0.008030889\n",
      "Epoka 1080: Loss = 0.007723785\n",
      "Epoka 1090: Loss = 0.007422271\n",
      "Epoka 1100: Loss = 0.007124304\n",
      "Epoka 1110: Loss = 0.006839203\n",
      "Epoka 1120: Loss = 0.006573482\n",
      "Epoka 1130: Loss = 0.006324719\n",
      "Epoka 1140: Loss = 0.006085631\n",
      "Epoka 1150: Loss = 0.005835720\n",
      "Epoka 1160: Loss = 0.005613790\n",
      "Epoka 1170: Loss = 0.005399318\n",
      "Epoka 1180: Loss = 0.005189156\n",
      "Epoka 1190: Loss = 0.004995297\n",
      "Epoka 1200: Loss = 0.004800352\n",
      "Epoka 1210: Loss = 0.004615716\n",
      "Epoka 1220: Loss = 0.004435237\n",
      "Epoka 1230: Loss = 0.004264147\n",
      "Epoka 1240: Loss = 0.004104359\n",
      "Epoka 1250: Loss = 0.003942590\n",
      "Epoka 1260: Loss = 0.003786383\n",
      "Epoka 1270: Loss = 0.003662250\n",
      "Epoka 1280: Loss = 0.003514385\n",
      "Epoka 1290: Loss = 0.003370100\n",
      "Epoka 1300: Loss = 0.003248172\n",
      "Epoka 1310: Loss = 0.003115134\n",
      "Epoka 1320: Loss = 0.002989924\n",
      "Epoka 1330: Loss = 0.002867711\n",
      "Epoka 1340: Loss = 0.002752820\n",
      "Epoka 1350: Loss = 0.002639889\n",
      "Epoka 1360: Loss = 0.002547931\n",
      "Epoka 1370: Loss = 0.002433751\n",
      "Epoka 1380: Loss = 0.002340393\n",
      "Epoka 1390: Loss = 0.002241173\n",
      "Epoka 1400: Loss = 0.002156597\n",
      "Epoka 1410: Loss = 0.002066242\n",
      "Epoka 1420: Loss = 0.001984451\n",
      "Epoka 1430: Loss = 0.001903741\n",
      "Epoka 1440: Loss = 0.001828933\n",
      "Epoka 1450: Loss = 0.001753064\n",
      "Epoka 1460: Loss = 0.001685802\n",
      "Epoka 1470: Loss = 0.001611761\n",
      "Epoka 1480: Loss = 0.001550265\n",
      "Epoka 1490: Loss = 0.001481341\n",
      "Epoka 1500: Loss = 0.001427848\n",
      "Epoka 1510: Loss = 0.001362704\n",
      "Epoka 1520: Loss = 0.001305257\n",
      "Epoka 1530: Loss = 0.001261931\n",
      "Epoka 1540: Loss = 0.001201361\n",
      "Epoka 1550: Loss = 0.001154207\n",
      "Epoka 1560: Loss = 0.001106262\n",
      "Epoka 1570: Loss = 0.001062582\n",
      "Epoka 1580: Loss = 0.001019480\n",
      "Epoka 1590: Loss = 0.000987197\n",
      "Epoka 1600: Loss = 0.000942051\n",
      "Epoka 1610: Loss = 0.000911679\n",
      "Epoka 1620: Loss = 0.000876487\n",
      "Epoka 1630: Loss = 0.000836565\n",
      "Epoka 1640: Loss = 0.000806026\n",
      "Epoka 1650: Loss = 0.000775793\n",
      "Epoka 1660: Loss = 0.000746436\n",
      "Epoka 1670: Loss = 0.000719869\n",
      "Epoka 1680: Loss = 0.000696326\n",
      "Epoka 1690: Loss = 0.000673254\n",
      "Epoka 1700: Loss = 0.000661803\n",
      "Epoka 1710: Loss = 0.000629536\n",
      "Epoka 1720: Loss = 0.000609832\n",
      "Epoka 1730: Loss = 0.000598825\n",
      "Epoka 1740: Loss = 0.000574821\n",
      "Epoka 1750: Loss = 0.000564869\n",
      "Epoka 1760: Loss = 0.000541809\n",
      "Epoka 1770: Loss = 0.000530061\n",
      "Epoka 1780: Loss = 0.000516277\n",
      "Epoka 1790: Loss = 0.000505674\n",
      "Epoka 1800: Loss = 0.000490799\n",
      "Epoka 1810: Loss = 0.000479963\n",
      "Epoka 1820: Loss = 0.000468452\n",
      "Epoka 1830: Loss = 0.000460290\n",
      "Epoka 1840: Loss = 0.000452487\n",
      "Epoka 1850: Loss = 0.000440644\n",
      "Epoka 1860: Loss = 0.000433863\n",
      "Epoka 1870: Loss = 0.000433491\n",
      "Epoka 1880: Loss = 0.000417586\n",
      "Epoka 1890: Loss = 0.000411437\n",
      "Epoka 1900: Loss = 0.000404930\n",
      "Epoka 1910: Loss = 0.000397846\n",
      "Epoka 1920: Loss = 0.000392064\n",
      "Epoka 1930: Loss = 0.000388183\n",
      "Epoka 1940: Loss = 0.000380140\n",
      "Epoka 1950: Loss = 0.000374236\n",
      "Epoka 1960: Loss = 0.000369233\n",
      "Epoka 1970: Loss = 0.000364275\n",
      "Epoka 1980: Loss = 0.000359827\n",
      "Epoka 1990: Loss = 0.000355005\n",
      "Epoka 2000: Loss = 0.000357294\n",
      "Epoka 2010: Loss = 0.000349632\n",
      "Epoka 2020: Loss = 0.000343604\n",
      "Epoka 2030: Loss = 0.000338179\n",
      "Epoka 2040: Loss = 0.000334326\n",
      "Epoka 2050: Loss = 0.000331036\n",
      "Epoka 2060: Loss = 0.000328339\n",
      "Epoka 2070: Loss = 0.000328924\n",
      "Epoka 2080: Loss = 0.000323537\n",
      "Epoka 2090: Loss = 0.000317517\n",
      "Epoka 2100: Loss = 0.000312940\n",
      "Epoka 2110: Loss = 0.000311966\n",
      "Epoka 2120: Loss = 0.000306165\n",
      "Epoka 2130: Loss = 0.000307271\n",
      "Epoka 2140: Loss = 0.000301764\n",
      "Epoka 2150: Loss = 0.000297238\n",
      "Epoka 2160: Loss = 0.000293958\n",
      "Epoka 2170: Loss = 0.000290968\n",
      "Epoka 2180: Loss = 0.000289223\n",
      "Epoka 2190: Loss = 0.000285190\n",
      "Epoka 2200: Loss = 0.000285383\n",
      "Epoka 2210: Loss = 0.000279538\n",
      "Epoka 2220: Loss = 0.000277376\n",
      "Epoka 2230: Loss = 0.000273776\n",
      "Epoka 2240: Loss = 0.000270456\n",
      "Epoka 2250: Loss = 0.000268162\n",
      "Epoka 2260: Loss = 0.000270141\n",
      "Epoka 2270: Loss = 0.000263171\n",
      "Epoka 2280: Loss = 0.000261769\n",
      "Epoka 2290: Loss = 0.000256098\n",
      "Epoka 2300: Loss = 0.000254068\n",
      "Epoka 2310: Loss = 0.000252447\n",
      "Epoka 2320: Loss = 0.000249232\n",
      "Epoka 2330: Loss = 0.000246156\n",
      "Epoka 2340: Loss = 0.000243196\n",
      "Epoka 2350: Loss = 0.000240221\n",
      "Epoka 2360: Loss = 0.000237485\n",
      "Epoka 2370: Loss = 0.000235672\n",
      "Epoka 2380: Loss = 0.000233689\n",
      "Epoka 2390: Loss = 0.000229837\n",
      "Epoka 2400: Loss = 0.000227623\n",
      "Epoka 2410: Loss = 0.000226601\n",
      "Epoka 2420: Loss = 0.000222475\n",
      "Epoka 2430: Loss = 0.000220651\n",
      "Epoka 2440: Loss = 0.000217376\n",
      "Epoka 2450: Loss = 0.000214896\n",
      "Epoka 2460: Loss = 0.000213044\n",
      "Epoka 2470: Loss = 0.000211320\n",
      "Epoka 2480: Loss = 0.000208050\n",
      "Epoka 2490: Loss = 0.000209573\n",
      "Epoka 2500: Loss = 0.000202882\n",
      "Epoka 2510: Loss = 0.000199394\n",
      "Epoka 2520: Loss = 0.000196546\n",
      "Epoka 2530: Loss = 0.000195090\n",
      "Epoka 2540: Loss = 0.000191425\n",
      "Epoka 2550: Loss = 0.000188673\n",
      "Epoka 2560: Loss = 0.000186261\n",
      "Epoka 2570: Loss = 0.000186426\n",
      "Epoka 2580: Loss = 0.000181007\n",
      "Epoka 2590: Loss = 0.000182902\n",
      "Epoka 2600: Loss = 0.000177409\n",
      "Epoka 2610: Loss = 0.000173908\n",
      "Epoka 2620: Loss = 0.000171110\n",
      "Epoka 2630: Loss = 0.000168902\n",
      "Epoka 2640: Loss = 0.000166780\n",
      "Epoka 2650: Loss = 0.000166203\n",
      "Epoka 2660: Loss = 0.000162478\n",
      "Epoka 2670: Loss = 0.000159836\n",
      "Epoka 2680: Loss = 0.000156092\n",
      "Epoka 2690: Loss = 0.000153609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 2700: Loss = 0.000151410\n",
      "Epoka 2710: Loss = 0.000149170\n",
      "Epoka 2720: Loss = 0.000146476\n",
      "Epoka 2730: Loss = 0.000149473\n",
      "Epoka 2740: Loss = 0.000143152\n",
      "Epoka 2750: Loss = 0.000139765\n",
      "Epoka 2760: Loss = 0.000137468\n",
      "Epoka 2770: Loss = 0.000136541\n",
      "Epoka 2780: Loss = 0.000134726\n",
      "Epoka 2790: Loss = 0.000135258\n",
      "Epoka 2800: Loss = 0.000128322\n",
      "Epoka 2810: Loss = 0.000125784\n",
      "Epoka 2820: Loss = 0.000123456\n",
      "Epoka 2830: Loss = 0.000121249\n",
      "Epoka 2840: Loss = 0.000120477\n",
      "Epoka 2850: Loss = 0.000118077\n",
      "Epoka 2860: Loss = 0.000115513\n",
      "Epoka 2870: Loss = 0.000112882\n",
      "Epoka 2880: Loss = 0.000113748\n",
      "Epoka 2890: Loss = 0.000108980\n",
      "Epoka 2900: Loss = 0.000106898\n",
      "Epoka 2910: Loss = 0.000104443\n",
      "Epoka 2920: Loss = 0.000103715\n",
      "Epoka 2930: Loss = 0.000100659\n",
      "Epoka 2940: Loss = 0.000100266\n",
      "Epoka 2950: Loss = 0.000096815\n",
      "Epoka 2960: Loss = 0.000096513\n",
      "Epoka 2970: Loss = 0.000093818\n",
      "Epoka 2980: Loss = 0.000092932\n",
      "Epoka 2990: Loss = 0.000091229\n",
      "Epoka 3000: Loss = 0.000089946\n",
      "Epoka 3010: Loss = 0.000086998\n",
      "Epoka 3020: Loss = 0.000085237\n",
      "Epoka 3030: Loss = 0.000084369\n",
      "Epoka 3040: Loss = 0.000081978\n",
      "Epoka 3050: Loss = 0.000080578\n",
      "Epoka 3060: Loss = 0.000079611\n",
      "Epoka 3070: Loss = 0.000079556\n",
      "Epoka 3080: Loss = 0.000076668\n",
      "Epoka 3090: Loss = 0.000075744\n",
      "Epoka 3100: Loss = 0.000073627\n",
      "Epoka 3110: Loss = 0.000074298\n",
      "Epoka 3120: Loss = 0.000071524\n",
      "Epoka 3130: Loss = 0.000070072\n",
      "Epoka 3140: Loss = 0.000069210\n",
      "Epoka 3150: Loss = 0.000076062\n",
      "Epoka 3160: Loss = 0.000067413\n",
      "Epoka 3170: Loss = 0.000065670\n",
      "Epoka 3180: Loss = 0.000064796\n",
      "Epoka 3190: Loss = 0.000064779\n",
      "Epoka 3200: Loss = 0.000063056\n",
      "Epoka 3210: Loss = 0.000062871\n",
      "Epoka 3220: Loss = 0.000061019\n",
      "Epoka 3230: Loss = 0.000060332\n",
      "Epoka 3240: Loss = 0.000061650\n",
      "Epoka 3250: Loss = 0.000059756\n",
      "Epoka 3260: Loss = 0.000059401\n",
      "Epoka 3270: Loss = 0.000057056\n",
      "Epoka 3280: Loss = 0.000056920\n",
      "Epoka 3290: Loss = 0.000055905\n",
      "Epoka 3300: Loss = 0.000054467\n",
      "Epoka 3310: Loss = 0.000053951\n",
      "Epoka 3320: Loss = 0.000053380\n",
      "Epoka 3330: Loss = 0.000053473\n",
      "Epoka 3340: Loss = 0.000054284\n",
      "Epoka 3350: Loss = 0.000051704\n",
      "Epoka 3360: Loss = 0.000051739\n",
      "Epoka 3370: Loss = 0.000052071\n",
      "Epoka 3380: Loss = 0.000049909\n",
      "Epoka 3390: Loss = 0.000049286\n",
      "Epoka 3400: Loss = 0.000048894\n",
      "Epoka 3410: Loss = 0.000052384\n",
      "Epoka 3420: Loss = 0.000047308\n",
      "Epoka 3430: Loss = 0.000047281\n",
      "Epoka 3440: Loss = 0.000047277\n",
      "Epoka 3450: Loss = 0.000046682\n",
      "Epoka 3460: Loss = 0.000046722\n",
      "Epoka 3470: Loss = 0.000046163\n",
      "Epoka 3480: Loss = 0.000045415\n",
      "Epoka 3490: Loss = 0.000044270\n",
      "Epoka 3500: Loss = 0.000045417\n",
      "Epoka 3510: Loss = 0.000048558\n",
      "Epoka 3520: Loss = 0.000043043\n",
      "Epoka 3530: Loss = 0.000044148\n",
      "Epoka 3540: Loss = 0.000042705\n",
      "Epoka 3550: Loss = 0.000043617\n",
      "Epoka 3560: Loss = 0.000042972\n",
      "Epoka 3570: Loss = 0.000042048\n",
      "Epoka 3580: Loss = 0.000041425\n",
      "Epoka 3590: Loss = 0.000041590\n",
      "Epoka 3600: Loss = 0.000040996\n",
      "Epoka 3610: Loss = 0.000041300\n",
      "Epoka 3620: Loss = 0.000039744\n",
      "Epoka 3630: Loss = 0.000039398\n",
      "Epoka 3640: Loss = 0.000039431\n",
      "Epoka 3650: Loss = 0.000038813\n",
      "Epoka 3660: Loss = 0.000040337\n",
      "Epoka 3670: Loss = 0.000039055\n",
      "Epoka 3680: Loss = 0.000038216\n",
      "Epoka 3690: Loss = 0.000039775\n",
      "Epoka 3700: Loss = 0.000038283\n",
      "Epoka 3710: Loss = 0.000037520\n",
      "Epoka 3720: Loss = 0.000038905\n",
      "Epoka 3730: Loss = 0.000037035\n",
      "Epoka 3740: Loss = 0.000038567\n",
      "Epoka 3750: Loss = 0.000038187\n",
      "Epoka 3760: Loss = 0.000036576\n",
      "Epoka 3770: Loss = 0.000038426\n",
      "Epoka 3780: Loss = 0.000036884\n",
      "Epoka 3790: Loss = 0.000035599\n",
      "Epoka 3800: Loss = 0.000035585\n",
      "Epoka 3810: Loss = 0.000035649\n",
      "Epoka 3820: Loss = 0.000035126\n",
      "Epoka 3830: Loss = 0.000035128\n",
      "Epoka 3840: Loss = 0.000034578\n",
      "Epoka 3850: Loss = 0.000037648\n",
      "Epoka 3860: Loss = 0.000034488\n",
      "Epoka 3870: Loss = 0.000034460\n",
      "Epoka 3880: Loss = 0.000033879\n",
      "Epoka 3890: Loss = 0.000034002\n",
      "Epoka 3900: Loss = 0.000034397\n",
      "Epoka 3910: Loss = 0.000033726\n",
      "Epoka 3920: Loss = 0.000036541\n",
      "Epoka 3930: Loss = 0.000033977\n",
      "Epoka 3940: Loss = 0.000033347\n",
      "Epoka 3950: Loss = 0.000032781\n",
      "Epoka 3960: Loss = 0.000033165\n",
      "Epoka 3970: Loss = 0.000032421\n",
      "Epoka 3980: Loss = 0.000034172\n",
      "Epoka 3990: Loss = 0.000033186\n",
      "Epoka 4000: Loss = 0.000031970\n",
      "Epoka 4010: Loss = 0.000033428\n",
      "Epoka 4020: Loss = 0.000031748\n",
      "Epoka 4030: Loss = 0.000031581\n",
      "Epoka 4040: Loss = 0.000031477\n",
      "Epoka 4050: Loss = 0.000031498\n",
      "Epoka 4060: Loss = 0.000031618\n",
      "Epoka 4070: Loss = 0.000032753\n",
      "Epoka 4080: Loss = 0.000031248\n",
      "Epoka 4090: Loss = 0.000031559\n",
      "Epoka 4100: Loss = 0.000030823\n",
      "Epoka 4110: Loss = 0.000030434\n",
      "Epoka 4120: Loss = 0.000031336\n",
      "Epoka 4130: Loss = 0.000030698\n",
      "Epoka 4140: Loss = 0.000030336\n",
      "Epoka 4150: Loss = 0.000031327\n",
      "Epoka 4160: Loss = 0.000030036\n",
      "Epoka 4170: Loss = 0.000029582\n",
      "Epoka 4180: Loss = 0.000029540\n",
      "Epoka 4190: Loss = 0.000030138\n",
      "Epoka 4200: Loss = 0.000034000\n",
      "Epoka 4210: Loss = 0.000029673\n",
      "Epoka 4220: Loss = 0.000029145\n",
      "Epoka 4230: Loss = 0.000029759\n",
      "Epoka 4240: Loss = 0.000029208\n",
      "Epoka 4250: Loss = 0.000031199\n",
      "Epoka 4260: Loss = 0.000028615\n",
      "Epoka 4270: Loss = 0.000028553\n",
      "Epoka 4280: Loss = 0.000028498\n",
      "Epoka 4290: Loss = 0.000028789\n",
      "Epoka 4300: Loss = 0.000028717\n",
      "Epoka 4310: Loss = 0.000029151\n",
      "Epoka 4320: Loss = 0.000028115\n",
      "Epoka 4330: Loss = 0.000029736\n",
      "Epoka 4340: Loss = 0.000028897\n",
      "Epoka 4350: Loss = 0.000028486\n",
      "Epoka 4360: Loss = 0.000028469\n",
      "Epoka 4370: Loss = 0.000027457\n",
      "Epoka 4380: Loss = 0.000028355\n",
      "Epoka 4390: Loss = 0.000028719\n",
      "Epoka 4400: Loss = 0.000027768\n",
      "Epoka 4410: Loss = 0.000028992\n",
      "Epoka 4420: Loss = 0.000027224\n",
      "Epoka 4430: Loss = 0.000028038\n",
      "Epoka 4440: Loss = 0.000026873\n",
      "Epoka 4450: Loss = 0.000026627\n",
      "Epoka 4460: Loss = 0.000028141\n",
      "Epoka 4470: Loss = 0.000026921\n",
      "Epoka 4480: Loss = 0.000028495\n",
      "Epoka 4490: Loss = 0.000026208\n",
      "Epoka 4500: Loss = 0.000027492\n",
      "Epoka 4510: Loss = 0.000026699\n",
      "Epoka 4520: Loss = 0.000025930\n",
      "Epoka 4530: Loss = 0.000025988\n",
      "Epoka 4540: Loss = 0.000026913\n",
      "Epoka 4550: Loss = 0.000026826\n",
      "Epoka 4560: Loss = 0.000027222\n",
      "Epoka 4570: Loss = 0.000026051\n",
      "Epoka 4580: Loss = 0.000026996\n",
      "Epoka 4590: Loss = 0.000026675\n",
      "Epoka 4600: Loss = 0.000026386\n",
      "Epoka 4610: Loss = 0.000025778\n",
      "Epoka 4620: Loss = 0.000025882\n",
      "Epoka 4630: Loss = 0.000024988\n",
      "Epoka 4640: Loss = 0.000024819\n",
      "Epoka 4650: Loss = 0.000025191\n",
      "Epoka 4660: Loss = 0.000024907\n",
      "Epoka 4670: Loss = 0.000024863\n",
      "Epoka 4680: Loss = 0.000025249\n",
      "Epoka 4690: Loss = 0.000027076\n",
      "Epoka 4700: Loss = 0.000024870\n",
      "Epoka 4710: Loss = 0.000024715\n",
      "Epoka 4720: Loss = 0.000024406\n",
      "Epoka 4730: Loss = 0.000024737\n",
      "Epoka 4740: Loss = 0.000024676\n",
      "Epoka 4750: Loss = 0.000023862\n",
      "Epoka 4760: Loss = 0.000024393\n",
      "Epoka 4770: Loss = 0.000024151\n",
      "Epoka 4780: Loss = 0.000024492\n",
      "Epoka 4790: Loss = 0.000024150\n",
      "Epoka 4800: Loss = 0.000024846\n",
      "Epoka 4810: Loss = 0.000031202\n",
      "Epoka 4820: Loss = 0.000023539\n",
      "Epoka 4830: Loss = 0.000023236\n",
      "Epoka 4840: Loss = 0.000026253\n",
      "Epoka 4850: Loss = 0.000023508\n",
      "Epoka 4860: Loss = 0.000023038\n",
      "Epoka 4870: Loss = 0.000023105\n",
      "Epoka 4880: Loss = 0.000023869\n",
      "Epoka 4890: Loss = 0.000023484\n",
      "Epoka 4900: Loss = 0.000022727\n",
      "Epoka 4910: Loss = 0.000023628\n",
      "Epoka 4920: Loss = 0.000022983\n",
      "Epoka 4930: Loss = 0.000022754\n",
      "Epoka 4940: Loss = 0.000024770\n",
      "Epoka 4950: Loss = 0.000022868\n",
      "Epoka 4960: Loss = 0.000022349\n",
      "Epoka 4970: Loss = 0.000022647\n",
      "Epoka 4980: Loss = 0.000022505\n",
      "Epoka 4990: Loss = 0.000022168\n",
      "Epoka 5000: Loss = 0.000023405\n",
      "Epoka 5010: Loss = 0.000021961\n",
      "Epoka 5020: Loss = 0.000022398\n",
      "Epoka 5030: Loss = 0.000021977\n",
      "Epoka 5040: Loss = 0.000022789\n",
      "Epoka 5050: Loss = 0.000021880\n",
      "Epoka 5060: Loss = 0.000022142\n",
      "Epoka 5070: Loss = 0.000021570\n",
      "Epoka 5080: Loss = 0.000022435\n",
      "Epoka 5090: Loss = 0.000022550\n",
      "Epoka 5100: Loss = 0.000023059\n",
      "Epoka 5110: Loss = 0.000021388\n",
      "Epoka 5120: Loss = 0.000021661\n",
      "Epoka 5130: Loss = 0.000021520\n",
      "Epoka 5140: Loss = 0.000021877\n",
      "Epoka 5150: Loss = 0.000022439\n",
      "Epoka 5160: Loss = 0.000020949\n",
      "Epoka 5170: Loss = 0.000021078\n",
      "Epoka 5180: Loss = 0.000020955\n",
      "Epoka 5190: Loss = 0.000021545\n",
      "Epoka 5200: Loss = 0.000020586\n",
      "Epoka 5210: Loss = 0.000022494\n",
      "Epoka 5220: Loss = 0.000023179\n",
      "Epoka 5230: Loss = 0.000020507\n",
      "Epoka 5240: Loss = 0.000020346\n",
      "Epoka 5250: Loss = 0.000022568\n",
      "Epoka 5260: Loss = 0.000021402\n",
      "Epoka 5270: Loss = 0.000020983\n",
      "Epoka 5280: Loss = 0.000020138\n",
      "Epoka 5290: Loss = 0.000020256\n",
      "Epoka 5300: Loss = 0.000019967\n",
      "Epoka 5310: Loss = 0.000020229\n",
      "Epoka 5320: Loss = 0.000019913\n",
      "Epoka 5330: Loss = 0.000019901\n",
      "Epoka 5340: Loss = 0.000019846\n",
      "Epoka 5350: Loss = 0.000020761\n",
      "Epoka 5360: Loss = 0.000020507\n",
      "Epoka 5370: Loss = 0.000020036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 5380: Loss = 0.000019565\n",
      "Epoka 5390: Loss = 0.000020402\n",
      "Epoka 5400: Loss = 0.000019589\n",
      "Epoka 5410: Loss = 0.000019894\n",
      "Epoka 5420: Loss = 0.000020363\n",
      "Epoka 5430: Loss = 0.000019977\n",
      "Epoka 5440: Loss = 0.000019577\n",
      "Epoka 5450: Loss = 0.000019546\n",
      "Epoka 5460: Loss = 0.000019286\n",
      "Epoka 5470: Loss = 0.000018979\n",
      "Epoka 5480: Loss = 0.000020780\n",
      "Epoka 5490: Loss = 0.000019006\n",
      "Epoka 5500: Loss = 0.000019144\n",
      "Epoka 5510: Loss = 0.000018895\n",
      "Epoka 5520: Loss = 0.000018962\n",
      "Epoka 5530: Loss = 0.000019582\n",
      "Epoka 5540: Loss = 0.000021022\n",
      "Epoka 5550: Loss = 0.000018770\n",
      "Epoka 5560: Loss = 0.000018435\n",
      "Epoka 5570: Loss = 0.000018569\n",
      "Epoka 5580: Loss = 0.000018498\n",
      "Epoka 5590: Loss = 0.000018429\n",
      "Epoka 5600: Loss = 0.000018495\n",
      "Epoka 5610: Loss = 0.000019650\n",
      "Epoka 5620: Loss = 0.000019640\n",
      "Epoka 5630: Loss = 0.000018339\n",
      "Epoka 5640: Loss = 0.000018757\n",
      "Epoka 5650: Loss = 0.000018427\n",
      "Epoka 5660: Loss = 0.000018174\n",
      "Epoka 5670: Loss = 0.000018954\n",
      "Epoka 5680: Loss = 0.000018320\n",
      "Epoka 5690: Loss = 0.000018106\n",
      "Epoka 5700: Loss = 0.000017780\n",
      "Epoka 5710: Loss = 0.000017669\n",
      "Epoka 5720: Loss = 0.000018146\n",
      "Epoka 5730: Loss = 0.000017536\n",
      "Epoka 5740: Loss = 0.000017576\n",
      "Epoka 5750: Loss = 0.000018322\n",
      "Epoka 5760: Loss = 0.000019375\n",
      "Epoka 5770: Loss = 0.000017549\n",
      "Epoka 5780: Loss = 0.000017409\n",
      "Epoka 5790: Loss = 0.000017909\n",
      "Epoka 5800: Loss = 0.000017340\n",
      "Epoka 5810: Loss = 0.000017928\n",
      "Epoka 5820: Loss = 0.000018834\n",
      "Epoka 5830: Loss = 0.000017659\n",
      "Epoka 5840: Loss = 0.000017817\n",
      "Epoka 5850: Loss = 0.000017201\n",
      "Epoka 5860: Loss = 0.000017102\n",
      "Epoka 5870: Loss = 0.000017417\n",
      "Epoka 5880: Loss = 0.000017985\n",
      "Epoka 5890: Loss = 0.000016967\n",
      "Epoka 5900: Loss = 0.000017000\n",
      "Epoka 5910: Loss = 0.000017862\n",
      "Epoka 5920: Loss = 0.000017265\n",
      "Epoka 5930: Loss = 0.000016815\n",
      "Epoka 5940: Loss = 0.000018745\n",
      "Epoka 5950: Loss = 0.000017499\n",
      "Epoka 5960: Loss = 0.000016508\n",
      "Epoka 5970: Loss = 0.000017075\n",
      "Epoka 5980: Loss = 0.000016515\n",
      "Epoka 5990: Loss = 0.000017128\n",
      "Epoka 6000: Loss = 0.000016951\n",
      "Epoka 6010: Loss = 0.000016729\n",
      "Epoka 6020: Loss = 0.000016371\n",
      "Epoka 6030: Loss = 0.000016174\n",
      "Epoka 6040: Loss = 0.000017904\n",
      "Epoka 6050: Loss = 0.000016315\n",
      "Epoka 6060: Loss = 0.000016515\n",
      "Epoka 6070: Loss = 0.000016457\n",
      "Epoka 6080: Loss = 0.000016428\n",
      "Epoka 6090: Loss = 0.000016308\n",
      "Epoka 6100: Loss = 0.000017214\n",
      "Epoka 6110: Loss = 0.000016051\n",
      "Epoka 6120: Loss = 0.000017226\n",
      "Epoka 6130: Loss = 0.000015768\n",
      "Epoka 6140: Loss = 0.000016195\n",
      "Epoka 6150: Loss = 0.000015861\n",
      "Epoka 6160: Loss = 0.000017073\n",
      "Epoka 6170: Loss = 0.000015615\n",
      "Epoka 6180: Loss = 0.000016079\n",
      "Epoka 6190: Loss = 0.000016588\n",
      "Epoka 6200: Loss = 0.000016235\n",
      "Epoka 6210: Loss = 0.000015821\n",
      "Epoka 6220: Loss = 0.000015337\n",
      "Epoka 6230: Loss = 0.000015972\n",
      "Epoka 6240: Loss = 0.000015428\n",
      "Epoka 6250: Loss = 0.000015693\n",
      "Epoka 6260: Loss = 0.000015217\n",
      "Epoka 6270: Loss = 0.000015124\n",
      "Epoka 6280: Loss = 0.000015550\n",
      "Epoka 6290: Loss = 0.000016276\n",
      "Epoka 6300: Loss = 0.000015288\n",
      "Epoka 6310: Loss = 0.000015575\n",
      "Epoka 6320: Loss = 0.000015229\n",
      "Epoka 6330: Loss = 0.000015096\n",
      "Epoka 6340: Loss = 0.000017097\n",
      "Epoka 6350: Loss = 0.000015543\n",
      "Epoka 6360: Loss = 0.000014900\n",
      "Epoka 6370: Loss = 0.000014722\n",
      "Epoka 6380: Loss = 0.000014756\n",
      "Epoka 6390: Loss = 0.000014689\n",
      "Epoka 6400: Loss = 0.000015750\n",
      "Epoka 6410: Loss = 0.000014867\n",
      "Epoka 6420: Loss = 0.000015814\n",
      "Epoka 6430: Loss = 0.000014734\n",
      "Epoka 6440: Loss = 0.000015721\n",
      "Epoka 6450: Loss = 0.000014470\n",
      "Epoka 6460: Loss = 0.000014795\n",
      "Epoka 6470: Loss = 0.000014574\n",
      "Epoka 6480: Loss = 0.000015218\n",
      "Epoka 6490: Loss = 0.000014600\n",
      "Epoka 6500: Loss = 0.000014505\n",
      "Epoka 6510: Loss = 0.000014281\n",
      "Epoka 6520: Loss = 0.000014497\n",
      "Epoka 6530: Loss = 0.000014406\n",
      "Epoka 6540: Loss = 0.000014017\n",
      "Epoka 6550: Loss = 0.000014186\n",
      "Epoka 6560: Loss = 0.000014684\n",
      "Epoka 6570: Loss = 0.000015029\n",
      "Epoka 6580: Loss = 0.000014329\n",
      "Epoka 6590: Loss = 0.000014049\n",
      "Epoka 6600: Loss = 0.000014649\n",
      "Epoka 6610: Loss = 0.000015349\n",
      "Epoka 6620: Loss = 0.000013881\n",
      "Epoka 6630: Loss = 0.000013801\n",
      "Epoka 6640: Loss = 0.000015364\n",
      "Epoka 6650: Loss = 0.000013719\n",
      "Epoka 6660: Loss = 0.000013978\n",
      "Epoka 6670: Loss = 0.000013684\n",
      "Epoka 6680: Loss = 0.000013586\n",
      "Epoka 6690: Loss = 0.000013912\n",
      "Epoka 6700: Loss = 0.000013825\n",
      "Epoka 6710: Loss = 0.000017373\n",
      "Epoka 6720: Loss = 0.000014150\n",
      "Epoka 6730: Loss = 0.000014777\n",
      "Epoka 6740: Loss = 0.000013831\n",
      "Epoka 6750: Loss = 0.000013297\n",
      "Epoka 6760: Loss = 0.000013282\n",
      "Epoka 6770: Loss = 0.000013546\n",
      "Epoka 6780: Loss = 0.000013493\n",
      "Epoka 6790: Loss = 0.000014538\n",
      "Epoka 6800: Loss = 0.000013681\n",
      "Epoka 6810: Loss = 0.000013554\n",
      "Epoka 6820: Loss = 0.000014582\n",
      "Epoka 6830: Loss = 0.000014515\n",
      "Epoka 6840: Loss = 0.000014003\n",
      "Epoka 6850: Loss = 0.000013637\n",
      "Epoka 6860: Loss = 0.000013336\n",
      "Epoka 6870: Loss = 0.000012893\n",
      "Epoka 6880: Loss = 0.000013235\n",
      "Epoka 6890: Loss = 0.000013092\n",
      "Epoka 6900: Loss = 0.000013112\n",
      "Epoka 6910: Loss = 0.000012780\n",
      "Epoka 6920: Loss = 0.000012749\n",
      "Epoka 6930: Loss = 0.000014242\n",
      "Epoka 6940: Loss = 0.000013941\n",
      "Epoka 6950: Loss = 0.000012692\n",
      "Epoka 6960: Loss = 0.000012699\n",
      "Epoka 6970: Loss = 0.000012656\n",
      "Epoka 6980: Loss = 0.000015941\n",
      "Epoka 6990: Loss = 0.000014642\n",
      "Epoka 7000: Loss = 0.000012806\n",
      "Epoka 7010: Loss = 0.000012894\n",
      "Epoka 7020: Loss = 0.000013997\n",
      "Epoka 7030: Loss = 0.000012621\n",
      "Epoka 7040: Loss = 0.000012528\n",
      "Epoka 7050: Loss = 0.000012833\n",
      "Epoka 7060: Loss = 0.000012391\n",
      "Epoka 7070: Loss = 0.000012734\n",
      "Epoka 7080: Loss = 0.000012246\n",
      "Epoka 7090: Loss = 0.000012735\n",
      "Epoka 7100: Loss = 0.000012672\n",
      "Epoka 7110: Loss = 0.000013630\n",
      "Epoka 7120: Loss = 0.000012749\n",
      "Epoka 7130: Loss = 0.000012788\n",
      "Epoka 7140: Loss = 0.000013810\n",
      "Epoka 7150: Loss = 0.000013679\n",
      "Epoka 7160: Loss = 0.000012131\n",
      "Epoka 7170: Loss = 0.000012070\n",
      "Epoka 7180: Loss = 0.000012545\n",
      "Epoka 7190: Loss = 0.000011931\n",
      "Epoka 7200: Loss = 0.000011902\n",
      "Epoka 7210: Loss = 0.000011974\n",
      "Epoka 7220: Loss = 0.000012165\n",
      "Epoka 7230: Loss = 0.000011850\n",
      "Epoka 7240: Loss = 0.000012614\n",
      "Epoka 7250: Loss = 0.000012987\n",
      "Epoka 7260: Loss = 0.000012833\n",
      "Epoka 7270: Loss = 0.000011751\n",
      "Epoka 7280: Loss = 0.000012376\n",
      "Epoka 7290: Loss = 0.000011655\n",
      "Epoka 7300: Loss = 0.000012081\n",
      "Epoka 7310: Loss = 0.000011663\n",
      "Epoka 7320: Loss = 0.000011914\n",
      "Epoka 7330: Loss = 0.000011634\n",
      "Epoka 7340: Loss = 0.000011801\n",
      "Epoka 7350: Loss = 0.000011672\n",
      "Epoka 7360: Loss = 0.000012715\n",
      "Epoka 7370: Loss = 0.000013936\n",
      "Epoka 7380: Loss = 0.000011500\n",
      "Epoka 7390: Loss = 0.000012207\n",
      "Epoka 7400: Loss = 0.000011442\n",
      "Epoka 7410: Loss = 0.000011467\n",
      "Epoka 7420: Loss = 0.000012446\n",
      "Epoka 7430: Loss = 0.000011624\n",
      "Epoka 7440: Loss = 0.000011731\n",
      "Epoka 7450: Loss = 0.000011617\n",
      "Epoka 7460: Loss = 0.000011503\n",
      "Epoka 7470: Loss = 0.000011314\n",
      "Epoka 7480: Loss = 0.000011482\n",
      "Epoka 7490: Loss = 0.000012001\n",
      "Epoka 7500: Loss = 0.000011081\n",
      "Epoka 7510: Loss = 0.000012241\n",
      "Epoka 7520: Loss = 0.000011338\n",
      "Epoka 7530: Loss = 0.000011115\n",
      "Epoka 7540: Loss = 0.000011095\n",
      "Epoka 7550: Loss = 0.000011403\n",
      "Epoka 7560: Loss = 0.000011190\n",
      "Epoka 7570: Loss = 0.000012188\n",
      "Epoka 7580: Loss = 0.000011334\n",
      "Epoka 7590: Loss = 0.000013898\n",
      "Epoka 7600: Loss = 0.000012085\n",
      "Epoka 7610: Loss = 0.000010974\n",
      "Epoka 7620: Loss = 0.000010937\n",
      "Epoka 7630: Loss = 0.000010802\n",
      "Epoka 7640: Loss = 0.000012258\n",
      "Epoka 7650: Loss = 0.000010754\n",
      "Epoka 7660: Loss = 0.000012289\n",
      "Epoka 7670: Loss = 0.000010942\n",
      "Epoka 7680: Loss = 0.000012094\n",
      "Epoka 7690: Loss = 0.000010620\n",
      "Epoka 7700: Loss = 0.000011324\n",
      "Epoka 7710: Loss = 0.000011017\n",
      "Epoka 7720: Loss = 0.000010565\n",
      "Epoka 7730: Loss = 0.000010625\n",
      "Epoka 7740: Loss = 0.000010505\n",
      "Epoka 7750: Loss = 0.000010531\n",
      "Epoka 7760: Loss = 0.000010590\n",
      "Epoka 7770: Loss = 0.000011569\n",
      "Epoka 7780: Loss = 0.000010473\n",
      "Epoka 7790: Loss = 0.000010432\n",
      "Epoka 7800: Loss = 0.000011057\n",
      "Epoka 7810: Loss = 0.000010508\n",
      "Epoka 7820: Loss = 0.000010448\n",
      "Epoka 7830: Loss = 0.000010529\n",
      "Epoka 7840: Loss = 0.000010341\n",
      "Epoka 7850: Loss = 0.000010779\n",
      "Epoka 7860: Loss = 0.000010181\n",
      "Epoka 7870: Loss = 0.000011486\n",
      "Epoka 7880: Loss = 0.000011340\n",
      "Epoka 7890: Loss = 0.000010351\n",
      "Epoka 7900: Loss = 0.000010156\n",
      "Epoka 7910: Loss = 0.000011202\n",
      "Epoka 7920: Loss = 0.000013357\n",
      "Epoka 7930: Loss = 0.000010483\n",
      "Epoka 7940: Loss = 0.000011028\n",
      "Epoka 7950: Loss = 0.000010332\n",
      "Epoka 7960: Loss = 0.000010650\n",
      "Epoka 7970: Loss = 0.000010939\n",
      "Epoka 7980: Loss = 0.000010115\n",
      "Epoka 7990: Loss = 0.000010037\n",
      "Epoka 8000: Loss = 0.000010280\n",
      "Epoka 8010: Loss = 0.000010173\n",
      "Epoka 8020: Loss = 0.000010403\n",
      "Epoka 8030: Loss = 0.000010608\n",
      "Epoka 8040: Loss = 0.000010508\n",
      "Epoka 8050: Loss = 0.000010472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 8060: Loss = 0.000009772\n",
      "Epoka 8070: Loss = 0.000011679\n",
      "Epoka 8080: Loss = 0.000010117\n",
      "Epoka 8090: Loss = 0.000011471\n",
      "Epoka 8100: Loss = 0.000009668\n",
      "Epoka 8110: Loss = 0.000009725\n",
      "Epoka 8120: Loss = 0.000010215\n",
      "Epoka 8130: Loss = 0.000009908\n",
      "Epoka 8140: Loss = 0.000010829\n",
      "Epoka 8150: Loss = 0.000009677\n",
      "Epoka 8160: Loss = 0.000009859\n",
      "Epoka 8170: Loss = 0.000009916\n",
      "Epoka 8180: Loss = 0.000010351\n",
      "Epoka 8190: Loss = 0.000009483\n",
      "Epoka 8200: Loss = 0.000009650\n",
      "Epoka 8210: Loss = 0.000009727\n",
      "Epoka 8220: Loss = 0.000009595\n",
      "Epoka 8230: Loss = 0.000010345\n",
      "Epoka 8240: Loss = 0.000009547\n",
      "Epoka 8250: Loss = 0.000009823\n",
      "Epoka 8260: Loss = 0.000009956\n",
      "Epoka 8270: Loss = 0.000012101\n",
      "Epoka 8280: Loss = 0.000011891\n",
      "Epoka 8290: Loss = 0.000009403\n",
      "Epoka 8300: Loss = 0.000009595\n",
      "Epoka 8310: Loss = 0.000009777\n",
      "Epoka 8320: Loss = 0.000010143\n",
      "Epoka 8330: Loss = 0.000009382\n",
      "Epoka 8340: Loss = 0.000009868\n",
      "Epoka 8350: Loss = 0.000009819\n",
      "Epoka 8360: Loss = 0.000009398\n",
      "Epoka 8370: Loss = 0.000009448\n",
      "Epoka 8380: Loss = 0.000009398\n",
      "Epoka 8390: Loss = 0.000011314\n",
      "Epoka 8400: Loss = 0.000009071\n",
      "Epoka 8410: Loss = 0.000009040\n",
      "Epoka 8420: Loss = 0.000009464\n",
      "Epoka 8430: Loss = 0.000009595\n",
      "Epoka 8440: Loss = 0.000009332\n",
      "Epoka 8450: Loss = 0.000009096\n",
      "Epoka 8460: Loss = 0.000009080\n",
      "Epoka 8470: Loss = 0.000009274\n",
      "Epoka 8480: Loss = 0.000011917\n",
      "Epoka 8490: Loss = 0.000009211\n",
      "Epoka 8500: Loss = 0.000009723\n",
      "Epoka 8510: Loss = 0.000009670\n",
      "Epoka 8520: Loss = 0.000009627\n",
      "Epoka 8530: Loss = 0.000008973\n",
      "Epoka 8540: Loss = 0.000009056\n",
      "Epoka 8550: Loss = 0.000008796\n",
      "Epoka 8560: Loss = 0.000008892\n",
      "Epoka 8570: Loss = 0.000009157\n",
      "Epoka 8580: Loss = 0.000009353\n",
      "Epoka 8590: Loss = 0.000008823\n",
      "Epoka 8600: Loss = 0.000008700\n",
      "Epoka 8610: Loss = 0.000011467\n",
      "Epoka 8620: Loss = 0.000009284\n",
      "Epoka 8630: Loss = 0.000009570\n",
      "Epoka 8640: Loss = 0.000008713\n",
      "Epoka 8650: Loss = 0.000008640\n",
      "Epoka 8660: Loss = 0.000009774\n",
      "Epoka 8670: Loss = 0.000008809\n",
      "Epoka 8680: Loss = 0.000009796\n",
      "Epoka 8690: Loss = 0.000009206\n",
      "Epoka 8700: Loss = 0.000008530\n",
      "Epoka 8710: Loss = 0.000008528\n",
      "Epoka 8720: Loss = 0.000009240\n",
      "Epoka 8730: Loss = 0.000009683\n",
      "Epoka 8740: Loss = 0.000008572\n",
      "Epoka 8750: Loss = 0.000008446\n",
      "Epoka 8760: Loss = 0.000008713\n",
      "Epoka 8770: Loss = 0.000009033\n",
      "Epoka 8780: Loss = 0.000009296\n",
      "Epoka 8790: Loss = 0.000009055\n",
      "Epoka 8800: Loss = 0.000008699\n",
      "Epoka 8810: Loss = 0.000008938\n",
      "Epoka 8820: Loss = 0.000008481\n",
      "Epoka 8830: Loss = 0.000008436\n",
      "Epoka 8840: Loss = 0.000008492\n",
      "Epoka 8850: Loss = 0.000009173\n",
      "Epoka 8860: Loss = 0.000008613\n",
      "Epoka 8870: Loss = 0.000008607\n",
      "Epoka 8880: Loss = 0.000008334\n",
      "Epoka 8890: Loss = 0.000008317\n",
      "Epoka 8900: Loss = 0.000008164\n",
      "Epoka 8910: Loss = 0.000008258\n",
      "Epoka 8920: Loss = 0.000009888\n",
      "Epoka 8930: Loss = 0.000008104\n",
      "Epoka 8940: Loss = 0.000008290\n",
      "Epoka 8950: Loss = 0.000008852\n",
      "Epoka 8960: Loss = 0.000010995\n",
      "Epoka 8970: Loss = 0.000008084\n",
      "Epoka 8980: Loss = 0.000008221\n",
      "Epoka 8990: Loss = 0.000008274\n",
      "Epoka 9000: Loss = 0.000008387\n",
      "Epoka 9010: Loss = 0.000008055\n",
      "Epoka 9020: Loss = 0.000008007\n",
      "Epoka 9030: Loss = 0.000007994\n",
      "Epoka 9040: Loss = 0.000008383\n",
      "Epoka 9050: Loss = 0.000008674\n",
      "Epoka 9060: Loss = 0.000007953\n",
      "Epoka 9070: Loss = 0.000008120\n",
      "Epoka 9080: Loss = 0.000008142\n",
      "Epoka 9090: Loss = 0.000008274\n",
      "Epoka 9100: Loss = 0.000007840\n",
      "Epoka 9110: Loss = 0.000008062\n",
      "Epoka 9120: Loss = 0.000007966\n",
      "Epoka 9130: Loss = 0.000008419\n",
      "Epoka 9140: Loss = 0.000007947\n",
      "Epoka 9150: Loss = 0.000007722\n",
      "Epoka 9160: Loss = 0.000007866\n",
      "Epoka 9170: Loss = 0.000007921\n",
      "Epoka 9180: Loss = 0.000008355\n",
      "Epoka 9190: Loss = 0.000008006\n",
      "Epoka 9200: Loss = 0.000007622\n",
      "Epoka 9210: Loss = 0.000008015\n",
      "Epoka 9220: Loss = 0.000007610\n",
      "Epoka 9230: Loss = 0.000008069\n",
      "Epoka 9240: Loss = 0.000007652\n",
      "Epoka 9250: Loss = 0.000007743\n",
      "Epoka 9260: Loss = 0.000007673\n",
      "Epoka 9270: Loss = 0.000009048\n",
      "Epoka 9280: Loss = 0.000008383\n",
      "Epoka 9290: Loss = 0.000007538\n",
      "Epoka 9300: Loss = 0.000007580\n",
      "Epoka 9310: Loss = 0.000007781\n",
      "Epoka 9320: Loss = 0.000008953\n",
      "Epoka 9330: Loss = 0.000008244\n",
      "Epoka 9340: Loss = 0.000007906\n",
      "Epoka 9350: Loss = 0.000007454\n",
      "Epoka 9360: Loss = 0.000007718\n",
      "Epoka 9370: Loss = 0.000008084\n",
      "Epoka 9380: Loss = 0.000009693\n",
      "Epoka 9390: Loss = 0.000007582\n",
      "Epoka 9400: Loss = 0.000008179\n",
      "Epoka 9410: Loss = 0.000007728\n",
      "Epoka 9420: Loss = 0.000007530\n",
      "Epoka 9430: Loss = 0.000007382\n",
      "Epoka 9440: Loss = 0.000007901\n",
      "Epoka 9450: Loss = 0.000007576\n",
      "Epoka 9460: Loss = 0.000007344\n",
      "Epoka 9470: Loss = 0.000008861\n",
      "Epoka 9480: Loss = 0.000007356\n",
      "Epoka 9490: Loss = 0.000007207\n",
      "Epoka 9500: Loss = 0.000007897\n",
      "Epoka 9510: Loss = 0.000008100\n",
      "Epoka 9520: Loss = 0.000007502\n",
      "Epoka 9530: Loss = 0.000007593\n",
      "Epoka 9540: Loss = 0.000007493\n",
      "Epoka 9550: Loss = 0.000007193\n",
      "Epoka 9560: Loss = 0.000009184\n",
      "Epoka 9570: Loss = 0.000007996\n",
      "Epoka 9580: Loss = 0.000007287\n",
      "Epoka 9590: Loss = 0.000007091\n",
      "Epoka 9600: Loss = 0.000007530\n",
      "Epoka 9610: Loss = 0.000007430\n",
      "Epoka 9620: Loss = 0.000008058\n",
      "Epoka 9630: Loss = 0.000008337\n",
      "Epoka 9640: Loss = 0.000007272\n",
      "Epoka 9650: Loss = 0.000006962\n",
      "Epoka 9660: Loss = 0.000007113\n",
      "Epoka 9670: Loss = 0.000006922\n",
      "Epoka 9680: Loss = 0.000007031\n",
      "Epoka 9690: Loss = 0.000007350\n",
      "Epoka 9700: Loss = 0.000006972\n",
      "Epoka 9710: Loss = 0.000006897\n",
      "Epoka 9720: Loss = 0.000006879\n",
      "Epoka 9730: Loss = 0.000008472\n",
      "Epoka 9740: Loss = 0.000007401\n",
      "Epoka 9750: Loss = 0.000007559\n",
      "Epoka 9760: Loss = 0.000007035\n",
      "Epoka 9770: Loss = 0.000007175\n",
      "Epoka 9780: Loss = 0.000006821\n",
      "Epoka 9790: Loss = 0.000007105\n",
      "Epoka 9800: Loss = 0.000006821\n",
      "Epoka 9810: Loss = 0.000008248\n",
      "Epoka 9820: Loss = 0.000007397\n",
      "Epoka 9830: Loss = 0.000006924\n",
      "Epoka 9840: Loss = 0.000007108\n",
      "Epoka 9850: Loss = 0.000006896\n",
      "Epoka 9860: Loss = 0.000007149\n",
      "Epoka 9870: Loss = 0.000006806\n",
      "Epoka 9880: Loss = 0.000007806\n",
      "Epoka 9890: Loss = 0.000007991\n",
      "Epoka 9900: Loss = 0.000007790\n",
      "Epoka 9910: Loss = 0.000006922\n",
      "Epoka 9920: Loss = 0.000006874\n",
      "Epoka 9930: Loss = 0.000006702\n",
      "Epoka 9940: Loss = 0.000006720\n",
      "Epoka 9950: Loss = 0.000006693\n",
      "Epoka 9960: Loss = 0.000007589\n",
      "Epoka 9970: Loss = 0.000007061\n",
      "Epoka 9980: Loss = 0.000007051\n",
      "Epoka 9990: Loss = 0.000007168\n",
      "Epoka 10000: Loss = 0.000006745\n",
      "Epoka 10010: Loss = 0.000006745\n",
      "Epoka 10020: Loss = 0.000006588\n",
      "Epoka 10030: Loss = 0.000007748\n",
      "Epoka 10040: Loss = 0.000006594\n",
      "Epoka 10050: Loss = 0.000007066\n",
      "Epoka 10060: Loss = 0.000007035\n",
      "Epoka 10070: Loss = 0.000006730\n",
      "Epoka 10080: Loss = 0.000006683\n",
      "Epoka 10090: Loss = 0.000006887\n",
      "Epoka 10100: Loss = 0.000006794\n",
      "Epoka 10110: Loss = 0.000006761\n",
      "Epoka 10120: Loss = 0.000006923\n",
      "Epoka 10130: Loss = 0.000006372\n",
      "Epoka 10140: Loss = 0.000006520\n",
      "Epoka 10150: Loss = 0.000006557\n",
      "Epoka 10160: Loss = 0.000007213\n",
      "Epoka 10170: Loss = 0.000008506\n",
      "Epoka 10180: Loss = 0.000006503\n",
      "Epoka 10190: Loss = 0.000007117\n",
      "Epoka 10200: Loss = 0.000006315\n",
      "Epoka 10210: Loss = 0.000007554\n",
      "Epoka 10220: Loss = 0.000007615\n",
      "Epoka 10230: Loss = 0.000006757\n",
      "Epoka 10240: Loss = 0.000006256\n",
      "Epoka 10250: Loss = 0.000006597\n",
      "Epoka 10260: Loss = 0.000006873\n",
      "Epoka 10270: Loss = 0.000006284\n",
      "Epoka 10280: Loss = 0.000007582\n",
      "Epoka 10290: Loss = 0.000006384\n",
      "Epoka 10300: Loss = 0.000006516\n",
      "Epoka 10310: Loss = 0.000007499\n",
      "Epoka 10320: Loss = 0.000006106\n",
      "Epoka 10330: Loss = 0.000006870\n",
      "Epoka 10340: Loss = 0.000006972\n",
      "Epoka 10350: Loss = 0.000006574\n",
      "Epoka 10360: Loss = 0.000006586\n",
      "Epoka 10370: Loss = 0.000006134\n",
      "Epoka 10380: Loss = 0.000006067\n",
      "Epoka 10390: Loss = 0.000006100\n",
      "Epoka 10400: Loss = 0.000006833\n",
      "Epoka 10410: Loss = 0.000007949\n",
      "Epoka 10420: Loss = 0.000006500\n",
      "Epoka 10430: Loss = 0.000006443\n",
      "Epoka 10440: Loss = 0.000008806\n",
      "Epoka 10450: Loss = 0.000006606\n",
      "Epoka 10460: Loss = 0.000006071\n",
      "Epoka 10470: Loss = 0.000006539\n",
      "Epoka 10480: Loss = 0.000006701\n",
      "Epoka 10490: Loss = 0.000006365\n",
      "Epoka 10500: Loss = 0.000005979\n",
      "Epoka 10510: Loss = 0.000005995\n",
      "Epoka 10520: Loss = 0.000005892\n",
      "Epoka 10530: Loss = 0.000006232\n",
      "Epoka 10540: Loss = 0.000006968\n",
      "Epoka 10550: Loss = 0.000007198\n",
      "Epoka 10560: Loss = 0.000006262\n",
      "Epoka 10570: Loss = 0.000006211\n",
      "Epoka 10580: Loss = 0.000005988\n",
      "Epoka 10590: Loss = 0.000005852\n",
      "Epoka 10600: Loss = 0.000006087\n",
      "Epoka 10610: Loss = 0.000005840\n",
      "Epoka 10620: Loss = 0.000006980\n",
      "Epoka 10630: Loss = 0.000005812\n",
      "Epoka 10640: Loss = 0.000006251\n",
      "Epoka 10650: Loss = 0.000006157\n",
      "Epoka 10660: Loss = 0.000006003\n",
      "Epoka 10670: Loss = 0.000006454\n",
      "Epoka 10680: Loss = 0.000006907\n",
      "Epoka 10690: Loss = 0.000006093\n",
      "Epoka 10700: Loss = 0.000006220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 10710: Loss = 0.000006419\n",
      "Epoka 10720: Loss = 0.000007059\n",
      "Epoka 10730: Loss = 0.000005936\n",
      "Epoka 10740: Loss = 0.000005887\n",
      "Epoka 10750: Loss = 0.000005692\n",
      "Epoka 10760: Loss = 0.000006250\n",
      "Epoka 10770: Loss = 0.000006446\n",
      "Epoka 10780: Loss = 0.000006059\n",
      "Epoka 10790: Loss = 0.000005934\n",
      "Epoka 10800: Loss = 0.000006665\n",
      "Epoka 10810: Loss = 0.000005829\n",
      "Epoka 10820: Loss = 0.000006429\n",
      "Epoka 10830: Loss = 0.000005633\n",
      "Epoka 10840: Loss = 0.000005755\n",
      "Epoka 10850: Loss = 0.000005808\n",
      "Epoka 10860: Loss = 0.000005833\n",
      "Epoka 10870: Loss = 0.000006551\n",
      "Epoka 10880: Loss = 0.000005547\n",
      "Epoka 10890: Loss = 0.000005530\n",
      "Epoka 10900: Loss = 0.000006139\n",
      "Epoka 10910: Loss = 0.000005910\n",
      "Epoka 10920: Loss = 0.000005543\n",
      "Epoka 10930: Loss = 0.000005507\n",
      "Epoka 10940: Loss = 0.000006864\n",
      "Epoka 10950: Loss = 0.000006834\n",
      "Epoka 10960: Loss = 0.000005616\n",
      "Epoka 10970: Loss = 0.000006165\n",
      "Epoka 10980: Loss = 0.000005728\n",
      "Epoka 10990: Loss = 0.000006567\n",
      "Epoka 11000: Loss = 0.000005838\n",
      "Epoka 11010: Loss = 0.000006471\n",
      "Epoka 11020: Loss = 0.000005758\n",
      "Epoka 11030: Loss = 0.000005509\n",
      "Epoka 11040: Loss = 0.000005481\n",
      "Epoka 11050: Loss = 0.000005990\n",
      "Epoka 11060: Loss = 0.000005977\n",
      "Epoka 11070: Loss = 0.000005332\n",
      "Epoka 11080: Loss = 0.000005292\n",
      "Epoka 11090: Loss = 0.000005971\n",
      "Epoka 11100: Loss = 0.000005864\n",
      "Epoka 11110: Loss = 0.000005616\n",
      "Epoka 11120: Loss = 0.000005559\n",
      "Epoka 11130: Loss = 0.000005244\n",
      "Epoka 11140: Loss = 0.000005614\n",
      "Epoka 11150: Loss = 0.000005550\n",
      "Epoka 11160: Loss = 0.000005222\n",
      "Epoka 11170: Loss = 0.000006335\n",
      "Epoka 11180: Loss = 0.000005388\n",
      "Epoka 11190: Loss = 0.000005382\n",
      "Epoka 11200: Loss = 0.000005539\n",
      "Epoka 11210: Loss = 0.000005231\n",
      "Epoka 11220: Loss = 0.000005216\n",
      "Epoka 11230: Loss = 0.000005372\n",
      "Epoka 11240: Loss = 0.000005287\n",
      "Epoka 11250: Loss = 0.000005289\n",
      "Epoka 11260: Loss = 0.000005822\n",
      "Epoka 11270: Loss = 0.000006119\n",
      "Epoka 11280: Loss = 0.000005283\n",
      "Epoka 11290: Loss = 0.000005611\n",
      "Epoka 11300: Loss = 0.000006112\n",
      "Epoka 11310: Loss = 0.000005779\n",
      "Epoka 11320: Loss = 0.000006712\n",
      "Epoka 11330: Loss = 0.000005493\n",
      "Epoka 11340: Loss = 0.000005555\n",
      "Epoka 11350: Loss = 0.000005459\n",
      "Epoka 11360: Loss = 0.000005269\n",
      "Epoka 11370: Loss = 0.000006063\n",
      "Epoka 11380: Loss = 0.000005081\n",
      "Epoka 11390: Loss = 0.000005301\n",
      "Epoka 11400: Loss = 0.000005007\n",
      "Epoka 11410: Loss = 0.000005068\n",
      "Epoka 11420: Loss = 0.000005126\n",
      "Epoka 11430: Loss = 0.000005023\n",
      "Epoka 11440: Loss = 0.000005318\n",
      "Epoka 11450: Loss = 0.000005562\n",
      "Epoka 11460: Loss = 0.000004980\n",
      "Epoka 11470: Loss = 0.000005006\n",
      "Epoka 11480: Loss = 0.000005200\n",
      "Epoka 11490: Loss = 0.000004968\n",
      "Epoka 11500: Loss = 0.000004971\n",
      "Epoka 11510: Loss = 0.000005406\n",
      "Epoka 11520: Loss = 0.000005231\n",
      "Epoka 11530: Loss = 0.000005672\n",
      "Epoka 11540: Loss = 0.000005225\n",
      "Epoka 11550: Loss = 0.000006622\n",
      "Epoka 11560: Loss = 0.000004939\n",
      "Epoka 11570: Loss = 0.000006117\n",
      "Epoka 11580: Loss = 0.000004923\n",
      "Epoka 11590: Loss = 0.000005845\n",
      "Epoka 11600: Loss = 0.000005291\n",
      "Epoka 11610: Loss = 0.000005080\n",
      "Epoka 11620: Loss = 0.000005823\n",
      "Epoka 11630: Loss = 0.000005404\n",
      "Epoka 11640: Loss = 0.000005378\n",
      "Epoka 11650: Loss = 0.000005242\n",
      "Epoka 11660: Loss = 0.000005367\n",
      "Epoka 11670: Loss = 0.000005419\n",
      "Epoka 11680: Loss = 0.000006408\n",
      "Epoka 11690: Loss = 0.000004984\n",
      "Epoka 11700: Loss = 0.000004756\n",
      "Epoka 11710: Loss = 0.000004918\n",
      "Epoka 11720: Loss = 0.000004742\n",
      "Epoka 11730: Loss = 0.000005083\n",
      "Epoka 11740: Loss = 0.000004736\n",
      "Epoka 11750: Loss = 0.000004968\n",
      "Epoka 11760: Loss = 0.000004964\n",
      "Epoka 11770: Loss = 0.000005719\n",
      "Epoka 11780: Loss = 0.000004868\n",
      "Epoka 11790: Loss = 0.000005189\n",
      "Epoka 11800: Loss = 0.000004774\n",
      "Epoka 11810: Loss = 0.000005629\n",
      "Epoka 11820: Loss = 0.000005358\n",
      "Epoka 11830: Loss = 0.000004910\n",
      "Epoka 11840: Loss = 0.000005271\n",
      "Epoka 11850: Loss = 0.000004743\n",
      "Epoka 11860: Loss = 0.000004849\n",
      "Epoka 11870: Loss = 0.000005075\n",
      "Epoka 11880: Loss = 0.000004605\n",
      "Epoka 11890: Loss = 0.000005314\n",
      "Epoka 11900: Loss = 0.000004876\n",
      "Epoka 11910: Loss = 0.000005050\n",
      "Epoka 11920: Loss = 0.000004994\n",
      "Epoka 11930: Loss = 0.000004615\n",
      "Epoka 11940: Loss = 0.000004744\n",
      "Epoka 11950: Loss = 0.000005634\n",
      "Epoka 11960: Loss = 0.000004550\n",
      "Epoka 11970: Loss = 0.000005321\n",
      "Epoka 11980: Loss = 0.000004621\n",
      "Epoka 11990: Loss = 0.000004781\n",
      "Epoka 12000: Loss = 0.000004675\n",
      "Epoka 12010: Loss = 0.000005436\n",
      "Epoka 12020: Loss = 0.000004740\n",
      "Epoka 12030: Loss = 0.000005383\n",
      "Epoka 12040: Loss = 0.000004480\n",
      "Epoka 12050: Loss = 0.000004868\n",
      "Epoka 12060: Loss = 0.000004467\n",
      "Epoka 12070: Loss = 0.000005785\n",
      "Epoka 12080: Loss = 0.000004731\n",
      "Epoka 12090: Loss = 0.000004472\n",
      "Epoka 12100: Loss = 0.000005704\n",
      "Epoka 12110: Loss = 0.000004546\n",
      "Epoka 12120: Loss = 0.000004838\n",
      "Epoka 12130: Loss = 0.000004653\n",
      "Epoka 12140: Loss = 0.000004870\n",
      "Epoka 12150: Loss = 0.000004531\n",
      "Epoka 12160: Loss = 0.000005009\n",
      "Epoka 12170: Loss = 0.000004829\n",
      "Epoka 12180: Loss = 0.000004538\n",
      "Epoka 12190: Loss = 0.000005672\n",
      "Epoka 12200: Loss = 0.000004538\n",
      "Epoka 12210: Loss = 0.000004919\n",
      "Epoka 12220: Loss = 0.000004510\n",
      "Epoka 12230: Loss = 0.000004429\n",
      "Epoka 12240: Loss = 0.000004504\n",
      "Epoka 12250: Loss = 0.000004351\n",
      "Epoka 12260: Loss = 0.000005657\n",
      "Epoka 12270: Loss = 0.000004653\n",
      "Epoka 12280: Loss = 0.000004573\n",
      "Epoka 12290: Loss = 0.000005286\n",
      "Epoka 12300: Loss = 0.000005535\n",
      "Epoka 12310: Loss = 0.000007488\n",
      "Epoka 12320: Loss = 0.000004515\n",
      "Epoka 12330: Loss = 0.000005295\n",
      "Epoka 12340: Loss = 0.000004540\n",
      "Epoka 12350: Loss = 0.000004446\n",
      "Epoka 12360: Loss = 0.000004322\n",
      "Epoka 12370: Loss = 0.000005417\n",
      "Epoka 12380: Loss = 0.000004234\n",
      "Epoka 12390: Loss = 0.000005922\n",
      "Epoka 12400: Loss = 0.000004753\n",
      "Epoka 12410: Loss = 0.000004459\n",
      "Epoka 12420: Loss = 0.000004252\n",
      "Epoka 12430: Loss = 0.000004342\n",
      "Epoka 12440: Loss = 0.000004535\n",
      "Epoka 12450: Loss = 0.000004305\n",
      "Epoka 12460: Loss = 0.000004239\n",
      "Epoka 12470: Loss = 0.000004334\n",
      "Epoka 12480: Loss = 0.000004288\n",
      "Epoka 12490: Loss = 0.000004865\n",
      "Epoka 12500: Loss = 0.000005010\n",
      "Epoka 12510: Loss = 0.000004801\n",
      "Epoka 12520: Loss = 0.000004215\n",
      "Epoka 12530: Loss = 0.000004637\n",
      "Epoka 12540: Loss = 0.000004451\n",
      "Epoka 12550: Loss = 0.000004248\n",
      "Epoka 12560: Loss = 0.000004241\n",
      "Epoka 12570: Loss = 0.000004728\n",
      "Epoka 12580: Loss = 0.000005281\n",
      "Epoka 12590: Loss = 0.000005049\n",
      "Epoka 12600: Loss = 0.000004497\n",
      "Epoka 12610: Loss = 0.000004624\n",
      "Epoka 12620: Loss = 0.000004629\n",
      "Epoka 12630: Loss = 0.000004070\n",
      "Epoka 12640: Loss = 0.000004763\n",
      "Epoka 12650: Loss = 0.000004644\n",
      "Epoka 12660: Loss = 0.000005454\n",
      "Epoka 12670: Loss = 0.000004275\n",
      "Epoka 12680: Loss = 0.000004166\n",
      "Epoka 12690: Loss = 0.000004100\n",
      "Epoka 12700: Loss = 0.000004093\n",
      "Epoka 12710: Loss = 0.000004129\n",
      "Epoka 12720: Loss = 0.000004649\n",
      "Epoka 12730: Loss = 0.000004337\n",
      "Epoka 12740: Loss = 0.000004307\n",
      "Epoka 12750: Loss = 0.000004342\n",
      "Epoka 12760: Loss = 0.000006308\n",
      "Epoka 12770: Loss = 0.000004132\n",
      "Epoka 12780: Loss = 0.000004465\n",
      "Epoka 12790: Loss = 0.000005426\n",
      "Epoka 12800: Loss = 0.000004644\n",
      "Epoka 12810: Loss = 0.000004914\n",
      "Epoka 12820: Loss = 0.000003988\n",
      "Epoka 12830: Loss = 0.000004188\n",
      "Epoka 12840: Loss = 0.000005335\n",
      "Epoka 12850: Loss = 0.000004817\n",
      "Epoka 12860: Loss = 0.000004027\n",
      "Epoka 12870: Loss = 0.000003980\n",
      "Epoka 12880: Loss = 0.000003920\n",
      "Epoka 12890: Loss = 0.000003963\n",
      "Epoka 12900: Loss = 0.000005047\n",
      "Epoka 12910: Loss = 0.000004101\n",
      "Epoka 12920: Loss = 0.000004102\n",
      "Epoka 12930: Loss = 0.000003964\n",
      "Epoka 12940: Loss = 0.000005014\n",
      "Epoka 12950: Loss = 0.000004384\n",
      "Epoka 12960: Loss = 0.000003918\n",
      "Epoka 12970: Loss = 0.000003956\n",
      "Epoka 12980: Loss = 0.000004261\n",
      "Epoka 12990: Loss = 0.000003875\n",
      "Epoka 13000: Loss = 0.000004923\n",
      "Epoka 13010: Loss = 0.000004029\n",
      "Epoka 13020: Loss = 0.000003921\n",
      "Epoka 13030: Loss = 0.000004588\n",
      "Epoka 13040: Loss = 0.000004656\n",
      "Epoka 13050: Loss = 0.000003791\n",
      "Epoka 13060: Loss = 0.000004935\n",
      "Epoka 13070: Loss = 0.000003885\n",
      "Epoka 13080: Loss = 0.000004229\n",
      "Epoka 13090: Loss = 0.000004833\n",
      "Epoka 13100: Loss = 0.000004005\n",
      "Epoka 13110: Loss = 0.000003906\n",
      "Epoka 13120: Loss = 0.000003942\n",
      "Epoka 13130: Loss = 0.000004539\n",
      "Epoka 13140: Loss = 0.000003782\n",
      "Epoka 13150: Loss = 0.000003950\n",
      "Epoka 13160: Loss = 0.000003818\n",
      "Epoka 13170: Loss = 0.000003786\n",
      "Epoka 13180: Loss = 0.000004125\n",
      "Epoka 13190: Loss = 0.000004360\n",
      "Epoka 13200: Loss = 0.000004285\n",
      "Epoka 13210: Loss = 0.000003832\n",
      "Epoka 13220: Loss = 0.000005191\n",
      "Epoka 13230: Loss = 0.000003938\n",
      "Epoka 13240: Loss = 0.000004551\n",
      "Epoka 13250: Loss = 0.000004784\n",
      "Epoka 13260: Loss = 0.000004002\n",
      "Epoka 13270: Loss = 0.000004547\n",
      "Epoka 13280: Loss = 0.000004171\n",
      "Epoka 13290: Loss = 0.000004221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 13300: Loss = 0.000003839\n",
      "Epoka 13310: Loss = 0.000004801\n",
      "Epoka 13320: Loss = 0.000004005\n",
      "Epoka 13330: Loss = 0.000004286\n",
      "Epoka 13340: Loss = 0.000003937\n",
      "Epoka 13350: Loss = 0.000004157\n",
      "Epoka 13360: Loss = 0.000003738\n",
      "Epoka 13370: Loss = 0.000004153\n",
      "Epoka 13380: Loss = 0.000004712\n",
      "Epoka 13390: Loss = 0.000004015\n",
      "Epoka 13400: Loss = 0.000003845\n",
      "Epoka 13410: Loss = 0.000004151\n",
      "Epoka 13420: Loss = 0.000003768\n",
      "Epoka 13430: Loss = 0.000004558\n",
      "Epoka 13440: Loss = 0.000003735\n",
      "Epoka 13450: Loss = 0.000003902\n",
      "Epoka 13460: Loss = 0.000003648\n",
      "Epoka 13470: Loss = 0.000004141\n",
      "Epoka 13480: Loss = 0.000003920\n",
      "Epoka 13490: Loss = 0.000003635\n",
      "Epoka 13500: Loss = 0.000004142\n",
      "Epoka 13510: Loss = 0.000003613\n",
      "Epoka 13520: Loss = 0.000003809\n",
      "Epoka 13530: Loss = 0.000003562\n",
      "Epoka 13540: Loss = 0.000003504\n",
      "Epoka 13550: Loss = 0.000003592\n",
      "Epoka 13560: Loss = 0.000003506\n",
      "Epoka 13570: Loss = 0.000004193\n",
      "Epoka 13580: Loss = 0.000003810\n",
      "Epoka 13590: Loss = 0.000003762\n",
      "Epoka 13600: Loss = 0.000004037\n",
      "Epoka 13610: Loss = 0.000003536\n",
      "Epoka 13620: Loss = 0.000003698\n",
      "Epoka 13630: Loss = 0.000003544\n",
      "Epoka 13640: Loss = 0.000003649\n",
      "Epoka 13650: Loss = 0.000003626\n",
      "Epoka 13660: Loss = 0.000003739\n",
      "Epoka 13670: Loss = 0.000003641\n",
      "Epoka 13680: Loss = 0.000003462\n",
      "Epoka 13690: Loss = 0.000003554\n",
      "Epoka 13700: Loss = 0.000003804\n",
      "Epoka 13710: Loss = 0.000003583\n",
      "Epoka 13720: Loss = 0.000003418\n",
      "Epoka 13730: Loss = 0.000003471\n",
      "Epoka 13740: Loss = 0.000004433\n",
      "Epoka 13750: Loss = 0.000003606\n",
      "Epoka 13760: Loss = 0.000003501\n",
      "Epoka 13770: Loss = 0.000003697\n",
      "Epoka 13780: Loss = 0.000005648\n",
      "Epoka 13790: Loss = 0.000004162\n",
      "Epoka 13800: Loss = 0.000003430\n",
      "Epoka 13810: Loss = 0.000003556\n",
      "Epoka 13820: Loss = 0.000003542\n",
      "Epoka 13830: Loss = 0.000003544\n",
      "Epoka 13840: Loss = 0.000003370\n",
      "Epoka 13850: Loss = 0.000003423\n",
      "Epoka 13860: Loss = 0.000003698\n",
      "Epoka 13870: Loss = 0.000003540\n",
      "Epoka 13880: Loss = 0.000003367\n",
      "Epoka 13890: Loss = 0.000003684\n",
      "Epoka 13900: Loss = 0.000003621\n",
      "Epoka 13910: Loss = 0.000003391\n",
      "Epoka 13920: Loss = 0.000003440\n",
      "Epoka 13930: Loss = 0.000003495\n",
      "Epoka 13940: Loss = 0.000003324\n",
      "Epoka 13950: Loss = 0.000003340\n",
      "Epoka 13960: Loss = 0.000004148\n",
      "Epoka 13970: Loss = 0.000003351\n",
      "Epoka 13980: Loss = 0.000003460\n",
      "Epoka 13990: Loss = 0.000003388\n",
      "Epoka 14000: Loss = 0.000003488\n",
      "Epoka 14010: Loss = 0.000003594\n",
      "Epoka 14020: Loss = 0.000003673\n",
      "Epoka 14030: Loss = 0.000003507\n",
      "Epoka 14040: Loss = 0.000003415\n",
      "Epoka 14050: Loss = 0.000003361\n",
      "Epoka 14060: Loss = 0.000003473\n",
      "Epoka 14070: Loss = 0.000005717\n",
      "Epoka 14080: Loss = 0.000003219\n",
      "Epoka 14090: Loss = 0.000003310\n",
      "Epoka 14100: Loss = 0.000003932\n",
      "Epoka 14110: Loss = 0.000003704\n",
      "Epoka 14120: Loss = 0.000003263\n",
      "Epoka 14130: Loss = 0.000003452\n",
      "Epoka 14140: Loss = 0.000003458\n",
      "Epoka 14150: Loss = 0.000003787\n",
      "Epoka 14160: Loss = 0.000003503\n",
      "Epoka 14170: Loss = 0.000003542\n",
      "Epoka 14180: Loss = 0.000003575\n",
      "Epoka 14190: Loss = 0.000003556\n",
      "Epoka 14200: Loss = 0.000003451\n",
      "Epoka 14210: Loss = 0.000003780\n",
      "Epoka 14220: Loss = 0.000003495\n",
      "Epoka 14230: Loss = 0.000003487\n",
      "Epoka 14240: Loss = 0.000004801\n",
      "Epoka 14250: Loss = 0.000003383\n",
      "Epoka 14260: Loss = 0.000003825\n",
      "Epoka 14270: Loss = 0.000003336\n",
      "Epoka 14280: Loss = 0.000003364\n",
      "Epoka 14290: Loss = 0.000003486\n",
      "Epoka 14300: Loss = 0.000003317\n",
      "Epoka 14310: Loss = 0.000004687\n",
      "Epoka 14320: Loss = 0.000003202\n",
      "Epoka 14330: Loss = 0.000003613\n",
      "Epoka 14340: Loss = 0.000003431\n",
      "Epoka 14350: Loss = 0.000003353\n",
      "Epoka 14360: Loss = 0.000004014\n",
      "Epoka 14370: Loss = 0.000003157\n",
      "Epoka 14380: Loss = 0.000003524\n",
      "Epoka 14390: Loss = 0.000003421\n",
      "Epoka 14400: Loss = 0.000003323\n",
      "Epoka 14410: Loss = 0.000003099\n",
      "Epoka 14420: Loss = 0.000003102\n",
      "Epoka 14430: Loss = 0.000003142\n",
      "Epoka 14440: Loss = 0.000003403\n",
      "Epoka 14450: Loss = 0.000003119\n",
      "Epoka 14460: Loss = 0.000003291\n",
      "Epoka 14470: Loss = 0.000003086\n",
      "Epoka 14480: Loss = 0.000003436\n",
      "Epoka 14490: Loss = 0.000003453\n",
      "Epoka 14500: Loss = 0.000003633\n",
      "Epoka 14510: Loss = 0.000003233\n",
      "Epoka 14520: Loss = 0.000003410\n",
      "Epoka 14530: Loss = 0.000003029\n",
      "Epoka 14540: Loss = 0.000006847\n",
      "Epoka 14550: Loss = 0.000003286\n",
      "Epoka 14560: Loss = 0.000003399\n",
      "Epoka 14570: Loss = 0.000003034\n",
      "Epoka 14580: Loss = 0.000003222\n",
      "Epoka 14590: Loss = 0.000003028\n",
      "Epoka 14600: Loss = 0.000003038\n",
      "Epoka 14610: Loss = 0.000003014\n",
      "Epoka 14620: Loss = 0.000003814\n",
      "Epoka 14630: Loss = 0.000003374\n",
      "Epoka 14640: Loss = 0.000003069\n",
      "Epoka 14650: Loss = 0.000003857\n",
      "Epoka 14660: Loss = 0.000003252\n",
      "Epoka 14670: Loss = 0.000003164\n",
      "Epoka 14680: Loss = 0.000006157\n",
      "Epoka 14690: Loss = 0.000005650\n",
      "Epoka 14700: Loss = 0.000003018\n",
      "Epoka 14710: Loss = 0.000003152\n",
      "Epoka 14720: Loss = 0.000003712\n",
      "Epoka 14730: Loss = 0.000003182\n",
      "Epoka 14740: Loss = 0.000003985\n",
      "Epoka 14750: Loss = 0.000003868\n",
      "Epoka 14760: Loss = 0.000003027\n",
      "Epoka 14770: Loss = 0.000003036\n",
      "Epoka 14780: Loss = 0.000003522\n",
      "Epoka 14790: Loss = 0.000003595\n",
      "Epoka 14800: Loss = 0.000003227\n",
      "Epoka 14810: Loss = 0.000003048\n",
      "Epoka 14820: Loss = 0.000003112\n",
      "Epoka 14830: Loss = 0.000003094\n",
      "Epoka 14840: Loss = 0.000003146\n",
      "Epoka 14850: Loss = 0.000002959\n",
      "Epoka 14860: Loss = 0.000003267\n",
      "Epoka 14870: Loss = 0.000003031\n",
      "Epoka 14880: Loss = 0.000003569\n",
      "Epoka 14890: Loss = 0.000003019\n",
      "Epoka 14900: Loss = 0.000003116\n",
      "Epoka 14910: Loss = 0.000002970\n",
      "Epoka 14920: Loss = 0.000004816\n",
      "Epoka 14930: Loss = 0.000003905\n",
      "Epoka 14940: Loss = 0.000004405\n",
      "Epoka 14950: Loss = 0.000002889\n",
      "Epoka 14960: Loss = 0.000003151\n",
      "Epoka 14970: Loss = 0.000002914\n",
      "Epoka 14980: Loss = 0.000003174\n",
      "Epoka 14990: Loss = 0.000002916\n",
      "Epoka 15000: Loss = 0.000002998\n",
      "Epoka 15010: Loss = 0.000002977\n",
      "Epoka 15020: Loss = 0.000002965\n",
      "Epoka 15030: Loss = 0.000002923\n",
      "Epoka 15040: Loss = 0.000003015\n",
      "Epoka 15050: Loss = 0.000004015\n",
      "Epoka 15060: Loss = 0.000002859\n",
      "Epoka 15070: Loss = 0.000002972\n",
      "Epoka 15080: Loss = 0.000003121\n",
      "Epoka 15090: Loss = 0.000002882\n",
      "Epoka 15100: Loss = 0.000003493\n",
      "Epoka 15110: Loss = 0.000002788\n",
      "Epoka 15120: Loss = 0.000003539\n",
      "Epoka 15130: Loss = 0.000003479\n",
      "Epoka 15140: Loss = 0.000003402\n",
      "Epoka 15150: Loss = 0.000002806\n",
      "Epoka 15160: Loss = 0.000002760\n",
      "Epoka 15170: Loss = 0.000003068\n",
      "Epoka 15180: Loss = 0.000003092\n",
      "Epoka 15190: Loss = 0.000003412\n",
      "Epoka 15200: Loss = 0.000003336\n",
      "Epoka 15210: Loss = 0.000002826\n",
      "Epoka 15220: Loss = 0.000002843\n",
      "Epoka 15230: Loss = 0.000003017\n",
      "Epoka 15240: Loss = 0.000002759\n",
      "Epoka 15250: Loss = 0.000003020\n",
      "Epoka 15260: Loss = 0.000003200\n",
      "Epoka 15270: Loss = 0.000003031\n",
      "Epoka 15280: Loss = 0.000002792\n",
      "Epoka 15290: Loss = 0.000002767\n",
      "Epoka 15300: Loss = 0.000002823\n",
      "Epoka 15310: Loss = 0.000002723\n",
      "Epoka 15320: Loss = 0.000002735\n",
      "Epoka 15330: Loss = 0.000004001\n",
      "Epoka 15340: Loss = 0.000003201\n",
      "Epoka 15350: Loss = 0.000002728\n",
      "Epoka 15360: Loss = 0.000002870\n",
      "Epoka 15370: Loss = 0.000002905\n",
      "Epoka 15380: Loss = 0.000003773\n",
      "Epoka 15390: Loss = 0.000003305\n",
      "Epoka 15400: Loss = 0.000002888\n",
      "Epoka 15410: Loss = 0.000002765\n",
      "Epoka 15420: Loss = 0.000002758\n",
      "Epoka 15430: Loss = 0.000002812\n",
      "Epoka 15440: Loss = 0.000002695\n",
      "Epoka 15450: Loss = 0.000002948\n",
      "Epoka 15460: Loss = 0.000002715\n",
      "Epoka 15470: Loss = 0.000002650\n",
      "Epoka 15480: Loss = 0.000003286\n",
      "Epoka 15490: Loss = 0.000002720\n",
      "Epoka 15500: Loss = 0.000002640\n",
      "Epoka 15510: Loss = 0.000002667\n",
      "Epoka 15520: Loss = 0.000002807\n",
      "Epoka 15530: Loss = 0.000003707\n",
      "Epoka 15540: Loss = 0.000002706\n",
      "Epoka 15550: Loss = 0.000002785\n",
      "Epoka 15560: Loss = 0.000003555\n",
      "Epoka 15570: Loss = 0.000002706\n",
      "Epoka 15580: Loss = 0.000002831\n",
      "Epoka 15590: Loss = 0.000003531\n",
      "Epoka 15600: Loss = 0.000003006\n",
      "Epoka 15610: Loss = 0.000002589\n",
      "Epoka 15620: Loss = 0.000002589\n",
      "Epoka 15630: Loss = 0.000002599\n",
      "Epoka 15640: Loss = 0.000002575\n",
      "Epoka 15650: Loss = 0.000002591\n",
      "Epoka 15660: Loss = 0.000003249\n",
      "Epoka 15670: Loss = 0.000003609\n",
      "Epoka 15680: Loss = 0.000002644\n",
      "Epoka 15690: Loss = 0.000002729\n",
      "Epoka 15700: Loss = 0.000003041\n",
      "Epoka 15710: Loss = 0.000003010\n",
      "Epoka 15720: Loss = 0.000002689\n",
      "Epoka 15730: Loss = 0.000002627\n",
      "Epoka 15740: Loss = 0.000003069\n",
      "Epoka 15750: Loss = 0.000002783\n",
      "Epoka 15760: Loss = 0.000002651\n",
      "Epoka 15770: Loss = 0.000004338\n",
      "Epoka 15780: Loss = 0.000003364\n",
      "Epoka 15790: Loss = 0.000002794\n",
      "Epoka 15800: Loss = 0.000002959\n",
      "Epoka 15810: Loss = 0.000002769\n",
      "Epoka 15820: Loss = 0.000002775\n",
      "Epoka 15830: Loss = 0.000002590\n",
      "Epoka 15840: Loss = 0.000002801\n",
      "Epoka 15850: Loss = 0.000002894\n",
      "Epoka 15860: Loss = 0.000003500\n",
      "Epoka 15870: Loss = 0.000002612\n",
      "Epoka 15880: Loss = 0.000002750\n",
      "Epoka 15890: Loss = 0.000002500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 15900: Loss = 0.000002609\n",
      "Epoka 15910: Loss = 0.000002672\n",
      "Epoka 15920: Loss = 0.000002651\n",
      "Epoka 15930: Loss = 0.000002688\n",
      "Epoka 15940: Loss = 0.000002861\n",
      "Epoka 15950: Loss = 0.000002887\n",
      "Epoka 15960: Loss = 0.000002608\n",
      "Epoka 15970: Loss = 0.000002732\n",
      "Epoka 15980: Loss = 0.000004784\n",
      "Epoka 15990: Loss = 0.000003099\n",
      "Epoka 16000: Loss = 0.000002827\n",
      "Epoka 16010: Loss = 0.000002556\n",
      "Epoka 16020: Loss = 0.000003069\n",
      "Epoka 16030: Loss = 0.000002708\n",
      "Epoka 16040: Loss = 0.000002822\n",
      "Epoka 16050: Loss = 0.000002916\n",
      "Epoka 16060: Loss = 0.000003136\n",
      "Epoka 16070: Loss = 0.000002617\n",
      "Epoka 16080: Loss = 0.000002576\n",
      "Epoka 16090: Loss = 0.000002956\n",
      "Epoka 16100: Loss = 0.000002514\n",
      "Epoka 16110: Loss = 0.000002726\n",
      "Epoka 16120: Loss = 0.000003275\n",
      "Epoka 16130: Loss = 0.000002945\n",
      "Epoka 16140: Loss = 0.000003146\n",
      "Epoka 16150: Loss = 0.000003040\n",
      "Epoka 16160: Loss = 0.000003586\n",
      "Epoka 16170: Loss = 0.000003187\n",
      "Epoka 16180: Loss = 0.000002450\n",
      "Epoka 16190: Loss = 0.000002525\n",
      "Epoka 16200: Loss = 0.000002701\n",
      "Epoka 16210: Loss = 0.000003268\n",
      "Epoka 16220: Loss = 0.000002523\n",
      "Epoka 16230: Loss = 0.000002591\n",
      "Epoka 16240: Loss = 0.000002527\n",
      "Epoka 16250: Loss = 0.000002427\n",
      "Epoka 16260: Loss = 0.000002719\n",
      "Epoka 16270: Loss = 0.000002794\n",
      "Epoka 16280: Loss = 0.000002406\n",
      "Epoka 16290: Loss = 0.000003389\n",
      "Epoka 16300: Loss = 0.000002370\n",
      "Epoka 16310: Loss = 0.000002541\n",
      "Epoka 16320: Loss = 0.000002483\n",
      "Epoka 16330: Loss = 0.000002423\n",
      "Epoka 16340: Loss = 0.000002888\n",
      "Epoka 16350: Loss = 0.000002408\n",
      "Epoka 16360: Loss = 0.000002951\n",
      "Epoka 16370: Loss = 0.000002766\n",
      "Epoka 16380: Loss = 0.000002417\n",
      "Epoka 16390: Loss = 0.000002534\n",
      "Epoka 16400: Loss = 0.000003598\n",
      "Epoka 16410: Loss = 0.000002563\n",
      "Epoka 16420: Loss = 0.000002397\n",
      "Epoka 16430: Loss = 0.000002784\n",
      "Epoka 16440: Loss = 0.000002587\n",
      "Epoka 16450: Loss = 0.000002596\n",
      "Epoka 16460: Loss = 0.000002320\n",
      "Epoka 16470: Loss = 0.000002825\n",
      "Epoka 16480: Loss = 0.000002358\n",
      "Epoka 16490: Loss = 0.000002403\n",
      "Epoka 16500: Loss = 0.000002479\n",
      "Epoka 16510: Loss = 0.000003737\n",
      "Epoka 16520: Loss = 0.000003134\n",
      "Epoka 16530: Loss = 0.000002338\n",
      "Epoka 16540: Loss = 0.000002718\n",
      "Epoka 16550: Loss = 0.000002403\n",
      "Epoka 16560: Loss = 0.000002377\n",
      "Epoka 16570: Loss = 0.000002293\n",
      "Epoka 16580: Loss = 0.000003173\n",
      "Epoka 16590: Loss = 0.000002738\n",
      "Epoka 16600: Loss = 0.000002976\n",
      "Epoka 16610: Loss = 0.000002557\n",
      "Epoka 16620: Loss = 0.000002327\n",
      "Epoka 16630: Loss = 0.000003025\n",
      "Epoka 16640: Loss = 0.000002453\n",
      "Epoka 16650: Loss = 0.000002785\n",
      "Epoka 16660: Loss = 0.000002362\n",
      "Epoka 16670: Loss = 0.000002963\n",
      "Epoka 16680: Loss = 0.000002530\n",
      "Epoka 16690: Loss = 0.000002568\n",
      "Epoka 16700: Loss = 0.000002651\n",
      "Epoka 16710: Loss = 0.000002419\n",
      "Epoka 16720: Loss = 0.000002505\n",
      "Epoka 16730: Loss = 0.000002472\n",
      "Epoka 16740: Loss = 0.000002486\n",
      "Epoka 16750: Loss = 0.000002398\n",
      "Epoka 16760: Loss = 0.000003945\n",
      "Epoka 16770: Loss = 0.000002419\n",
      "Epoka 16780: Loss = 0.000003729\n",
      "Epoka 16790: Loss = 0.000002687\n",
      "Epoka 16800: Loss = 0.000002882\n",
      "Epoka 16810: Loss = 0.000002871\n",
      "Epoka 16820: Loss = 0.000002387\n",
      "Epoka 16830: Loss = 0.000002210\n",
      "Epoka 16840: Loss = 0.000002757\n",
      "Epoka 16850: Loss = 0.000002371\n",
      "Epoka 16860: Loss = 0.000002281\n",
      "Epoka 16870: Loss = 0.000002588\n",
      "Epoka 16880: Loss = 0.000002195\n",
      "Epoka 16890: Loss = 0.000002473\n",
      "Epoka 16900: Loss = 0.000002557\n",
      "Epoka 16910: Loss = 0.000002198\n",
      "Epoka 16920: Loss = 0.000002390\n",
      "Epoka 16930: Loss = 0.000002187\n",
      "Epoka 16940: Loss = 0.000002850\n",
      "Epoka 16950: Loss = 0.000002331\n",
      "Epoka 16960: Loss = 0.000002207\n",
      "Epoka 16970: Loss = 0.000002663\n",
      "Epoka 16980: Loss = 0.000002634\n",
      "Epoka 16990: Loss = 0.000002851\n",
      "Epoka 17000: Loss = 0.000002238\n",
      "Epoka 17010: Loss = 0.000002668\n",
      "Epoka 17020: Loss = 0.000002730\n",
      "Epoka 17030: Loss = 0.000002144\n",
      "Epoka 17040: Loss = 0.000002989\n",
      "Epoka 17050: Loss = 0.000002364\n",
      "Epoka 17060: Loss = 0.000002169\n",
      "Epoka 17070: Loss = 0.000002219\n",
      "Epoka 17080: Loss = 0.000002615\n",
      "Epoka 17090: Loss = 0.000002296\n",
      "Epoka 17100: Loss = 0.000002234\n",
      "Epoka 17110: Loss = 0.000002175\n",
      "Epoka 17120: Loss = 0.000002152\n",
      "Epoka 17130: Loss = 0.000002336\n",
      "Epoka 17140: Loss = 0.000002447\n",
      "Epoka 17150: Loss = 0.000003597\n",
      "Epoka 17160: Loss = 0.000002240\n",
      "Epoka 17170: Loss = 0.000002356\n",
      "Epoka 17180: Loss = 0.000002138\n",
      "Epoka 17190: Loss = 0.000002121\n",
      "Epoka 17200: Loss = 0.000002462\n",
      "Epoka 17210: Loss = 0.000002258\n",
      "Epoka 17220: Loss = 0.000002318\n",
      "Epoka 17230: Loss = 0.000002315\n",
      "Epoka 17240: Loss = 0.000002176\n",
      "Epoka 17250: Loss = 0.000003304\n",
      "Epoka 17260: Loss = 0.000002241\n",
      "Epoka 17270: Loss = 0.000002565\n",
      "Epoka 17280: Loss = 0.000002150\n",
      "Epoka 17290: Loss = 0.000002611\n",
      "Epoka 17300: Loss = 0.000002661\n",
      "Epoka 17310: Loss = 0.000002565\n",
      "Epoka 17320: Loss = 0.000002087\n",
      "Epoka 17330: Loss = 0.000002069\n",
      "Epoka 17340: Loss = 0.000002077\n",
      "Epoka 17350: Loss = 0.000002631\n",
      "Epoka 17360: Loss = 0.000002200\n",
      "Epoka 17370: Loss = 0.000002315\n",
      "Epoka 17380: Loss = 0.000002710\n",
      "Epoka 17390: Loss = 0.000002069\n",
      "Epoka 17400: Loss = 0.000002203\n",
      "Epoka 17410: Loss = 0.000002330\n",
      "Epoka 17420: Loss = 0.000002108\n",
      "Epoka 17430: Loss = 0.000002436\n",
      "Epoka 17440: Loss = 0.000002359\n",
      "Epoka 17450: Loss = 0.000002474\n",
      "Epoka 17460: Loss = 0.000002434\n",
      "Epoka 17470: Loss = 0.000002490\n",
      "Epoka 17480: Loss = 0.000002346\n",
      "Epoka 17490: Loss = 0.000003217\n",
      "Epoka 17500: Loss = 0.000002241\n",
      "Epoka 17510: Loss = 0.000003182\n",
      "Epoka 17520: Loss = 0.000002428\n",
      "Epoka 17530: Loss = 0.000002080\n",
      "Epoka 17540: Loss = 0.000003564\n",
      "Epoka 17550: Loss = 0.000002506\n",
      "Epoka 17560: Loss = 0.000002977\n",
      "Epoka 17570: Loss = 0.000002093\n",
      "Epoka 17580: Loss = 0.000003393\n",
      "Epoka 17590: Loss = 0.000002178\n",
      "Epoka 17600: Loss = 0.000002633\n",
      "Epoka 17610: Loss = 0.000002330\n",
      "Epoka 17620: Loss = 0.000002084\n",
      "Epoka 17630: Loss = 0.000004170\n",
      "Epoka 17640: Loss = 0.000004042\n",
      "Epoka 17650: Loss = 0.000002026\n",
      "Epoka 17660: Loss = 0.000002054\n",
      "Epoka 17670: Loss = 0.000002012\n",
      "Epoka 17680: Loss = 0.000002331\n",
      "Epoka 17690: Loss = 0.000002132\n",
      "Epoka 17700: Loss = 0.000002963\n",
      "Epoka 17710: Loss = 0.000002048\n",
      "Epoka 17720: Loss = 0.000003134\n",
      "Epoka 17730: Loss = 0.000002463\n",
      "Epoka 17740: Loss = 0.000002273\n",
      "Epoka 17750: Loss = 0.000002020\n",
      "Epoka 17760: Loss = 0.000002445\n",
      "Epoka 17770: Loss = 0.000002024\n",
      "Epoka 17780: Loss = 0.000002020\n",
      "Epoka 17790: Loss = 0.000002911\n",
      "Epoka 17800: Loss = 0.000002060\n",
      "Epoka 17810: Loss = 0.000002423\n",
      "Epoka 17820: Loss = 0.000002655\n",
      "Epoka 17830: Loss = 0.000002394\n",
      "Epoka 17840: Loss = 0.000002421\n",
      "Epoka 17850: Loss = 0.000002188\n",
      "Epoka 17860: Loss = 0.000002153\n",
      "Epoka 17870: Loss = 0.000002327\n",
      "Epoka 17880: Loss = 0.000003576\n",
      "Epoka 17890: Loss = 0.000001968\n",
      "Epoka 17900: Loss = 0.000002107\n",
      "Epoka 17910: Loss = 0.000001980\n",
      "Epoka 17920: Loss = 0.000002936\n",
      "Epoka 17930: Loss = 0.000002666\n",
      "Epoka 17940: Loss = 0.000002133\n",
      "Epoka 17950: Loss = 0.000002055\n",
      "Epoka 17960: Loss = 0.000002184\n",
      "Epoka 17970: Loss = 0.000002826\n",
      "Epoka 17980: Loss = 0.000002019\n",
      "Epoka 17990: Loss = 0.000001998\n",
      "Epoka 18000: Loss = 0.000002037\n",
      "Epoka 18010: Loss = 0.000002811\n",
      "Epoka 18020: Loss = 0.000002307\n",
      "Epoka 18030: Loss = 0.000002061\n",
      "Epoka 18040: Loss = 0.000002840\n",
      "Epoka 18050: Loss = 0.000002894\n",
      "Epoka 18060: Loss = 0.000002237\n",
      "Epoka 18070: Loss = 0.000002323\n",
      "Epoka 18080: Loss = 0.000001946\n",
      "Epoka 18090: Loss = 0.000001938\n",
      "Epoka 18100: Loss = 0.000002069\n",
      "Epoka 18110: Loss = 0.000002990\n",
      "Epoka 18120: Loss = 0.000002149\n",
      "Epoka 18130: Loss = 0.000002171\n",
      "Epoka 18140: Loss = 0.000001926\n",
      "Epoka 18150: Loss = 0.000001887\n",
      "Epoka 18160: Loss = 0.000001913\n",
      "Epoka 18170: Loss = 0.000002125\n",
      "Epoka 18180: Loss = 0.000002074\n",
      "Epoka 18190: Loss = 0.000002024\n",
      "Epoka 18200: Loss = 0.000002612\n",
      "Epoka 18210: Loss = 0.000002392\n",
      "Epoka 18220: Loss = 0.000002388\n",
      "Epoka 18230: Loss = 0.000001901\n",
      "Epoka 18240: Loss = 0.000002144\n",
      "Epoka 18250: Loss = 0.000001879\n",
      "Epoka 18260: Loss = 0.000001901\n",
      "Epoka 18270: Loss = 0.000001992\n",
      "Epoka 18280: Loss = 0.000002122\n",
      "Epoka 18290: Loss = 0.000001970\n",
      "Epoka 18300: Loss = 0.000002660\n",
      "Epoka 18310: Loss = 0.000001868\n",
      "Epoka 18320: Loss = 0.000001965\n",
      "Epoka 18330: Loss = 0.000002025\n",
      "Epoka 18340: Loss = 0.000002030\n",
      "Epoka 18350: Loss = 0.000001838\n",
      "Epoka 18360: Loss = 0.000001873\n",
      "Epoka 18370: Loss = 0.000002216\n",
      "Epoka 18380: Loss = 0.000002574\n",
      "Epoka 18390: Loss = 0.000002275\n",
      "Epoka 18400: Loss = 0.000001891\n",
      "Epoka 18410: Loss = 0.000001849\n",
      "Epoka 18420: Loss = 0.000001991\n",
      "Epoka 18430: Loss = 0.000002080\n",
      "Epoka 18440: Loss = 0.000001984\n",
      "Epoka 18450: Loss = 0.000002215\n",
      "Epoka 18460: Loss = 0.000002600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 18470: Loss = 0.000001932\n",
      "Epoka 18480: Loss = 0.000002524\n",
      "Epoka 18490: Loss = 0.000002045\n",
      "Epoka 18500: Loss = 0.000002089\n",
      "Epoka 18510: Loss = 0.000002113\n",
      "Epoka 18520: Loss = 0.000002106\n",
      "Epoka 18530: Loss = 0.000001955\n",
      "Epoka 18540: Loss = 0.000001987\n",
      "Epoka 18550: Loss = 0.000001917\n",
      "Epoka 18560: Loss = 0.000002230\n",
      "Epoka 18570: Loss = 0.000002052\n",
      "Epoka 18580: Loss = 0.000001953\n",
      "Epoka 18590: Loss = 0.000001781\n",
      "Epoka 18600: Loss = 0.000002129\n",
      "Epoka 18610: Loss = 0.000002106\n",
      "Epoka 18620: Loss = 0.000002103\n",
      "Epoka 18630: Loss = 0.000002070\n",
      "Epoka 18640: Loss = 0.000002171\n",
      "Epoka 18650: Loss = 0.000002786\n",
      "Epoka 18660: Loss = 0.000001896\n",
      "Epoka 18670: Loss = 0.000002523\n",
      "Epoka 18680: Loss = 0.000002553\n",
      "Epoka 18690: Loss = 0.000001800\n",
      "Epoka 18700: Loss = 0.000001810\n",
      "Epoka 18710: Loss = 0.000002263\n",
      "Epoka 18720: Loss = 0.000002000\n",
      "Epoka 18730: Loss = 0.000002352\n",
      "Epoka 18740: Loss = 0.000001979\n",
      "Epoka 18750: Loss = 0.000002684\n",
      "Epoka 18760: Loss = 0.000002550\n",
      "Epoka 18770: Loss = 0.000001985\n",
      "Epoka 18780: Loss = 0.000002138\n",
      "Epoka 18790: Loss = 0.000001993\n",
      "Epoka 18800: Loss = 0.000002144\n",
      "Epoka 18810: Loss = 0.000002635\n",
      "Epoka 18820: Loss = 0.000001819\n",
      "Epoka 18830: Loss = 0.000002237\n",
      "Epoka 18840: Loss = 0.000002127\n",
      "Epoka 18850: Loss = 0.000002114\n",
      "Epoka 18860: Loss = 0.000001743\n",
      "Epoka 18870: Loss = 0.000001768\n",
      "Epoka 18880: Loss = 0.000002061\n",
      "Epoka 18890: Loss = 0.000002015\n",
      "Epoka 18900: Loss = 0.000003475\n",
      "Epoka 18910: Loss = 0.000004466\n",
      "Epoka 18920: Loss = 0.000002475\n",
      "Epoka 18930: Loss = 0.000002331\n",
      "Epoka 18940: Loss = 0.000002444\n",
      "Epoka 18950: Loss = 0.000001762\n",
      "Epoka 18960: Loss = 0.000002018\n",
      "Epoka 18970: Loss = 0.000003958\n",
      "Epoka 18980: Loss = 0.000002053\n",
      "Epoka 18990: Loss = 0.000002271\n",
      "Epoka 19000: Loss = 0.000001738\n",
      "Epoka 19010: Loss = 0.000002319\n",
      "Epoka 19020: Loss = 0.000002080\n",
      "Epoka 19030: Loss = 0.000001753\n",
      "Epoka 19040: Loss = 0.000001723\n",
      "Epoka 19050: Loss = 0.000002402\n",
      "Epoka 19060: Loss = 0.000001730\n",
      "Epoka 19070: Loss = 0.000001774\n",
      "Epoka 19080: Loss = 0.000001690\n",
      "Epoka 19090: Loss = 0.000001941\n",
      "Epoka 19100: Loss = 0.000002827\n",
      "Epoka 19110: Loss = 0.000002874\n",
      "Epoka 19120: Loss = 0.000002031\n",
      "Epoka 19130: Loss = 0.000002692\n",
      "Epoka 19140: Loss = 0.000002224\n",
      "Epoka 19150: Loss = 0.000001836\n",
      "Epoka 19160: Loss = 0.000001898\n",
      "Epoka 19170: Loss = 0.000002312\n",
      "Epoka 19180: Loss = 0.000001780\n",
      "Epoka 19190: Loss = 0.000001824\n",
      "Epoka 19200: Loss = 0.000001921\n",
      "Epoka 19210: Loss = 0.000001688\n",
      "Epoka 19220: Loss = 0.000001834\n",
      "Epoka 19230: Loss = 0.000001889\n",
      "Epoka 19240: Loss = 0.000001697\n",
      "Epoka 19250: Loss = 0.000001662\n",
      "Epoka 19260: Loss = 0.000001739\n",
      "Epoka 19270: Loss = 0.000001658\n",
      "Epoka 19280: Loss = 0.000001693\n",
      "Epoka 19290: Loss = 0.000001917\n",
      "Epoka 19300: Loss = 0.000004943\n",
      "Epoka 19310: Loss = 0.000001938\n",
      "Epoka 19320: Loss = 0.000002487\n",
      "Epoka 19330: Loss = 0.000001719\n",
      "Epoka 19340: Loss = 0.000001749\n",
      "Epoka 19350: Loss = 0.000002116\n",
      "Epoka 19360: Loss = 0.000001746\n",
      "Epoka 19370: Loss = 0.000002652\n",
      "Epoka 19380: Loss = 0.000001900\n",
      "Epoka 19390: Loss = 0.000001732\n",
      "Epoka 19400: Loss = 0.000001734\n",
      "Epoka 19410: Loss = 0.000001727\n",
      "Epoka 19420: Loss = 0.000002764\n",
      "Epoka 19430: Loss = 0.000001698\n",
      "Epoka 19440: Loss = 0.000001714\n",
      "Epoka 19450: Loss = 0.000001633\n",
      "Epoka 19460: Loss = 0.000001895\n",
      "Epoka 19470: Loss = 0.000001900\n",
      "Epoka 19480: Loss = 0.000001828\n",
      "Epoka 19490: Loss = 0.000001695\n",
      "Epoka 19500: Loss = 0.000001688\n",
      "Epoka 19510: Loss = 0.000001635\n",
      "Epoka 19520: Loss = 0.000001621\n",
      "Epoka 19530: Loss = 0.000002159\n",
      "Epoka 19540: Loss = 0.000002020\n",
      "Epoka 19550: Loss = 0.000003394\n",
      "Epoka 19560: Loss = 0.000001689\n",
      "Epoka 19570: Loss = 0.000002510\n",
      "Epoka 19580: Loss = 0.000002230\n",
      "Epoka 19590: Loss = 0.000002284\n",
      "Epoka 19600: Loss = 0.000002689\n",
      "Epoka 19610: Loss = 0.000002336\n",
      "Epoka 19620: Loss = 0.000001745\n",
      "Epoka 19630: Loss = 0.000001907\n",
      "Epoka 19640: Loss = 0.000001630\n",
      "Epoka 19650: Loss = 0.000001696\n",
      "Epoka 19660: Loss = 0.000001929\n",
      "Epoka 19670: Loss = 0.000002442\n",
      "Epoka 19680: Loss = 0.000001987\n",
      "Epoka 19690: Loss = 0.000001726\n",
      "Epoka 19700: Loss = 0.000002257\n",
      "Epoka 19710: Loss = 0.000001736\n",
      "Epoka 19720: Loss = 0.000001616\n",
      "Epoka 19730: Loss = 0.000001998\n",
      "Epoka 19740: Loss = 0.000002203\n",
      "Epoka 19750: Loss = 0.000001583\n",
      "Epoka 19760: Loss = 0.000001681\n",
      "Epoka 19770: Loss = 0.000001704\n",
      "Epoka 19780: Loss = 0.000001598\n",
      "Epoka 19790: Loss = 0.000001668\n",
      "Epoka 19800: Loss = 0.000001658\n",
      "Epoka 19810: Loss = 0.000001622\n",
      "Epoka 19820: Loss = 0.000002315\n",
      "Epoka 19830: Loss = 0.000001725\n",
      "Epoka 19840: Loss = 0.000001634\n",
      "Epoka 19850: Loss = 0.000001696\n",
      "Epoka 19860: Loss = 0.000001590\n",
      "Epoka 19870: Loss = 0.000002032\n",
      "Epoka 19880: Loss = 0.000001949\n",
      "Epoka 19890: Loss = 0.000001621\n",
      "Epoka 19900: Loss = 0.000001596\n",
      "Epoka 19910: Loss = 0.000001656\n",
      "Epoka 19920: Loss = 0.000001754\n",
      "Epoka 19930: Loss = 0.000001546\n",
      "Epoka 19940: Loss = 0.000001769\n",
      "Epoka 19950: Loss = 0.000001610\n",
      "Epoka 19960: Loss = 0.000002155\n",
      "Epoka 19970: Loss = 0.000001593\n",
      "Epoka 19980: Loss = 0.000001574\n",
      "Epoka 19990: Loss = 0.000001794\n",
      "Epoka 20000: Loss = 0.000001636\n",
      "Epoka 20010: Loss = 0.000002019\n",
      "Epoka 20020: Loss = 0.000001933\n",
      "Epoka 20030: Loss = 0.000001574\n",
      "Epoka 20040: Loss = 0.000001565\n",
      "Epoka 20050: Loss = 0.000001644\n",
      "Epoka 20060: Loss = 0.000001764\n",
      "Epoka 20070: Loss = 0.000002177\n",
      "Epoka 20080: Loss = 0.000001562\n",
      "Epoka 20090: Loss = 0.000001597\n",
      "Epoka 20100: Loss = 0.000001640\n",
      "Epoka 20110: Loss = 0.000001519\n",
      "Epoka 20120: Loss = 0.000001662\n",
      "Epoka 20130: Loss = 0.000001491\n",
      "Epoka 20140: Loss = 0.000001593\n",
      "Epoka 20150: Loss = 0.000001659\n",
      "Epoka 20160: Loss = 0.000001513\n",
      "Epoka 20170: Loss = 0.000001869\n",
      "Epoka 20180: Loss = 0.000001529\n",
      "Epoka 20190: Loss = 0.000002519\n",
      "Epoka 20200: Loss = 0.000001737\n",
      "Epoka 20210: Loss = 0.000002019\n",
      "Epoka 20220: Loss = 0.000001537\n",
      "Epoka 20230: Loss = 0.000001641\n",
      "Epoka 20240: Loss = 0.000002429\n",
      "Epoka 20250: Loss = 0.000002022\n",
      "Epoka 20260: Loss = 0.000002730\n",
      "Epoka 20270: Loss = 0.000001545\n",
      "Epoka 20280: Loss = 0.000001991\n",
      "Epoka 20290: Loss = 0.000001612\n",
      "Epoka 20300: Loss = 0.000001816\n",
      "Epoka 20310: Loss = 0.000001788\n",
      "Epoka 20320: Loss = 0.000002138\n",
      "Epoka 20330: Loss = 0.000001474\n",
      "Epoka 20340: Loss = 0.000001570\n",
      "Epoka 20350: Loss = 0.000001511\n",
      "Epoka 20360: Loss = 0.000001468\n",
      "Epoka 20370: Loss = 0.000001527\n",
      "Epoka 20380: Loss = 0.000001495\n",
      "Epoka 20390: Loss = 0.000001679\n",
      "Epoka 20400: Loss = 0.000001464\n",
      "Epoka 20410: Loss = 0.000001526\n",
      "Epoka 20420: Loss = 0.000001456\n",
      "Epoka 20430: Loss = 0.000002980\n",
      "Epoka 20440: Loss = 0.000002944\n",
      "Epoka 20450: Loss = 0.000002041\n",
      "Epoka 20460: Loss = 0.000001953\n",
      "Epoka 20470: Loss = 0.000001505\n",
      "Epoka 20480: Loss = 0.000001750\n",
      "Epoka 20490: Loss = 0.000002968\n",
      "Epoka 20500: Loss = 0.000001487\n",
      "Epoka 20510: Loss = 0.000001759\n",
      "Epoka 20520: Loss = 0.000001434\n",
      "Epoka 20530: Loss = 0.000001795\n",
      "Epoka 20540: Loss = 0.000001502\n",
      "Epoka 20550: Loss = 0.000001487\n",
      "Epoka 20560: Loss = 0.000001490\n",
      "Epoka 20570: Loss = 0.000002128\n",
      "Epoka 20580: Loss = 0.000002803\n",
      "Epoka 20590: Loss = 0.000001578\n",
      "Epoka 20600: Loss = 0.000001449\n",
      "Epoka 20610: Loss = 0.000001454\n",
      "Epoka 20620: Loss = 0.000001489\n",
      "Epoka 20630: Loss = 0.000001823\n",
      "Epoka 20640: Loss = 0.000001564\n",
      "Epoka 20650: Loss = 0.000001582\n",
      "Epoka 20660: Loss = 0.000001427\n",
      "Epoka 20670: Loss = 0.000001634\n",
      "Epoka 20680: Loss = 0.000001453\n",
      "Epoka 20690: Loss = 0.000001595\n",
      "Epoka 20700: Loss = 0.000001605\n",
      "Epoka 20710: Loss = 0.000001577\n",
      "Epoka 20720: Loss = 0.000002809\n",
      "Epoka 20730: Loss = 0.000002111\n",
      "Epoka 20740: Loss = 0.000001983\n",
      "Epoka 20750: Loss = 0.000001616\n",
      "Epoka 20760: Loss = 0.000001814\n",
      "Epoka 20770: Loss = 0.000002024\n",
      "Epoka 20780: Loss = 0.000001760\n",
      "Epoka 20790: Loss = 0.000001533\n",
      "Epoka 20800: Loss = 0.000001691\n",
      "Epoka 20810: Loss = 0.000002035\n",
      "Epoka 20820: Loss = 0.000002408\n",
      "Epoka 20830: Loss = 0.000001533\n",
      "Epoka 20840: Loss = 0.000002199\n",
      "Epoka 20850: Loss = 0.000001974\n",
      "Epoka 20860: Loss = 0.000001406\n",
      "Epoka 20870: Loss = 0.000001473\n",
      "Epoka 20880: Loss = 0.000001793\n",
      "Epoka 20890: Loss = 0.000001485\n",
      "Epoka 20900: Loss = 0.000001704\n",
      "Epoka 20910: Loss = 0.000001527\n",
      "Epoka 20920: Loss = 0.000001824\n",
      "Epoka 20930: Loss = 0.000003144\n",
      "Epoka 20940: Loss = 0.000002116\n",
      "Epoka 20950: Loss = 0.000001582\n",
      "Epoka 20960: Loss = 0.000003822\n",
      "Epoka 20970: Loss = 0.000001622\n",
      "Epoka 20980: Loss = 0.000001386\n",
      "Epoka 20990: Loss = 0.000001392\n",
      "Epoka 21000: Loss = 0.000001373\n",
      "Epoka 21010: Loss = 0.000001707\n",
      "Epoka 21020: Loss = 0.000001480\n",
      "Epoka 21030: Loss = 0.000001587\n",
      "Epoka 21040: Loss = 0.000001550\n",
      "Epoka 21050: Loss = 0.000001621\n",
      "Epoka 21060: Loss = 0.000001366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 21070: Loss = 0.000001411\n",
      "Epoka 21080: Loss = 0.000001733\n",
      "Epoka 21090: Loss = 0.000001518\n",
      "Epoka 21100: Loss = 0.000001414\n",
      "Epoka 21110: Loss = 0.000001585\n",
      "Epoka 21120: Loss = 0.000002288\n",
      "Epoka 21130: Loss = 0.000001354\n",
      "Epoka 21140: Loss = 0.000003274\n",
      "Epoka 21150: Loss = 0.000001686\n",
      "Epoka 21160: Loss = 0.000001364\n",
      "Epoka 21170: Loss = 0.000002271\n",
      "Epoka 21180: Loss = 0.000001786\n",
      "Epoka 21190: Loss = 0.000001512\n",
      "Epoka 21200: Loss = 0.000001423\n",
      "Epoka 21210: Loss = 0.000001352\n",
      "Epoka 21220: Loss = 0.000001375\n",
      "Epoka 21230: Loss = 0.000001448\n",
      "Epoka 21240: Loss = 0.000001695\n",
      "Epoka 21250: Loss = 0.000001596\n",
      "Epoka 21260: Loss = 0.000001378\n",
      "Epoka 21270: Loss = 0.000001631\n",
      "Epoka 21280: Loss = 0.000001423\n",
      "Epoka 21290: Loss = 0.000001428\n",
      "Epoka 21300: Loss = 0.000001352\n",
      "Epoka 21310: Loss = 0.000001326\n",
      "Epoka 21320: Loss = 0.000002148\n",
      "Epoka 21330: Loss = 0.000002245\n",
      "Epoka 21340: Loss = 0.000001794\n",
      "Epoka 21350: Loss = 0.000001454\n",
      "Epoka 21360: Loss = 0.000001848\n",
      "Epoka 21370: Loss = 0.000001520\n",
      "Epoka 21380: Loss = 0.000001412\n",
      "Epoka 21390: Loss = 0.000001874\n",
      "Epoka 21400: Loss = 0.000002310\n",
      "Epoka 21410: Loss = 0.000001574\n",
      "Epoka 21420: Loss = 0.000001832\n",
      "Epoka 21430: Loss = 0.000002107\n",
      "Epoka 21440: Loss = 0.000001667\n",
      "Epoka 21450: Loss = 0.000001370\n",
      "Epoka 21460: Loss = 0.000001430\n",
      "Epoka 21470: Loss = 0.000001493\n",
      "Epoka 21480: Loss = 0.000001344\n",
      "Epoka 21490: Loss = 0.000002833\n",
      "Epoka 21500: Loss = 0.000001329\n",
      "Epoka 21510: Loss = 0.000001440\n",
      "Epoka 21520: Loss = 0.000001679\n",
      "Epoka 21530: Loss = 0.000001345\n",
      "Epoka 21540: Loss = 0.000001401\n",
      "Epoka 21550: Loss = 0.000001653\n",
      "Epoka 21560: Loss = 0.000001450\n",
      "Epoka 21570: Loss = 0.000001907\n",
      "Epoka 21580: Loss = 0.000001465\n",
      "Epoka 21590: Loss = 0.000001625\n",
      "Epoka 21600: Loss = 0.000001450\n",
      "Epoka 21610: Loss = 0.000002276\n",
      "Epoka 21620: Loss = 0.000001675\n",
      "Epoka 21630: Loss = 0.000001531\n",
      "Epoka 21640: Loss = 0.000001553\n",
      "Epoka 21650: Loss = 0.000001508\n",
      "Epoka 21660: Loss = 0.000002506\n",
      "Epoka 21670: Loss = 0.000001342\n",
      "Epoka 21680: Loss = 0.000001662\n",
      "Epoka 21690: Loss = 0.000001412\n",
      "Epoka 21700: Loss = 0.000001723\n",
      "Epoka 21710: Loss = 0.000001377\n",
      "Epoka 21720: Loss = 0.000001318\n",
      "Epoka 21730: Loss = 0.000001557\n",
      "Epoka 21740: Loss = 0.000001463\n",
      "Epoka 21750: Loss = 0.000001354\n",
      "Epoka 21760: Loss = 0.000001736\n",
      "Epoka 21770: Loss = 0.000001530\n",
      "Epoka 21780: Loss = 0.000001570\n",
      "Epoka 21790: Loss = 0.000001314\n",
      "Epoka 21800: Loss = 0.000001602\n",
      "Epoka 21810: Loss = 0.000001866\n",
      "Epoka 21820: Loss = 0.000001720\n",
      "Epoka 21830: Loss = 0.000001290\n",
      "Epoka 21840: Loss = 0.000001279\n",
      "Epoka 21850: Loss = 0.000001351\n",
      "Epoka 21860: Loss = 0.000001342\n",
      "Epoka 21870: Loss = 0.000001600\n",
      "Epoka 21880: Loss = 0.000001329\n",
      "Epoka 21890: Loss = 0.000001581\n",
      "Epoka 21900: Loss = 0.000001245\n",
      "Epoka 21910: Loss = 0.000001518\n",
      "Epoka 21920: Loss = 0.000001245\n",
      "Epoka 21930: Loss = 0.000001550\n",
      "Epoka 21940: Loss = 0.000002363\n",
      "Epoka 21950: Loss = 0.000001264\n",
      "Epoka 21960: Loss = 0.000001985\n",
      "Epoka 21970: Loss = 0.000001272\n",
      "Epoka 21980: Loss = 0.000001631\n",
      "Epoka 21990: Loss = 0.000001398\n",
      "Epoka 22000: Loss = 0.000001407\n",
      "Epoka 22010: Loss = 0.000001814\n",
      "Epoka 22020: Loss = 0.000001257\n",
      "Epoka 22030: Loss = 0.000001560\n",
      "Epoka 22040: Loss = 0.000001708\n",
      "Epoka 22050: Loss = 0.000001283\n",
      "Epoka 22060: Loss = 0.000001238\n",
      "Epoka 22070: Loss = 0.000001587\n",
      "Epoka 22080: Loss = 0.000001482\n",
      "Epoka 22090: Loss = 0.000001274\n",
      "Epoka 22100: Loss = 0.000002079\n",
      "Epoka 22110: Loss = 0.000001285\n",
      "Epoka 22120: Loss = 0.000001331\n",
      "Epoka 22130: Loss = 0.000001943\n",
      "Epoka 22140: Loss = 0.000001572\n",
      "Epoka 22150: Loss = 0.000001224\n",
      "Epoka 22160: Loss = 0.000001499\n",
      "Epoka 22170: Loss = 0.000001448\n",
      "Epoka 22180: Loss = 0.000001264\n",
      "Epoka 22190: Loss = 0.000001506\n",
      "Epoka 22200: Loss = 0.000001568\n",
      "Epoka 22210: Loss = 0.000002129\n",
      "Epoka 22220: Loss = 0.000001534\n",
      "Epoka 22230: Loss = 0.000001288\n",
      "Epoka 22240: Loss = 0.000001229\n",
      "Epoka 22250: Loss = 0.000001358\n",
      "Epoka 22260: Loss = 0.000001478\n",
      "Epoka 22270: Loss = 0.000001195\n",
      "Epoka 22280: Loss = 0.000001792\n",
      "Epoka 22290: Loss = 0.000001465\n",
      "Epoka 22300: Loss = 0.000001229\n",
      "Epoka 22310: Loss = 0.000001388\n",
      "Epoka 22320: Loss = 0.000001532\n",
      "Epoka 22330: Loss = 0.000001660\n",
      "Epoka 22340: Loss = 0.000001226\n",
      "Epoka 22350: Loss = 0.000001604\n",
      "Epoka 22360: Loss = 0.000001251\n",
      "Epoka 22370: Loss = 0.000001186\n",
      "Epoka 22380: Loss = 0.000001250\n",
      "Epoka 22390: Loss = 0.000001420\n",
      "Epoka 22400: Loss = 0.000001794\n",
      "Epoka 22410: Loss = 0.000001299\n",
      "Epoka 22420: Loss = 0.000001540\n",
      "Epoka 22430: Loss = 0.000001183\n",
      "Epoka 22440: Loss = 0.000001335\n",
      "Epoka 22450: Loss = 0.000001338\n",
      "Epoka 22460: Loss = 0.000001541\n",
      "Epoka 22470: Loss = 0.000002109\n",
      "Epoka 22480: Loss = 0.000001251\n",
      "Epoka 22490: Loss = 0.000001325\n",
      "Epoka 22500: Loss = 0.000001608\n",
      "Epoka 22510: Loss = 0.000002077\n",
      "Epoka 22520: Loss = 0.000001281\n",
      "Epoka 22530: Loss = 0.000001197\n",
      "Epoka 22540: Loss = 0.000001281\n",
      "Epoka 22550: Loss = 0.000001725\n",
      "Epoka 22560: Loss = 0.000001170\n",
      "Epoka 22570: Loss = 0.000001501\n",
      "Epoka 22580: Loss = 0.000001516\n",
      "Epoka 22590: Loss = 0.000001304\n",
      "Epoka 22600: Loss = 0.000001221\n",
      "Epoka 22610: Loss = 0.000001720\n",
      "Epoka 22620: Loss = 0.000001186\n",
      "Epoka 22630: Loss = 0.000001181\n",
      "Epoka 22640: Loss = 0.000001270\n",
      "Epoka 22650: Loss = 0.000001322\n",
      "Epoka 22660: Loss = 0.000001299\n",
      "Epoka 22670: Loss = 0.000001450\n",
      "Epoka 22680: Loss = 0.000001462\n",
      "Epoka 22690: Loss = 0.000002149\n",
      "Epoka 22700: Loss = 0.000001559\n",
      "Epoka 22710: Loss = 0.000001721\n",
      "Epoka 22720: Loss = 0.000001179\n",
      "Epoka 22730: Loss = 0.000001388\n",
      "Epoka 22740: Loss = 0.000001265\n",
      "Epoka 22750: Loss = 0.000001242\n",
      "Epoka 22760: Loss = 0.000001150\n",
      "Epoka 22770: Loss = 0.000001272\n",
      "Epoka 22780: Loss = 0.000001523\n",
      "Epoka 22790: Loss = 0.000002317\n",
      "Epoka 22800: Loss = 0.000001362\n",
      "Epoka 22810: Loss = 0.000001214\n",
      "Epoka 22820: Loss = 0.000001635\n",
      "Epoka 22830: Loss = 0.000001347\n",
      "Epoka 22840: Loss = 0.000001469\n",
      "Epoka 22850: Loss = 0.000001152\n",
      "Epoka 22860: Loss = 0.000001617\n",
      "Epoka 22870: Loss = 0.000001172\n",
      "Epoka 22880: Loss = 0.000001164\n",
      "Epoka 22890: Loss = 0.000001588\n",
      "Epoka 22900: Loss = 0.000001807\n",
      "Epoka 22910: Loss = 0.000002152\n",
      "Epoka 22920: Loss = 0.000001168\n",
      "Epoka 22930: Loss = 0.000001310\n",
      "Epoka 22940: Loss = 0.000001180\n",
      "Epoka 22950: Loss = 0.000001145\n",
      "Epoka 22960: Loss = 0.000001554\n",
      "Epoka 22970: Loss = 0.000001733\n",
      "Epoka 22980: Loss = 0.000001305\n",
      "Epoka 22990: Loss = 0.000001123\n",
      "Epoka 23000: Loss = 0.000001128\n",
      "Epoka 23010: Loss = 0.000001465\n",
      "Epoka 23020: Loss = 0.000002074\n",
      "Epoka 23030: Loss = 0.000001360\n",
      "Epoka 23040: Loss = 0.000001171\n",
      "Epoka 23050: Loss = 0.000001522\n",
      "Epoka 23060: Loss = 0.000001152\n",
      "Epoka 23070: Loss = 0.000001709\n",
      "Epoka 23080: Loss = 0.000001280\n",
      "Epoka 23090: Loss = 0.000001173\n",
      "Epoka 23100: Loss = 0.000001333\n",
      "Epoka 23110: Loss = 0.000001957\n",
      "Epoka 23120: Loss = 0.000001192\n",
      "Epoka 23130: Loss = 0.000001281\n",
      "Epoka 23140: Loss = 0.000001133\n",
      "Epoka 23150: Loss = 0.000001255\n",
      "Epoka 23160: Loss = 0.000001142\n",
      "Epoka 23170: Loss = 0.000001368\n",
      "Epoka 23180: Loss = 0.000001407\n",
      "Epoka 23190: Loss = 0.000001274\n",
      "Epoka 23200: Loss = 0.000001400\n",
      "Epoka 23210: Loss = 0.000001281\n",
      "Epoka 23220: Loss = 0.000001204\n",
      "Epoka 23230: Loss = 0.000001696\n",
      "Epoka 23240: Loss = 0.000001487\n",
      "Epoka 23250: Loss = 0.000001333\n",
      "Epoka 23260: Loss = 0.000001515\n",
      "Epoka 23270: Loss = 0.000001091\n",
      "Epoka 23280: Loss = 0.000001830\n",
      "Epoka 23290: Loss = 0.000001175\n",
      "Epoka 23300: Loss = 0.000001587\n",
      "Epoka 23310: Loss = 0.000001453\n",
      "Epoka 23320: Loss = 0.000001232\n",
      "Epoka 23330: Loss = 0.000001096\n",
      "Epoka 23340: Loss = 0.000001295\n",
      "Epoka 23350: Loss = 0.000001511\n",
      "Epoka 23360: Loss = 0.000001145\n",
      "Epoka 23370: Loss = 0.000001103\n",
      "Epoka 23380: Loss = 0.000001152\n",
      "Epoka 23390: Loss = 0.000001085\n",
      "Epoka 23400: Loss = 0.000001310\n",
      "Epoka 23410: Loss = 0.000001268\n",
      "Epoka 23420: Loss = 0.000001388\n",
      "Epoka 23430: Loss = 0.000001661\n",
      "Epoka 23440: Loss = 0.000001412\n",
      "Epoka 23450: Loss = 0.000001321\n",
      "Epoka 23460: Loss = 0.000001550\n",
      "Epoka 23470: Loss = 0.000001233\n",
      "Epoka 23480: Loss = 0.000001085\n",
      "Epoka 23490: Loss = 0.000001184\n",
      "Epoka 23500: Loss = 0.000001093\n",
      "Epoka 23510: Loss = 0.000001108\n",
      "Epoka 23520: Loss = 0.000001096\n",
      "Epoka 23530: Loss = 0.000001289\n",
      "Epoka 23540: Loss = 0.000001357\n",
      "Epoka 23550: Loss = 0.000001253\n",
      "Epoka 23560: Loss = 0.000001134\n",
      "Epoka 23570: Loss = 0.000001405\n",
      "Epoka 23580: Loss = 0.000001142\n",
      "Epoka 23590: Loss = 0.000001126\n",
      "Epoka 23600: Loss = 0.000001348\n",
      "Epoka 23610: Loss = 0.000001522\n",
      "Epoka 23620: Loss = 0.000001206\n",
      "Epoka 23630: Loss = 0.000001217\n",
      "Epoka 23640: Loss = 0.000001092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 23650: Loss = 0.000001391\n",
      "Epoka 23660: Loss = 0.000001080\n",
      "Epoka 23670: Loss = 0.000001231\n",
      "Epoka 23680: Loss = 0.000001100\n",
      "Epoka 23690: Loss = 0.000001364\n",
      "Epoka 23700: Loss = 0.000002230\n",
      "Epoka 23710: Loss = 0.000001044\n",
      "Epoka 23720: Loss = 0.000001140\n",
      "Epoka 23730: Loss = 0.000001152\n",
      "Epoka 23740: Loss = 0.000001300\n",
      "Epoka 23750: Loss = 0.000001290\n",
      "Epoka 23760: Loss = 0.000001108\n",
      "Epoka 23770: Loss = 0.000001331\n",
      "Epoka 23780: Loss = 0.000001257\n",
      "Epoka 23790: Loss = 0.000001295\n",
      "Epoka 23800: Loss = 0.000001270\n",
      "Epoka 23810: Loss = 0.000001044\n",
      "Epoka 23820: Loss = 0.000001166\n",
      "Epoka 23830: Loss = 0.000001138\n",
      "Epoka 23840: Loss = 0.000001131\n",
      "Epoka 23850: Loss = 0.000001289\n",
      "Epoka 23860: Loss = 0.000001175\n",
      "Epoka 23870: Loss = 0.000001084\n",
      "Epoka 23880: Loss = 0.000001225\n",
      "Epoka 23890: Loss = 0.000001048\n",
      "Epoka 23900: Loss = 0.000001059\n",
      "Epoka 23910: Loss = 0.000001384\n",
      "Epoka 23920: Loss = 0.000001204\n",
      "Epoka 23930: Loss = 0.000001479\n",
      "Epoka 23940: Loss = 0.000001599\n",
      "Epoka 23950: Loss = 0.000001172\n",
      "Epoka 23960: Loss = 0.000001137\n",
      "Epoka 23970: Loss = 0.000001684\n",
      "Epoka 23980: Loss = 0.000001393\n",
      "Epoka 23990: Loss = 0.000001052\n",
      "Epoka 24000: Loss = 0.000002203\n",
      "Epoka 24010: Loss = 0.000001504\n",
      "Epoka 24020: Loss = 0.000001248\n",
      "Epoka 24030: Loss = 0.000001074\n",
      "Epoka 24040: Loss = 0.000001617\n",
      "Epoka 24050: Loss = 0.000001728\n",
      "Epoka 24060: Loss = 0.000001304\n",
      "Epoka 24070: Loss = 0.000001090\n",
      "Epoka 24080: Loss = 0.000001202\n",
      "Epoka 24090: Loss = 0.000001026\n",
      "Epoka 24100: Loss = 0.000001331\n",
      "Epoka 24110: Loss = 0.000001627\n",
      "Epoka 24120: Loss = 0.000001012\n",
      "Epoka 24130: Loss = 0.000001249\n",
      "Epoka 24140: Loss = 0.000001073\n",
      "Epoka 24150: Loss = 0.000001040\n",
      "Epoka 24160: Loss = 0.000001122\n",
      "Epoka 24170: Loss = 0.000001115\n",
      "Epoka 24180: Loss = 0.000001425\n",
      "Epoka 24190: Loss = 0.000001033\n",
      "Epoka 24200: Loss = 0.000001045\n",
      "Epoka 24210: Loss = 0.000001149\n",
      "Epoka 24220: Loss = 0.000001286\n",
      "Epoka 24230: Loss = 0.000001275\n",
      "Epoka 24240: Loss = 0.000001046\n",
      "Epoka 24250: Loss = 0.000001239\n",
      "Epoka 24260: Loss = 0.000001410\n",
      "Epoka 24270: Loss = 0.000001056\n",
      "Epoka 24280: Loss = 0.000001102\n",
      "Epoka 24290: Loss = 0.000001199\n",
      "Epoka 24300: Loss = 0.000001057\n",
      "Epoka 24310: Loss = 0.000001313\n",
      "Epoka 24320: Loss = 0.000001594\n",
      "Epoka 24330: Loss = 0.000001356\n",
      "Epoka 24340: Loss = 0.000001007\n",
      "Epoka 24350: Loss = 0.000001070\n",
      "Epoka 24360: Loss = 0.000001653\n",
      "Epoka 24370: Loss = 0.000000996\n",
      "Epoka 24380: Loss = 0.000001643\n",
      "Epoka 24390: Loss = 0.000001107\n",
      "Epoka 24400: Loss = 0.000001047\n",
      "Epoka 24410: Loss = 0.000001022\n",
      "Epoka 24420: Loss = 0.000001107\n",
      "Epoka 24430: Loss = 0.000001618\n",
      "Epoka 24440: Loss = 0.000001283\n",
      "Epoka 24450: Loss = 0.000000992\n",
      "Epoka 24460: Loss = 0.000001072\n",
      "Epoka 24470: Loss = 0.000001178\n",
      "Epoka 24480: Loss = 0.000001120\n",
      "Epoka 24490: Loss = 0.000001396\n",
      "Epoka 24500: Loss = 0.000001104\n",
      "Epoka 24510: Loss = 0.000001097\n",
      "Epoka 24520: Loss = 0.000001001\n",
      "Epoka 24530: Loss = 0.000001040\n",
      "Epoka 24540: Loss = 0.000001179\n",
      "Epoka 24550: Loss = 0.000001755\n",
      "Epoka 24560: Loss = 0.000000983\n",
      "Epoka 24570: Loss = 0.000001662\n",
      "Epoka 24580: Loss = 0.000001041\n",
      "Epoka 24590: Loss = 0.000001002\n",
      "Epoka 24600: Loss = 0.000001518\n",
      "Epoka 24610: Loss = 0.000001327\n",
      "Epoka 24620: Loss = 0.000001123\n",
      "Epoka 24630: Loss = 0.000001284\n",
      "Epoka 24640: Loss = 0.000001045\n",
      "Epoka 24650: Loss = 0.000001094\n",
      "Epoka 24660: Loss = 0.000001600\n",
      "Epoka 24670: Loss = 0.000001103\n",
      "Epoka 24680: Loss = 0.000000988\n",
      "Epoka 24690: Loss = 0.000003080\n",
      "Epoka 24700: Loss = 0.000001406\n",
      "Epoka 24710: Loss = 0.000001145\n",
      "Epoka 24720: Loss = 0.000001011\n",
      "Epoka 24730: Loss = 0.000000978\n",
      "Epoka 24740: Loss = 0.000001156\n",
      "Epoka 24750: Loss = 0.000001079\n",
      "Epoka 24760: Loss = 0.000001440\n",
      "Epoka 24770: Loss = 0.000002639\n",
      "Epoka 24780: Loss = 0.000001050\n",
      "Epoka 24790: Loss = 0.000000950\n",
      "Epoka 24800: Loss = 0.000001351\n",
      "Epoka 24810: Loss = 0.000002350\n",
      "Epoka 24820: Loss = 0.000000984\n",
      "Epoka 24830: Loss = 0.000001068\n",
      "Epoka 24840: Loss = 0.000001026\n",
      "Epoka 24850: Loss = 0.000001452\n",
      "Epoka 24860: Loss = 0.000000966\n",
      "Epoka 24870: Loss = 0.000001306\n",
      "Epoka 24880: Loss = 0.000001128\n",
      "Epoka 24890: Loss = 0.000001145\n",
      "Epoka 24900: Loss = 0.000001237\n",
      "Epoka 24910: Loss = 0.000000946\n",
      "Epoka 24920: Loss = 0.000001029\n",
      "Epoka 24930: Loss = 0.000000998\n",
      "Epoka 24940: Loss = 0.000001044\n",
      "Epoka 24950: Loss = 0.000003084\n",
      "Epoka 24960: Loss = 0.000001383\n",
      "Epoka 24970: Loss = 0.000001298\n",
      "Epoka 24980: Loss = 0.000001281\n",
      "Epoka 24990: Loss = 0.000000943\n",
      "Epoka 25000: Loss = 0.000000931\n",
      "Epoka 25010: Loss = 0.000000936\n",
      "Epoka 25020: Loss = 0.000001291\n",
      "Epoka 25030: Loss = 0.000001674\n",
      "Epoka 25040: Loss = 0.000000949\n",
      "Epoka 25050: Loss = 0.000000988\n",
      "Epoka 25060: Loss = 0.000001264\n",
      "Epoka 25070: Loss = 0.000001191\n",
      "Epoka 25080: Loss = 0.000001048\n",
      "Epoka 25090: Loss = 0.000001312\n",
      "Epoka 25100: Loss = 0.000001038\n",
      "Epoka 25110: Loss = 0.000001026\n",
      "Epoka 25120: Loss = 0.000001312\n",
      "Epoka 25130: Loss = 0.000000957\n",
      "Epoka 25140: Loss = 0.000000930\n",
      "Epoka 25150: Loss = 0.000001114\n",
      "Epoka 25160: Loss = 0.000001009\n",
      "Epoka 25170: Loss = 0.000001914\n",
      "Epoka 25180: Loss = 0.000000952\n",
      "Epoka 25190: Loss = 0.000001016\n",
      "Epoka 25200: Loss = 0.000001257\n",
      "Epoka 25210: Loss = 0.000001483\n",
      "Epoka 25220: Loss = 0.000000939\n",
      "Epoka 25230: Loss = 0.000001277\n",
      "Epoka 25240: Loss = 0.000000924\n",
      "Epoka 25250: Loss = 0.000001827\n",
      "Epoka 25260: Loss = 0.000000929\n",
      "Epoka 25270: Loss = 0.000001150\n",
      "Epoka 25280: Loss = 0.000001006\n",
      "Epoka 25290: Loss = 0.000001139\n",
      "Epoka 25300: Loss = 0.000000932\n",
      "Epoka 25310: Loss = 0.000001053\n",
      "Epoka 25320: Loss = 0.000001608\n",
      "Epoka 25330: Loss = 0.000000920\n",
      "Epoka 25340: Loss = 0.000000958\n",
      "Epoka 25350: Loss = 0.000001100\n",
      "Epoka 25360: Loss = 0.000001214\n",
      "Epoka 25370: Loss = 0.000001179\n",
      "Epoka 25380: Loss = 0.000000960\n",
      "Epoka 25390: Loss = 0.000000912\n",
      "Epoka 25400: Loss = 0.000001567\n",
      "Epoka 25410: Loss = 0.000000991\n",
      "Epoka 25420: Loss = 0.000001462\n",
      "Epoka 25430: Loss = 0.000001063\n",
      "Epoka 25440: Loss = 0.000001954\n",
      "Epoka 25450: Loss = 0.000002296\n",
      "Epoka 25460: Loss = 0.000001383\n",
      "Epoka 25470: Loss = 0.000000987\n",
      "Epoka 25480: Loss = 0.000000990\n",
      "Epoka 25490: Loss = 0.000001086\n",
      "Epoka 25500: Loss = 0.000001324\n",
      "Epoka 25510: Loss = 0.000000917\n",
      "Epoka 25520: Loss = 0.000000932\n",
      "Epoka 25530: Loss = 0.000000991\n",
      "Epoka 25540: Loss = 0.000001070\n",
      "Epoka 25550: Loss = 0.000000891\n",
      "Epoka 25560: Loss = 0.000001136\n",
      "Epoka 25570: Loss = 0.000000950\n",
      "Epoka 25580: Loss = 0.000001027\n",
      "Epoka 25590: Loss = 0.000001412\n",
      "Epoka 25600: Loss = 0.000001901\n",
      "Epoka 25610: Loss = 0.000001226\n",
      "Epoka 25620: Loss = 0.000001126\n",
      "Epoka 25630: Loss = 0.000001280\n",
      "Epoka 25640: Loss = 0.000000953\n",
      "Epoka 25650: Loss = 0.000001133\n",
      "Epoka 25660: Loss = 0.000001034\n",
      "Epoka 25670: Loss = 0.000001209\n",
      "Epoka 25680: Loss = 0.000001164\n",
      "Epoka 25690: Loss = 0.000000960\n",
      "Epoka 25700: Loss = 0.000001172\n",
      "Epoka 25710: Loss = 0.000000884\n",
      "Epoka 25720: Loss = 0.000000994\n",
      "Epoka 25730: Loss = 0.000001303\n",
      "Epoka 25740: Loss = 0.000001050\n",
      "Epoka 25750: Loss = 0.000000979\n",
      "Epoka 25760: Loss = 0.000000916\n",
      "Epoka 25770: Loss = 0.000000924\n",
      "Epoka 25780: Loss = 0.000000884\n",
      "Epoka 25790: Loss = 0.000001089\n",
      "Epoka 25800: Loss = 0.000002095\n",
      "Epoka 25810: Loss = 0.000000881\n",
      "Epoka 25820: Loss = 0.000000953\n",
      "Epoka 25830: Loss = 0.000001715\n",
      "Epoka 25840: Loss = 0.000000876\n",
      "Epoka 25850: Loss = 0.000001302\n",
      "Epoka 25860: Loss = 0.000000910\n",
      "Epoka 25870: Loss = 0.000001581\n",
      "Epoka 25880: Loss = 0.000001266\n",
      "Epoka 25890: Loss = 0.000001338\n",
      "Epoka 25900: Loss = 0.000000862\n",
      "Epoka 25910: Loss = 0.000000867\n",
      "Epoka 25920: Loss = 0.000000872\n",
      "Epoka 25930: Loss = 0.000000906\n",
      "Epoka 25940: Loss = 0.000000860\n",
      "Epoka 25950: Loss = 0.000001416\n",
      "Epoka 25960: Loss = 0.000000936\n",
      "Epoka 25970: Loss = 0.000001021\n",
      "Epoka 25980: Loss = 0.000000949\n",
      "Epoka 25990: Loss = 0.000001024\n",
      "Epoka 26000: Loss = 0.000001205\n",
      "Epoka 26010: Loss = 0.000000948\n",
      "Epoka 26020: Loss = 0.000001126\n",
      "Epoka 26030: Loss = 0.000000932\n",
      "Epoka 26040: Loss = 0.000000986\n",
      "Epoka 26050: Loss = 0.000001071\n",
      "Epoka 26060: Loss = 0.000001617\n",
      "Epoka 26070: Loss = 0.000000916\n",
      "Epoka 26080: Loss = 0.000001054\n",
      "Epoka 26090: Loss = 0.000001023\n",
      "Epoka 26100: Loss = 0.000001089\n",
      "Epoka 26110: Loss = 0.000000898\n",
      "Epoka 26120: Loss = 0.000001045\n",
      "Epoka 26130: Loss = 0.000000869\n",
      "Epoka 26140: Loss = 0.000000868\n",
      "Epoka 26150: Loss = 0.000000941\n",
      "Epoka 26160: Loss = 0.000001006\n",
      "Epoka 26170: Loss = 0.000001379\n",
      "Epoka 26180: Loss = 0.000001864\n",
      "Epoka 26190: Loss = 0.000001016\n",
      "Epoka 26200: Loss = 0.000000878\n",
      "Epoka 26210: Loss = 0.000000896\n",
      "Epoka 26220: Loss = 0.000001023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 26230: Loss = 0.000000866\n",
      "Epoka 26240: Loss = 0.000001167\n",
      "Epoka 26250: Loss = 0.000001100\n",
      "Epoka 26260: Loss = 0.000001077\n",
      "Epoka 26270: Loss = 0.000001636\n",
      "Epoka 26280: Loss = 0.000000981\n",
      "Epoka 26290: Loss = 0.000001882\n",
      "Epoka 26300: Loss = 0.000001371\n",
      "Epoka 26310: Loss = 0.000000861\n",
      "Epoka 26320: Loss = 0.000001041\n",
      "Epoka 26330: Loss = 0.000000924\n",
      "Epoka 26340: Loss = 0.000000832\n",
      "Epoka 26350: Loss = 0.000001205\n",
      "Epoka 26360: Loss = 0.000000957\n",
      "Epoka 26370: Loss = 0.000000867\n",
      "Epoka 26380: Loss = 0.000001024\n",
      "Epoka 26390: Loss = 0.000001264\n",
      "Epoka 26400: Loss = 0.000001113\n",
      "Epoka 26410: Loss = 0.000001266\n",
      "Epoka 26420: Loss = 0.000000970\n",
      "Epoka 26430: Loss = 0.000001268\n",
      "Epoka 26440: Loss = 0.000000857\n",
      "Epoka 26450: Loss = 0.000000931\n",
      "Epoka 26460: Loss = 0.000001153\n",
      "Epoka 26470: Loss = 0.000000833\n",
      "Epoka 26480: Loss = 0.000000897\n",
      "Epoka 26490: Loss = 0.000000933\n",
      "Epoka 26500: Loss = 0.000001003\n",
      "Epoka 26510: Loss = 0.000002934\n",
      "Epoka 26520: Loss = 0.000001637\n",
      "Epoka 26530: Loss = 0.000000863\n",
      "Epoka 26540: Loss = 0.000001190\n",
      "Epoka 26550: Loss = 0.000002108\n",
      "Epoka 26560: Loss = 0.000000891\n",
      "Epoka 26570: Loss = 0.000001000\n",
      "Epoka 26580: Loss = 0.000001177\n",
      "Epoka 26590: Loss = 0.000000833\n",
      "Epoka 26600: Loss = 0.000001024\n",
      "Epoka 26610: Loss = 0.000001197\n",
      "Epoka 26620: Loss = 0.000001042\n",
      "Epoka 26630: Loss = 0.000001153\n",
      "Epoka 26640: Loss = 0.000001528\n",
      "Epoka 26650: Loss = 0.000001102\n",
      "Epoka 26660: Loss = 0.000000895\n",
      "Epoka 26670: Loss = 0.000000838\n",
      "Epoka 26680: Loss = 0.000000955\n",
      "Epoka 26690: Loss = 0.000001063\n",
      "Epoka 26700: Loss = 0.000001006\n",
      "Epoka 26710: Loss = 0.000000893\n",
      "Epoka 26720: Loss = 0.000000879\n",
      "Epoka 26730: Loss = 0.000001025\n",
      "Epoka 26740: Loss = 0.000001101\n",
      "Epoka 26750: Loss = 0.000000840\n",
      "Epoka 26760: Loss = 0.000001099\n",
      "Epoka 26770: Loss = 0.000000921\n",
      "Epoka 26780: Loss = 0.000000922\n",
      "Epoka 26790: Loss = 0.000000809\n",
      "Epoka 26800: Loss = 0.000001411\n",
      "Epoka 26810: Loss = 0.000001213\n",
      "Epoka 26820: Loss = 0.000001132\n",
      "Epoka 26830: Loss = 0.000000827\n",
      "Epoka 26840: Loss = 0.000000886\n",
      "Epoka 26850: Loss = 0.000001201\n",
      "Epoka 26860: Loss = 0.000001604\n",
      "Epoka 26870: Loss = 0.000000880\n",
      "Epoka 26880: Loss = 0.000000864\n",
      "Epoka 26890: Loss = 0.000000817\n",
      "Epoka 26900: Loss = 0.000000944\n",
      "Epoka 26910: Loss = 0.000000810\n",
      "Epoka 26920: Loss = 0.000000874\n",
      "Epoka 26930: Loss = 0.000001136\n",
      "Epoka 26940: Loss = 0.000000846\n",
      "Epoka 26950: Loss = 0.000000885\n",
      "Epoka 26960: Loss = 0.000000855\n",
      "Epoka 26970: Loss = 0.000000960\n",
      "Epoka 26980: Loss = 0.000000838\n",
      "Epoka 26990: Loss = 0.000000810\n",
      "Epoka 27000: Loss = 0.000000882\n",
      "Epoka 27010: Loss = 0.000001007\n",
      "Epoka 27020: Loss = 0.000001069\n",
      "Epoka 27030: Loss = 0.000000858\n",
      "Epoka 27040: Loss = 0.000000824\n",
      "Epoka 27050: Loss = 0.000000884\n",
      "Epoka 27060: Loss = 0.000000836\n",
      "Epoka 27070: Loss = 0.000001123\n",
      "Epoka 27080: Loss = 0.000000849\n",
      "Epoka 27090: Loss = 0.000000824\n",
      "Epoka 27100: Loss = 0.000000806\n",
      "Epoka 27110: Loss = 0.000000791\n",
      "Epoka 27120: Loss = 0.000001027\n",
      "Epoka 27130: Loss = 0.000000866\n",
      "Epoka 27140: Loss = 0.000000936\n",
      "Epoka 27150: Loss = 0.000001730\n",
      "Epoka 27160: Loss = 0.000001014\n",
      "Epoka 27170: Loss = 0.000001426\n",
      "Epoka 27180: Loss = 0.000000856\n",
      "Epoka 27190: Loss = 0.000001065\n",
      "Epoka 27200: Loss = 0.000001165\n",
      "Epoka 27210: Loss = 0.000000908\n",
      "Epoka 27220: Loss = 0.000001212\n",
      "Epoka 27230: Loss = 0.000000917\n",
      "Epoka 27240: Loss = 0.000001186\n",
      "Epoka 27250: Loss = 0.000000772\n",
      "Epoka 27260: Loss = 0.000002007\n",
      "Epoka 27270: Loss = 0.000000892\n",
      "Epoka 27280: Loss = 0.000001055\n",
      "Epoka 27290: Loss = 0.000000962\n",
      "Epoka 27300: Loss = 0.000001104\n",
      "Epoka 27310: Loss = 0.000000861\n",
      "Epoka 27320: Loss = 0.000001619\n",
      "Epoka 27330: Loss = 0.000002184\n",
      "Epoka 27340: Loss = 0.000001279\n",
      "Epoka 27350: Loss = 0.000000880\n",
      "Epoka 27360: Loss = 0.000000811\n",
      "Epoka 27370: Loss = 0.000000954\n",
      "Epoka 27380: Loss = 0.000000973\n",
      "Epoka 27390: Loss = 0.000001061\n",
      "Epoka 27400: Loss = 0.000000779\n",
      "Epoka 27410: Loss = 0.000001087\n",
      "Epoka 27420: Loss = 0.000000915\n",
      "Epoka 27430: Loss = 0.000001574\n",
      "Epoka 27440: Loss = 0.000001985\n",
      "Epoka 27450: Loss = 0.000000902\n",
      "Epoka 27460: Loss = 0.000001231\n",
      "Epoka 27470: Loss = 0.000001042\n",
      "Epoka 27480: Loss = 0.000000920\n",
      "Epoka 27490: Loss = 0.000001538\n",
      "Epoka 27500: Loss = 0.000000764\n",
      "Epoka 27510: Loss = 0.000000776\n",
      "Epoka 27520: Loss = 0.000000927\n",
      "Epoka 27530: Loss = 0.000000917\n",
      "Epoka 27540: Loss = 0.000000948\n",
      "Epoka 27550: Loss = 0.000000992\n",
      "Epoka 27560: Loss = 0.000001010\n",
      "Epoka 27570: Loss = 0.000001310\n",
      "Epoka 27580: Loss = 0.000001070\n",
      "Epoka 27590: Loss = 0.000000979\n",
      "Epoka 27600: Loss = 0.000001176\n",
      "Epoka 27610: Loss = 0.000000882\n",
      "Epoka 27620: Loss = 0.000000759\n",
      "Epoka 27630: Loss = 0.000000854\n",
      "Epoka 27640: Loss = 0.000001522\n",
      "Epoka 27650: Loss = 0.000000812\n",
      "Epoka 27660: Loss = 0.000000893\n",
      "Epoka 27670: Loss = 0.000000851\n",
      "Epoka 27680: Loss = 0.000000775\n",
      "Epoka 27690: Loss = 0.000000816\n",
      "Epoka 27700: Loss = 0.000000770\n",
      "Epoka 27710: Loss = 0.000001030\n",
      "Epoka 27720: Loss = 0.000001137\n",
      "Epoka 27730: Loss = 0.000000827\n",
      "Epoka 27740: Loss = 0.000000813\n",
      "Epoka 27750: Loss = 0.000000881\n",
      "Epoka 27760: Loss = 0.000000902\n",
      "Epoka 27770: Loss = 0.000001168\n",
      "Epoka 27780: Loss = 0.000001109\n",
      "Epoka 27790: Loss = 0.000000986\n",
      "Epoka 27800: Loss = 0.000000894\n",
      "Epoka 27810: Loss = 0.000001096\n",
      "Epoka 27820: Loss = 0.000000946\n",
      "Epoka 27830: Loss = 0.000001409\n",
      "Epoka 27840: Loss = 0.000001022\n",
      "Epoka 27850: Loss = 0.000000841\n",
      "Epoka 27860: Loss = 0.000000935\n",
      "Epoka 27870: Loss = 0.000001013\n",
      "Epoka 27880: Loss = 0.000000842\n",
      "Epoka 27890: Loss = 0.000001757\n",
      "Epoka 27900: Loss = 0.000000778\n",
      "Epoka 27910: Loss = 0.000001072\n",
      "Epoka 27920: Loss = 0.000000832\n",
      "Epoka 27930: Loss = 0.000000964\n",
      "Epoka 27940: Loss = 0.000001389\n",
      "Epoka 27950: Loss = 0.000001062\n",
      "Epoka 27960: Loss = 0.000000736\n",
      "Epoka 27970: Loss = 0.000000732\n",
      "Epoka 27980: Loss = 0.000000742\n",
      "Epoka 27990: Loss = 0.000000937\n",
      "Epoka 28000: Loss = 0.000000767\n",
      "Epoka 28010: Loss = 0.000000844\n",
      "Epoka 28020: Loss = 0.000000973\n",
      "Epoka 28030: Loss = 0.000001066\n",
      "Epoka 28040: Loss = 0.000000736\n",
      "Epoka 28050: Loss = 0.000001722\n",
      "Epoka 28060: Loss = 0.000000808\n",
      "Epoka 28070: Loss = 0.000001383\n",
      "Epoka 28080: Loss = 0.000000952\n",
      "Epoka 28090: Loss = 0.000000745\n",
      "Epoka 28100: Loss = 0.000000812\n",
      "Epoka 28110: Loss = 0.000001244\n",
      "Epoka 28120: Loss = 0.000000757\n",
      "Epoka 28130: Loss = 0.000000843\n",
      "Epoka 28140: Loss = 0.000000828\n",
      "Epoka 28150: Loss = 0.000001217\n",
      "Epoka 28160: Loss = 0.000000893\n",
      "Epoka 28170: Loss = 0.000001371\n",
      "Epoka 28180: Loss = 0.000001027\n",
      "Epoka 28190: Loss = 0.000000875\n",
      "Epoka 28200: Loss = 0.000000761\n",
      "Epoka 28210: Loss = 0.000000794\n",
      "Epoka 28220: Loss = 0.000000847\n",
      "Epoka 28230: Loss = 0.000000810\n",
      "Epoka 28240: Loss = 0.000000873\n",
      "Epoka 28250: Loss = 0.000000808\n",
      "Epoka 28260: Loss = 0.000000736\n",
      "Epoka 28270: Loss = 0.000001866\n",
      "Epoka 28280: Loss = 0.000002763\n",
      "Epoka 28290: Loss = 0.000000903\n",
      "Epoka 28300: Loss = 0.000000794\n",
      "Epoka 28310: Loss = 0.000000757\n",
      "Epoka 28320: Loss = 0.000000792\n",
      "Epoka 28330: Loss = 0.000001410\n",
      "Epoka 28340: Loss = 0.000000710\n",
      "Epoka 28350: Loss = 0.000000732\n",
      "Epoka 28360: Loss = 0.000001123\n",
      "Epoka 28370: Loss = 0.000000921\n",
      "Epoka 28380: Loss = 0.000001357\n",
      "Epoka 28390: Loss = 0.000000706\n",
      "Epoka 28400: Loss = 0.000000734\n",
      "Epoka 28410: Loss = 0.000000989\n",
      "Epoka 28420: Loss = 0.000001267\n",
      "Epoka 28430: Loss = 0.000000897\n",
      "Epoka 28440: Loss = 0.000000909\n",
      "Epoka 28450: Loss = 0.000000791\n",
      "Epoka 28460: Loss = 0.000002130\n",
      "Epoka 28470: Loss = 0.000000737\n",
      "Epoka 28480: Loss = 0.000000747\n",
      "Epoka 28490: Loss = 0.000000938\n",
      "Epoka 28500: Loss = 0.000000807\n",
      "Epoka 28510: Loss = 0.000000829\n",
      "Epoka 28520: Loss = 0.000000717\n",
      "Epoka 28530: Loss = 0.000000705\n",
      "Epoka 28540: Loss = 0.000000807\n",
      "Epoka 28550: Loss = 0.000001353\n",
      "Epoka 28560: Loss = 0.000000830\n",
      "Epoka 28570: Loss = 0.000001663\n",
      "Epoka 28580: Loss = 0.000000724\n",
      "Epoka 28590: Loss = 0.000001115\n",
      "Epoka 28600: Loss = 0.000000708\n",
      "Epoka 28610: Loss = 0.000000704\n",
      "Epoka 28620: Loss = 0.000001622\n",
      "Epoka 28630: Loss = 0.000000856\n",
      "Epoka 28640: Loss = 0.000000982\n",
      "Epoka 28650: Loss = 0.000001228\n",
      "Epoka 28660: Loss = 0.000000714\n",
      "Epoka 28670: Loss = 0.000000727\n",
      "Epoka 28680: Loss = 0.000001150\n",
      "Epoka 28690: Loss = 0.000001793\n",
      "Epoka 28700: Loss = 0.000000731\n",
      "Epoka 28710: Loss = 0.000001341\n",
      "Epoka 28720: Loss = 0.000000817\n",
      "Epoka 28730: Loss = 0.000000732\n",
      "Epoka 28740: Loss = 0.000000776\n",
      "Epoka 28750: Loss = 0.000000835\n",
      "Epoka 28760: Loss = 0.000000730\n",
      "Epoka 28770: Loss = 0.000000741\n",
      "Epoka 28780: Loss = 0.000000726\n",
      "Epoka 28790: Loss = 0.000000782\n",
      "Epoka 28800: Loss = 0.000000979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 28810: Loss = 0.000001120\n",
      "Epoka 28820: Loss = 0.000001020\n",
      "Epoka 28830: Loss = 0.000001701\n",
      "Epoka 28840: Loss = 0.000000768\n",
      "Epoka 28850: Loss = 0.000000756\n",
      "Epoka 28860: Loss = 0.000000946\n",
      "Epoka 28870: Loss = 0.000000752\n",
      "Epoka 28880: Loss = 0.000001291\n",
      "Epoka 28890: Loss = 0.000001137\n",
      "Epoka 28900: Loss = 0.000000975\n",
      "Epoka 28910: Loss = 0.000000929\n",
      "Epoka 28920: Loss = 0.000000894\n",
      "Epoka 28930: Loss = 0.000001233\n",
      "Epoka 28940: Loss = 0.000000766\n",
      "Epoka 28950: Loss = 0.000000682\n",
      "Epoka 28960: Loss = 0.000000736\n",
      "Epoka 28970: Loss = 0.000001016\n",
      "Epoka 28980: Loss = 0.000000692\n",
      "Epoka 28990: Loss = 0.000000699\n",
      "Epoka 29000: Loss = 0.000000714\n",
      "Epoka 29010: Loss = 0.000000738\n",
      "Epoka 29020: Loss = 0.000000777\n",
      "Epoka 29030: Loss = 0.000000681\n",
      "Epoka 29040: Loss = 0.000000693\n",
      "Epoka 29050: Loss = 0.000001211\n",
      "Epoka 29060: Loss = 0.000000945\n",
      "Epoka 29070: Loss = 0.000001872\n",
      "Epoka 29080: Loss = 0.000000687\n",
      "Epoka 29090: Loss = 0.000001283\n",
      "Epoka 29100: Loss = 0.000000839\n",
      "Epoka 29110: Loss = 0.000000790\n",
      "Epoka 29120: Loss = 0.000001199\n",
      "Epoka 29130: Loss = 0.000001122\n",
      "Epoka 29140: Loss = 0.000001293\n",
      "Epoka 29150: Loss = 0.000000689\n",
      "Epoka 29160: Loss = 0.000000996\n",
      "Epoka 29170: Loss = 0.000002401\n",
      "Epoka 29180: Loss = 0.000000924\n",
      "Epoka 29190: Loss = 0.000000798\n",
      "Epoka 29200: Loss = 0.000000849\n",
      "Epoka 29210: Loss = 0.000000817\n",
      "Epoka 29220: Loss = 0.000000733\n",
      "Epoka 29230: Loss = 0.000001503\n",
      "Epoka 29240: Loss = 0.000000937\n",
      "Epoka 29250: Loss = 0.000001406\n",
      "Epoka 29260: Loss = 0.000000695\n",
      "Epoka 29270: Loss = 0.000000748\n",
      "Epoka 29280: Loss = 0.000000881\n",
      "Epoka 29290: Loss = 0.000001052\n",
      "Epoka 29300: Loss = 0.000000676\n",
      "Epoka 29310: Loss = 0.000000831\n",
      "Epoka 29320: Loss = 0.000000708\n",
      "Epoka 29330: Loss = 0.000000702\n",
      "Epoka 29340: Loss = 0.000000851\n",
      "Epoka 29350: Loss = 0.000001032\n",
      "Epoka 29360: Loss = 0.000000706\n",
      "Epoka 29370: Loss = 0.000001346\n",
      "Epoka 29380: Loss = 0.000001028\n",
      "Epoka 29390: Loss = 0.000000794\n",
      "Epoka 29400: Loss = 0.000000684\n",
      "Epoka 29410: Loss = 0.000000720\n",
      "Epoka 29420: Loss = 0.000000709\n",
      "Epoka 29430: Loss = 0.000000964\n",
      "Epoka 29440: Loss = 0.000000983\n",
      "Epoka 29450: Loss = 0.000000833\n",
      "Epoka 29460: Loss = 0.000001126\n",
      "Epoka 29470: Loss = 0.000001023\n",
      "Epoka 29480: Loss = 0.000000762\n",
      "Epoka 29490: Loss = 0.000000662\n",
      "Epoka 29500: Loss = 0.000000723\n",
      "Epoka 29510: Loss = 0.000000687\n",
      "Epoka 29520: Loss = 0.000001044\n",
      "Epoka 29530: Loss = 0.000000939\n",
      "Epoka 29540: Loss = 0.000000666\n",
      "Epoka 29550: Loss = 0.000000833\n",
      "Epoka 29560: Loss = 0.000000691\n",
      "Epoka 29570: Loss = 0.000000766\n",
      "Epoka 29580: Loss = 0.000000723\n",
      "Epoka 29590: Loss = 0.000000740\n",
      "Epoka 29600: Loss = 0.000000979\n",
      "Epoka 29610: Loss = 0.000000679\n",
      "Epoka 29620: Loss = 0.000000720\n",
      "Epoka 29630: Loss = 0.000000822\n",
      "Epoka 29640: Loss = 0.000000835\n",
      "Epoka 29650: Loss = 0.000000712\n",
      "Epoka 29660: Loss = 0.000000956\n",
      "Epoka 29670: Loss = 0.000000737\n",
      "Epoka 29680: Loss = 0.000000844\n",
      "Epoka 29690: Loss = 0.000000765\n",
      "Epoka 29700: Loss = 0.000000708\n",
      "Epoka 29710: Loss = 0.000001067\n",
      "Epoka 29720: Loss = 0.000001331\n",
      "Epoka 29730: Loss = 0.000000750\n",
      "Epoka 29740: Loss = 0.000000706\n",
      "Epoka 29750: Loss = 0.000000961\n",
      "Epoka 29760: Loss = 0.000001022\n",
      "Epoka 29770: Loss = 0.000000944\n",
      "Epoka 29780: Loss = 0.000000768\n",
      "Epoka 29790: Loss = 0.000000667\n",
      "Epoka 29800: Loss = 0.000000866\n",
      "Epoka 29810: Loss = 0.000000757\n",
      "Epoka 29820: Loss = 0.000000681\n",
      "Epoka 29830: Loss = 0.000000831\n",
      "Epoka 29840: Loss = 0.000001033\n",
      "Epoka 29850: Loss = 0.000000698\n",
      "Epoka 29860: Loss = 0.000000800\n",
      "Epoka 29870: Loss = 0.000000922\n",
      "Epoka 29880: Loss = 0.000000779\n",
      "Epoka 29890: Loss = 0.000001014\n",
      "Epoka 29900: Loss = 0.000000741\n",
      "Epoka 29910: Loss = 0.000000754\n",
      "Epoka 29920: Loss = 0.000001118\n",
      "Epoka 29930: Loss = 0.000001940\n",
      "Epoka 29940: Loss = 0.000000705\n",
      "Epoka 29950: Loss = 0.000000925\n",
      "Epoka 29960: Loss = 0.000001070\n",
      "Epoka 29970: Loss = 0.000001226\n",
      "Epoka 29980: Loss = 0.000000980\n",
      "Epoka 29990: Loss = 0.000000846\n",
      "Epoka 30000: Loss = 0.000000693\n",
      "Epoka 30010: Loss = 0.000000774\n",
      "Epoka 30020: Loss = 0.000000795\n",
      "Epoka 30030: Loss = 0.000001871\n",
      "Epoka 30040: Loss = 0.000000739\n",
      "Epoka 30050: Loss = 0.000000683\n",
      "Epoka 30060: Loss = 0.000000661\n",
      "Epoka 30070: Loss = 0.000001059\n",
      "Epoka 30080: Loss = 0.000000705\n",
      "Epoka 30090: Loss = 0.000000795\n",
      "Epoka 30100: Loss = 0.000000686\n",
      "Epoka 30110: Loss = 0.000000891\n",
      "Epoka 30120: Loss = 0.000000773\n",
      "Epoka 30130: Loss = 0.000002269\n",
      "Epoka 30140: Loss = 0.000000754\n",
      "Epoka 30150: Loss = 0.000001245\n",
      "Epoka 30160: Loss = 0.000000768\n",
      "Epoka 30170: Loss = 0.000000715\n",
      "Epoka 30180: Loss = 0.000000924\n",
      "Epoka 30190: Loss = 0.000000737\n",
      "Epoka 30200: Loss = 0.000000695\n",
      "Epoka 30210: Loss = 0.000000911\n",
      "Epoka 30220: Loss = 0.000000821\n",
      "Epoka 30230: Loss = 0.000000808\n",
      "Epoka 30240: Loss = 0.000000838\n",
      "Epoka 30250: Loss = 0.000001144\n",
      "Epoka 30260: Loss = 0.000000720\n",
      "Epoka 30270: Loss = 0.000000796\n",
      "Epoka 30280: Loss = 0.000000681\n",
      "Epoka 30290: Loss = 0.000000950\n",
      "Epoka 30300: Loss = 0.000001264\n",
      "Epoka 30310: Loss = 0.000000980\n",
      "Epoka 30320: Loss = 0.000001352\n",
      "Epoka 30330: Loss = 0.000000660\n",
      "Epoka 30340: Loss = 0.000001469\n",
      "Epoka 30350: Loss = 0.000000626\n",
      "Epoka 30360: Loss = 0.000000665\n",
      "Epoka 30370: Loss = 0.000000966\n",
      "Epoka 30380: Loss = 0.000001131\n",
      "Epoka 30390: Loss = 0.000000753\n",
      "Epoka 30400: Loss = 0.000000919\n",
      "Epoka 30410: Loss = 0.000001014\n",
      "Epoka 30420: Loss = 0.000001125\n",
      "Epoka 30430: Loss = 0.000000980\n",
      "Epoka 30440: Loss = 0.000000628\n",
      "Epoka 30450: Loss = 0.000001353\n",
      "Epoka 30460: Loss = 0.000000652\n",
      "Epoka 30470: Loss = 0.000000968\n",
      "Epoka 30480: Loss = 0.000000815\n",
      "Epoka 30490: Loss = 0.000000742\n",
      "Epoka 30500: Loss = 0.000000619\n",
      "Epoka 30510: Loss = 0.000001036\n",
      "Epoka 30520: Loss = 0.000000701\n",
      "Epoka 30530: Loss = 0.000001074\n",
      "Epoka 30540: Loss = 0.000001138\n",
      "Epoka 30550: Loss = 0.000001021\n",
      "Epoka 30560: Loss = 0.000000726\n",
      "Epoka 30570: Loss = 0.000000671\n",
      "Epoka 30580: Loss = 0.000001020\n",
      "Epoka 30590: Loss = 0.000000643\n",
      "Epoka 30600: Loss = 0.000000623\n",
      "Epoka 30610: Loss = 0.000000730\n",
      "Epoka 30620: Loss = 0.000000684\n",
      "Epoka 30630: Loss = 0.000000930\n",
      "Epoka 30640: Loss = 0.000000942\n",
      "Epoka 30650: Loss = 0.000000715\n",
      "Epoka 30660: Loss = 0.000001023\n",
      "Epoka 30670: Loss = 0.000000773\n",
      "Epoka 30680: Loss = 0.000000632\n",
      "Epoka 30690: Loss = 0.000000723\n",
      "Epoka 30700: Loss = 0.000000649\n",
      "Epoka 30710: Loss = 0.000000658\n",
      "Epoka 30720: Loss = 0.000000703\n",
      "Epoka 30730: Loss = 0.000000643\n",
      "Epoka 30740: Loss = 0.000001051\n",
      "Epoka 30750: Loss = 0.000001105\n",
      "Epoka 30760: Loss = 0.000000632\n",
      "Epoka 30770: Loss = 0.000000641\n",
      "Epoka 30780: Loss = 0.000000930\n",
      "Epoka 30790: Loss = 0.000000662\n",
      "Epoka 30800: Loss = 0.000000798\n",
      "Epoka 30810: Loss = 0.000000625\n",
      "Epoka 30820: Loss = 0.000001189\n",
      "Epoka 30830: Loss = 0.000000643\n",
      "Epoka 30840: Loss = 0.000000617\n",
      "Epoka 30850: Loss = 0.000000630\n",
      "Epoka 30860: Loss = 0.000001577\n",
      "Epoka 30870: Loss = 0.000001097\n",
      "Epoka 30880: Loss = 0.000000769\n",
      "Epoka 30890: Loss = 0.000000720\n",
      "Epoka 30900: Loss = 0.000000706\n",
      "Epoka 30910: Loss = 0.000000699\n",
      "Epoka 30920: Loss = 0.000000975\n",
      "Epoka 30930: Loss = 0.000000945\n",
      "Epoka 30940: Loss = 0.000000936\n",
      "Epoka 30950: Loss = 0.000000733\n",
      "Epoka 30960: Loss = 0.000000749\n",
      "Epoka 30970: Loss = 0.000000775\n",
      "Epoka 30980: Loss = 0.000000678\n",
      "Epoka 30990: Loss = 0.000000747\n",
      "Epoka 31000: Loss = 0.000000701\n",
      "Epoka 31010: Loss = 0.000000634\n",
      "Epoka 31020: Loss = 0.000000684\n",
      "Epoka 31030: Loss = 0.000001091\n",
      "Epoka 31040: Loss = 0.000000711\n",
      "Epoka 31050: Loss = 0.000001240\n",
      "Epoka 31060: Loss = 0.000000703\n",
      "Epoka 31070: Loss = 0.000000630\n",
      "Epoka 31080: Loss = 0.000000604\n",
      "Epoka 31090: Loss = 0.000000746\n",
      "Epoka 31100: Loss = 0.000000864\n",
      "Epoka 31110: Loss = 0.000000797\n",
      "Epoka 31120: Loss = 0.000000665\n",
      "Epoka 31130: Loss = 0.000000842\n",
      "Epoka 31140: Loss = 0.000001083\n",
      "Epoka 31150: Loss = 0.000001056\n",
      "Epoka 31160: Loss = 0.000001044\n",
      "Epoka 31170: Loss = 0.000000876\n",
      "Epoka 31180: Loss = 0.000000648\n",
      "Epoka 31190: Loss = 0.000000818\n",
      "Epoka 31200: Loss = 0.000000629\n",
      "Epoka 31210: Loss = 0.000000989\n",
      "Epoka 31220: Loss = 0.000000791\n",
      "Epoka 31230: Loss = 0.000002655\n",
      "Epoka 31240: Loss = 0.000000981\n",
      "Epoka 31250: Loss = 0.000000779\n",
      "Epoka 31260: Loss = 0.000000715\n",
      "Epoka 31270: Loss = 0.000000762\n",
      "Epoka 31280: Loss = 0.000000827\n",
      "Epoka 31290: Loss = 0.000000629\n",
      "Epoka 31300: Loss = 0.000000842\n",
      "Epoka 31310: Loss = 0.000000590\n",
      "Epoka 31320: Loss = 0.000000648\n",
      "Epoka 31330: Loss = 0.000000882\n",
      "Epoka 31340: Loss = 0.000000623\n",
      "Epoka 31350: Loss = 0.000000895\n",
      "Epoka 31360: Loss = 0.000000702\n",
      "Epoka 31370: Loss = 0.000000911\n",
      "Epoka 31380: Loss = 0.000001844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 31390: Loss = 0.000000842\n",
      "Epoka 31400: Loss = 0.000001458\n",
      "Epoka 31410: Loss = 0.000000656\n",
      "Epoka 31420: Loss = 0.000001082\n",
      "Epoka 31430: Loss = 0.000000761\n",
      "Epoka 31440: Loss = 0.000000608\n",
      "Epoka 31450: Loss = 0.000001141\n",
      "Epoka 31460: Loss = 0.000000674\n",
      "Epoka 31470: Loss = 0.000000934\n",
      "Epoka 31480: Loss = 0.000000797\n",
      "Epoka 31490: Loss = 0.000000662\n",
      "Epoka 31500: Loss = 0.000001265\n",
      "Epoka 31510: Loss = 0.000000599\n",
      "Epoka 31520: Loss = 0.000000983\n",
      "Epoka 31530: Loss = 0.000001324\n",
      "Epoka 31540: Loss = 0.000000979\n",
      "Epoka 31550: Loss = 0.000000766\n",
      "Epoka 31560: Loss = 0.000001349\n",
      "Epoka 31570: Loss = 0.000000696\n",
      "Epoka 31580: Loss = 0.000000658\n",
      "Epoka 31590: Loss = 0.000000658\n",
      "Epoka 31600: Loss = 0.000000878\n",
      "Epoka 31610: Loss = 0.000000879\n",
      "Epoka 31620: Loss = 0.000000748\n",
      "Epoka 31630: Loss = 0.000000599\n",
      "Epoka 31640: Loss = 0.000000637\n",
      "Epoka 31650: Loss = 0.000000652\n",
      "Epoka 31660: Loss = 0.000000617\n",
      "Epoka 31670: Loss = 0.000000922\n",
      "Epoka 31680: Loss = 0.000000613\n",
      "Epoka 31690: Loss = 0.000000762\n",
      "Epoka 31700: Loss = 0.000000624\n",
      "Epoka 31710: Loss = 0.000000804\n",
      "Epoka 31720: Loss = 0.000000728\n",
      "Epoka 31730: Loss = 0.000000962\n",
      "Epoka 31740: Loss = 0.000000715\n",
      "Epoka 31750: Loss = 0.000000596\n",
      "Epoka 31760: Loss = 0.000000660\n",
      "Epoka 31770: Loss = 0.000000735\n",
      "Epoka 31780: Loss = 0.000001173\n",
      "Epoka 31790: Loss = 0.000001147\n",
      "Epoka 31800: Loss = 0.000001883\n",
      "Epoka 31810: Loss = 0.000000664\n",
      "Epoka 31820: Loss = 0.000000626\n",
      "Epoka 31830: Loss = 0.000000681\n",
      "Epoka 31840: Loss = 0.000001128\n",
      "Epoka 31850: Loss = 0.000000635\n",
      "Epoka 31860: Loss = 0.000000857\n",
      "Epoka 31870: Loss = 0.000000853\n",
      "Epoka 31880: Loss = 0.000000942\n",
      "Epoka 31890: Loss = 0.000001148\n",
      "Epoka 31900: Loss = 0.000000564\n",
      "Epoka 31910: Loss = 0.000001388\n",
      "Epoka 31920: Loss = 0.000001167\n",
      "Epoka 31930: Loss = 0.000000577\n",
      "Epoka 31940: Loss = 0.000001057\n",
      "Epoka 31950: Loss = 0.000000595\n",
      "Epoka 31960: Loss = 0.000000775\n",
      "Epoka 31970: Loss = 0.000000853\n",
      "Epoka 31980: Loss = 0.000000617\n",
      "Epoka 31990: Loss = 0.000000724\n",
      "Epoka 32000: Loss = 0.000000583\n",
      "Epoka 32010: Loss = 0.000000558\n",
      "Epoka 32020: Loss = 0.000000608\n",
      "Epoka 32030: Loss = 0.000000869\n",
      "Epoka 32040: Loss = 0.000001356\n",
      "Epoka 32050: Loss = 0.000000598\n",
      "Epoka 32060: Loss = 0.000000805\n",
      "Epoka 32070: Loss = 0.000000727\n",
      "Epoka 32080: Loss = 0.000000591\n",
      "Epoka 32090: Loss = 0.000000596\n",
      "Epoka 32100: Loss = 0.000000995\n",
      "Epoka 32110: Loss = 0.000000547\n",
      "Epoka 32120: Loss = 0.000000634\n",
      "Epoka 32130: Loss = 0.000000836\n",
      "Epoka 32140: Loss = 0.000000568\n",
      "Epoka 32150: Loss = 0.000000848\n",
      "Epoka 32160: Loss = 0.000000639\n",
      "Epoka 32170: Loss = 0.000000560\n",
      "Epoka 32180: Loss = 0.000000671\n",
      "Epoka 32190: Loss = 0.000001254\n",
      "Epoka 32200: Loss = 0.000000998\n",
      "Epoka 32210: Loss = 0.000000848\n",
      "Epoka 32220: Loss = 0.000001447\n",
      "Epoka 32230: Loss = 0.000000840\n",
      "Epoka 32240: Loss = 0.000000659\n",
      "Epoka 32250: Loss = 0.000000623\n",
      "Epoka 32260: Loss = 0.000000669\n",
      "Epoka 32270: Loss = 0.000001232\n",
      "Epoka 32280: Loss = 0.000000781\n",
      "Epoka 32290: Loss = 0.000000659\n",
      "Epoka 32300: Loss = 0.000001451\n",
      "Epoka 32310: Loss = 0.000000590\n",
      "Epoka 32320: Loss = 0.000000586\n",
      "Epoka 32330: Loss = 0.000000568\n",
      "Epoka 32340: Loss = 0.000001699\n",
      "Epoka 32350: Loss = 0.000000747\n",
      "Epoka 32360: Loss = 0.000000587\n",
      "Epoka 32370: Loss = 0.000000594\n",
      "Epoka 32380: Loss = 0.000000630\n",
      "Epoka 32390: Loss = 0.000000726\n",
      "Epoka 32400: Loss = 0.000001024\n",
      "Epoka 32410: Loss = 0.000000586\n",
      "Epoka 32420: Loss = 0.000001292\n",
      "Epoka 32430: Loss = 0.000000574\n",
      "Epoka 32440: Loss = 0.000000554\n",
      "Epoka 32450: Loss = 0.000001020\n",
      "Epoka 32460: Loss = 0.000001309\n",
      "Epoka 32470: Loss = 0.000000670\n",
      "Epoka 32480: Loss = 0.000000538\n",
      "Epoka 32490: Loss = 0.000000805\n",
      "Epoka 32500: Loss = 0.000000906\n",
      "Epoka 32510: Loss = 0.000000577\n",
      "Epoka 32520: Loss = 0.000000601\n",
      "Epoka 32530: Loss = 0.000001093\n",
      "Epoka 32540: Loss = 0.000000641\n",
      "Epoka 32550: Loss = 0.000000599\n",
      "Epoka 32560: Loss = 0.000000607\n",
      "Epoka 32570: Loss = 0.000000620\n",
      "Epoka 32580: Loss = 0.000000889\n",
      "Epoka 32590: Loss = 0.000000830\n",
      "Epoka 32600: Loss = 0.000001166\n",
      "Epoka 32610: Loss = 0.000000661\n",
      "Epoka 32620: Loss = 0.000000648\n",
      "Epoka 32630: Loss = 0.000000650\n",
      "Epoka 32640: Loss = 0.000000535\n",
      "Epoka 32650: Loss = 0.000000627\n",
      "Epoka 32660: Loss = 0.000000666\n",
      "Epoka 32670: Loss = 0.000000566\n",
      "Epoka 32680: Loss = 0.000000672\n",
      "Epoka 32690: Loss = 0.000000578\n",
      "Epoka 32700: Loss = 0.000000553\n",
      "Epoka 32710: Loss = 0.000000621\n",
      "Epoka 32720: Loss = 0.000001915\n",
      "Epoka 32730: Loss = 0.000000853\n",
      "Epoka 32740: Loss = 0.000000787\n",
      "Epoka 32750: Loss = 0.000000841\n",
      "Epoka 32760: Loss = 0.000000666\n",
      "Epoka 32770: Loss = 0.000002127\n",
      "Epoka 32780: Loss = 0.000000593\n",
      "Epoka 32790: Loss = 0.000000673\n",
      "Epoka 32800: Loss = 0.000000538\n",
      "Epoka 32810: Loss = 0.000000786\n",
      "Epoka 32820: Loss = 0.000001037\n",
      "Epoka 32830: Loss = 0.000000666\n",
      "Epoka 32840: Loss = 0.000000781\n",
      "Epoka 32850: Loss = 0.000000843\n",
      "Epoka 32860: Loss = 0.000000889\n",
      "Epoka 32870: Loss = 0.000000556\n",
      "Epoka 32880: Loss = 0.000000599\n",
      "Epoka 32890: Loss = 0.000000841\n",
      "Epoka 32900: Loss = 0.000000575\n",
      "Epoka 32910: Loss = 0.000000589\n",
      "Epoka 32920: Loss = 0.000000715\n",
      "Epoka 32930: Loss = 0.000000715\n",
      "Epoka 32940: Loss = 0.000000567\n",
      "Epoka 32950: Loss = 0.000001220\n",
      "Epoka 32960: Loss = 0.000000716\n",
      "Epoka 32970: Loss = 0.000001093\n",
      "Epoka 32980: Loss = 0.000001696\n",
      "Epoka 32990: Loss = 0.000001465\n",
      "Epoka 33000: Loss = 0.000000921\n",
      "Epoka 33010: Loss = 0.000000816\n",
      "Epoka 33020: Loss = 0.000000921\n",
      "Epoka 33030: Loss = 0.000000710\n",
      "Epoka 33040: Loss = 0.000000861\n",
      "Epoka 33050: Loss = 0.000000763\n",
      "Epoka 33060: Loss = 0.000001178\n",
      "Epoka 33070: Loss = 0.000000580\n",
      "Epoka 33080: Loss = 0.000000619\n",
      "Epoka 33090: Loss = 0.000000525\n",
      "Epoka 33100: Loss = 0.000000592\n",
      "Epoka 33110: Loss = 0.000000523\n",
      "Epoka 33120: Loss = 0.000000651\n",
      "Epoka 33130: Loss = 0.000000604\n",
      "Epoka 33140: Loss = 0.000000540\n",
      "Epoka 33150: Loss = 0.000000522\n",
      "Epoka 33160: Loss = 0.000000598\n",
      "Epoka 33170: Loss = 0.000000801\n",
      "Epoka 33180: Loss = 0.000000536\n",
      "Epoka 33190: Loss = 0.000000713\n",
      "Epoka 33200: Loss = 0.000000584\n",
      "Epoka 33210: Loss = 0.000000780\n",
      "Epoka 33220: Loss = 0.000000519\n",
      "Epoka 33230: Loss = 0.000000865\n",
      "Epoka 33240: Loss = 0.000001395\n",
      "Epoka 33250: Loss = 0.000000696\n",
      "Epoka 33260: Loss = 0.000000534\n",
      "Epoka 33270: Loss = 0.000001285\n",
      "Epoka 33280: Loss = 0.000000617\n",
      "Epoka 33290: Loss = 0.000000800\n",
      "Epoka 33300: Loss = 0.000000867\n",
      "Epoka 33310: Loss = 0.000000510\n",
      "Epoka 33320: Loss = 0.000000524\n",
      "Epoka 33330: Loss = 0.000000984\n",
      "Epoka 33340: Loss = 0.000000876\n",
      "Epoka 33350: Loss = 0.000000551\n",
      "Epoka 33360: Loss = 0.000000615\n",
      "Epoka 33370: Loss = 0.000000730\n",
      "Epoka 33380: Loss = 0.000000973\n",
      "Epoka 33390: Loss = 0.000000755\n",
      "Epoka 33400: Loss = 0.000000718\n",
      "Epoka 33410: Loss = 0.000002298\n",
      "Epoka 33420: Loss = 0.000000647\n",
      "Epoka 33430: Loss = 0.000001249\n",
      "Epoka 33440: Loss = 0.000000717\n",
      "Epoka 33450: Loss = 0.000000668\n",
      "Epoka 33460: Loss = 0.000000560\n",
      "Epoka 33470: Loss = 0.000000617\n",
      "Epoka 33480: Loss = 0.000000684\n",
      "Epoka 33490: Loss = 0.000000683\n",
      "Epoka 33500: Loss = 0.000002022\n",
      "Epoka 33510: Loss = 0.000000518\n",
      "Epoka 33520: Loss = 0.000000704\n",
      "Epoka 33530: Loss = 0.000000921\n",
      "Epoka 33540: Loss = 0.000000862\n",
      "Epoka 33550: Loss = 0.000000511\n",
      "Epoka 33560: Loss = 0.000001142\n",
      "Epoka 33570: Loss = 0.000000536\n",
      "Epoka 33580: Loss = 0.000000842\n",
      "Epoka 33590: Loss = 0.000000610\n",
      "Epoka 33600: Loss = 0.000000569\n",
      "Epoka 33610: Loss = 0.000001366\n",
      "Epoka 33620: Loss = 0.000000723\n",
      "Epoka 33630: Loss = 0.000000629\n",
      "Epoka 33640: Loss = 0.000000888\n",
      "Epoka 33650: Loss = 0.000000512\n",
      "Epoka 33660: Loss = 0.000000565\n",
      "Epoka 33670: Loss = 0.000000675\n",
      "Epoka 33680: Loss = 0.000000521\n",
      "Epoka 33690: Loss = 0.000000623\n",
      "Epoka 33700: Loss = 0.000001235\n",
      "Epoka 33710: Loss = 0.000001997\n",
      "Epoka 33720: Loss = 0.000000634\n",
      "Epoka 33730: Loss = 0.000000848\n",
      "Epoka 33740: Loss = 0.000000964\n",
      "Epoka 33750: Loss = 0.000000511\n",
      "Epoka 33760: Loss = 0.000000536\n",
      "Epoka 33770: Loss = 0.000000635\n",
      "Epoka 33780: Loss = 0.000000566\n",
      "Epoka 33790: Loss = 0.000000631\n",
      "Epoka 33800: Loss = 0.000000543\n",
      "Epoka 33810: Loss = 0.000000790\n",
      "Epoka 33820: Loss = 0.000000727\n",
      "Epoka 33830: Loss = 0.000000650\n",
      "Epoka 33840: Loss = 0.000000794\n",
      "Epoka 33850: Loss = 0.000000695\n",
      "Epoka 33860: Loss = 0.000000531\n",
      "Epoka 33870: Loss = 0.000000881\n",
      "Epoka 33880: Loss = 0.000000642\n",
      "Epoka 33890: Loss = 0.000000511\n",
      "Epoka 33900: Loss = 0.000000496\n",
      "Epoka 33910: Loss = 0.000000698\n",
      "Epoka 33920: Loss = 0.000000500\n",
      "Epoka 33930: Loss = 0.000000690\n",
      "Epoka 33940: Loss = 0.000000840\n",
      "Epoka 33950: Loss = 0.000000540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 33960: Loss = 0.000000610\n",
      "Epoka 33970: Loss = 0.000000648\n",
      "Epoka 33980: Loss = 0.000000959\n",
      "Epoka 33990: Loss = 0.000000532\n",
      "Epoka 34000: Loss = 0.000000796\n",
      "Epoka 34010: Loss = 0.000000524\n",
      "Epoka 34020: Loss = 0.000000582\n",
      "Epoka 34030: Loss = 0.000000650\n",
      "Epoka 34040: Loss = 0.000000564\n",
      "Epoka 34050: Loss = 0.000000548\n",
      "Epoka 34060: Loss = 0.000000765\n",
      "Epoka 34070: Loss = 0.000000879\n",
      "Epoka 34080: Loss = 0.000000666\n",
      "Epoka 34090: Loss = 0.000000562\n",
      "Epoka 34100: Loss = 0.000000650\n",
      "Epoka 34110: Loss = 0.000000634\n",
      "Epoka 34120: Loss = 0.000000715\n",
      "Epoka 34130: Loss = 0.000000595\n",
      "Epoka 34140: Loss = 0.000000621\n",
      "Epoka 34150: Loss = 0.000001378\n",
      "Epoka 34160: Loss = 0.000001346\n",
      "Epoka 34170: Loss = 0.000000931\n",
      "Epoka 34180: Loss = 0.000000728\n",
      "Epoka 34190: Loss = 0.000000634\n",
      "Epoka 34200: Loss = 0.000000617\n",
      "Epoka 34210: Loss = 0.000000701\n",
      "Epoka 34220: Loss = 0.000000565\n",
      "Epoka 34230: Loss = 0.000000689\n",
      "Epoka 34240: Loss = 0.000001677\n",
      "Epoka 34250: Loss = 0.000001373\n",
      "Epoka 34260: Loss = 0.000000506\n",
      "Epoka 34270: Loss = 0.000000601\n",
      "Epoka 34280: Loss = 0.000000934\n",
      "Epoka 34290: Loss = 0.000000562\n",
      "Epoka 34300: Loss = 0.000000525\n",
      "Epoka 34310: Loss = 0.000000562\n",
      "Epoka 34320: Loss = 0.000000495\n",
      "Epoka 34330: Loss = 0.000000740\n",
      "Epoka 34340: Loss = 0.000000551\n",
      "Epoka 34350: Loss = 0.000000520\n",
      "Epoka 34360: Loss = 0.000000501\n",
      "Epoka 34370: Loss = 0.000000532\n",
      "Epoka 34380: Loss = 0.000000695\n",
      "Epoka 34390: Loss = 0.000000760\n",
      "Epoka 34400: Loss = 0.000000812\n",
      "Epoka 34410: Loss = 0.000000600\n",
      "Epoka 34420: Loss = 0.000000741\n",
      "Epoka 34430: Loss = 0.000000607\n",
      "Epoka 34440: Loss = 0.000001043\n",
      "Epoka 34450: Loss = 0.000000574\n",
      "Epoka 34460: Loss = 0.000000543\n",
      "Epoka 34470: Loss = 0.000000670\n",
      "Epoka 34480: Loss = 0.000000508\n",
      "Epoka 34490: Loss = 0.000000542\n",
      "Epoka 34500: Loss = 0.000000792\n",
      "Epoka 34510: Loss = 0.000000977\n",
      "Epoka 34520: Loss = 0.000001055\n",
      "Epoka 34530: Loss = 0.000000508\n",
      "Epoka 34540: Loss = 0.000000648\n",
      "Epoka 34550: Loss = 0.000000757\n",
      "Epoka 34560: Loss = 0.000000493\n",
      "Epoka 34570: Loss = 0.000000575\n",
      "Epoka 34580: Loss = 0.000000622\n",
      "Epoka 34590: Loss = 0.000001111\n",
      "Epoka 34600: Loss = 0.000000883\n",
      "Epoka 34610: Loss = 0.000000495\n",
      "Epoka 34620: Loss = 0.000000737\n",
      "Epoka 34630: Loss = 0.000000623\n",
      "Epoka 34640: Loss = 0.000000834\n",
      "Epoka 34650: Loss = 0.000000489\n",
      "Epoka 34660: Loss = 0.000000986\n",
      "Epoka 34670: Loss = 0.000000717\n",
      "Epoka 34680: Loss = 0.000000535\n",
      "Epoka 34690: Loss = 0.000000612\n",
      "Epoka 34700: Loss = 0.000000602\n",
      "Epoka 34710: Loss = 0.000000574\n",
      "Epoka 34720: Loss = 0.000001111\n",
      "Epoka 34730: Loss = 0.000000518\n",
      "Epoka 34740: Loss = 0.000000486\n",
      "Epoka 34750: Loss = 0.000000648\n",
      "Epoka 34760: Loss = 0.000000773\n",
      "Epoka 34770: Loss = 0.000000520\n",
      "Epoka 34780: Loss = 0.000000492\n",
      "Epoka 34790: Loss = 0.000000549\n",
      "Epoka 34800: Loss = 0.000000594\n",
      "Epoka 34810: Loss = 0.000000763\n",
      "Epoka 34820: Loss = 0.000000707\n",
      "Epoka 34830: Loss = 0.000000494\n",
      "Epoka 34840: Loss = 0.000000565\n",
      "Epoka 34850: Loss = 0.000000635\n",
      "Epoka 34860: Loss = 0.000000481\n",
      "Epoka 34870: Loss = 0.000000483\n",
      "Epoka 34880: Loss = 0.000001075\n",
      "Epoka 34890: Loss = 0.000000507\n",
      "Epoka 34900: Loss = 0.000000834\n",
      "Epoka 34910: Loss = 0.000000704\n",
      "Epoka 34920: Loss = 0.000000592\n",
      "Epoka 34930: Loss = 0.000000501\n",
      "Epoka 34940: Loss = 0.000000696\n",
      "Epoka 34950: Loss = 0.000000469\n",
      "Epoka 34960: Loss = 0.000000535\n",
      "Epoka 34970: Loss = 0.000000572\n",
      "Epoka 34980: Loss = 0.000001030\n",
      "Epoka 34990: Loss = 0.000000713\n",
      "Epoka 35000: Loss = 0.000000479\n",
      "Epoka 35010: Loss = 0.000000530\n",
      "Epoka 35020: Loss = 0.000000733\n",
      "Epoka 35030: Loss = 0.000000678\n",
      "Epoka 35040: Loss = 0.000000864\n",
      "Epoka 35050: Loss = 0.000000617\n",
      "Epoka 35060: Loss = 0.000000600\n",
      "Epoka 35070: Loss = 0.000000470\n",
      "Epoka 35080: Loss = 0.000000479\n",
      "Epoka 35090: Loss = 0.000000556\n",
      "Epoka 35100: Loss = 0.000000564\n",
      "Epoka 35110: Loss = 0.000000717\n",
      "Epoka 35120: Loss = 0.000000472\n",
      "Epoka 35130: Loss = 0.000000648\n",
      "Epoka 35140: Loss = 0.000000680\n",
      "Epoka 35150: Loss = 0.000000602\n",
      "Epoka 35160: Loss = 0.000001105\n",
      "Epoka 35170: Loss = 0.000000491\n",
      "Epoka 35180: Loss = 0.000000471\n",
      "Epoka 35190: Loss = 0.000000646\n",
      "Epoka 35200: Loss = 0.000000463\n",
      "Epoka 35210: Loss = 0.000000504\n",
      "Epoka 35220: Loss = 0.000000481\n",
      "Epoka 35230: Loss = 0.000000505\n",
      "Epoka 35240: Loss = 0.000000510\n",
      "Epoka 35250: Loss = 0.000000517\n",
      "Epoka 35260: Loss = 0.000001018\n",
      "Epoka 35270: Loss = 0.000000508\n",
      "Epoka 35280: Loss = 0.000000540\n",
      "Epoka 35290: Loss = 0.000000776\n",
      "Epoka 35300: Loss = 0.000000842\n",
      "Epoka 35310: Loss = 0.000000525\n",
      "Epoka 35320: Loss = 0.000000748\n",
      "Epoka 35330: Loss = 0.000000459\n",
      "Epoka 35340: Loss = 0.000000500\n",
      "Epoka 35350: Loss = 0.000000991\n",
      "Epoka 35360: Loss = 0.000000556\n",
      "Epoka 35370: Loss = 0.000000482\n",
      "Epoka 35380: Loss = 0.000000662\n",
      "Epoka 35390: Loss = 0.000000649\n",
      "Epoka 35400: Loss = 0.000000494\n",
      "Epoka 35410: Loss = 0.000000529\n",
      "Epoka 35420: Loss = 0.000000654\n",
      "Epoka 35430: Loss = 0.000000591\n",
      "Epoka 35440: Loss = 0.000000642\n",
      "Epoka 35450: Loss = 0.000000728\n",
      "Epoka 35460: Loss = 0.000000679\n",
      "Epoka 35470: Loss = 0.000000607\n",
      "Epoka 35480: Loss = 0.000000512\n",
      "Epoka 35490: Loss = 0.000000510\n",
      "Epoka 35500: Loss = 0.000000845\n",
      "Epoka 35510: Loss = 0.000001324\n",
      "Epoka 35520: Loss = 0.000000537\n",
      "Epoka 35530: Loss = 0.000000715\n",
      "Epoka 35540: Loss = 0.000000562\n",
      "Epoka 35550: Loss = 0.000001300\n",
      "Epoka 35560: Loss = 0.000000607\n",
      "Epoka 35570: Loss = 0.000000721\n",
      "Epoka 35580: Loss = 0.000001084\n",
      "Epoka 35590: Loss = 0.000000660\n",
      "Epoka 35600: Loss = 0.000000495\n",
      "Epoka 35610: Loss = 0.000000457\n",
      "Epoka 35620: Loss = 0.000001036\n",
      "Epoka 35630: Loss = 0.000000850\n",
      "Epoka 35640: Loss = 0.000000517\n",
      "Epoka 35650: Loss = 0.000000464\n",
      "Epoka 35660: Loss = 0.000000486\n",
      "Epoka 35670: Loss = 0.000000572\n",
      "Epoka 35680: Loss = 0.000000580\n",
      "Epoka 35690: Loss = 0.000000567\n",
      "Epoka 35700: Loss = 0.000000457\n",
      "Epoka 35710: Loss = 0.000000673\n",
      "Epoka 35720: Loss = 0.000000537\n",
      "Epoka 35730: Loss = 0.000001089\n",
      "Epoka 35740: Loss = 0.000000530\n",
      "Epoka 35750: Loss = 0.000000490\n",
      "Epoka 35760: Loss = 0.000000476\n",
      "Epoka 35770: Loss = 0.000000993\n",
      "Epoka 35780: Loss = 0.000000759\n",
      "Epoka 35790: Loss = 0.000000477\n",
      "Epoka 35800: Loss = 0.000001660\n",
      "Epoka 35810: Loss = 0.000000451\n",
      "Epoka 35820: Loss = 0.000000972\n",
      "Epoka 35830: Loss = 0.000000479\n",
      "Epoka 35840: Loss = 0.000000693\n",
      "Epoka 35850: Loss = 0.000000460\n",
      "Epoka 35860: Loss = 0.000000567\n",
      "Epoka 35870: Loss = 0.000000463\n",
      "Epoka 35880: Loss = 0.000000633\n",
      "Epoka 35890: Loss = 0.000001390\n",
      "Epoka 35900: Loss = 0.000000552\n",
      "Epoka 35910: Loss = 0.000001005\n",
      "Epoka 35920: Loss = 0.000000687\n",
      "Epoka 35930: Loss = 0.000000466\n",
      "Epoka 35940: Loss = 0.000000518\n",
      "Epoka 35950: Loss = 0.000000496\n",
      "Epoka 35960: Loss = 0.000000505\n",
      "Epoka 35970: Loss = 0.000000466\n",
      "Epoka 35980: Loss = 0.000000918\n",
      "Epoka 35990: Loss = 0.000000843\n",
      "Epoka 36000: Loss = 0.000000466\n",
      "Epoka 36010: Loss = 0.000000525\n",
      "Epoka 36020: Loss = 0.000000826\n",
      "Epoka 36030: Loss = 0.000000547\n",
      "Epoka 36040: Loss = 0.000000945\n",
      "Epoka 36050: Loss = 0.000001232\n",
      "Epoka 36060: Loss = 0.000000552\n",
      "Epoka 36070: Loss = 0.000000463\n",
      "Epoka 36080: Loss = 0.000000482\n",
      "Epoka 36090: Loss = 0.000000759\n",
      "Epoka 36100: Loss = 0.000001310\n",
      "Epoka 36110: Loss = 0.000000755\n",
      "Epoka 36120: Loss = 0.000000510\n",
      "Epoka 36130: Loss = 0.000000546\n",
      "Epoka 36140: Loss = 0.000000819\n",
      "Epoka 36150: Loss = 0.000000485\n",
      "Epoka 36160: Loss = 0.000000503\n",
      "Epoka 36170: Loss = 0.000000859\n",
      "Epoka 36180: Loss = 0.000000641\n",
      "Epoka 36190: Loss = 0.000000514\n",
      "Epoka 36200: Loss = 0.000000553\n",
      "Epoka 36210: Loss = 0.000000612\n",
      "Epoka 36220: Loss = 0.000001101\n",
      "Epoka 36230: Loss = 0.000000543\n",
      "Epoka 36240: Loss = 0.000001001\n",
      "Epoka 36250: Loss = 0.000000627\n",
      "Epoka 36260: Loss = 0.000000584\n",
      "Epoka 36270: Loss = 0.000000724\n",
      "Epoka 36280: Loss = 0.000000574\n",
      "Epoka 36290: Loss = 0.000000444\n",
      "Epoka 36300: Loss = 0.000000702\n",
      "Epoka 36310: Loss = 0.000000892\n",
      "Epoka 36320: Loss = 0.000000785\n",
      "Epoka 36330: Loss = 0.000001340\n",
      "Epoka 36340: Loss = 0.000000663\n",
      "Epoka 36350: Loss = 0.000000797\n",
      "Epoka 36360: Loss = 0.000000574\n",
      "Epoka 36370: Loss = 0.000000462\n",
      "Epoka 36380: Loss = 0.000000489\n",
      "Epoka 36390: Loss = 0.000000555\n",
      "Epoka 36400: Loss = 0.000000442\n",
      "Epoka 36410: Loss = 0.000000547\n",
      "Epoka 36420: Loss = 0.000000510\n",
      "Epoka 36430: Loss = 0.000000904\n",
      "Epoka 36440: Loss = 0.000000433\n",
      "Epoka 36450: Loss = 0.000000457\n",
      "Epoka 36460: Loss = 0.000000488\n",
      "Epoka 36470: Loss = 0.000000686\n",
      "Epoka 36480: Loss = 0.000000479\n",
      "Epoka 36490: Loss = 0.000000484\n",
      "Epoka 36500: Loss = 0.000000585\n",
      "Epoka 36510: Loss = 0.000000529\n",
      "Epoka 36520: Loss = 0.000000440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 36530: Loss = 0.000000478\n",
      "Epoka 36540: Loss = 0.000000478\n",
      "Epoka 36550: Loss = 0.000000483\n",
      "Epoka 36560: Loss = 0.000000693\n",
      "Epoka 36570: Loss = 0.000000587\n",
      "Epoka 36580: Loss = 0.000000731\n",
      "Epoka 36590: Loss = 0.000001136\n",
      "Epoka 36600: Loss = 0.000000835\n",
      "Epoka 36610: Loss = 0.000000494\n",
      "Epoka 36620: Loss = 0.000000467\n",
      "Epoka 36630: Loss = 0.000001078\n",
      "Epoka 36640: Loss = 0.000000768\n",
      "Epoka 36650: Loss = 0.000000630\n",
      "Epoka 36660: Loss = 0.000000660\n",
      "Epoka 36670: Loss = 0.000000444\n",
      "Epoka 36680: Loss = 0.000000534\n",
      "Epoka 36690: Loss = 0.000000548\n",
      "Epoka 36700: Loss = 0.000000757\n",
      "Epoka 36710: Loss = 0.000000463\n",
      "Epoka 36720: Loss = 0.000000500\n",
      "Epoka 36730: Loss = 0.000000439\n",
      "Epoka 36740: Loss = 0.000000468\n",
      "Epoka 36750: Loss = 0.000000688\n",
      "Epoka 36760: Loss = 0.000000718\n",
      "Epoka 36770: Loss = 0.000000613\n",
      "Epoka 36780: Loss = 0.000000435\n",
      "Epoka 36790: Loss = 0.000000421\n",
      "Epoka 36800: Loss = 0.000000705\n",
      "Epoka 36810: Loss = 0.000000526\n",
      "Epoka 36820: Loss = 0.000000554\n",
      "Epoka 36830: Loss = 0.000000520\n",
      "Epoka 36840: Loss = 0.000000674\n",
      "Epoka 36850: Loss = 0.000000431\n",
      "Epoka 36860: Loss = 0.000000513\n",
      "Epoka 36870: Loss = 0.000000455\n",
      "Epoka 36880: Loss = 0.000000504\n",
      "Epoka 36890: Loss = 0.000000502\n",
      "Epoka 36900: Loss = 0.000000823\n",
      "Epoka 36910: Loss = 0.000000753\n",
      "Epoka 36920: Loss = 0.000000636\n",
      "Epoka 36930: Loss = 0.000001133\n",
      "Epoka 36940: Loss = 0.000000674\n",
      "Epoka 36950: Loss = 0.000000510\n",
      "Epoka 36960: Loss = 0.000000981\n",
      "Epoka 36970: Loss = 0.000000426\n",
      "Epoka 36980: Loss = 0.000000513\n",
      "Epoka 36990: Loss = 0.000000721\n",
      "Epoka 37000: Loss = 0.000000431\n",
      "Epoka 37010: Loss = 0.000000826\n",
      "Epoka 37020: Loss = 0.000000965\n",
      "Epoka 37030: Loss = 0.000000428\n",
      "Epoka 37040: Loss = 0.000000708\n",
      "Epoka 37050: Loss = 0.000000451\n",
      "Epoka 37060: Loss = 0.000000877\n",
      "Epoka 37070: Loss = 0.000000862\n",
      "Epoka 37080: Loss = 0.000000568\n",
      "Epoka 37090: Loss = 0.000000596\n",
      "Epoka 37100: Loss = 0.000000690\n",
      "Epoka 37110: Loss = 0.000000427\n",
      "Epoka 37120: Loss = 0.000000438\n",
      "Epoka 37130: Loss = 0.000000423\n",
      "Epoka 37140: Loss = 0.000000779\n",
      "Epoka 37150: Loss = 0.000000425\n",
      "Epoka 37160: Loss = 0.000000912\n",
      "Epoka 37170: Loss = 0.000000866\n",
      "Epoka 37180: Loss = 0.000000455\n",
      "Epoka 37190: Loss = 0.000000619\n",
      "Epoka 37200: Loss = 0.000000454\n",
      "Epoka 37210: Loss = 0.000000412\n",
      "Epoka 37220: Loss = 0.000000660\n",
      "Epoka 37230: Loss = 0.000000512\n",
      "Epoka 37240: Loss = 0.000000533\n",
      "Epoka 37250: Loss = 0.000000428\n",
      "Epoka 37260: Loss = 0.000001087\n",
      "Epoka 37270: Loss = 0.000001062\n",
      "Epoka 37280: Loss = 0.000000763\n",
      "Epoka 37290: Loss = 0.000000461\n",
      "Epoka 37300: Loss = 0.000000579\n",
      "Epoka 37310: Loss = 0.000000958\n",
      "Epoka 37320: Loss = 0.000000676\n",
      "Epoka 37330: Loss = 0.000000658\n",
      "Epoka 37340: Loss = 0.000000567\n",
      "Epoka 37350: Loss = 0.000000429\n",
      "Epoka 37360: Loss = 0.000001088\n",
      "Epoka 37370: Loss = 0.000000572\n",
      "Epoka 37380: Loss = 0.000000431\n",
      "Epoka 37390: Loss = 0.000000415\n",
      "Epoka 37400: Loss = 0.000000476\n",
      "Epoka 37410: Loss = 0.000000471\n",
      "Epoka 37420: Loss = 0.000000826\n",
      "Epoka 37430: Loss = 0.000000936\n",
      "Epoka 37440: Loss = 0.000001174\n",
      "Epoka 37450: Loss = 0.000000410\n",
      "Epoka 37460: Loss = 0.000000538\n",
      "Epoka 37470: Loss = 0.000000479\n",
      "Epoka 37480: Loss = 0.000000748\n",
      "Epoka 37490: Loss = 0.000001040\n",
      "Epoka 37500: Loss = 0.000000460\n",
      "Epoka 37510: Loss = 0.000000440\n",
      "Epoka 37520: Loss = 0.000000432\n",
      "Epoka 37530: Loss = 0.000000543\n",
      "Epoka 37540: Loss = 0.000000485\n",
      "Epoka 37550: Loss = 0.000000677\n",
      "Epoka 37560: Loss = 0.000000486\n",
      "Epoka 37570: Loss = 0.000000473\n",
      "Epoka 37580: Loss = 0.000000415\n",
      "Epoka 37590: Loss = 0.000001376\n",
      "Epoka 37600: Loss = 0.000000458\n",
      "Epoka 37610: Loss = 0.000000611\n",
      "Epoka 37620: Loss = 0.000000638\n",
      "Epoka 37630: Loss = 0.000001019\n",
      "Epoka 37640: Loss = 0.000000468\n",
      "Epoka 37650: Loss = 0.000000541\n",
      "Epoka 37660: Loss = 0.000000600\n",
      "Epoka 37670: Loss = 0.000000646\n",
      "Epoka 37680: Loss = 0.000000467\n",
      "Epoka 37690: Loss = 0.000000490\n",
      "Epoka 37700: Loss = 0.000000444\n",
      "Epoka 37710: Loss = 0.000000505\n",
      "Epoka 37720: Loss = 0.000000567\n",
      "Epoka 37730: Loss = 0.000000944\n",
      "Epoka 37740: Loss = 0.000000411\n",
      "Epoka 37750: Loss = 0.000000848\n",
      "Epoka 37760: Loss = 0.000000568\n",
      "Epoka 37770: Loss = 0.000000775\n",
      "Epoka 37780: Loss = 0.000000502\n",
      "Epoka 37790: Loss = 0.000000952\n",
      "Epoka 37800: Loss = 0.000000549\n",
      "Epoka 37810: Loss = 0.000000500\n",
      "Epoka 37820: Loss = 0.000000464\n",
      "Epoka 37830: Loss = 0.000000541\n",
      "Epoka 37840: Loss = 0.000000411\n",
      "Epoka 37850: Loss = 0.000000813\n",
      "Epoka 37860: Loss = 0.000000427\n",
      "Epoka 37870: Loss = 0.000001086\n",
      "Epoka 37880: Loss = 0.000000409\n",
      "Epoka 37890: Loss = 0.000000973\n",
      "Epoka 37900: Loss = 0.000000413\n",
      "Epoka 37910: Loss = 0.000000509\n",
      "Epoka 37920: Loss = 0.000000636\n",
      "Epoka 37930: Loss = 0.000000421\n",
      "Epoka 37940: Loss = 0.000000585\n",
      "Epoka 37950: Loss = 0.000000451\n",
      "Epoka 37960: Loss = 0.000001295\n",
      "Epoka 37970: Loss = 0.000000486\n",
      "Epoka 37980: Loss = 0.000000760\n",
      "Epoka 37990: Loss = 0.000000446\n",
      "Epoka 38000: Loss = 0.000000915\n",
      "Epoka 38010: Loss = 0.000000635\n",
      "Epoka 38020: Loss = 0.000000404\n",
      "Epoka 38030: Loss = 0.000000538\n",
      "Epoka 38040: Loss = 0.000000423\n",
      "Epoka 38050: Loss = 0.000000549\n",
      "Epoka 38060: Loss = 0.000000581\n",
      "Epoka 38070: Loss = 0.000000982\n",
      "Epoka 38080: Loss = 0.000001155\n",
      "Epoka 38090: Loss = 0.000000889\n",
      "Epoka 38100: Loss = 0.000000400\n",
      "Epoka 38110: Loss = 0.000000665\n",
      "Epoka 38120: Loss = 0.000000589\n",
      "Epoka 38130: Loss = 0.000000469\n",
      "Epoka 38140: Loss = 0.000000761\n",
      "Epoka 38150: Loss = 0.000000438\n",
      "Epoka 38160: Loss = 0.000000468\n",
      "Epoka 38170: Loss = 0.000001211\n",
      "Epoka 38180: Loss = 0.000000684\n",
      "Epoka 38190: Loss = 0.000001355\n",
      "Epoka 38200: Loss = 0.000000415\n",
      "Epoka 38210: Loss = 0.000000419\n",
      "Epoka 38220: Loss = 0.000000618\n",
      "Epoka 38230: Loss = 0.000000598\n",
      "Epoka 38240: Loss = 0.000001039\n",
      "Epoka 38250: Loss = 0.000000675\n",
      "Epoka 38260: Loss = 0.000000543\n",
      "Epoka 38270: Loss = 0.000001117\n",
      "Epoka 38280: Loss = 0.000000550\n",
      "Epoka 38290: Loss = 0.000001020\n",
      "Epoka 38300: Loss = 0.000000396\n",
      "Epoka 38310: Loss = 0.000000413\n",
      "Epoka 38320: Loss = 0.000000563\n",
      "Epoka 38330: Loss = 0.000000424\n",
      "Epoka 38340: Loss = 0.000000466\n",
      "Epoka 38350: Loss = 0.000000526\n",
      "Epoka 38360: Loss = 0.000000651\n",
      "Epoka 38370: Loss = 0.000000603\n",
      "Epoka 38380: Loss = 0.000000416\n",
      "Epoka 38390: Loss = 0.000001379\n",
      "Epoka 38400: Loss = 0.000000419\n",
      "Epoka 38410: Loss = 0.000000438\n",
      "Epoka 38420: Loss = 0.000000492\n",
      "Epoka 38430: Loss = 0.000000747\n",
      "Epoka 38440: Loss = 0.000001071\n",
      "Epoka 38450: Loss = 0.000001147\n",
      "Epoka 38460: Loss = 0.000000832\n",
      "Epoka 38470: Loss = 0.000000661\n",
      "Epoka 38480: Loss = 0.000000434\n",
      "Epoka 38490: Loss = 0.000000445\n",
      "Epoka 38500: Loss = 0.000000387\n",
      "Epoka 38510: Loss = 0.000000401\n",
      "Epoka 38520: Loss = 0.000000780\n",
      "Epoka 38530: Loss = 0.000000395\n",
      "Epoka 38540: Loss = 0.000000504\n",
      "Epoka 38550: Loss = 0.000000564\n",
      "Epoka 38560: Loss = 0.000000413\n",
      "Epoka 38570: Loss = 0.000000856\n",
      "Epoka 38580: Loss = 0.000000669\n",
      "Epoka 38590: Loss = 0.000000522\n",
      "Epoka 38600: Loss = 0.000000500\n",
      "Epoka 38610: Loss = 0.000000527\n",
      "Epoka 38620: Loss = 0.000000457\n",
      "Epoka 38630: Loss = 0.000002291\n",
      "Epoka 38640: Loss = 0.000000722\n",
      "Epoka 38650: Loss = 0.000000644\n",
      "Epoka 38660: Loss = 0.000000450\n",
      "Epoka 38670: Loss = 0.000001194\n",
      "Epoka 38680: Loss = 0.000000638\n",
      "Epoka 38690: Loss = 0.000000397\n",
      "Epoka 38700: Loss = 0.000000531\n",
      "Epoka 38710: Loss = 0.000000401\n",
      "Epoka 38720: Loss = 0.000000814\n",
      "Epoka 38730: Loss = 0.000000484\n",
      "Epoka 38740: Loss = 0.000000440\n",
      "Epoka 38750: Loss = 0.000000440\n",
      "Epoka 38760: Loss = 0.000000978\n",
      "Epoka 38770: Loss = 0.000001365\n",
      "Epoka 38780: Loss = 0.000000709\n",
      "Epoka 38790: Loss = 0.000000397\n",
      "Epoka 38800: Loss = 0.000000443\n",
      "Epoka 38810: Loss = 0.000000395\n",
      "Epoka 38820: Loss = 0.000000581\n",
      "Epoka 38830: Loss = 0.000000471\n",
      "Epoka 38840: Loss = 0.000000793\n",
      "Epoka 38850: Loss = 0.000000414\n",
      "Epoka 38860: Loss = 0.000000425\n",
      "Epoka 38870: Loss = 0.000000426\n",
      "Epoka 38880: Loss = 0.000000977\n",
      "Epoka 38890: Loss = 0.000000386\n",
      "Epoka 38900: Loss = 0.000000389\n",
      "Epoka 38910: Loss = 0.000000419\n",
      "Epoka 38920: Loss = 0.000000426\n",
      "Epoka 38930: Loss = 0.000000422\n",
      "Epoka 38940: Loss = 0.000000710\n",
      "Epoka 38950: Loss = 0.000000395\n",
      "Epoka 38960: Loss = 0.000000392\n",
      "Epoka 38970: Loss = 0.000000550\n",
      "Epoka 38980: Loss = 0.000000531\n",
      "Epoka 38990: Loss = 0.000000505\n",
      "Epoka 39000: Loss = 0.000001864\n",
      "Epoka 39010: Loss = 0.000000496\n",
      "Epoka 39020: Loss = 0.000000424\n",
      "Epoka 39030: Loss = 0.000000548\n",
      "Epoka 39040: Loss = 0.000000435\n",
      "Epoka 39050: Loss = 0.000001247\n",
      "Epoka 39060: Loss = 0.000000478\n",
      "Epoka 39070: Loss = 0.000000550\n",
      "Epoka 39080: Loss = 0.000000518\n",
      "Epoka 39090: Loss = 0.000000468\n",
      "Epoka 39100: Loss = 0.000000962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 39110: Loss = 0.000000629\n",
      "Epoka 39120: Loss = 0.000000495\n",
      "Epoka 39130: Loss = 0.000000383\n",
      "Epoka 39140: Loss = 0.000000607\n",
      "Epoka 39150: Loss = 0.000000407\n",
      "Epoka 39160: Loss = 0.000000410\n",
      "Epoka 39170: Loss = 0.000000421\n",
      "Epoka 39180: Loss = 0.000000669\n",
      "Epoka 39190: Loss = 0.000000484\n",
      "Epoka 39200: Loss = 0.000000382\n",
      "Epoka 39210: Loss = 0.000000386\n",
      "Epoka 39220: Loss = 0.000000662\n",
      "Epoka 39230: Loss = 0.000000424\n",
      "Epoka 39240: Loss = 0.000000524\n",
      "Epoka 39250: Loss = 0.000001094\n",
      "Epoka 39260: Loss = 0.000000806\n",
      "Epoka 39270: Loss = 0.000000423\n",
      "Epoka 39280: Loss = 0.000000518\n",
      "Epoka 39290: Loss = 0.000000589\n",
      "Epoka 39300: Loss = 0.000001127\n",
      "Epoka 39310: Loss = 0.000001258\n",
      "Epoka 39320: Loss = 0.000000397\n",
      "Epoka 39330: Loss = 0.000000424\n",
      "Epoka 39340: Loss = 0.000000441\n",
      "Epoka 39350: Loss = 0.000000857\n",
      "Epoka 39360: Loss = 0.000000971\n",
      "Epoka 39370: Loss = 0.000000638\n",
      "Epoka 39380: Loss = 0.000000762\n",
      "Epoka 39390: Loss = 0.000000372\n",
      "Epoka 39400: Loss = 0.000000744\n",
      "Epoka 39410: Loss = 0.000000433\n",
      "Epoka 39420: Loss = 0.000000396\n",
      "Epoka 39430: Loss = 0.000001238\n",
      "Epoka 39440: Loss = 0.000000543\n",
      "Epoka 39450: Loss = 0.000000450\n",
      "Epoka 39460: Loss = 0.000000455\n",
      "Epoka 39470: Loss = 0.000000391\n",
      "Epoka 39480: Loss = 0.000000614\n",
      "Epoka 39490: Loss = 0.000001021\n",
      "Epoka 39500: Loss = 0.000000395\n",
      "Epoka 39510: Loss = 0.000000662\n",
      "Epoka 39520: Loss = 0.000000379\n",
      "Epoka 39530: Loss = 0.000000391\n",
      "Epoka 39540: Loss = 0.000000424\n",
      "Epoka 39550: Loss = 0.000000535\n",
      "Epoka 39560: Loss = 0.000000390\n",
      "Epoka 39570: Loss = 0.000000561\n",
      "Epoka 39580: Loss = 0.000000543\n",
      "Epoka 39590: Loss = 0.000000612\n",
      "Epoka 39600: Loss = 0.000000408\n",
      "Epoka 39610: Loss = 0.000001447\n",
      "Epoka 39620: Loss = 0.000001078\n",
      "Epoka 39630: Loss = 0.000000641\n",
      "Epoka 39640: Loss = 0.000000374\n",
      "Epoka 39650: Loss = 0.000000376\n",
      "Epoka 39660: Loss = 0.000000680\n",
      "Epoka 39670: Loss = 0.000000369\n",
      "Epoka 39680: Loss = 0.000001277\n",
      "Epoka 39690: Loss = 0.000000460\n",
      "Epoka 39700: Loss = 0.000000882\n",
      "Epoka 39710: Loss = 0.000000491\n",
      "Epoka 39720: Loss = 0.000000938\n",
      "Epoka 39730: Loss = 0.000001059\n",
      "Epoka 39740: Loss = 0.000000556\n",
      "Epoka 39750: Loss = 0.000000526\n",
      "Epoka 39760: Loss = 0.000000850\n",
      "Epoka 39770: Loss = 0.000000881\n",
      "Epoka 39780: Loss = 0.000000636\n",
      "Epoka 39790: Loss = 0.000000570\n",
      "Epoka 39800: Loss = 0.000000491\n",
      "Epoka 39810: Loss = 0.000000506\n",
      "Epoka 39820: Loss = 0.000000395\n",
      "Epoka 39830: Loss = 0.000000500\n",
      "Epoka 39840: Loss = 0.000000403\n",
      "Epoka 39850: Loss = 0.000000404\n",
      "Epoka 39860: Loss = 0.000000523\n",
      "Epoka 39870: Loss = 0.000000540\n",
      "Epoka 39880: Loss = 0.000000415\n",
      "Epoka 39890: Loss = 0.000000420\n",
      "Epoka 39900: Loss = 0.000000417\n",
      "Epoka 39910: Loss = 0.000000527\n",
      "Epoka 39920: Loss = 0.000000527\n",
      "Epoka 39930: Loss = 0.000000949\n",
      "Epoka 39940: Loss = 0.000000627\n",
      "Epoka 39950: Loss = 0.000000375\n",
      "Epoka 39960: Loss = 0.000000526\n",
      "Epoka 39970: Loss = 0.000000433\n",
      "Epoka 39980: Loss = 0.000000685\n",
      "Epoka 39990: Loss = 0.000000388\n",
      "Czas wykonania: 253.907934 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_squareL2 = MLPNoBackprop(layer_sizes = [1, 10, 1])\n",
    "start_time = time.time()\n",
    "mlp_squareL2.RMSprop(X_squareL_train_normalized, Y_squareL_train_normalized, epochs = 40000, learning_rate=0.001, beta=0.8, epsilon=1e-7, batch_size=32)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "50f5f15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.061736735484688\n"
     ]
    }
   ],
   "source": [
    "ypred_normalized = mlp_squareL2.predict(X_squareL_test_normalized)\n",
    "ypred = ypred_normalized *np.std(Y_squareL_train) +np.mean(Y_squareL_train)\n",
    "print(mlp_squareL2.mse(ypred, Y_squareL_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec867089",
   "metadata": {},
   "source": [
    "# mlp for steps large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310fe1c",
   "metadata": {},
   "source": [
    "## momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3bfc1d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 0.078298925\n",
      "Epoka 10: Loss = 0.073589094\n",
      "Epoka 20: Loss = 0.065887900\n",
      "Epoka 30: Loss = 0.065368869\n",
      "Epoka 40: Loss = 0.065370452\n",
      "Epoka 50: Loss = 0.064943214\n",
      "Epoka 60: Loss = 0.060482421\n",
      "Epoka 70: Loss = 0.057023564\n",
      "Epoka 80: Loss = 0.049337958\n",
      "Epoka 90: Loss = 0.035568235\n",
      "Epoka 100: Loss = 0.023999735\n",
      "Epoka 110: Loss = 0.021487372\n",
      "Epoka 120: Loss = 0.021175079\n",
      "Epoka 130: Loss = 0.019596136\n",
      "Epoka 140: Loss = 0.017504484\n",
      "Epoka 150: Loss = 0.015907085\n",
      "Epoka 160: Loss = 0.015273219\n",
      "Epoka 170: Loss = 0.014131078\n",
      "Epoka 180: Loss = 0.013981119\n",
      "Epoka 190: Loss = 0.012760201\n",
      "Epoka 200: Loss = 0.012056824\n",
      "Epoka 210: Loss = 0.011625913\n",
      "Epoka 220: Loss = 0.011216200\n",
      "Epoka 230: Loss = 0.011471128\n",
      "Epoka 240: Loss = 0.010701082\n",
      "Epoka 250: Loss = 0.010098069\n",
      "Epoka 260: Loss = 0.010497229\n",
      "Epoka 270: Loss = 0.009203224\n",
      "Epoka 280: Loss = 0.009042871\n",
      "Epoka 290: Loss = 0.008960283\n",
      "Epoka 300: Loss = 0.008378702\n",
      "Epoka 310: Loss = 0.008458612\n",
      "Epoka 320: Loss = 0.008065324\n",
      "Epoka 330: Loss = 0.009260769\n",
      "Epoka 340: Loss = 0.007647338\n",
      "Epoka 350: Loss = 0.008951940\n",
      "Epoka 360: Loss = 0.007917805\n",
      "Epoka 370: Loss = 0.007968553\n",
      "Epoka 380: Loss = 0.007418490\n",
      "Epoka 390: Loss = 0.007850479\n",
      "Epoka 400: Loss = 0.007234733\n",
      "Epoka 410: Loss = 0.006981395\n",
      "Epoka 420: Loss = 0.006911216\n",
      "Epoka 430: Loss = 0.006891834\n",
      "Epoka 440: Loss = 0.006754786\n",
      "Epoka 450: Loss = 0.006687663\n",
      "Epoka 460: Loss = 0.007162567\n",
      "Epoka 470: Loss = 0.006545445\n",
      "Epoka 480: Loss = 0.006480943\n",
      "Epoka 490: Loss = 0.006354112\n",
      "Epoka 500: Loss = 0.006450485\n",
      "Epoka 510: Loss = 0.006648730\n",
      "Epoka 520: Loss = 0.006440656\n",
      "Epoka 530: Loss = 0.006251124\n",
      "Epoka 540: Loss = 0.006796347\n",
      "Epoka 550: Loss = 0.006114346\n",
      "Epoka 560: Loss = 0.005994805\n",
      "Epoka 570: Loss = 0.006001377\n",
      "Epoka 580: Loss = 0.005928080\n",
      "Epoka 590: Loss = 0.005918574\n",
      "Epoka 600: Loss = 0.006306214\n",
      "Epoka 610: Loss = 0.005916553\n",
      "Epoka 620: Loss = 0.005656431\n",
      "Epoka 630: Loss = 0.005751232\n",
      "Epoka 640: Loss = 0.005672655\n",
      "Epoka 650: Loss = 0.005782102\n",
      "Epoka 660: Loss = 0.005453357\n",
      "Epoka 670: Loss = 0.005710086\n",
      "Epoka 680: Loss = 0.005486449\n",
      "Epoka 690: Loss = 0.005598523\n",
      "Epoka 700: Loss = 0.005349869\n",
      "Epoka 710: Loss = 0.005461924\n",
      "Epoka 720: Loss = 0.005420031\n",
      "Epoka 730: Loss = 0.005222508\n",
      "Epoka 740: Loss = 0.005176752\n",
      "Epoka 750: Loss = 0.005168983\n",
      "Epoka 760: Loss = 0.005312987\n",
      "Epoka 770: Loss = 0.005793076\n",
      "Epoka 780: Loss = 0.005128073\n",
      "Epoka 790: Loss = 0.005229618\n",
      "Epoka 800: Loss = 0.004926788\n",
      "Epoka 810: Loss = 0.004920454\n",
      "Epoka 820: Loss = 0.004880276\n",
      "Epoka 830: Loss = 0.004911114\n",
      "Epoka 840: Loss = 0.004896787\n",
      "Epoka 850: Loss = 0.004732149\n",
      "Epoka 860: Loss = 0.005011650\n",
      "Epoka 870: Loss = 0.004712856\n",
      "Epoka 880: Loss = 0.005002752\n",
      "Epoka 890: Loss = 0.004630311\n",
      "Epoka 900: Loss = 0.004580456\n",
      "Epoka 910: Loss = 0.004754837\n",
      "Epoka 920: Loss = 0.004967921\n",
      "Epoka 930: Loss = 0.004832852\n",
      "Epoka 940: Loss = 0.004626280\n",
      "Epoka 950: Loss = 0.004500814\n",
      "Epoka 960: Loss = 0.004973999\n",
      "Epoka 970: Loss = 0.004400102\n",
      "Epoka 980: Loss = 0.004561577\n",
      "Epoka 990: Loss = 0.004369255\n",
      "Epoka 1000: Loss = 0.004502888\n",
      "Epoka 1010: Loss = 0.004515852\n",
      "Epoka 1020: Loss = 0.004381765\n",
      "Epoka 1030: Loss = 0.004363105\n",
      "Epoka 1040: Loss = 0.004444581\n",
      "Epoka 1050: Loss = 0.004342913\n",
      "Epoka 1060: Loss = 0.004240731\n",
      "Epoka 1070: Loss = 0.004328054\n",
      "Epoka 1080: Loss = 0.004194980\n",
      "Epoka 1090: Loss = 0.004345464\n",
      "Epoka 1100: Loss = 0.004121531\n",
      "Epoka 1110: Loss = 0.004128801\n",
      "Epoka 1120: Loss = 0.004211009\n",
      "Epoka 1130: Loss = 0.004897785\n",
      "Epoka 1140: Loss = 0.004044404\n",
      "Epoka 1150: Loss = 0.004162492\n",
      "Epoka 1160: Loss = 0.004135579\n",
      "Epoka 1170: Loss = 0.004022231\n",
      "Epoka 1180: Loss = 0.003979166\n",
      "Epoka 1190: Loss = 0.004051310\n",
      "Epoka 1200: Loss = 0.003977260\n",
      "Epoka 1210: Loss = 0.003935991\n",
      "Epoka 1220: Loss = 0.004070231\n",
      "Epoka 1230: Loss = 0.003882651\n",
      "Epoka 1240: Loss = 0.003879779\n",
      "Epoka 1250: Loss = 0.003844104\n",
      "Epoka 1260: Loss = 0.003811778\n",
      "Epoka 1270: Loss = 0.003820157\n",
      "Epoka 1280: Loss = 0.004022892\n",
      "Epoka 1290: Loss = 0.003826085\n",
      "Epoka 1300: Loss = 0.003963748\n",
      "Epoka 1310: Loss = 0.003730019\n",
      "Epoka 1320: Loss = 0.003775619\n",
      "Epoka 1330: Loss = 0.003723425\n",
      "Epoka 1340: Loss = 0.003725391\n",
      "Epoka 1350: Loss = 0.003844222\n",
      "Epoka 1360: Loss = 0.003655161\n",
      "Epoka 1370: Loss = 0.003703357\n",
      "Epoka 1380: Loss = 0.003716672\n",
      "Epoka 1390: Loss = 0.003791182\n",
      "Epoka 1400: Loss = 0.003594043\n",
      "Epoka 1410: Loss = 0.003586548\n",
      "Epoka 1420: Loss = 0.003654082\n",
      "Epoka 1430: Loss = 0.003528718\n",
      "Epoka 1440: Loss = 0.003552313\n",
      "Epoka 1450: Loss = 0.003732118\n",
      "Epoka 1460: Loss = 0.003512403\n",
      "Epoka 1470: Loss = 0.003573656\n",
      "Epoka 1480: Loss = 0.003643590\n",
      "Epoka 1490: Loss = 0.003595601\n",
      "Epoka 1500: Loss = 0.003456380\n",
      "Epoka 1510: Loss = 0.003530829\n",
      "Epoka 1520: Loss = 0.003523016\n",
      "Epoka 1530: Loss = 0.003447332\n",
      "Epoka 1540: Loss = 0.003449869\n",
      "Epoka 1550: Loss = 0.003439382\n",
      "Epoka 1560: Loss = 0.003404144\n",
      "Epoka 1570: Loss = 0.003391164\n",
      "Epoka 1580: Loss = 0.003507119\n",
      "Epoka 1590: Loss = 0.003336242\n",
      "Epoka 1600: Loss = 0.003342151\n",
      "Epoka 1610: Loss = 0.003558060\n",
      "Epoka 1620: Loss = 0.003543628\n",
      "Epoka 1630: Loss = 0.003314723\n",
      "Epoka 1640: Loss = 0.003329872\n",
      "Epoka 1650: Loss = 0.003281367\n",
      "Epoka 1660: Loss = 0.003276322\n",
      "Epoka 1670: Loss = 0.003361867\n",
      "Epoka 1680: Loss = 0.003402008\n",
      "Epoka 1690: Loss = 0.003301429\n",
      "Epoka 1700: Loss = 0.003213404\n",
      "Epoka 1710: Loss = 0.003317355\n",
      "Epoka 1720: Loss = 0.003176265\n",
      "Epoka 1730: Loss = 0.003335818\n",
      "Epoka 1740: Loss = 0.003239618\n",
      "Epoka 1750: Loss = 0.003405230\n",
      "Epoka 1760: Loss = 0.003232103\n",
      "Epoka 1770: Loss = 0.003237552\n",
      "Epoka 1780: Loss = 0.003203667\n",
      "Epoka 1790: Loss = 0.003148771\n",
      "Epoka 1800: Loss = 0.003149168\n",
      "Epoka 1810: Loss = 0.003125965\n",
      "Epoka 1820: Loss = 0.003171337\n",
      "Epoka 1830: Loss = 0.003169284\n",
      "Epoka 1840: Loss = 0.003186200\n",
      "Epoka 1850: Loss = 0.003045200\n",
      "Epoka 1860: Loss = 0.003135892\n",
      "Epoka 1870: Loss = 0.003065834\n",
      "Epoka 1880: Loss = 0.003192809\n",
      "Epoka 1890: Loss = 0.003136297\n",
      "Epoka 1900: Loss = 0.003065767\n",
      "Epoka 1910: Loss = 0.003347000\n",
      "Epoka 1920: Loss = 0.003089634\n",
      "Epoka 1930: Loss = 0.003115126\n",
      "Epoka 1940: Loss = 0.002983253\n",
      "Epoka 1950: Loss = 0.003036492\n",
      "Epoka 1960: Loss = 0.003093027\n",
      "Epoka 1970: Loss = 0.003020289\n",
      "Epoka 1980: Loss = 0.003051424\n",
      "Epoka 1990: Loss = 0.003001673\n",
      "Epoka 2000: Loss = 0.002962652\n",
      "Epoka 2010: Loss = 0.002969289\n",
      "Epoka 2020: Loss = 0.003039661\n",
      "Epoka 2030: Loss = 0.002967236\n",
      "Epoka 2040: Loss = 0.002983204\n",
      "Epoka 2050: Loss = 0.002897131\n",
      "Epoka 2060: Loss = 0.002911220\n",
      "Epoka 2070: Loss = 0.002927748\n",
      "Epoka 2080: Loss = 0.003023525\n",
      "Epoka 2090: Loss = 0.002923059\n",
      "Epoka 2100: Loss = 0.002822776\n",
      "Epoka 2110: Loss = 0.003089177\n",
      "Epoka 2120: Loss = 0.002926166\n",
      "Epoka 2130: Loss = 0.002872078\n",
      "Epoka 2140: Loss = 0.002880856\n",
      "Epoka 2150: Loss = 0.002895450\n",
      "Epoka 2160: Loss = 0.003043365\n",
      "Epoka 2170: Loss = 0.002881087\n",
      "Epoka 2180: Loss = 0.002821912\n",
      "Epoka 2190: Loss = 0.002930769\n",
      "Epoka 2200: Loss = 0.002936994\n",
      "Epoka 2210: Loss = 0.002819534\n",
      "Epoka 2220: Loss = 0.002831996\n",
      "Epoka 2230: Loss = 0.002909426\n",
      "Epoka 2240: Loss = 0.003061164\n",
      "Epoka 2250: Loss = 0.002839471\n",
      "Epoka 2260: Loss = 0.002697594\n",
      "Epoka 2270: Loss = 0.002738352\n",
      "Epoka 2280: Loss = 0.002902791\n",
      "Epoka 2290: Loss = 0.002815847\n",
      "Epoka 2300: Loss = 0.002725966\n",
      "Epoka 2310: Loss = 0.002656809\n",
      "Epoka 2320: Loss = 0.002695918\n",
      "Epoka 2330: Loss = 0.002668396\n",
      "Epoka 2340: Loss = 0.002783746\n",
      "Epoka 2350: Loss = 0.002679593\n",
      "Epoka 2360: Loss = 0.002807162\n",
      "Epoka 2370: Loss = 0.002752194\n",
      "Epoka 2380: Loss = 0.002671703\n",
      "Epoka 2390: Loss = 0.002872381\n",
      "Epoka 2400: Loss = 0.002806351\n",
      "Epoka 2410: Loss = 0.002616814\n",
      "Epoka 2420: Loss = 0.002703415\n",
      "Epoka 2430: Loss = 0.002717804\n",
      "Epoka 2440: Loss = 0.002593451\n",
      "Epoka 2450: Loss = 0.002634801\n",
      "Epoka 2460: Loss = 0.002816791\n",
      "Epoka 2470: Loss = 0.002590673\n",
      "Epoka 2480: Loss = 0.002658491\n",
      "Epoka 2490: Loss = 0.002690170\n",
      "Epoka 2500: Loss = 0.002750907\n",
      "Epoka 2510: Loss = 0.002760941\n",
      "Epoka 2520: Loss = 0.002643640\n",
      "Epoka 2530: Loss = 0.002580127\n",
      "Epoka 2540: Loss = 0.002613606\n",
      "Epoka 2550: Loss = 0.002606954\n",
      "Epoka 2560: Loss = 0.002582234\n",
      "Epoka 2570: Loss = 0.002510892\n",
      "Epoka 2580: Loss = 0.002585893\n",
      "Epoka 2590: Loss = 0.002554667\n",
      "Epoka 2600: Loss = 0.002573117\n",
      "Epoka 2610: Loss = 0.002497143\n",
      "Epoka 2620: Loss = 0.002642280\n",
      "Epoka 2630: Loss = 0.002474886\n",
      "Epoka 2640: Loss = 0.002492957\n",
      "Epoka 2650: Loss = 0.002477327\n",
      "Epoka 2660: Loss = 0.002498318\n",
      "Epoka 2670: Loss = 0.002507173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 2680: Loss = 0.002431360\n",
      "Epoka 2690: Loss = 0.002438535\n",
      "Epoka 2700: Loss = 0.002406432\n",
      "Epoka 2710: Loss = 0.002518947\n",
      "Epoka 2720: Loss = 0.002404382\n",
      "Epoka 2730: Loss = 0.002587202\n",
      "Epoka 2740: Loss = 0.002790277\n",
      "Epoka 2750: Loss = 0.002425120\n",
      "Epoka 2760: Loss = 0.002448436\n",
      "Epoka 2770: Loss = 0.002574954\n",
      "Epoka 2780: Loss = 0.002391214\n",
      "Epoka 2790: Loss = 0.002381329\n",
      "Epoka 2800: Loss = 0.002547043\n",
      "Epoka 2810: Loss = 0.002472277\n",
      "Epoka 2820: Loss = 0.002502831\n",
      "Epoka 2830: Loss = 0.002800505\n",
      "Epoka 2840: Loss = 0.002381561\n",
      "Epoka 2850: Loss = 0.002365846\n",
      "Epoka 2860: Loss = 0.002416413\n",
      "Epoka 2870: Loss = 0.002428317\n",
      "Epoka 2880: Loss = 0.002429228\n",
      "Epoka 2890: Loss = 0.002435879\n",
      "Epoka 2900: Loss = 0.002384466\n",
      "Epoka 2910: Loss = 0.002651302\n",
      "Epoka 2920: Loss = 0.002313429\n",
      "Epoka 2930: Loss = 0.002341046\n",
      "Epoka 2940: Loss = 0.002361217\n",
      "Epoka 2950: Loss = 0.002334320\n",
      "Epoka 2960: Loss = 0.002675608\n",
      "Epoka 2970: Loss = 0.002345916\n",
      "Epoka 2980: Loss = 0.002332633\n",
      "Epoka 2990: Loss = 0.002286598\n",
      "Epoka 3000: Loss = 0.002597344\n",
      "Epoka 3010: Loss = 0.002279376\n",
      "Epoka 3020: Loss = 0.002253933\n",
      "Epoka 3030: Loss = 0.002404460\n",
      "Epoka 3040: Loss = 0.002410506\n",
      "Epoka 3050: Loss = 0.002238658\n",
      "Epoka 3060: Loss = 0.002286526\n",
      "Epoka 3070: Loss = 0.002304722\n",
      "Epoka 3080: Loss = 0.002350138\n",
      "Epoka 3090: Loss = 0.002263519\n",
      "Epoka 3100: Loss = 0.002326893\n",
      "Epoka 3110: Loss = 0.002211161\n",
      "Epoka 3120: Loss = 0.002297351\n",
      "Epoka 3130: Loss = 0.002343676\n",
      "Epoka 3140: Loss = 0.002212166\n",
      "Epoka 3150: Loss = 0.002399129\n",
      "Epoka 3160: Loss = 0.002261049\n",
      "Epoka 3170: Loss = 0.002320898\n",
      "Epoka 3180: Loss = 0.002178754\n",
      "Epoka 3190: Loss = 0.002216327\n",
      "Epoka 3200: Loss = 0.002198252\n",
      "Epoka 3210: Loss = 0.002195332\n",
      "Epoka 3220: Loss = 0.002166801\n",
      "Epoka 3230: Loss = 0.002259764\n",
      "Epoka 3240: Loss = 0.002553609\n",
      "Epoka 3250: Loss = 0.002337505\n",
      "Epoka 3260: Loss = 0.002134730\n",
      "Epoka 3270: Loss = 0.002146935\n",
      "Epoka 3280: Loss = 0.002257363\n",
      "Epoka 3290: Loss = 0.002203454\n",
      "Epoka 3300: Loss = 0.002295154\n",
      "Epoka 3310: Loss = 0.002383803\n",
      "Epoka 3320: Loss = 0.002154443\n",
      "Epoka 3330: Loss = 0.002144305\n",
      "Epoka 3340: Loss = 0.002132136\n",
      "Epoka 3350: Loss = 0.002262402\n",
      "Epoka 3360: Loss = 0.002134854\n",
      "Epoka 3370: Loss = 0.002147954\n",
      "Epoka 3380: Loss = 0.002128133\n",
      "Epoka 3390: Loss = 0.002113778\n",
      "Epoka 3400: Loss = 0.002270080\n",
      "Epoka 3410: Loss = 0.002334856\n",
      "Epoka 3420: Loss = 0.002106007\n",
      "Epoka 3430: Loss = 0.002214465\n",
      "Epoka 3440: Loss = 0.002147704\n",
      "Epoka 3450: Loss = 0.002104061\n",
      "Epoka 3460: Loss = 0.002061292\n",
      "Epoka 3470: Loss = 0.002114890\n",
      "Epoka 3480: Loss = 0.002195123\n",
      "Epoka 3490: Loss = 0.002206470\n",
      "Epoka 3500: Loss = 0.002091168\n",
      "Epoka 3510: Loss = 0.002119138\n",
      "Epoka 3520: Loss = 0.002138150\n",
      "Epoka 3530: Loss = 0.002051606\n",
      "Epoka 3540: Loss = 0.002060485\n",
      "Epoka 3550: Loss = 0.002073515\n",
      "Epoka 3560: Loss = 0.002089630\n",
      "Epoka 3570: Loss = 0.002057784\n",
      "Epoka 3580: Loss = 0.002077355\n",
      "Epoka 3590: Loss = 0.002037121\n",
      "Epoka 3600: Loss = 0.002101294\n",
      "Epoka 3610: Loss = 0.002134104\n",
      "Epoka 3620: Loss = 0.002064024\n",
      "Epoka 3630: Loss = 0.002050248\n",
      "Epoka 3640: Loss = 0.002347606\n",
      "Epoka 3650: Loss = 0.002085403\n",
      "Epoka 3660: Loss = 0.002269554\n",
      "Epoka 3670: Loss = 0.002058428\n",
      "Epoka 3680: Loss = 0.002353806\n",
      "Epoka 3690: Loss = 0.002088079\n",
      "Epoka 3700: Loss = 0.002007310\n",
      "Epoka 3710: Loss = 0.002072300\n",
      "Epoka 3720: Loss = 0.002009022\n",
      "Epoka 3730: Loss = 0.002053432\n",
      "Epoka 3740: Loss = 0.002551707\n",
      "Epoka 3750: Loss = 0.002064779\n",
      "Epoka 3760: Loss = 0.002206113\n",
      "Epoka 3770: Loss = 0.002005485\n",
      "Epoka 3780: Loss = 0.001988831\n",
      "Epoka 3790: Loss = 0.002000448\n",
      "Epoka 3800: Loss = 0.002053069\n",
      "Epoka 3810: Loss = 0.002057870\n",
      "Epoka 3820: Loss = 0.001976996\n",
      "Epoka 3830: Loss = 0.002148540\n",
      "Epoka 3840: Loss = 0.002018322\n",
      "Epoka 3850: Loss = 0.002004253\n",
      "Epoka 3860: Loss = 0.002090289\n",
      "Epoka 3870: Loss = 0.002047843\n",
      "Epoka 3880: Loss = 0.001955884\n",
      "Epoka 3890: Loss = 0.002040366\n",
      "Epoka 3900: Loss = 0.001994357\n",
      "Epoka 3910: Loss = 0.002121703\n",
      "Epoka 3920: Loss = 0.002048443\n",
      "Epoka 3930: Loss = 0.002110622\n",
      "Epoka 3940: Loss = 0.002031188\n",
      "Epoka 3950: Loss = 0.001969668\n",
      "Epoka 3960: Loss = 0.002059062\n",
      "Epoka 3970: Loss = 0.002032512\n",
      "Epoka 3980: Loss = 0.002075438\n",
      "Epoka 3990: Loss = 0.002009427\n",
      "Epoka 4000: Loss = 0.001983716\n",
      "Epoka 4010: Loss = 0.001917596\n",
      "Epoka 4020: Loss = 0.002189659\n",
      "Epoka 4030: Loss = 0.002116307\n",
      "Epoka 4040: Loss = 0.002125225\n",
      "Epoka 4050: Loss = 0.001974441\n",
      "Epoka 4060: Loss = 0.001919322\n",
      "Epoka 4070: Loss = 0.001982238\n",
      "Epoka 4080: Loss = 0.001938286\n",
      "Epoka 4090: Loss = 0.001988005\n",
      "Epoka 4100: Loss = 0.001944934\n",
      "Epoka 4110: Loss = 0.001896019\n",
      "Epoka 4120: Loss = 0.001947544\n",
      "Epoka 4130: Loss = 0.001926849\n",
      "Epoka 4140: Loss = 0.001991096\n",
      "Epoka 4150: Loss = 0.001928687\n",
      "Epoka 4160: Loss = 0.001887118\n",
      "Epoka 4170: Loss = 0.002019326\n",
      "Epoka 4180: Loss = 0.002024176\n",
      "Epoka 4190: Loss = 0.001912581\n",
      "Epoka 4200: Loss = 0.001946722\n",
      "Epoka 4210: Loss = 0.001886089\n",
      "Epoka 4220: Loss = 0.001973586\n",
      "Epoka 4230: Loss = 0.001882563\n",
      "Epoka 4240: Loss = 0.001888779\n",
      "Epoka 4250: Loss = 0.001882986\n",
      "Epoka 4260: Loss = 0.002271289\n",
      "Epoka 4270: Loss = 0.001911296\n",
      "Epoka 4280: Loss = 0.001900845\n",
      "Epoka 4290: Loss = 0.001876456\n",
      "Epoka 4300: Loss = 0.001880900\n",
      "Epoka 4310: Loss = 0.001993536\n",
      "Epoka 4320: Loss = 0.002044832\n",
      "Epoka 4330: Loss = 0.001923367\n",
      "Epoka 4340: Loss = 0.002002768\n",
      "Epoka 4350: Loss = 0.001957385\n",
      "Epoka 4360: Loss = 0.002045732\n",
      "Epoka 4370: Loss = 0.001867762\n",
      "Epoka 4380: Loss = 0.001872033\n",
      "Epoka 4390: Loss = 0.001896232\n",
      "Epoka 4400: Loss = 0.001842769\n",
      "Epoka 4410: Loss = 0.001831276\n",
      "Epoka 4420: Loss = 0.002276255\n",
      "Epoka 4430: Loss = 0.001859904\n",
      "Epoka 4440: Loss = 0.001874277\n",
      "Epoka 4450: Loss = 0.001868866\n",
      "Epoka 4460: Loss = 0.001957103\n",
      "Epoka 4470: Loss = 0.002071233\n",
      "Epoka 4480: Loss = 0.002013808\n",
      "Epoka 4490: Loss = 0.001818367\n",
      "Epoka 4500: Loss = 0.001976615\n",
      "Epoka 4510: Loss = 0.001843236\n",
      "Epoka 4520: Loss = 0.001995194\n",
      "Epoka 4530: Loss = 0.001929668\n",
      "Epoka 4540: Loss = 0.001857654\n",
      "Epoka 4550: Loss = 0.001812963\n",
      "Epoka 4560: Loss = 0.001967287\n",
      "Epoka 4570: Loss = 0.001864141\n",
      "Epoka 4580: Loss = 0.002031939\n",
      "Epoka 4590: Loss = 0.001895162\n",
      "Epoka 4600: Loss = 0.001873180\n",
      "Epoka 4610: Loss = 0.001929648\n",
      "Epoka 4620: Loss = 0.001842492\n",
      "Epoka 4630: Loss = 0.001881642\n",
      "Epoka 4640: Loss = 0.001802509\n",
      "Epoka 4650: Loss = 0.001907972\n",
      "Epoka 4660: Loss = 0.001803262\n",
      "Epoka 4670: Loss = 0.001976454\n",
      "Epoka 4680: Loss = 0.001846322\n",
      "Epoka 4690: Loss = 0.001812324\n",
      "Epoka 4700: Loss = 0.001906416\n",
      "Epoka 4710: Loss = 0.001837435\n",
      "Epoka 4720: Loss = 0.001811963\n",
      "Epoka 4730: Loss = 0.001866433\n",
      "Epoka 4740: Loss = 0.001786195\n",
      "Epoka 4750: Loss = 0.001794881\n",
      "Epoka 4760: Loss = 0.001922570\n",
      "Epoka 4770: Loss = 0.001767084\n",
      "Epoka 4780: Loss = 0.001781733\n",
      "Epoka 4790: Loss = 0.001886108\n",
      "Epoka 4800: Loss = 0.001791424\n",
      "Epoka 4810: Loss = 0.001807516\n",
      "Epoka 4820: Loss = 0.001771465\n",
      "Epoka 4830: Loss = 0.001758993\n",
      "Epoka 4840: Loss = 0.001828094\n",
      "Epoka 4850: Loss = 0.001769772\n",
      "Epoka 4860: Loss = 0.001904275\n",
      "Epoka 4870: Loss = 0.001750427\n",
      "Epoka 4880: Loss = 0.001802571\n",
      "Epoka 4890: Loss = 0.001876278\n",
      "Epoka 4900: Loss = 0.001904057\n",
      "Epoka 4910: Loss = 0.001745748\n",
      "Epoka 4920: Loss = 0.001868249\n",
      "Epoka 4930: Loss = 0.001764382\n",
      "Epoka 4940: Loss = 0.001770842\n",
      "Epoka 4950: Loss = 0.001945870\n",
      "Epoka 4960: Loss = 0.001739688\n",
      "Epoka 4970: Loss = 0.001899479\n",
      "Epoka 4980: Loss = 0.001786843\n",
      "Epoka 4990: Loss = 0.001940320\n",
      "Epoka 5000: Loss = 0.001743511\n",
      "Epoka 5010: Loss = 0.001740249\n",
      "Epoka 5020: Loss = 0.001765749\n",
      "Epoka 5030: Loss = 0.001745866\n",
      "Epoka 5040: Loss = 0.001862525\n",
      "Epoka 5050: Loss = 0.001738900\n",
      "Epoka 5060: Loss = 0.001753236\n",
      "Epoka 5070: Loss = 0.001750776\n",
      "Epoka 5080: Loss = 0.001711258\n",
      "Epoka 5090: Loss = 0.001822349\n",
      "Epoka 5100: Loss = 0.001817566\n",
      "Epoka 5110: Loss = 0.001724737\n",
      "Epoka 5120: Loss = 0.001898071\n",
      "Epoka 5130: Loss = 0.001704648\n",
      "Epoka 5140: Loss = 0.001821639\n",
      "Epoka 5150: Loss = 0.001871968\n",
      "Epoka 5160: Loss = 0.001707484\n",
      "Epoka 5170: Loss = 0.001761842\n",
      "Epoka 5180: Loss = 0.001723796\n",
      "Epoka 5190: Loss = 0.001748254\n",
      "Epoka 5200: Loss = 0.001705304\n",
      "Epoka 5210: Loss = 0.001928393\n",
      "Epoka 5220: Loss = 0.001699718\n",
      "Epoka 5230: Loss = 0.001833880\n",
      "Epoka 5240: Loss = 0.001720366\n",
      "Epoka 5250: Loss = 0.001708447\n",
      "Epoka 5260: Loss = 0.001688564\n",
      "Epoka 5270: Loss = 0.001707686\n",
      "Epoka 5280: Loss = 0.001708714\n",
      "Epoka 5290: Loss = 0.001698553\n",
      "Epoka 5300: Loss = 0.001730198\n",
      "Epoka 5310: Loss = 0.001686646\n",
      "Epoka 5320: Loss = 0.001750685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 5330: Loss = 0.001706309\n",
      "Epoka 5340: Loss = 0.001850850\n",
      "Epoka 5350: Loss = 0.001816794\n",
      "Epoka 5360: Loss = 0.001842090\n",
      "Epoka 5370: Loss = 0.001877243\n",
      "Epoka 5380: Loss = 0.001782558\n",
      "Epoka 5390: Loss = 0.001784261\n",
      "Epoka 5400: Loss = 0.001713683\n",
      "Epoka 5410: Loss = 0.001706136\n",
      "Epoka 5420: Loss = 0.001659429\n",
      "Epoka 5430: Loss = 0.001688008\n",
      "Epoka 5440: Loss = 0.001660671\n",
      "Epoka 5450: Loss = 0.001659218\n",
      "Epoka 5460: Loss = 0.001750939\n",
      "Epoka 5470: Loss = 0.001706875\n",
      "Epoka 5480: Loss = 0.001718133\n",
      "Epoka 5490: Loss = 0.001805189\n",
      "Epoka 5500: Loss = 0.001695549\n",
      "Epoka 5510: Loss = 0.001691430\n",
      "Epoka 5520: Loss = 0.001763114\n",
      "Epoka 5530: Loss = 0.001722893\n",
      "Epoka 5540: Loss = 0.001654763\n",
      "Epoka 5550: Loss = 0.001628017\n",
      "Epoka 5560: Loss = 0.001708998\n",
      "Epoka 5570: Loss = 0.001682612\n",
      "Epoka 5580: Loss = 0.001728703\n",
      "Epoka 5590: Loss = 0.001738392\n",
      "Epoka 5600: Loss = 0.001704485\n",
      "Epoka 5610: Loss = 0.001739234\n",
      "Epoka 5620: Loss = 0.001739521\n",
      "Epoka 5630: Loss = 0.001610707\n",
      "Epoka 5640: Loss = 0.001719488\n",
      "Epoka 5650: Loss = 0.001868707\n",
      "Epoka 5660: Loss = 0.001682974\n",
      "Epoka 5670: Loss = 0.001614255\n",
      "Epoka 5680: Loss = 0.001693048\n",
      "Epoka 5690: Loss = 0.001636348\n",
      "Epoka 5700: Loss = 0.001700744\n",
      "Epoka 5710: Loss = 0.001623225\n",
      "Epoka 5720: Loss = 0.001627653\n",
      "Epoka 5730: Loss = 0.001752752\n",
      "Epoka 5740: Loss = 0.001681947\n",
      "Epoka 5750: Loss = 0.001663804\n",
      "Epoka 5760: Loss = 0.001824129\n",
      "Epoka 5770: Loss = 0.001738977\n",
      "Epoka 5780: Loss = 0.001646873\n",
      "Epoka 5790: Loss = 0.001785820\n",
      "Epoka 5800: Loss = 0.001651129\n",
      "Epoka 5810: Loss = 0.001623862\n",
      "Epoka 5820: Loss = 0.001720916\n",
      "Epoka 5830: Loss = 0.001860266\n",
      "Epoka 5840: Loss = 0.001620758\n",
      "Epoka 5850: Loss = 0.001674884\n",
      "Epoka 5860: Loss = 0.001618511\n",
      "Epoka 5870: Loss = 0.001671787\n",
      "Epoka 5880: Loss = 0.001747817\n",
      "Epoka 5890: Loss = 0.001702879\n",
      "Epoka 5900: Loss = 0.001707727\n",
      "Epoka 5910: Loss = 0.001641422\n",
      "Epoka 5920: Loss = 0.001604220\n",
      "Epoka 5930: Loss = 0.001582411\n",
      "Epoka 5940: Loss = 0.001682073\n",
      "Epoka 5950: Loss = 0.001680822\n",
      "Epoka 5960: Loss = 0.001760031\n",
      "Epoka 5970: Loss = 0.001644782\n",
      "Epoka 5980: Loss = 0.001722640\n",
      "Epoka 5990: Loss = 0.001624336\n",
      "Epoka 6000: Loss = 0.001562337\n",
      "Epoka 6010: Loss = 0.001641154\n",
      "Epoka 6020: Loss = 0.001580213\n",
      "Epoka 6030: Loss = 0.001596088\n",
      "Epoka 6040: Loss = 0.001567614\n",
      "Epoka 6050: Loss = 0.001659719\n",
      "Epoka 6060: Loss = 0.001569913\n",
      "Epoka 6070: Loss = 0.001725373\n",
      "Epoka 6080: Loss = 0.001581121\n",
      "Epoka 6090: Loss = 0.001571883\n",
      "Epoka 6100: Loss = 0.001573494\n",
      "Epoka 6110: Loss = 0.001549015\n",
      "Epoka 6120: Loss = 0.001644599\n",
      "Epoka 6130: Loss = 0.002111928\n",
      "Epoka 6140: Loss = 0.001546578\n",
      "Epoka 6150: Loss = 0.001726760\n",
      "Epoka 6160: Loss = 0.001638489\n",
      "Epoka 6170: Loss = 0.001700919\n",
      "Epoka 6180: Loss = 0.001591207\n",
      "Epoka 6190: Loss = 0.001705217\n",
      "Epoka 6200: Loss = 0.001589752\n",
      "Epoka 6210: Loss = 0.001656435\n",
      "Epoka 6220: Loss = 0.001720000\n",
      "Epoka 6230: Loss = 0.001560600\n",
      "Epoka 6240: Loss = 0.001635018\n",
      "Epoka 6250: Loss = 0.001715368\n",
      "Epoka 6260: Loss = 0.001620179\n",
      "Epoka 6270: Loss = 0.001957645\n",
      "Epoka 6280: Loss = 0.001571318\n",
      "Epoka 6290: Loss = 0.001809306\n",
      "Epoka 6300: Loss = 0.001564664\n",
      "Epoka 6310: Loss = 0.001596744\n",
      "Epoka 6320: Loss = 0.001564285\n",
      "Epoka 6330: Loss = 0.001562288\n",
      "Epoka 6340: Loss = 0.001598410\n",
      "Epoka 6350: Loss = 0.001552005\n",
      "Epoka 6360: Loss = 0.001671679\n",
      "Epoka 6370: Loss = 0.001638048\n",
      "Epoka 6380: Loss = 0.001895740\n",
      "Epoka 6390: Loss = 0.001607451\n",
      "Epoka 6400: Loss = 0.001575452\n",
      "Epoka 6410: Loss = 0.001665690\n",
      "Epoka 6420: Loss = 0.001774308\n",
      "Epoka 6430: Loss = 0.001584431\n",
      "Epoka 6440: Loss = 0.001590326\n",
      "Epoka 6450: Loss = 0.001621823\n",
      "Epoka 6460: Loss = 0.001721527\n",
      "Epoka 6470: Loss = 0.001533413\n",
      "Epoka 6480: Loss = 0.001736457\n",
      "Epoka 6490: Loss = 0.001559703\n",
      "Epoka 6500: Loss = 0.001652176\n",
      "Epoka 6510: Loss = 0.001546066\n",
      "Epoka 6520: Loss = 0.001611289\n",
      "Epoka 6530: Loss = 0.001537205\n",
      "Epoka 6540: Loss = 0.001573287\n",
      "Epoka 6550: Loss = 0.001636761\n",
      "Epoka 6560: Loss = 0.001629457\n",
      "Epoka 6570: Loss = 0.001534281\n",
      "Epoka 6580: Loss = 0.001551650\n",
      "Epoka 6590: Loss = 0.001490738\n",
      "Epoka 6600: Loss = 0.001546842\n",
      "Epoka 6610: Loss = 0.001626221\n",
      "Epoka 6620: Loss = 0.001530811\n",
      "Epoka 6630: Loss = 0.001555775\n",
      "Epoka 6640: Loss = 0.001514931\n",
      "Epoka 6650: Loss = 0.001489997\n",
      "Epoka 6660: Loss = 0.001529590\n",
      "Epoka 6670: Loss = 0.001510273\n",
      "Epoka 6680: Loss = 0.001516327\n",
      "Epoka 6690: Loss = 0.001507837\n",
      "Epoka 6700: Loss = 0.001632126\n",
      "Epoka 6710: Loss = 0.001536706\n",
      "Epoka 6720: Loss = 0.001507751\n",
      "Epoka 6730: Loss = 0.001613435\n",
      "Epoka 6740: Loss = 0.001587386\n",
      "Epoka 6750: Loss = 0.001473281\n",
      "Epoka 6760: Loss = 0.001508222\n",
      "Epoka 6770: Loss = 0.001654133\n",
      "Epoka 6780: Loss = 0.001693280\n",
      "Epoka 6790: Loss = 0.001529651\n",
      "Epoka 6800: Loss = 0.001532194\n",
      "Epoka 6810: Loss = 0.001500072\n",
      "Epoka 6820: Loss = 0.001530804\n",
      "Epoka 6830: Loss = 0.001493930\n",
      "Epoka 6840: Loss = 0.001624347\n",
      "Epoka 6850: Loss = 0.001532309\n",
      "Epoka 6860: Loss = 0.001600353\n",
      "Epoka 6870: Loss = 0.001495194\n",
      "Epoka 6880: Loss = 0.001488197\n",
      "Epoka 6890: Loss = 0.001498147\n",
      "Epoka 6900: Loss = 0.001469810\n",
      "Epoka 6910: Loss = 0.001501415\n",
      "Epoka 6920: Loss = 0.001561913\n",
      "Epoka 6930: Loss = 0.001545910\n",
      "Epoka 6940: Loss = 0.001689205\n",
      "Epoka 6950: Loss = 0.001509105\n",
      "Epoka 6960: Loss = 0.001484376\n",
      "Epoka 6970: Loss = 0.001585884\n",
      "Epoka 6980: Loss = 0.001473512\n",
      "Epoka 6990: Loss = 0.001487068\n",
      "Epoka 7000: Loss = 0.001544147\n",
      "Epoka 7010: Loss = 0.001564886\n",
      "Epoka 7020: Loss = 0.001553520\n",
      "Epoka 7030: Loss = 0.001694947\n",
      "Epoka 7040: Loss = 0.001543852\n",
      "Epoka 7050: Loss = 0.001486769\n",
      "Epoka 7060: Loss = 0.001621568\n",
      "Epoka 7070: Loss = 0.001501066\n",
      "Epoka 7080: Loss = 0.001485135\n",
      "Epoka 7090: Loss = 0.001532944\n",
      "Epoka 7100: Loss = 0.001466347\n",
      "Epoka 7110: Loss = 0.001498321\n",
      "Epoka 7120: Loss = 0.001523848\n",
      "Epoka 7130: Loss = 0.001532677\n",
      "Epoka 7140: Loss = 0.001461602\n",
      "Epoka 7150: Loss = 0.001492528\n",
      "Epoka 7160: Loss = 0.001563208\n",
      "Epoka 7170: Loss = 0.001462999\n",
      "Epoka 7180: Loss = 0.001545474\n",
      "Epoka 7190: Loss = 0.001629274\n",
      "Epoka 7200: Loss = 0.001430945\n",
      "Epoka 7210: Loss = 0.001485368\n",
      "Epoka 7220: Loss = 0.001452394\n",
      "Epoka 7230: Loss = 0.001598345\n",
      "Epoka 7240: Loss = 0.001546865\n",
      "Epoka 7250: Loss = 0.001440147\n",
      "Epoka 7260: Loss = 0.001577491\n",
      "Epoka 7270: Loss = 0.001441731\n",
      "Epoka 7280: Loss = 0.001478423\n",
      "Epoka 7290: Loss = 0.001569611\n",
      "Epoka 7300: Loss = 0.001443452\n",
      "Epoka 7310: Loss = 0.001423278\n",
      "Epoka 7320: Loss = 0.001456172\n",
      "Epoka 7330: Loss = 0.001416005\n",
      "Epoka 7340: Loss = 0.001510504\n",
      "Epoka 7350: Loss = 0.001516659\n",
      "Epoka 7360: Loss = 0.001505389\n",
      "Epoka 7370: Loss = 0.001458586\n",
      "Epoka 7380: Loss = 0.001456698\n",
      "Epoka 7390: Loss = 0.001538077\n",
      "Epoka 7400: Loss = 0.001457485\n",
      "Epoka 7410: Loss = 0.001437419\n",
      "Epoka 7420: Loss = 0.001507639\n",
      "Epoka 7430: Loss = 0.001523437\n",
      "Epoka 7440: Loss = 0.001485793\n",
      "Epoka 7450: Loss = 0.001586212\n",
      "Epoka 7460: Loss = 0.001525715\n",
      "Epoka 7470: Loss = 0.001477709\n",
      "Epoka 7480: Loss = 0.001429041\n",
      "Epoka 7490: Loss = 0.001530642\n",
      "Epoka 7500: Loss = 0.001740965\n",
      "Epoka 7510: Loss = 0.001438335\n",
      "Epoka 7520: Loss = 0.001426336\n",
      "Epoka 7530: Loss = 0.001400714\n",
      "Epoka 7540: Loss = 0.001418644\n",
      "Epoka 7550: Loss = 0.001411348\n",
      "Epoka 7560: Loss = 0.001433755\n",
      "Epoka 7570: Loss = 0.001534350\n",
      "Epoka 7580: Loss = 0.001591856\n",
      "Epoka 7590: Loss = 0.001398721\n",
      "Epoka 7600: Loss = 0.001439263\n",
      "Epoka 7610: Loss = 0.001402802\n",
      "Epoka 7620: Loss = 0.001538399\n",
      "Epoka 7630: Loss = 0.001431154\n",
      "Epoka 7640: Loss = 0.001426045\n",
      "Epoka 7650: Loss = 0.001449135\n",
      "Epoka 7660: Loss = 0.001435187\n",
      "Epoka 7670: Loss = 0.001514726\n",
      "Epoka 7680: Loss = 0.001541729\n",
      "Epoka 7690: Loss = 0.001421261\n",
      "Epoka 7700: Loss = 0.001540011\n",
      "Epoka 7710: Loss = 0.001479481\n",
      "Epoka 7720: Loss = 0.001510706\n",
      "Epoka 7730: Loss = 0.001410795\n",
      "Epoka 7740: Loss = 0.001375752\n",
      "Epoka 7750: Loss = 0.001380934\n",
      "Epoka 7760: Loss = 0.001422513\n",
      "Epoka 7770: Loss = 0.001617994\n",
      "Epoka 7780: Loss = 0.001449662\n",
      "Epoka 7790: Loss = 0.001377510\n",
      "Epoka 7800: Loss = 0.001429383\n",
      "Epoka 7810: Loss = 0.001423226\n",
      "Epoka 7820: Loss = 0.001424308\n",
      "Epoka 7830: Loss = 0.001448088\n",
      "Epoka 7840: Loss = 0.001424313\n",
      "Epoka 7850: Loss = 0.001577257\n",
      "Epoka 7860: Loss = 0.001457254\n",
      "Epoka 7870: Loss = 0.001381421\n",
      "Epoka 7880: Loss = 0.001377384\n",
      "Epoka 7890: Loss = 0.001600384\n",
      "Epoka 7900: Loss = 0.001405170\n",
      "Epoka 7910: Loss = 0.001389226\n",
      "Epoka 7920: Loss = 0.001626433\n",
      "Epoka 7930: Loss = 0.001365557\n",
      "Epoka 7940: Loss = 0.001601654\n",
      "Epoka 7950: Loss = 0.001453108\n",
      "Epoka 7960: Loss = 0.001433131\n",
      "Epoka 7970: Loss = 0.001645951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 7980: Loss = 0.001385884\n",
      "Epoka 7990: Loss = 0.001408457\n",
      "Epoka 8000: Loss = 0.001447860\n",
      "Epoka 8010: Loss = 0.001444880\n",
      "Epoka 8020: Loss = 0.001369364\n",
      "Epoka 8030: Loss = 0.001448646\n",
      "Epoka 8040: Loss = 0.001478600\n",
      "Epoka 8050: Loss = 0.001447696\n",
      "Epoka 8060: Loss = 0.001453722\n",
      "Epoka 8070: Loss = 0.001385452\n",
      "Epoka 8080: Loss = 0.001424622\n",
      "Epoka 8090: Loss = 0.001366577\n",
      "Epoka 8100: Loss = 0.001394876\n",
      "Epoka 8110: Loss = 0.001440544\n",
      "Epoka 8120: Loss = 0.001433125\n",
      "Epoka 8130: Loss = 0.001458500\n",
      "Epoka 8140: Loss = 0.001349102\n",
      "Epoka 8150: Loss = 0.001385187\n",
      "Epoka 8160: Loss = 0.001380474\n",
      "Epoka 8170: Loss = 0.001398175\n",
      "Epoka 8180: Loss = 0.001394228\n",
      "Epoka 8190: Loss = 0.001554683\n",
      "Epoka 8200: Loss = 0.001370027\n",
      "Epoka 8210: Loss = 0.001361764\n",
      "Epoka 8220: Loss = 0.001368239\n",
      "Epoka 8230: Loss = 0.001367502\n",
      "Epoka 8240: Loss = 0.001375468\n",
      "Epoka 8250: Loss = 0.001476198\n",
      "Epoka 8260: Loss = 0.001384874\n",
      "Epoka 8270: Loss = 0.001614298\n",
      "Epoka 8280: Loss = 0.001352625\n",
      "Epoka 8290: Loss = 0.001401342\n",
      "Epoka 8300: Loss = 0.001328272\n",
      "Epoka 8310: Loss = 0.001329539\n",
      "Epoka 8320: Loss = 0.001537954\n",
      "Epoka 8330: Loss = 0.001342044\n",
      "Epoka 8340: Loss = 0.001476524\n",
      "Epoka 8350: Loss = 0.001372039\n",
      "Epoka 8360: Loss = 0.001630767\n",
      "Epoka 8370: Loss = 0.001392945\n",
      "Epoka 8380: Loss = 0.001480712\n",
      "Epoka 8390: Loss = 0.001569235\n",
      "Epoka 8400: Loss = 0.001328191\n",
      "Epoka 8410: Loss = 0.001450878\n",
      "Epoka 8420: Loss = 0.001346657\n",
      "Epoka 8430: Loss = 0.001457475\n",
      "Epoka 8440: Loss = 0.001355608\n",
      "Epoka 8450: Loss = 0.001308062\n",
      "Epoka 8460: Loss = 0.001394444\n",
      "Epoka 8470: Loss = 0.001532379\n",
      "Epoka 8480: Loss = 0.001519601\n",
      "Epoka 8490: Loss = 0.001397266\n",
      "Epoka 8500: Loss = 0.001343793\n",
      "Epoka 8510: Loss = 0.001446932\n",
      "Epoka 8520: Loss = 0.001468645\n",
      "Epoka 8530: Loss = 0.001426931\n",
      "Epoka 8540: Loss = 0.001418763\n",
      "Epoka 8550: Loss = 0.001523908\n",
      "Epoka 8560: Loss = 0.001331556\n",
      "Epoka 8570: Loss = 0.001344423\n",
      "Epoka 8580: Loss = 0.001504131\n",
      "Epoka 8590: Loss = 0.001431615\n",
      "Epoka 8600: Loss = 0.001412229\n",
      "Epoka 8610: Loss = 0.001307656\n",
      "Epoka 8620: Loss = 0.001331751\n",
      "Epoka 8630: Loss = 0.001394470\n",
      "Epoka 8640: Loss = 0.001396911\n",
      "Epoka 8650: Loss = 0.001458267\n",
      "Epoka 8660: Loss = 0.001353844\n",
      "Epoka 8670: Loss = 0.001326752\n",
      "Epoka 8680: Loss = 0.001341968\n",
      "Epoka 8690: Loss = 0.001329199\n",
      "Epoka 8700: Loss = 0.001313881\n",
      "Epoka 8710: Loss = 0.001394996\n",
      "Epoka 8720: Loss = 0.001377016\n",
      "Epoka 8730: Loss = 0.001442278\n",
      "Epoka 8740: Loss = 0.001398028\n",
      "Epoka 8750: Loss = 0.001397671\n",
      "Epoka 8760: Loss = 0.001433543\n",
      "Epoka 8770: Loss = 0.001334291\n",
      "Epoka 8780: Loss = 0.001335137\n",
      "Epoka 8790: Loss = 0.001314521\n",
      "Epoka 8800: Loss = 0.001367556\n",
      "Epoka 8810: Loss = 0.001338986\n",
      "Epoka 8820: Loss = 0.001423711\n",
      "Epoka 8830: Loss = 0.001358730\n",
      "Epoka 8840: Loss = 0.001335309\n",
      "Epoka 8850: Loss = 0.001311238\n",
      "Epoka 8860: Loss = 0.001331596\n",
      "Epoka 8870: Loss = 0.001563486\n",
      "Epoka 8880: Loss = 0.001357208\n",
      "Epoka 8890: Loss = 0.001361020\n",
      "Epoka 8900: Loss = 0.001320944\n",
      "Epoka 8910: Loss = 0.001283006\n",
      "Epoka 8920: Loss = 0.001373696\n",
      "Epoka 8930: Loss = 0.001381747\n",
      "Epoka 8940: Loss = 0.001296134\n",
      "Epoka 8950: Loss = 0.001312492\n",
      "Epoka 8960: Loss = 0.001285227\n",
      "Epoka 8970: Loss = 0.001317501\n",
      "Epoka 8980: Loss = 0.001324340\n",
      "Epoka 8990: Loss = 0.001311313\n",
      "Epoka 9000: Loss = 0.001307015\n",
      "Epoka 9010: Loss = 0.001430983\n",
      "Epoka 9020: Loss = 0.001425643\n",
      "Epoka 9030: Loss = 0.001283178\n",
      "Epoka 9040: Loss = 0.001283346\n",
      "Epoka 9050: Loss = 0.001381688\n",
      "Epoka 9060: Loss = 0.001365593\n",
      "Epoka 9070: Loss = 0.001275270\n",
      "Epoka 9080: Loss = 0.001275437\n",
      "Epoka 9090: Loss = 0.001301805\n",
      "Epoka 9100: Loss = 0.001416313\n",
      "Epoka 9110: Loss = 0.001261197\n",
      "Epoka 9120: Loss = 0.001314041\n",
      "Epoka 9130: Loss = 0.001388244\n",
      "Epoka 9140: Loss = 0.001262875\n",
      "Epoka 9150: Loss = 0.001444437\n",
      "Epoka 9160: Loss = 0.001324629\n",
      "Epoka 9170: Loss = 0.001358216\n",
      "Epoka 9180: Loss = 0.001270441\n",
      "Epoka 9190: Loss = 0.001335511\n",
      "Epoka 9200: Loss = 0.001400638\n",
      "Epoka 9210: Loss = 0.001280905\n",
      "Epoka 9220: Loss = 0.001260723\n",
      "Epoka 9230: Loss = 0.001265840\n",
      "Epoka 9240: Loss = 0.001294918\n",
      "Epoka 9250: Loss = 0.001279694\n",
      "Epoka 9260: Loss = 0.001276464\n",
      "Epoka 9270: Loss = 0.001284541\n",
      "Epoka 9280: Loss = 0.001285730\n",
      "Epoka 9290: Loss = 0.001333662\n",
      "Epoka 9300: Loss = 0.001257192\n",
      "Epoka 9310: Loss = 0.001379448\n",
      "Epoka 9320: Loss = 0.001443516\n",
      "Epoka 9330: Loss = 0.001371858\n",
      "Epoka 9340: Loss = 0.001256959\n",
      "Epoka 9350: Loss = 0.001333683\n",
      "Epoka 9360: Loss = 0.001263166\n",
      "Epoka 9370: Loss = 0.001322647\n",
      "Epoka 9380: Loss = 0.001279490\n",
      "Epoka 9390: Loss = 0.001300139\n",
      "Epoka 9400: Loss = 0.001367835\n",
      "Epoka 9410: Loss = 0.001342370\n",
      "Epoka 9420: Loss = 0.001366873\n",
      "Epoka 9430: Loss = 0.001281257\n",
      "Epoka 9440: Loss = 0.001276069\n",
      "Epoka 9450: Loss = 0.001240800\n",
      "Epoka 9460: Loss = 0.001376108\n",
      "Epoka 9470: Loss = 0.001289401\n",
      "Epoka 9480: Loss = 0.001239321\n",
      "Epoka 9490: Loss = 0.001457409\n",
      "Epoka 9500: Loss = 0.001254999\n",
      "Epoka 9510: Loss = 0.001450149\n",
      "Epoka 9520: Loss = 0.001288524\n",
      "Epoka 9530: Loss = 0.001287535\n",
      "Epoka 9540: Loss = 0.001252299\n",
      "Epoka 9550: Loss = 0.001365149\n",
      "Epoka 9560: Loss = 0.001390053\n",
      "Epoka 9570: Loss = 0.001314128\n",
      "Epoka 9580: Loss = 0.001356138\n",
      "Epoka 9590: Loss = 0.001262602\n",
      "Epoka 9600: Loss = 0.001243068\n",
      "Epoka 9610: Loss = 0.001297229\n",
      "Epoka 9620: Loss = 0.001284826\n",
      "Epoka 9630: Loss = 0.001251636\n",
      "Epoka 9640: Loss = 0.001393439\n",
      "Epoka 9650: Loss = 0.001305241\n",
      "Epoka 9660: Loss = 0.001326936\n",
      "Epoka 9670: Loss = 0.001245104\n",
      "Epoka 9680: Loss = 0.001275763\n",
      "Epoka 9690: Loss = 0.001383938\n",
      "Epoka 9700: Loss = 0.001289419\n",
      "Epoka 9710: Loss = 0.001261596\n",
      "Epoka 9720: Loss = 0.001271147\n",
      "Epoka 9730: Loss = 0.001232958\n",
      "Epoka 9740: Loss = 0.001299480\n",
      "Epoka 9750: Loss = 0.001240579\n",
      "Epoka 9760: Loss = 0.001275405\n",
      "Epoka 9770: Loss = 0.001244833\n",
      "Epoka 9780: Loss = 0.001242750\n",
      "Epoka 9790: Loss = 0.001296253\n",
      "Epoka 9800: Loss = 0.001234466\n",
      "Epoka 9810: Loss = 0.001400790\n",
      "Epoka 9820: Loss = 0.001291429\n",
      "Epoka 9830: Loss = 0.001219867\n",
      "Epoka 9840: Loss = 0.001254665\n",
      "Epoka 9850: Loss = 0.001221980\n",
      "Epoka 9860: Loss = 0.001289315\n",
      "Epoka 9870: Loss = 0.001270951\n",
      "Epoka 9880: Loss = 0.001231668\n",
      "Epoka 9890: Loss = 0.001340441\n",
      "Epoka 9900: Loss = 0.001261893\n",
      "Epoka 9910: Loss = 0.001403756\n",
      "Epoka 9920: Loss = 0.001275776\n",
      "Epoka 9930: Loss = 0.001221670\n",
      "Epoka 9940: Loss = 0.001291761\n",
      "Epoka 9950: Loss = 0.001243833\n",
      "Epoka 9960: Loss = 0.001316555\n",
      "Epoka 9970: Loss = 0.001222611\n",
      "Epoka 9980: Loss = 0.001312806\n",
      "Epoka 9990: Loss = 0.001271164\n",
      "Epoka 10000: Loss = 0.001243274\n",
      "Epoka 10010: Loss = 0.001215836\n",
      "Epoka 10020: Loss = 0.001234455\n",
      "Epoka 10030: Loss = 0.001610475\n",
      "Epoka 10040: Loss = 0.001249605\n",
      "Epoka 10050: Loss = 0.001236428\n",
      "Epoka 10060: Loss = 0.001279316\n",
      "Epoka 10070: Loss = 0.001465331\n",
      "Epoka 10080: Loss = 0.001221978\n",
      "Epoka 10090: Loss = 0.001247717\n",
      "Epoka 10100: Loss = 0.001247057\n",
      "Epoka 10110: Loss = 0.001225565\n",
      "Epoka 10120: Loss = 0.001340289\n",
      "Epoka 10130: Loss = 0.001293905\n",
      "Epoka 10140: Loss = 0.001343188\n",
      "Epoka 10150: Loss = 0.001238320\n",
      "Epoka 10160: Loss = 0.001300500\n",
      "Epoka 10170: Loss = 0.001208918\n",
      "Epoka 10180: Loss = 0.001206172\n",
      "Epoka 10190: Loss = 0.001265196\n",
      "Epoka 10200: Loss = 0.001222060\n",
      "Epoka 10210: Loss = 0.001226724\n",
      "Epoka 10220: Loss = 0.001255270\n",
      "Epoka 10230: Loss = 0.001309767\n",
      "Epoka 10240: Loss = 0.001298248\n",
      "Epoka 10250: Loss = 0.001261021\n",
      "Epoka 10260: Loss = 0.001274946\n",
      "Epoka 10270: Loss = 0.001233746\n",
      "Epoka 10280: Loss = 0.001342921\n",
      "Epoka 10290: Loss = 0.001407459\n",
      "Epoka 10300: Loss = 0.001181131\n",
      "Epoka 10310: Loss = 0.001432247\n",
      "Epoka 10320: Loss = 0.001244038\n",
      "Epoka 10330: Loss = 0.001203943\n",
      "Epoka 10340: Loss = 0.001336803\n",
      "Epoka 10350: Loss = 0.001187990\n",
      "Epoka 10360: Loss = 0.001335407\n",
      "Epoka 10370: Loss = 0.001237588\n",
      "Epoka 10380: Loss = 0.001221613\n",
      "Epoka 10390: Loss = 0.001213433\n",
      "Epoka 10400: Loss = 0.001298945\n",
      "Epoka 10410: Loss = 0.001271323\n",
      "Epoka 10420: Loss = 0.001373025\n",
      "Epoka 10430: Loss = 0.001215118\n",
      "Epoka 10440: Loss = 0.001269013\n",
      "Epoka 10450: Loss = 0.001214982\n",
      "Epoka 10460: Loss = 0.001337519\n",
      "Epoka 10470: Loss = 0.001228096\n",
      "Epoka 10480: Loss = 0.001369451\n",
      "Epoka 10490: Loss = 0.001285264\n",
      "Epoka 10500: Loss = 0.001282130\n",
      "Epoka 10510: Loss = 0.001257605\n",
      "Epoka 10520: Loss = 0.001184120\n",
      "Epoka 10530: Loss = 0.001292815\n",
      "Epoka 10540: Loss = 0.001237534\n",
      "Epoka 10550: Loss = 0.001208511\n",
      "Epoka 10560: Loss = 0.001269462\n",
      "Epoka 10570: Loss = 0.001455699\n",
      "Epoka 10580: Loss = 0.001235600\n",
      "Epoka 10590: Loss = 0.001207395\n",
      "Epoka 10600: Loss = 0.001200108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 10610: Loss = 0.001385196\n",
      "Epoka 10620: Loss = 0.001240312\n",
      "Epoka 10630: Loss = 0.001367993\n",
      "Epoka 10640: Loss = 0.001229115\n",
      "Epoka 10650: Loss = 0.001208406\n",
      "Epoka 10660: Loss = 0.001225906\n",
      "Epoka 10670: Loss = 0.001268474\n",
      "Epoka 10680: Loss = 0.001325002\n",
      "Epoka 10690: Loss = 0.001339317\n",
      "Epoka 10700: Loss = 0.001325382\n",
      "Epoka 10710: Loss = 0.001252488\n",
      "Epoka 10720: Loss = 0.001360413\n",
      "Epoka 10730: Loss = 0.001399884\n",
      "Epoka 10740: Loss = 0.001207251\n",
      "Epoka 10750: Loss = 0.001220685\n",
      "Epoka 10760: Loss = 0.001235412\n",
      "Epoka 10770: Loss = 0.001225344\n",
      "Epoka 10780: Loss = 0.001161347\n",
      "Epoka 10790: Loss = 0.001251704\n",
      "Epoka 10800: Loss = 0.001283716\n",
      "Epoka 10810: Loss = 0.001212595\n",
      "Epoka 10820: Loss = 0.001201496\n",
      "Epoka 10830: Loss = 0.001201888\n",
      "Epoka 10840: Loss = 0.001244111\n",
      "Epoka 10850: Loss = 0.001289549\n",
      "Epoka 10860: Loss = 0.001163714\n",
      "Epoka 10870: Loss = 0.001164831\n",
      "Epoka 10880: Loss = 0.001162253\n",
      "Epoka 10890: Loss = 0.001371430\n",
      "Epoka 10900: Loss = 0.001249011\n",
      "Epoka 10910: Loss = 0.001207018\n",
      "Epoka 10920: Loss = 0.001203606\n",
      "Epoka 10930: Loss = 0.001201979\n",
      "Epoka 10940: Loss = 0.001194845\n",
      "Epoka 10950: Loss = 0.001189074\n",
      "Epoka 10960: Loss = 0.001180107\n",
      "Epoka 10970: Loss = 0.001257100\n",
      "Epoka 10980: Loss = 0.001172310\n",
      "Epoka 10990: Loss = 0.001193362\n",
      "Epoka 11000: Loss = 0.001154173\n",
      "Epoka 11010: Loss = 0.001194562\n",
      "Epoka 11020: Loss = 0.001240413\n",
      "Epoka 11030: Loss = 0.001163972\n",
      "Epoka 11040: Loss = 0.001175217\n",
      "Epoka 11050: Loss = 0.001186495\n",
      "Epoka 11060: Loss = 0.001183051\n",
      "Epoka 11070: Loss = 0.001272743\n",
      "Epoka 11080: Loss = 0.001180538\n",
      "Epoka 11090: Loss = 0.001174849\n",
      "Epoka 11100: Loss = 0.001270111\n",
      "Epoka 11110: Loss = 0.001171147\n",
      "Epoka 11120: Loss = 0.001163838\n",
      "Epoka 11130: Loss = 0.001198507\n",
      "Epoka 11140: Loss = 0.001257202\n",
      "Epoka 11150: Loss = 0.001198890\n",
      "Epoka 11160: Loss = 0.001179225\n",
      "Epoka 11170: Loss = 0.001228229\n",
      "Epoka 11180: Loss = 0.001212833\n",
      "Epoka 11190: Loss = 0.001157255\n",
      "Epoka 11200: Loss = 0.001153919\n",
      "Epoka 11210: Loss = 0.001183128\n",
      "Epoka 11220: Loss = 0.001166233\n",
      "Epoka 11230: Loss = 0.001214993\n",
      "Epoka 11240: Loss = 0.001160821\n",
      "Epoka 11250: Loss = 0.001227813\n",
      "Epoka 11260: Loss = 0.001199092\n",
      "Epoka 11270: Loss = 0.001303354\n",
      "Epoka 11280: Loss = 0.001149061\n",
      "Epoka 11290: Loss = 0.001227618\n",
      "Epoka 11300: Loss = 0.001334176\n",
      "Epoka 11310: Loss = 0.001329052\n",
      "Epoka 11320: Loss = 0.001171707\n",
      "Epoka 11330: Loss = 0.001132672\n",
      "Epoka 11340: Loss = 0.001166047\n",
      "Epoka 11350: Loss = 0.001249046\n",
      "Epoka 11360: Loss = 0.001276668\n",
      "Epoka 11370: Loss = 0.001144157\n",
      "Epoka 11380: Loss = 0.001271353\n",
      "Epoka 11390: Loss = 0.001318742\n",
      "Epoka 11400: Loss = 0.001205840\n",
      "Epoka 11410: Loss = 0.001206132\n",
      "Epoka 11420: Loss = 0.001135367\n",
      "Epoka 11430: Loss = 0.001390094\n",
      "Epoka 11440: Loss = 0.001137713\n",
      "Epoka 11450: Loss = 0.001218308\n",
      "Epoka 11460: Loss = 0.001144008\n",
      "Epoka 11470: Loss = 0.001142534\n",
      "Epoka 11480: Loss = 0.001133557\n",
      "Epoka 11490: Loss = 0.001181827\n",
      "Epoka 11500: Loss = 0.001251909\n",
      "Epoka 11510: Loss = 0.001164336\n",
      "Epoka 11520: Loss = 0.001127246\n",
      "Epoka 11530: Loss = 0.001185739\n",
      "Epoka 11540: Loss = 0.001234472\n",
      "Epoka 11550: Loss = 0.001195826\n",
      "Epoka 11560: Loss = 0.001149278\n",
      "Epoka 11570: Loss = 0.001174865\n",
      "Epoka 11580: Loss = 0.001184661\n",
      "Epoka 11590: Loss = 0.001143284\n",
      "Epoka 11600: Loss = 0.001106574\n",
      "Epoka 11610: Loss = 0.001136767\n",
      "Epoka 11620: Loss = 0.001239205\n",
      "Epoka 11630: Loss = 0.001148564\n",
      "Epoka 11640: Loss = 0.001132575\n",
      "Epoka 11650: Loss = 0.001138914\n",
      "Epoka 11660: Loss = 0.001256062\n",
      "Epoka 11670: Loss = 0.001232742\n",
      "Epoka 11680: Loss = 0.001321440\n",
      "Epoka 11690: Loss = 0.001208432\n",
      "Epoka 11700: Loss = 0.001143546\n",
      "Epoka 11710: Loss = 0.001187977\n",
      "Epoka 11720: Loss = 0.001136448\n",
      "Epoka 11730: Loss = 0.001158655\n",
      "Epoka 11740: Loss = 0.001237922\n",
      "Epoka 11750: Loss = 0.001166877\n",
      "Epoka 11760: Loss = 0.001133546\n",
      "Epoka 11770: Loss = 0.001116279\n",
      "Epoka 11780: Loss = 0.001230549\n",
      "Epoka 11790: Loss = 0.001192318\n",
      "Epoka 11800: Loss = 0.001176136\n",
      "Epoka 11810: Loss = 0.001179167\n",
      "Epoka 11820: Loss = 0.001138485\n",
      "Epoka 11830: Loss = 0.001165705\n",
      "Epoka 11840: Loss = 0.001104962\n",
      "Epoka 11850: Loss = 0.001115992\n",
      "Epoka 11860: Loss = 0.001103776\n",
      "Epoka 11870: Loss = 0.001239510\n",
      "Epoka 11880: Loss = 0.001094085\n",
      "Epoka 11890: Loss = 0.001198464\n",
      "Epoka 11900: Loss = 0.001109674\n",
      "Epoka 11910: Loss = 0.001123369\n",
      "Epoka 11920: Loss = 0.001130528\n",
      "Epoka 11930: Loss = 0.001273688\n",
      "Epoka 11940: Loss = 0.001161835\n",
      "Epoka 11950: Loss = 0.001160727\n",
      "Epoka 11960: Loss = 0.001160789\n",
      "Epoka 11970: Loss = 0.001155570\n",
      "Epoka 11980: Loss = 0.001104526\n",
      "Epoka 11990: Loss = 0.001140825\n",
      "Epoka 12000: Loss = 0.001162822\n",
      "Epoka 12010: Loss = 0.001242488\n",
      "Epoka 12020: Loss = 0.001168835\n",
      "Epoka 12030: Loss = 0.001172991\n",
      "Epoka 12040: Loss = 0.001114643\n",
      "Epoka 12050: Loss = 0.001126493\n",
      "Epoka 12060: Loss = 0.001178800\n",
      "Epoka 12070: Loss = 0.001141682\n",
      "Epoka 12080: Loss = 0.001090490\n",
      "Epoka 12090: Loss = 0.001128815\n",
      "Epoka 12100: Loss = 0.001083190\n",
      "Epoka 12110: Loss = 0.001103760\n",
      "Epoka 12120: Loss = 0.001124792\n",
      "Epoka 12130: Loss = 0.001114137\n",
      "Epoka 12140: Loss = 0.001117619\n",
      "Epoka 12150: Loss = 0.001361630\n",
      "Epoka 12160: Loss = 0.001155169\n",
      "Epoka 12170: Loss = 0.001098686\n",
      "Epoka 12180: Loss = 0.001153931\n",
      "Epoka 12190: Loss = 0.001175716\n",
      "Epoka 12200: Loss = 0.001113753\n",
      "Epoka 12210: Loss = 0.001101679\n",
      "Epoka 12220: Loss = 0.001099769\n",
      "Epoka 12230: Loss = 0.001103386\n",
      "Epoka 12240: Loss = 0.001119193\n",
      "Epoka 12250: Loss = 0.001146461\n",
      "Epoka 12260: Loss = 0.001095837\n",
      "Epoka 12270: Loss = 0.001322409\n",
      "Epoka 12280: Loss = 0.001129134\n",
      "Epoka 12290: Loss = 0.001115969\n",
      "Epoka 12300: Loss = 0.001088717\n",
      "Epoka 12310: Loss = 0.001145419\n",
      "Epoka 12320: Loss = 0.001093999\n",
      "Epoka 12330: Loss = 0.001111530\n",
      "Epoka 12340: Loss = 0.001138135\n",
      "Epoka 12350: Loss = 0.001219722\n",
      "Epoka 12360: Loss = 0.001124051\n",
      "Epoka 12370: Loss = 0.001157732\n",
      "Epoka 12380: Loss = 0.001148389\n",
      "Epoka 12390: Loss = 0.001115681\n",
      "Epoka 12400: Loss = 0.001197586\n",
      "Epoka 12410: Loss = 0.001085541\n",
      "Epoka 12420: Loss = 0.001127384\n",
      "Epoka 12430: Loss = 0.001193989\n",
      "Epoka 12440: Loss = 0.001093511\n",
      "Epoka 12450: Loss = 0.001298070\n",
      "Epoka 12460: Loss = 0.001097777\n",
      "Epoka 12470: Loss = 0.001077892\n",
      "Epoka 12480: Loss = 0.001123633\n",
      "Epoka 12490: Loss = 0.001270274\n",
      "Epoka 12500: Loss = 0.001152128\n",
      "Epoka 12510: Loss = 0.001459156\n",
      "Epoka 12520: Loss = 0.001221655\n",
      "Epoka 12530: Loss = 0.001214087\n",
      "Epoka 12540: Loss = 0.001074552\n",
      "Epoka 12550: Loss = 0.001136858\n",
      "Epoka 12560: Loss = 0.001103428\n",
      "Epoka 12570: Loss = 0.001080268\n",
      "Epoka 12580: Loss = 0.001110541\n",
      "Epoka 12590: Loss = 0.001143459\n",
      "Epoka 12600: Loss = 0.001094887\n",
      "Epoka 12610: Loss = 0.001108796\n",
      "Epoka 12620: Loss = 0.001109125\n",
      "Epoka 12630: Loss = 0.001137917\n",
      "Epoka 12640: Loss = 0.001139424\n",
      "Epoka 12650: Loss = 0.001073968\n",
      "Epoka 12660: Loss = 0.001085025\n",
      "Epoka 12670: Loss = 0.001154741\n",
      "Epoka 12680: Loss = 0.001070208\n",
      "Epoka 12690: Loss = 0.001168312\n",
      "Epoka 12700: Loss = 0.001289187\n",
      "Epoka 12710: Loss = 0.001097759\n",
      "Epoka 12720: Loss = 0.001161628\n",
      "Epoka 12730: Loss = 0.001134570\n",
      "Epoka 12740: Loss = 0.001279932\n",
      "Epoka 12750: Loss = 0.001093596\n",
      "Epoka 12760: Loss = 0.001106235\n",
      "Epoka 12770: Loss = 0.001084807\n",
      "Epoka 12780: Loss = 0.001190187\n",
      "Epoka 12790: Loss = 0.001154383\n",
      "Epoka 12800: Loss = 0.001115527\n",
      "Epoka 12810: Loss = 0.001203121\n",
      "Epoka 12820: Loss = 0.001127736\n",
      "Epoka 12830: Loss = 0.001077393\n",
      "Epoka 12840: Loss = 0.001059725\n",
      "Epoka 12850: Loss = 0.001101137\n",
      "Epoka 12860: Loss = 0.001206199\n",
      "Epoka 12870: Loss = 0.001138542\n",
      "Epoka 12880: Loss = 0.001087505\n",
      "Epoka 12890: Loss = 0.001095239\n",
      "Epoka 12900: Loss = 0.001111837\n",
      "Epoka 12910: Loss = 0.001105972\n",
      "Epoka 12920: Loss = 0.001199308\n",
      "Epoka 12930: Loss = 0.001100917\n",
      "Epoka 12940: Loss = 0.001162516\n",
      "Epoka 12950: Loss = 0.001082114\n",
      "Epoka 12960: Loss = 0.001186886\n",
      "Epoka 12970: Loss = 0.001232157\n",
      "Epoka 12980: Loss = 0.001169118\n",
      "Epoka 12990: Loss = 0.001070635\n",
      "Epoka 13000: Loss = 0.001119877\n",
      "Epoka 13010: Loss = 0.001112409\n",
      "Epoka 13020: Loss = 0.001050736\n",
      "Epoka 13030: Loss = 0.001129574\n",
      "Epoka 13040: Loss = 0.001082045\n",
      "Epoka 13050: Loss = 0.001077525\n",
      "Epoka 13060: Loss = 0.001092174\n",
      "Epoka 13070: Loss = 0.001181530\n",
      "Epoka 13080: Loss = 0.001081581\n",
      "Epoka 13090: Loss = 0.001091130\n",
      "Epoka 13100: Loss = 0.001137684\n",
      "Epoka 13110: Loss = 0.001157289\n",
      "Epoka 13120: Loss = 0.001108747\n",
      "Epoka 13130: Loss = 0.001108049\n",
      "Epoka 13140: Loss = 0.001052924\n",
      "Epoka 13150: Loss = 0.001124513\n",
      "Epoka 13160: Loss = 0.001063231\n",
      "Epoka 13170: Loss = 0.001069038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 13180: Loss = 0.001057048\n",
      "Epoka 13190: Loss = 0.001069212\n",
      "Epoka 13200: Loss = 0.001168351\n",
      "Epoka 13210: Loss = 0.001114012\n",
      "Epoka 13220: Loss = 0.001062150\n",
      "Epoka 13230: Loss = 0.001090573\n",
      "Epoka 13240: Loss = 0.001158430\n",
      "Epoka 13250: Loss = 0.001045852\n",
      "Epoka 13260: Loss = 0.001064098\n",
      "Epoka 13270: Loss = 0.001042075\n",
      "Epoka 13280: Loss = 0.001047806\n",
      "Epoka 13290: Loss = 0.001113230\n",
      "Epoka 13300: Loss = 0.001209452\n",
      "Epoka 13310: Loss = 0.001114653\n",
      "Epoka 13320: Loss = 0.001078234\n",
      "Epoka 13330: Loss = 0.001220860\n",
      "Epoka 13340: Loss = 0.001039660\n",
      "Epoka 13350: Loss = 0.001113173\n",
      "Epoka 13360: Loss = 0.001135449\n",
      "Epoka 13370: Loss = 0.001076377\n",
      "Epoka 13380: Loss = 0.001114762\n",
      "Epoka 13390: Loss = 0.001070147\n",
      "Epoka 13400: Loss = 0.001078252\n",
      "Epoka 13410: Loss = 0.001047530\n",
      "Epoka 13420: Loss = 0.001431992\n",
      "Epoka 13430: Loss = 0.001160183\n",
      "Epoka 13440: Loss = 0.001066536\n",
      "Epoka 13450: Loss = 0.001071921\n",
      "Epoka 13460: Loss = 0.001055108\n",
      "Epoka 13470: Loss = 0.001104171\n",
      "Epoka 13480: Loss = 0.001069170\n",
      "Epoka 13490: Loss = 0.001077293\n",
      "Epoka 13500: Loss = 0.001131150\n",
      "Epoka 13510: Loss = 0.001040788\n",
      "Epoka 13520: Loss = 0.001161110\n",
      "Epoka 13530: Loss = 0.001084531\n",
      "Epoka 13540: Loss = 0.001121708\n",
      "Epoka 13550: Loss = 0.001067266\n",
      "Epoka 13560: Loss = 0.001261910\n",
      "Epoka 13570: Loss = 0.001068274\n",
      "Epoka 13580: Loss = 0.001060195\n",
      "Epoka 13590: Loss = 0.001190593\n",
      "Epoka 13600: Loss = 0.001070541\n",
      "Epoka 13610: Loss = 0.001099641\n",
      "Epoka 13620: Loss = 0.001099952\n",
      "Epoka 13630: Loss = 0.001023822\n",
      "Epoka 13640: Loss = 0.001026279\n",
      "Epoka 13650: Loss = 0.001225853\n",
      "Epoka 13660: Loss = 0.001019756\n",
      "Epoka 13670: Loss = 0.001073207\n",
      "Epoka 13680: Loss = 0.001061974\n",
      "Epoka 13690: Loss = 0.001162358\n",
      "Epoka 13700: Loss = 0.001016367\n",
      "Epoka 13710: Loss = 0.001055801\n",
      "Epoka 13720: Loss = 0.001132266\n",
      "Epoka 13730: Loss = 0.001076190\n",
      "Epoka 13740: Loss = 0.001037284\n",
      "Epoka 13750: Loss = 0.001050711\n",
      "Epoka 13760: Loss = 0.001112088\n",
      "Epoka 13770: Loss = 0.001040170\n",
      "Epoka 13780: Loss = 0.001199377\n",
      "Epoka 13790: Loss = 0.001105683\n",
      "Epoka 13800: Loss = 0.001043775\n",
      "Epoka 13810: Loss = 0.001037886\n",
      "Epoka 13820: Loss = 0.001066206\n",
      "Epoka 13830: Loss = 0.001029493\n",
      "Epoka 13840: Loss = 0.001253080\n",
      "Epoka 13850: Loss = 0.001057051\n",
      "Epoka 13860: Loss = 0.001098821\n",
      "Epoka 13870: Loss = 0.001084603\n",
      "Epoka 13880: Loss = 0.001035076\n",
      "Epoka 13890: Loss = 0.001061508\n",
      "Epoka 13900: Loss = 0.001063095\n",
      "Epoka 13910: Loss = 0.001088626\n",
      "Epoka 13920: Loss = 0.001084186\n",
      "Epoka 13930: Loss = 0.001183085\n",
      "Epoka 13940: Loss = 0.001083488\n",
      "Epoka 13950: Loss = 0.001036328\n",
      "Epoka 13960: Loss = 0.001016818\n",
      "Epoka 13970: Loss = 0.001052799\n",
      "Epoka 13980: Loss = 0.001096619\n",
      "Epoka 13990: Loss = 0.001153307\n",
      "Epoka 14000: Loss = 0.001121851\n",
      "Epoka 14010: Loss = 0.001143301\n",
      "Epoka 14020: Loss = 0.001110607\n",
      "Epoka 14030: Loss = 0.001041607\n",
      "Epoka 14040: Loss = 0.001012465\n",
      "Epoka 14050: Loss = 0.001049278\n",
      "Epoka 14060: Loss = 0.001043254\n",
      "Epoka 14070: Loss = 0.001031132\n",
      "Epoka 14080: Loss = 0.001071943\n",
      "Epoka 14090: Loss = 0.001176180\n",
      "Epoka 14100: Loss = 0.001089397\n",
      "Epoka 14110: Loss = 0.001113177\n",
      "Epoka 14120: Loss = 0.001060293\n",
      "Epoka 14130: Loss = 0.001030267\n",
      "Epoka 14140: Loss = 0.001039716\n",
      "Epoka 14150: Loss = 0.001069479\n",
      "Epoka 14160: Loss = 0.001035064\n",
      "Epoka 14170: Loss = 0.001069772\n",
      "Epoka 14180: Loss = 0.001045035\n",
      "Epoka 14190: Loss = 0.001045753\n",
      "Epoka 14200: Loss = 0.001015706\n",
      "Epoka 14210: Loss = 0.001119853\n",
      "Epoka 14220: Loss = 0.001063951\n",
      "Epoka 14230: Loss = 0.000997069\n",
      "Epoka 14240: Loss = 0.001084944\n",
      "Epoka 14250: Loss = 0.001258480\n",
      "Epoka 14260: Loss = 0.001070839\n",
      "Epoka 14270: Loss = 0.001063620\n",
      "Epoka 14280: Loss = 0.001007516\n",
      "Epoka 14290: Loss = 0.001102263\n",
      "Epoka 14300: Loss = 0.001000023\n",
      "Epoka 14310: Loss = 0.001070293\n",
      "Epoka 14320: Loss = 0.001003312\n",
      "Epoka 14330: Loss = 0.001032750\n",
      "Epoka 14340: Loss = 0.001018481\n",
      "Epoka 14350: Loss = 0.000988991\n",
      "Epoka 14360: Loss = 0.001023108\n",
      "Epoka 14370: Loss = 0.001154518\n",
      "Epoka 14380: Loss = 0.001053896\n",
      "Epoka 14390: Loss = 0.001153047\n",
      "Epoka 14400: Loss = 0.000995114\n",
      "Epoka 14410: Loss = 0.000995328\n",
      "Epoka 14420: Loss = 0.001113188\n",
      "Epoka 14430: Loss = 0.001114042\n",
      "Epoka 14440: Loss = 0.001021577\n",
      "Epoka 14450: Loss = 0.001060528\n",
      "Epoka 14460: Loss = 0.001011177\n",
      "Epoka 14470: Loss = 0.001027865\n",
      "Epoka 14480: Loss = 0.001021801\n",
      "Epoka 14490: Loss = 0.001022334\n",
      "Epoka 14500: Loss = 0.000988364\n",
      "Epoka 14510: Loss = 0.001366818\n",
      "Epoka 14520: Loss = 0.001002176\n",
      "Epoka 14530: Loss = 0.001002960\n",
      "Epoka 14540: Loss = 0.001156232\n",
      "Epoka 14550: Loss = 0.001026923\n",
      "Epoka 14560: Loss = 0.001018677\n",
      "Epoka 14570: Loss = 0.001047245\n",
      "Epoka 14580: Loss = 0.001222172\n",
      "Epoka 14590: Loss = 0.001037815\n",
      "Epoka 14600: Loss = 0.000995345\n",
      "Epoka 14610: Loss = 0.001004413\n",
      "Epoka 14620: Loss = 0.001029837\n",
      "Epoka 14630: Loss = 0.001126840\n",
      "Epoka 14640: Loss = 0.001138795\n",
      "Epoka 14650: Loss = 0.000988975\n",
      "Epoka 14660: Loss = 0.000989200\n",
      "Epoka 14670: Loss = 0.001156813\n",
      "Epoka 14680: Loss = 0.001064489\n",
      "Epoka 14690: Loss = 0.001158833\n",
      "Epoka 14700: Loss = 0.001017700\n",
      "Epoka 14710: Loss = 0.001127401\n",
      "Epoka 14720: Loss = 0.001070137\n",
      "Epoka 14730: Loss = 0.001130860\n",
      "Epoka 14740: Loss = 0.001029954\n",
      "Epoka 14750: Loss = 0.000991165\n",
      "Epoka 14760: Loss = 0.001091668\n",
      "Epoka 14770: Loss = 0.001082960\n",
      "Epoka 14780: Loss = 0.000981892\n",
      "Epoka 14790: Loss = 0.000978928\n",
      "Epoka 14800: Loss = 0.001110246\n",
      "Epoka 14810: Loss = 0.001001831\n",
      "Epoka 14820: Loss = 0.001033274\n",
      "Epoka 14830: Loss = 0.001155727\n",
      "Epoka 14840: Loss = 0.001121772\n",
      "Epoka 14850: Loss = 0.001075304\n",
      "Epoka 14860: Loss = 0.000995056\n",
      "Epoka 14870: Loss = 0.000985508\n",
      "Epoka 14880: Loss = 0.001026131\n",
      "Epoka 14890: Loss = 0.001050817\n",
      "Epoka 14900: Loss = 0.001033440\n",
      "Epoka 14910: Loss = 0.000989477\n",
      "Epoka 14920: Loss = 0.000998058\n",
      "Epoka 14930: Loss = 0.000987495\n",
      "Epoka 14940: Loss = 0.001060699\n",
      "Epoka 14950: Loss = 0.000991081\n",
      "Epoka 14960: Loss = 0.000989878\n",
      "Epoka 14970: Loss = 0.001106743\n",
      "Epoka 14980: Loss = 0.001069502\n",
      "Epoka 14990: Loss = 0.001159200\n",
      "Epoka 15000: Loss = 0.000970216\n",
      "Epoka 15010: Loss = 0.001394092\n",
      "Epoka 15020: Loss = 0.000977844\n",
      "Epoka 15030: Loss = 0.001152492\n",
      "Epoka 15040: Loss = 0.000983747\n",
      "Epoka 15050: Loss = 0.001001902\n",
      "Epoka 15060: Loss = 0.001182089\n",
      "Epoka 15070: Loss = 0.000977593\n",
      "Epoka 15080: Loss = 0.001016371\n",
      "Epoka 15090: Loss = 0.001015327\n",
      "Epoka 15100: Loss = 0.001000191\n",
      "Epoka 15110: Loss = 0.001009828\n",
      "Epoka 15120: Loss = 0.000964533\n",
      "Epoka 15130: Loss = 0.001045835\n",
      "Epoka 15140: Loss = 0.001103494\n",
      "Epoka 15150: Loss = 0.000980958\n",
      "Epoka 15160: Loss = 0.001004025\n",
      "Epoka 15170: Loss = 0.000966383\n",
      "Epoka 15180: Loss = 0.001009293\n",
      "Epoka 15190: Loss = 0.001126518\n",
      "Epoka 15200: Loss = 0.000967266\n",
      "Epoka 15210: Loss = 0.000990565\n",
      "Epoka 15220: Loss = 0.001013287\n",
      "Epoka 15230: Loss = 0.001002816\n",
      "Epoka 15240: Loss = 0.001091425\n",
      "Epoka 15250: Loss = 0.000988185\n",
      "Epoka 15260: Loss = 0.001140991\n",
      "Epoka 15270: Loss = 0.001072237\n",
      "Epoka 15280: Loss = 0.001028099\n",
      "Epoka 15290: Loss = 0.001078450\n",
      "Epoka 15300: Loss = 0.000999576\n",
      "Epoka 15310: Loss = 0.001034216\n",
      "Epoka 15320: Loss = 0.001047139\n",
      "Epoka 15330: Loss = 0.001036603\n",
      "Epoka 15340: Loss = 0.000978638\n",
      "Epoka 15350: Loss = 0.000982702\n",
      "Epoka 15360: Loss = 0.000961835\n",
      "Epoka 15370: Loss = 0.001012264\n",
      "Epoka 15380: Loss = 0.001234333\n",
      "Epoka 15390: Loss = 0.001029170\n",
      "Epoka 15400: Loss = 0.001039595\n",
      "Epoka 15410: Loss = 0.001105770\n",
      "Epoka 15420: Loss = 0.000966814\n",
      "Epoka 15430: Loss = 0.000997166\n",
      "Epoka 15440: Loss = 0.000959211\n",
      "Epoka 15450: Loss = 0.000998453\n",
      "Epoka 15460: Loss = 0.001019771\n",
      "Epoka 15470: Loss = 0.001099963\n",
      "Epoka 15480: Loss = 0.000989047\n",
      "Epoka 15490: Loss = 0.001050839\n",
      "Epoka 15500: Loss = 0.000960479\n",
      "Epoka 15510: Loss = 0.001021576\n",
      "Epoka 15520: Loss = 0.000982139\n",
      "Epoka 15530: Loss = 0.001009691\n",
      "Epoka 15540: Loss = 0.001005329\n",
      "Epoka 15550: Loss = 0.001047101\n",
      "Epoka 15560: Loss = 0.001096290\n",
      "Epoka 15570: Loss = 0.001076941\n",
      "Epoka 15580: Loss = 0.000989349\n",
      "Epoka 15590: Loss = 0.001058228\n",
      "Epoka 15600: Loss = 0.001057444\n",
      "Epoka 15610: Loss = 0.000999197\n",
      "Epoka 15620: Loss = 0.000994153\n",
      "Epoka 15630: Loss = 0.000962920\n",
      "Epoka 15640: Loss = 0.000964000\n",
      "Epoka 15650: Loss = 0.001121921\n",
      "Epoka 15660: Loss = 0.001109532\n",
      "Epoka 15670: Loss = 0.001087739\n",
      "Epoka 15680: Loss = 0.001018194\n",
      "Epoka 15690: Loss = 0.001023090\n",
      "Epoka 15700: Loss = 0.001014847\n",
      "Epoka 15710: Loss = 0.001116935\n",
      "Epoka 15720: Loss = 0.000976151\n",
      "Epoka 15730: Loss = 0.001017235\n",
      "Epoka 15740: Loss = 0.000972985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 15750: Loss = 0.000963163\n",
      "Epoka 15760: Loss = 0.000984512\n",
      "Epoka 15770: Loss = 0.001016693\n",
      "Epoka 15780: Loss = 0.000940655\n",
      "Epoka 15790: Loss = 0.001043434\n",
      "Epoka 15800: Loss = 0.000981739\n",
      "Epoka 15810: Loss = 0.000970855\n",
      "Epoka 15820: Loss = 0.000978789\n",
      "Epoka 15830: Loss = 0.001120152\n",
      "Epoka 15840: Loss = 0.000953504\n",
      "Epoka 15850: Loss = 0.001087831\n",
      "Epoka 15860: Loss = 0.000988862\n",
      "Epoka 15870: Loss = 0.001001485\n",
      "Epoka 15880: Loss = 0.000960518\n",
      "Epoka 15890: Loss = 0.001102243\n",
      "Epoka 15900: Loss = 0.000993126\n",
      "Epoka 15910: Loss = 0.001169593\n",
      "Epoka 15920: Loss = 0.000969428\n",
      "Epoka 15930: Loss = 0.000947386\n",
      "Epoka 15940: Loss = 0.001101948\n",
      "Epoka 15950: Loss = 0.000988716\n",
      "Epoka 15960: Loss = 0.001095992\n",
      "Epoka 15970: Loss = 0.000965337\n",
      "Epoka 15980: Loss = 0.000957440\n",
      "Epoka 15990: Loss = 0.000990453\n",
      "Epoka 16000: Loss = 0.000952183\n",
      "Epoka 16010: Loss = 0.000966331\n",
      "Epoka 16020: Loss = 0.000958374\n",
      "Epoka 16030: Loss = 0.000954476\n",
      "Epoka 16040: Loss = 0.001073014\n",
      "Epoka 16050: Loss = 0.000974038\n",
      "Epoka 16060: Loss = 0.001008595\n",
      "Epoka 16070: Loss = 0.001147513\n",
      "Epoka 16080: Loss = 0.000989807\n",
      "Epoka 16090: Loss = 0.000970454\n",
      "Epoka 16100: Loss = 0.001046608\n",
      "Epoka 16110: Loss = 0.000937244\n",
      "Epoka 16120: Loss = 0.000942389\n",
      "Epoka 16130: Loss = 0.000997410\n",
      "Epoka 16140: Loss = 0.000965828\n",
      "Epoka 16150: Loss = 0.000980338\n",
      "Epoka 16160: Loss = 0.000983873\n",
      "Epoka 16170: Loss = 0.001010157\n",
      "Epoka 16180: Loss = 0.000986619\n",
      "Epoka 16190: Loss = 0.001426983\n",
      "Epoka 16200: Loss = 0.001004786\n",
      "Epoka 16210: Loss = 0.001254813\n",
      "Epoka 16220: Loss = 0.000928929\n",
      "Epoka 16230: Loss = 0.001019162\n",
      "Epoka 16240: Loss = 0.000945461\n",
      "Epoka 16250: Loss = 0.000957177\n",
      "Epoka 16260: Loss = 0.000954605\n",
      "Epoka 16270: Loss = 0.000993085\n",
      "Epoka 16280: Loss = 0.001078963\n",
      "Epoka 16290: Loss = 0.001212742\n",
      "Epoka 16300: Loss = 0.001135013\n",
      "Epoka 16310: Loss = 0.001008756\n",
      "Epoka 16320: Loss = 0.000950569\n",
      "Epoka 16330: Loss = 0.000963441\n",
      "Epoka 16340: Loss = 0.001059496\n",
      "Epoka 16350: Loss = 0.001115324\n",
      "Epoka 16360: Loss = 0.001106144\n",
      "Epoka 16370: Loss = 0.000930520\n",
      "Epoka 16380: Loss = 0.001010947\n",
      "Epoka 16390: Loss = 0.000940289\n",
      "Epoka 16400: Loss = 0.000943016\n",
      "Epoka 16410: Loss = 0.000962594\n",
      "Epoka 16420: Loss = 0.000950354\n",
      "Epoka 16430: Loss = 0.000928934\n",
      "Epoka 16440: Loss = 0.000992755\n",
      "Epoka 16450: Loss = 0.000941164\n",
      "Epoka 16460: Loss = 0.001264625\n",
      "Epoka 16470: Loss = 0.000961429\n",
      "Epoka 16480: Loss = 0.001261541\n",
      "Epoka 16490: Loss = 0.000987268\n",
      "Epoka 16500: Loss = 0.001080279\n",
      "Epoka 16510: Loss = 0.000926378\n",
      "Epoka 16520: Loss = 0.001120365\n",
      "Epoka 16530: Loss = 0.000985487\n",
      "Epoka 16540: Loss = 0.000932964\n",
      "Epoka 16550: Loss = 0.001046175\n",
      "Epoka 16560: Loss = 0.000921868\n",
      "Epoka 16570: Loss = 0.000996221\n",
      "Epoka 16580: Loss = 0.000937654\n",
      "Epoka 16590: Loss = 0.001009003\n",
      "Epoka 16600: Loss = 0.000940302\n",
      "Epoka 16610: Loss = 0.001045903\n",
      "Epoka 16620: Loss = 0.001014988\n",
      "Epoka 16630: Loss = 0.000969006\n",
      "Epoka 16640: Loss = 0.000932976\n",
      "Epoka 16650: Loss = 0.000999493\n",
      "Epoka 16660: Loss = 0.000965962\n",
      "Epoka 16670: Loss = 0.000975878\n",
      "Epoka 16680: Loss = 0.000915900\n",
      "Epoka 16690: Loss = 0.000987927\n",
      "Epoka 16700: Loss = 0.001039014\n",
      "Epoka 16710: Loss = 0.000992886\n",
      "Epoka 16720: Loss = 0.001031006\n",
      "Epoka 16730: Loss = 0.001176965\n",
      "Epoka 16740: Loss = 0.000908680\n",
      "Epoka 16750: Loss = 0.000947934\n",
      "Epoka 16760: Loss = 0.000906476\n",
      "Epoka 16770: Loss = 0.000930219\n",
      "Epoka 16780: Loss = 0.000943794\n",
      "Epoka 16790: Loss = 0.000944651\n",
      "Epoka 16800: Loss = 0.000905420\n",
      "Epoka 16810: Loss = 0.001002887\n",
      "Epoka 16820: Loss = 0.000962946\n",
      "Epoka 16830: Loss = 0.001040184\n",
      "Epoka 16840: Loss = 0.001082395\n",
      "Epoka 16850: Loss = 0.000934782\n",
      "Epoka 16860: Loss = 0.001014730\n",
      "Epoka 16870: Loss = 0.000958961\n",
      "Epoka 16880: Loss = 0.000980118\n",
      "Epoka 16890: Loss = 0.000939557\n",
      "Epoka 16900: Loss = 0.001051477\n",
      "Epoka 16910: Loss = 0.000921826\n",
      "Epoka 16920: Loss = 0.001021720\n",
      "Epoka 16930: Loss = 0.000935688\n",
      "Epoka 16940: Loss = 0.000950207\n",
      "Epoka 16950: Loss = 0.001066257\n",
      "Epoka 16960: Loss = 0.000988357\n",
      "Epoka 16970: Loss = 0.000928595\n",
      "Epoka 16980: Loss = 0.000962394\n",
      "Epoka 16990: Loss = 0.001031802\n",
      "Epoka 17000: Loss = 0.000977078\n",
      "Epoka 17010: Loss = 0.001002954\n",
      "Epoka 17020: Loss = 0.000991271\n",
      "Epoka 17030: Loss = 0.001133558\n",
      "Epoka 17040: Loss = 0.000907367\n",
      "Epoka 17050: Loss = 0.000945606\n",
      "Epoka 17060: Loss = 0.000930533\n",
      "Epoka 17070: Loss = 0.000953252\n",
      "Epoka 17080: Loss = 0.000915330\n",
      "Epoka 17090: Loss = 0.001032755\n",
      "Epoka 17100: Loss = 0.001074059\n",
      "Epoka 17110: Loss = 0.001008367\n",
      "Epoka 17120: Loss = 0.000932020\n",
      "Epoka 17130: Loss = 0.000935963\n",
      "Epoka 17140: Loss = 0.001148255\n",
      "Epoka 17150: Loss = 0.000920047\n",
      "Epoka 17160: Loss = 0.000994848\n",
      "Epoka 17170: Loss = 0.000959584\n",
      "Epoka 17180: Loss = 0.001046395\n",
      "Epoka 17190: Loss = 0.000944675\n",
      "Epoka 17200: Loss = 0.000932149\n",
      "Epoka 17210: Loss = 0.001122941\n",
      "Epoka 17220: Loss = 0.000957889\n",
      "Epoka 17230: Loss = 0.000945267\n",
      "Epoka 17240: Loss = 0.000927515\n",
      "Epoka 17250: Loss = 0.000962471\n",
      "Epoka 17260: Loss = 0.000959860\n",
      "Epoka 17270: Loss = 0.000955478\n",
      "Epoka 17280: Loss = 0.000911235\n",
      "Epoka 17290: Loss = 0.000974668\n",
      "Epoka 17300: Loss = 0.001055880\n",
      "Epoka 17310: Loss = 0.000942592\n",
      "Epoka 17320: Loss = 0.000953353\n",
      "Epoka 17330: Loss = 0.001100210\n",
      "Epoka 17340: Loss = 0.000991261\n",
      "Epoka 17350: Loss = 0.000902516\n",
      "Epoka 17360: Loss = 0.000959442\n",
      "Epoka 17370: Loss = 0.000912628\n",
      "Epoka 17380: Loss = 0.000917983\n",
      "Epoka 17390: Loss = 0.000968547\n",
      "Epoka 17400: Loss = 0.000945208\n",
      "Epoka 17410: Loss = 0.001012273\n",
      "Epoka 17420: Loss = 0.000963313\n",
      "Epoka 17430: Loss = 0.000945092\n",
      "Epoka 17440: Loss = 0.001133641\n",
      "Epoka 17450: Loss = 0.000893355\n",
      "Epoka 17460: Loss = 0.001056159\n",
      "Epoka 17470: Loss = 0.000922705\n",
      "Epoka 17480: Loss = 0.000908078\n",
      "Epoka 17490: Loss = 0.000957485\n",
      "Epoka 17500: Loss = 0.000903380\n",
      "Epoka 17510: Loss = 0.000906158\n",
      "Epoka 17520: Loss = 0.000906930\n",
      "Epoka 17530: Loss = 0.000940295\n",
      "Epoka 17540: Loss = 0.000960527\n",
      "Epoka 17550: Loss = 0.000982463\n",
      "Epoka 17560: Loss = 0.000887025\n",
      "Epoka 17570: Loss = 0.000922116\n",
      "Epoka 17580: Loss = 0.000966213\n",
      "Epoka 17590: Loss = 0.000941704\n",
      "Epoka 17600: Loss = 0.000932377\n",
      "Epoka 17610: Loss = 0.000904780\n",
      "Epoka 17620: Loss = 0.000902208\n",
      "Epoka 17630: Loss = 0.000890397\n",
      "Epoka 17640: Loss = 0.000933532\n",
      "Epoka 17650: Loss = 0.000919076\n",
      "Epoka 17660: Loss = 0.000961095\n",
      "Epoka 17670: Loss = 0.000949469\n",
      "Epoka 17680: Loss = 0.001085799\n",
      "Epoka 17690: Loss = 0.000918501\n",
      "Epoka 17700: Loss = 0.000927792\n",
      "Epoka 17710: Loss = 0.001008486\n",
      "Epoka 17720: Loss = 0.000906402\n",
      "Epoka 17730: Loss = 0.001034899\n",
      "Epoka 17740: Loss = 0.000911749\n",
      "Epoka 17750: Loss = 0.000878274\n",
      "Epoka 17760: Loss = 0.000957482\n",
      "Epoka 17770: Loss = 0.000909838\n",
      "Epoka 17780: Loss = 0.000888772\n",
      "Epoka 17790: Loss = 0.000907581\n",
      "Epoka 17800: Loss = 0.000890849\n",
      "Epoka 17810: Loss = 0.000943909\n",
      "Epoka 17820: Loss = 0.000934447\n",
      "Epoka 17830: Loss = 0.001051622\n",
      "Epoka 17840: Loss = 0.000904282\n",
      "Epoka 17850: Loss = 0.000934448\n",
      "Epoka 17860: Loss = 0.000937712\n",
      "Epoka 17870: Loss = 0.000975491\n",
      "Epoka 17880: Loss = 0.001438439\n",
      "Epoka 17890: Loss = 0.000975798\n",
      "Epoka 17900: Loss = 0.000969000\n",
      "Epoka 17910: Loss = 0.000939935\n",
      "Epoka 17920: Loss = 0.000905869\n",
      "Epoka 17930: Loss = 0.000878384\n",
      "Epoka 17940: Loss = 0.000950945\n",
      "Epoka 17950: Loss = 0.000885096\n",
      "Epoka 17960: Loss = 0.001006251\n",
      "Epoka 17970: Loss = 0.000878453\n",
      "Epoka 17980: Loss = 0.000957789\n",
      "Epoka 17990: Loss = 0.000916899\n",
      "Epoka 18000: Loss = 0.000900855\n",
      "Epoka 18010: Loss = 0.000976638\n",
      "Epoka 18020: Loss = 0.000931062\n",
      "Epoka 18030: Loss = 0.000929084\n",
      "Epoka 18040: Loss = 0.000943364\n",
      "Epoka 18050: Loss = 0.000994650\n",
      "Epoka 18060: Loss = 0.000873793\n",
      "Epoka 18070: Loss = 0.000937065\n",
      "Epoka 18080: Loss = 0.000871244\n",
      "Epoka 18090: Loss = 0.000980975\n",
      "Epoka 18100: Loss = 0.000947611\n",
      "Epoka 18110: Loss = 0.000875449\n",
      "Epoka 18120: Loss = 0.000956931\n",
      "Epoka 18130: Loss = 0.000976785\n",
      "Epoka 18140: Loss = 0.000969227\n",
      "Epoka 18150: Loss = 0.000955290\n",
      "Epoka 18160: Loss = 0.001025084\n",
      "Epoka 18170: Loss = 0.001087119\n",
      "Epoka 18180: Loss = 0.000952274\n",
      "Epoka 18190: Loss = 0.000976325\n",
      "Epoka 18200: Loss = 0.000881854\n",
      "Epoka 18210: Loss = 0.000868452\n",
      "Epoka 18220: Loss = 0.001055723\n",
      "Epoka 18230: Loss = 0.000923203\n",
      "Epoka 18240: Loss = 0.000874694\n",
      "Epoka 18250: Loss = 0.000925438\n",
      "Epoka 18260: Loss = 0.000895430\n",
      "Epoka 18270: Loss = 0.000904251\n",
      "Epoka 18280: Loss = 0.000946947\n",
      "Epoka 18290: Loss = 0.000931234\n",
      "Epoka 18300: Loss = 0.000943856\n",
      "Epoka 18310: Loss = 0.000995479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 18320: Loss = 0.001002918\n",
      "Epoka 18330: Loss = 0.001098066\n",
      "Epoka 18340: Loss = 0.000950367\n",
      "Epoka 18350: Loss = 0.000870904\n",
      "Epoka 18360: Loss = 0.001023546\n",
      "Epoka 18370: Loss = 0.000918210\n",
      "Epoka 18380: Loss = 0.000893849\n",
      "Epoka 18390: Loss = 0.000884066\n",
      "Epoka 18400: Loss = 0.000947204\n",
      "Epoka 18410: Loss = 0.001253969\n",
      "Epoka 18420: Loss = 0.000887036\n",
      "Epoka 18430: Loss = 0.001002692\n",
      "Epoka 18440: Loss = 0.000927555\n",
      "Epoka 18450: Loss = 0.001004805\n",
      "Epoka 18460: Loss = 0.000886546\n",
      "Epoka 18470: Loss = 0.000863028\n",
      "Epoka 18480: Loss = 0.000901167\n",
      "Epoka 18490: Loss = 0.000909840\n",
      "Epoka 18500: Loss = 0.000947908\n",
      "Epoka 18510: Loss = 0.000909256\n",
      "Epoka 18520: Loss = 0.000857614\n",
      "Epoka 18530: Loss = 0.000906743\n",
      "Epoka 18540: Loss = 0.000887575\n",
      "Epoka 18550: Loss = 0.001033008\n",
      "Epoka 18560: Loss = 0.000883489\n",
      "Epoka 18570: Loss = 0.000910349\n",
      "Epoka 18580: Loss = 0.000910053\n",
      "Epoka 18590: Loss = 0.000925942\n",
      "Epoka 18600: Loss = 0.000977933\n",
      "Epoka 18610: Loss = 0.000865869\n",
      "Epoka 18620: Loss = 0.000887755\n",
      "Epoka 18630: Loss = 0.000857708\n",
      "Epoka 18640: Loss = 0.000869100\n",
      "Epoka 18650: Loss = 0.000884445\n",
      "Epoka 18660: Loss = 0.000912762\n",
      "Epoka 18670: Loss = 0.000913516\n",
      "Epoka 18680: Loss = 0.000915064\n",
      "Epoka 18690: Loss = 0.000866852\n",
      "Epoka 18700: Loss = 0.000969800\n",
      "Epoka 18710: Loss = 0.000894074\n",
      "Epoka 18720: Loss = 0.000917172\n",
      "Epoka 18730: Loss = 0.001072172\n",
      "Epoka 18740: Loss = 0.000889051\n",
      "Epoka 18750: Loss = 0.000903122\n",
      "Epoka 18760: Loss = 0.000929200\n",
      "Epoka 18770: Loss = 0.000901170\n",
      "Epoka 18780: Loss = 0.000924947\n",
      "Epoka 18790: Loss = 0.000929242\n",
      "Epoka 18800: Loss = 0.000859966\n",
      "Epoka 18810: Loss = 0.000882403\n",
      "Epoka 18820: Loss = 0.000866542\n",
      "Epoka 18830: Loss = 0.001064868\n",
      "Epoka 18840: Loss = 0.000914520\n",
      "Epoka 18850: Loss = 0.000909885\n",
      "Epoka 18860: Loss = 0.000872283\n",
      "Epoka 18870: Loss = 0.000889211\n",
      "Epoka 18880: Loss = 0.000879794\n",
      "Epoka 18890: Loss = 0.000932206\n",
      "Epoka 18900: Loss = 0.001086733\n",
      "Epoka 18910: Loss = 0.000890820\n",
      "Epoka 18920: Loss = 0.000915808\n",
      "Epoka 18930: Loss = 0.000911894\n",
      "Epoka 18940: Loss = 0.000932127\n",
      "Epoka 18950: Loss = 0.000872868\n",
      "Epoka 18960: Loss = 0.000962945\n",
      "Epoka 18970: Loss = 0.000883780\n",
      "Epoka 18980: Loss = 0.000907766\n",
      "Epoka 18990: Loss = 0.000895055\n",
      "Epoka 19000: Loss = 0.000865544\n",
      "Epoka 19010: Loss = 0.000959479\n",
      "Epoka 19020: Loss = 0.000856633\n",
      "Epoka 19030: Loss = 0.000944942\n",
      "Epoka 19040: Loss = 0.000906375\n",
      "Epoka 19050: Loss = 0.000879681\n",
      "Epoka 19060: Loss = 0.000942610\n",
      "Epoka 19070: Loss = 0.000878710\n",
      "Epoka 19080: Loss = 0.000912609\n",
      "Epoka 19090: Loss = 0.000885104\n",
      "Epoka 19100: Loss = 0.000919823\n",
      "Epoka 19110: Loss = 0.000954898\n",
      "Epoka 19120: Loss = 0.000854086\n",
      "Epoka 19130: Loss = 0.000984359\n",
      "Epoka 19140: Loss = 0.000893729\n",
      "Epoka 19150: Loss = 0.000887117\n",
      "Epoka 19160: Loss = 0.000992473\n",
      "Epoka 19170: Loss = 0.000885706\n",
      "Epoka 19180: Loss = 0.000876279\n",
      "Epoka 19190: Loss = 0.000896923\n",
      "Epoka 19200: Loss = 0.000892685\n",
      "Epoka 19210: Loss = 0.000894075\n",
      "Epoka 19220: Loss = 0.000907387\n",
      "Epoka 19230: Loss = 0.000894884\n",
      "Epoka 19240: Loss = 0.001021088\n",
      "Epoka 19250: Loss = 0.000880357\n",
      "Epoka 19260: Loss = 0.000924079\n",
      "Epoka 19270: Loss = 0.000860956\n",
      "Epoka 19280: Loss = 0.000863676\n",
      "Epoka 19290: Loss = 0.001051119\n",
      "Epoka 19300: Loss = 0.000917187\n",
      "Epoka 19310: Loss = 0.000911297\n",
      "Epoka 19320: Loss = 0.001046940\n",
      "Epoka 19330: Loss = 0.000924625\n",
      "Epoka 19340: Loss = 0.000890186\n",
      "Epoka 19350: Loss = 0.000962302\n",
      "Epoka 19360: Loss = 0.000889032\n",
      "Epoka 19370: Loss = 0.000969133\n",
      "Epoka 19380: Loss = 0.000867647\n",
      "Epoka 19390: Loss = 0.000966534\n",
      "Epoka 19400: Loss = 0.000875329\n",
      "Epoka 19410: Loss = 0.001032410\n",
      "Epoka 19420: Loss = 0.000868942\n",
      "Epoka 19430: Loss = 0.000867735\n",
      "Epoka 19440: Loss = 0.000907627\n",
      "Epoka 19450: Loss = 0.000847883\n",
      "Epoka 19460: Loss = 0.000948128\n",
      "Epoka 19470: Loss = 0.001007831\n",
      "Epoka 19480: Loss = 0.000890175\n",
      "Epoka 19490: Loss = 0.000946554\n",
      "Epoka 19500: Loss = 0.000887336\n",
      "Epoka 19510: Loss = 0.000925083\n",
      "Epoka 19520: Loss = 0.000969125\n",
      "Epoka 19530: Loss = 0.000845197\n",
      "Epoka 19540: Loss = 0.000900504\n",
      "Epoka 19550: Loss = 0.000849067\n",
      "Epoka 19560: Loss = 0.000949643\n",
      "Epoka 19570: Loss = 0.000871052\n",
      "Epoka 19580: Loss = 0.000907884\n",
      "Epoka 19590: Loss = 0.000958407\n",
      "Epoka 19600: Loss = 0.000886134\n",
      "Epoka 19610: Loss = 0.000869572\n",
      "Epoka 19620: Loss = 0.000936165\n",
      "Epoka 19630: Loss = 0.000895771\n",
      "Epoka 19640: Loss = 0.001119830\n",
      "Epoka 19650: Loss = 0.000865182\n",
      "Epoka 19660: Loss = 0.000887475\n",
      "Epoka 19670: Loss = 0.000877670\n",
      "Epoka 19680: Loss = 0.000869566\n",
      "Epoka 19690: Loss = 0.000943360\n",
      "Epoka 19700: Loss = 0.000856626\n",
      "Epoka 19710: Loss = 0.000978771\n",
      "Epoka 19720: Loss = 0.000961224\n",
      "Epoka 19730: Loss = 0.000861639\n",
      "Epoka 19740: Loss = 0.000905169\n",
      "Epoka 19750: Loss = 0.000868262\n",
      "Epoka 19760: Loss = 0.000957799\n",
      "Epoka 19770: Loss = 0.000853755\n",
      "Epoka 19780: Loss = 0.000886516\n",
      "Epoka 19790: Loss = 0.000846380\n",
      "Epoka 19800: Loss = 0.000863568\n",
      "Epoka 19810: Loss = 0.000864964\n",
      "Epoka 19820: Loss = 0.000878465\n",
      "Epoka 19830: Loss = 0.000924627\n",
      "Epoka 19840: Loss = 0.000881978\n",
      "Epoka 19850: Loss = 0.000837475\n",
      "Epoka 19860: Loss = 0.000840644\n",
      "Epoka 19870: Loss = 0.000942675\n",
      "Epoka 19880: Loss = 0.000877270\n",
      "Epoka 19890: Loss = 0.000935904\n",
      "Epoka 19900: Loss = 0.001008778\n",
      "Epoka 19910: Loss = 0.000855475\n",
      "Epoka 19920: Loss = 0.000895044\n",
      "Epoka 19930: Loss = 0.000870547\n",
      "Epoka 19940: Loss = 0.000876965\n",
      "Epoka 19950: Loss = 0.000923635\n",
      "Epoka 19960: Loss = 0.000875505\n",
      "Epoka 19970: Loss = 0.001222810\n",
      "Epoka 19980: Loss = 0.000961044\n",
      "Epoka 19990: Loss = 0.000915438\n",
      "Epoka 20000: Loss = 0.000875202\n",
      "Epoka 20010: Loss = 0.000967869\n",
      "Epoka 20020: Loss = 0.000880831\n",
      "Epoka 20030: Loss = 0.000876512\n",
      "Epoka 20040: Loss = 0.000897978\n",
      "Epoka 20050: Loss = 0.000874587\n",
      "Epoka 20060: Loss = 0.000837429\n",
      "Epoka 20070: Loss = 0.000835616\n",
      "Epoka 20080: Loss = 0.001062703\n",
      "Epoka 20090: Loss = 0.000835609\n",
      "Epoka 20100: Loss = 0.000862634\n",
      "Epoka 20110: Loss = 0.000870516\n",
      "Epoka 20120: Loss = 0.000851208\n",
      "Epoka 20130: Loss = 0.000869236\n",
      "Epoka 20140: Loss = 0.000964996\n",
      "Epoka 20150: Loss = 0.000831879\n",
      "Epoka 20160: Loss = 0.000903336\n",
      "Epoka 20170: Loss = 0.000865581\n",
      "Epoka 20180: Loss = 0.000875369\n",
      "Epoka 20190: Loss = 0.000836213\n",
      "Epoka 20200: Loss = 0.000943812\n",
      "Epoka 20210: Loss = 0.000921107\n",
      "Epoka 20220: Loss = 0.000938816\n",
      "Epoka 20230: Loss = 0.000871941\n",
      "Epoka 20240: Loss = 0.000847234\n",
      "Epoka 20250: Loss = 0.000848105\n",
      "Epoka 20260: Loss = 0.000864993\n",
      "Epoka 20270: Loss = 0.000834776\n",
      "Epoka 20280: Loss = 0.000955479\n",
      "Epoka 20290: Loss = 0.000859533\n",
      "Epoka 20300: Loss = 0.000908667\n",
      "Epoka 20310: Loss = 0.000854571\n",
      "Epoka 20320: Loss = 0.000915077\n",
      "Epoka 20330: Loss = 0.000883429\n",
      "Epoka 20340: Loss = 0.000823693\n",
      "Epoka 20350: Loss = 0.000864149\n",
      "Epoka 20360: Loss = 0.000831046\n",
      "Epoka 20370: Loss = 0.000854651\n",
      "Epoka 20380: Loss = 0.000855179\n",
      "Epoka 20390: Loss = 0.000856756\n",
      "Epoka 20400: Loss = 0.000905206\n",
      "Epoka 20410: Loss = 0.000882711\n",
      "Epoka 20420: Loss = 0.000978573\n",
      "Epoka 20430: Loss = 0.000826116\n",
      "Epoka 20440: Loss = 0.000897703\n",
      "Epoka 20450: Loss = 0.000899158\n",
      "Epoka 20460: Loss = 0.000859537\n",
      "Epoka 20470: Loss = 0.000886528\n",
      "Epoka 20480: Loss = 0.000824309\n",
      "Epoka 20490: Loss = 0.000977467\n",
      "Epoka 20500: Loss = 0.000947150\n",
      "Epoka 20510: Loss = 0.000884799\n",
      "Epoka 20520: Loss = 0.000817707\n",
      "Epoka 20530: Loss = 0.000856527\n",
      "Epoka 20540: Loss = 0.000847107\n",
      "Epoka 20550: Loss = 0.001104986\n",
      "Epoka 20560: Loss = 0.000938301\n",
      "Epoka 20570: Loss = 0.000889643\n",
      "Epoka 20580: Loss = 0.000919679\n",
      "Epoka 20590: Loss = 0.000924480\n",
      "Epoka 20600: Loss = 0.000892908\n",
      "Epoka 20610: Loss = 0.001019789\n",
      "Epoka 20620: Loss = 0.000914961\n",
      "Epoka 20630: Loss = 0.000844811\n",
      "Epoka 20640: Loss = 0.001019187\n",
      "Epoka 20650: Loss = 0.000919158\n",
      "Epoka 20660: Loss = 0.000865071\n",
      "Epoka 20670: Loss = 0.000827362\n",
      "Epoka 20680: Loss = 0.000842110\n",
      "Epoka 20690: Loss = 0.000809156\n",
      "Epoka 20700: Loss = 0.000910997\n",
      "Epoka 20710: Loss = 0.000827202\n",
      "Epoka 20720: Loss = 0.000861610\n",
      "Epoka 20730: Loss = 0.000913537\n",
      "Epoka 20740: Loss = 0.000893449\n",
      "Epoka 20750: Loss = 0.000824682\n",
      "Epoka 20760: Loss = 0.000855549\n",
      "Epoka 20770: Loss = 0.000849579\n",
      "Epoka 20780: Loss = 0.000812940\n",
      "Epoka 20790: Loss = 0.000993153\n",
      "Epoka 20800: Loss = 0.000860928\n",
      "Epoka 20810: Loss = 0.000864773\n",
      "Epoka 20820: Loss = 0.000906475\n",
      "Epoka 20830: Loss = 0.000875920\n",
      "Epoka 20840: Loss = 0.000907037\n",
      "Epoka 20850: Loss = 0.000844046\n",
      "Epoka 20860: Loss = 0.000828593\n",
      "Epoka 20870: Loss = 0.000870753\n",
      "Epoka 20880: Loss = 0.000959049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 20890: Loss = 0.000827291\n",
      "Epoka 20900: Loss = 0.000888583\n",
      "Epoka 20910: Loss = 0.000821216\n",
      "Epoka 20920: Loss = 0.000854196\n",
      "Epoka 20930: Loss = 0.000900802\n",
      "Epoka 20940: Loss = 0.000828958\n",
      "Epoka 20950: Loss = 0.000832230\n",
      "Epoka 20960: Loss = 0.000838025\n",
      "Epoka 20970: Loss = 0.000917993\n",
      "Epoka 20980: Loss = 0.000838435\n",
      "Epoka 20990: Loss = 0.000839246\n",
      "Epoka 21000: Loss = 0.000886427\n",
      "Epoka 21010: Loss = 0.000912596\n",
      "Epoka 21020: Loss = 0.000808572\n",
      "Epoka 21030: Loss = 0.000896534\n",
      "Epoka 21040: Loss = 0.000931386\n",
      "Epoka 21050: Loss = 0.000819641\n",
      "Epoka 21060: Loss = 0.000841904\n",
      "Epoka 21070: Loss = 0.000809787\n",
      "Epoka 21080: Loss = 0.000840073\n",
      "Epoka 21090: Loss = 0.000818858\n",
      "Epoka 21100: Loss = 0.001031281\n",
      "Epoka 21110: Loss = 0.000837965\n",
      "Epoka 21120: Loss = 0.000979455\n",
      "Epoka 21130: Loss = 0.000803608\n",
      "Epoka 21140: Loss = 0.000849444\n",
      "Epoka 21150: Loss = 0.000841711\n",
      "Epoka 21160: Loss = 0.000910397\n",
      "Epoka 21170: Loss = 0.000905223\n",
      "Epoka 21180: Loss = 0.000866389\n",
      "Epoka 21190: Loss = 0.000840165\n",
      "Epoka 21200: Loss = 0.000818919\n",
      "Epoka 21210: Loss = 0.000816113\n",
      "Epoka 21220: Loss = 0.000879115\n",
      "Epoka 21230: Loss = 0.000925558\n",
      "Epoka 21240: Loss = 0.000901539\n",
      "Epoka 21250: Loss = 0.000880238\n",
      "Epoka 21260: Loss = 0.000835523\n",
      "Epoka 21270: Loss = 0.000899700\n",
      "Epoka 21280: Loss = 0.000854945\n",
      "Epoka 21290: Loss = 0.000913529\n",
      "Epoka 21300: Loss = 0.000908943\n",
      "Epoka 21310: Loss = 0.000859286\n",
      "Epoka 21320: Loss = 0.001085990\n",
      "Epoka 21330: Loss = 0.000907314\n",
      "Epoka 21340: Loss = 0.000803935\n",
      "Epoka 21350: Loss = 0.000859513\n",
      "Epoka 21360: Loss = 0.000854960\n",
      "Epoka 21370: Loss = 0.000840804\n",
      "Epoka 21380: Loss = 0.000832596\n",
      "Epoka 21390: Loss = 0.000816837\n",
      "Epoka 21400: Loss = 0.000887055\n",
      "Epoka 21410: Loss = 0.000840602\n",
      "Epoka 21420: Loss = 0.000958988\n",
      "Epoka 21430: Loss = 0.000826873\n",
      "Epoka 21440: Loss = 0.000829042\n",
      "Epoka 21450: Loss = 0.000935980\n",
      "Epoka 21460: Loss = 0.000878285\n",
      "Epoka 21470: Loss = 0.000892566\n",
      "Epoka 21480: Loss = 0.000867844\n",
      "Epoka 21490: Loss = 0.000818521\n",
      "Epoka 21500: Loss = 0.000851893\n",
      "Epoka 21510: Loss = 0.000840591\n",
      "Epoka 21520: Loss = 0.000813287\n",
      "Epoka 21530: Loss = 0.000801737\n",
      "Epoka 21540: Loss = 0.000990452\n",
      "Epoka 21550: Loss = 0.000895579\n",
      "Epoka 21560: Loss = 0.000856599\n",
      "Epoka 21570: Loss = 0.000856327\n",
      "Epoka 21580: Loss = 0.000938098\n",
      "Epoka 21590: Loss = 0.000818419\n",
      "Epoka 21600: Loss = 0.000902591\n",
      "Epoka 21610: Loss = 0.000855077\n",
      "Epoka 21620: Loss = 0.000827564\n",
      "Epoka 21630: Loss = 0.000845973\n",
      "Epoka 21640: Loss = 0.000803856\n",
      "Epoka 21650: Loss = 0.000862448\n",
      "Epoka 21660: Loss = 0.000842068\n",
      "Epoka 21670: Loss = 0.000893539\n",
      "Epoka 21680: Loss = 0.000878896\n",
      "Epoka 21690: Loss = 0.000877674\n",
      "Epoka 21700: Loss = 0.000806603\n",
      "Epoka 21710: Loss = 0.000799107\n",
      "Epoka 21720: Loss = 0.000849025\n",
      "Epoka 21730: Loss = 0.000888610\n",
      "Epoka 21740: Loss = 0.001040325\n",
      "Epoka 21750: Loss = 0.000822319\n",
      "Epoka 21760: Loss = 0.000839919\n",
      "Epoka 21770: Loss = 0.000901096\n",
      "Epoka 21780: Loss = 0.000804152\n",
      "Epoka 21790: Loss = 0.000808880\n",
      "Epoka 21800: Loss = 0.000832133\n",
      "Epoka 21810: Loss = 0.000816930\n",
      "Epoka 21820: Loss = 0.000794780\n",
      "Epoka 21830: Loss = 0.000877980\n",
      "Epoka 21840: Loss = 0.000933549\n",
      "Epoka 21850: Loss = 0.000799329\n",
      "Epoka 21860: Loss = 0.001032135\n",
      "Epoka 21870: Loss = 0.000827739\n",
      "Epoka 21880: Loss = 0.000816426\n",
      "Epoka 21890: Loss = 0.000836274\n",
      "Epoka 21900: Loss = 0.000865394\n",
      "Epoka 21910: Loss = 0.000965378\n",
      "Epoka 21920: Loss = 0.000871023\n",
      "Epoka 21930: Loss = 0.000813633\n",
      "Epoka 21940: Loss = 0.000937041\n",
      "Epoka 21950: Loss = 0.000792648\n",
      "Epoka 21960: Loss = 0.000970625\n",
      "Epoka 21970: Loss = 0.000821202\n",
      "Epoka 21980: Loss = 0.000917918\n",
      "Epoka 21990: Loss = 0.000860478\n",
      "Epoka 22000: Loss = 0.000821011\n",
      "Epoka 22010: Loss = 0.000841730\n",
      "Epoka 22020: Loss = 0.000865501\n",
      "Epoka 22030: Loss = 0.000927911\n",
      "Epoka 22040: Loss = 0.000816596\n",
      "Epoka 22050: Loss = 0.000821514\n",
      "Epoka 22060: Loss = 0.000915656\n",
      "Epoka 22070: Loss = 0.000857821\n",
      "Epoka 22080: Loss = 0.000862566\n",
      "Epoka 22090: Loss = 0.000869297\n",
      "Epoka 22100: Loss = 0.000839211\n",
      "Epoka 22110: Loss = 0.000790422\n",
      "Epoka 22120: Loss = 0.000821146\n",
      "Epoka 22130: Loss = 0.000928355\n",
      "Epoka 22140: Loss = 0.000857693\n",
      "Epoka 22150: Loss = 0.000936465\n",
      "Epoka 22160: Loss = 0.000784695\n",
      "Epoka 22170: Loss = 0.000841810\n",
      "Epoka 22180: Loss = 0.000876124\n",
      "Epoka 22190: Loss = 0.000827209\n",
      "Epoka 22200: Loss = 0.000793246\n",
      "Epoka 22210: Loss = 0.000788123\n",
      "Epoka 22220: Loss = 0.000805209\n",
      "Epoka 22230: Loss = 0.000937840\n",
      "Epoka 22240: Loss = 0.000816115\n",
      "Epoka 22250: Loss = 0.000795389\n",
      "Epoka 22260: Loss = 0.000792092\n",
      "Epoka 22270: Loss = 0.000818731\n",
      "Epoka 22280: Loss = 0.000797398\n",
      "Epoka 22290: Loss = 0.000798012\n",
      "Epoka 22300: Loss = 0.000881906\n",
      "Epoka 22310: Loss = 0.000956774\n",
      "Epoka 22320: Loss = 0.000812793\n",
      "Epoka 22330: Loss = 0.000811229\n",
      "Epoka 22340: Loss = 0.000851915\n",
      "Epoka 22350: Loss = 0.000825493\n",
      "Epoka 22360: Loss = 0.000812538\n",
      "Epoka 22370: Loss = 0.000798238\n",
      "Epoka 22380: Loss = 0.000843233\n",
      "Epoka 22390: Loss = 0.000856546\n",
      "Epoka 22400: Loss = 0.000846793\n",
      "Epoka 22410: Loss = 0.000858192\n",
      "Epoka 22420: Loss = 0.000796530\n",
      "Epoka 22430: Loss = 0.000948486\n",
      "Epoka 22440: Loss = 0.000863386\n",
      "Epoka 22450: Loss = 0.000793185\n",
      "Epoka 22460: Loss = 0.000803499\n",
      "Epoka 22470: Loss = 0.000871039\n",
      "Epoka 22480: Loss = 0.000872225\n",
      "Epoka 22490: Loss = 0.000844532\n",
      "Epoka 22500: Loss = 0.000831726\n",
      "Epoka 22510: Loss = 0.000956224\n",
      "Epoka 22520: Loss = 0.000886602\n",
      "Epoka 22530: Loss = 0.000809886\n",
      "Epoka 22540: Loss = 0.000878615\n",
      "Epoka 22550: Loss = 0.000783623\n",
      "Epoka 22560: Loss = 0.000823308\n",
      "Epoka 22570: Loss = 0.000791336\n",
      "Epoka 22580: Loss = 0.000876173\n",
      "Epoka 22590: Loss = 0.000834500\n",
      "Epoka 22600: Loss = 0.000834933\n",
      "Epoka 22610: Loss = 0.000775760\n",
      "Epoka 22620: Loss = 0.000843649\n",
      "Epoka 22630: Loss = 0.001023702\n",
      "Epoka 22640: Loss = 0.000865190\n",
      "Epoka 22650: Loss = 0.000820265\n",
      "Epoka 22660: Loss = 0.000816471\n",
      "Epoka 22670: Loss = 0.000809550\n",
      "Epoka 22680: Loss = 0.000801729\n",
      "Epoka 22690: Loss = 0.000775202\n",
      "Epoka 22700: Loss = 0.000950626\n",
      "Epoka 22710: Loss = 0.000845174\n",
      "Epoka 22720: Loss = 0.000881810\n",
      "Epoka 22730: Loss = 0.000816862\n",
      "Epoka 22740: Loss = 0.000824528\n",
      "Epoka 22750: Loss = 0.000951149\n",
      "Epoka 22760: Loss = 0.000851857\n",
      "Epoka 22770: Loss = 0.000871653\n",
      "Epoka 22780: Loss = 0.000774544\n",
      "Epoka 22790: Loss = 0.000819985\n",
      "Epoka 22800: Loss = 0.000841650\n",
      "Epoka 22810: Loss = 0.000794305\n",
      "Epoka 22820: Loss = 0.000797261\n",
      "Epoka 22830: Loss = 0.000789890\n",
      "Epoka 22840: Loss = 0.000934344\n",
      "Epoka 22850: Loss = 0.000803932\n",
      "Epoka 22860: Loss = 0.000851497\n",
      "Epoka 22870: Loss = 0.000966351\n",
      "Epoka 22880: Loss = 0.000774295\n",
      "Epoka 22890: Loss = 0.000835569\n",
      "Epoka 22900: Loss = 0.000782233\n",
      "Epoka 22910: Loss = 0.000793930\n",
      "Epoka 22920: Loss = 0.000816519\n",
      "Epoka 22930: Loss = 0.000776393\n",
      "Epoka 22940: Loss = 0.000761792\n",
      "Epoka 22950: Loss = 0.000854874\n",
      "Epoka 22960: Loss = 0.000812611\n",
      "Epoka 22970: Loss = 0.001037277\n",
      "Epoka 22980: Loss = 0.000770530\n",
      "Epoka 22990: Loss = 0.000768307\n",
      "Epoka 23000: Loss = 0.000939210\n",
      "Epoka 23010: Loss = 0.000912873\n",
      "Epoka 23020: Loss = 0.000833767\n",
      "Epoka 23030: Loss = 0.000781528\n",
      "Epoka 23040: Loss = 0.000828030\n",
      "Epoka 23050: Loss = 0.000934661\n",
      "Epoka 23060: Loss = 0.000769348\n",
      "Epoka 23070: Loss = 0.000842482\n",
      "Epoka 23080: Loss = 0.000908753\n",
      "Epoka 23090: Loss = 0.000849145\n",
      "Epoka 23100: Loss = 0.000783361\n",
      "Epoka 23110: Loss = 0.000788510\n",
      "Epoka 23120: Loss = 0.000849100\n",
      "Epoka 23130: Loss = 0.000821088\n",
      "Epoka 23140: Loss = 0.000810821\n",
      "Epoka 23150: Loss = 0.000938909\n",
      "Epoka 23160: Loss = 0.000793311\n",
      "Epoka 23170: Loss = 0.000802077\n",
      "Epoka 23180: Loss = 0.000870272\n",
      "Epoka 23190: Loss = 0.000769742\n",
      "Epoka 23200: Loss = 0.000982524\n",
      "Epoka 23210: Loss = 0.000775742\n",
      "Epoka 23220: Loss = 0.000797883\n",
      "Epoka 23230: Loss = 0.000787451\n",
      "Epoka 23240: Loss = 0.000762171\n",
      "Epoka 23250: Loss = 0.000984697\n",
      "Epoka 23260: Loss = 0.000962016\n",
      "Epoka 23270: Loss = 0.000839779\n",
      "Epoka 23280: Loss = 0.000894940\n",
      "Epoka 23290: Loss = 0.000777139\n",
      "Epoka 23300: Loss = 0.000857452\n",
      "Epoka 23310: Loss = 0.000828322\n",
      "Epoka 23320: Loss = 0.000824831\n",
      "Epoka 23330: Loss = 0.000798440\n",
      "Epoka 23340: Loss = 0.000952808\n",
      "Epoka 23350: Loss = 0.000768921\n",
      "Epoka 23360: Loss = 0.000761837\n",
      "Epoka 23370: Loss = 0.000825655\n",
      "Epoka 23380: Loss = 0.000813321\n",
      "Epoka 23390: Loss = 0.000769911\n",
      "Epoka 23400: Loss = 0.000957643\n",
      "Epoka 23410: Loss = 0.000796775\n",
      "Epoka 23420: Loss = 0.000790948\n",
      "Epoka 23430: Loss = 0.000849231\n",
      "Epoka 23440: Loss = 0.000770559\n",
      "Epoka 23450: Loss = 0.000762633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 23460: Loss = 0.000817766\n",
      "Epoka 23470: Loss = 0.000849182\n",
      "Epoka 23480: Loss = 0.000803448\n",
      "Epoka 23490: Loss = 0.000790284\n",
      "Epoka 23500: Loss = 0.000783919\n",
      "Epoka 23510: Loss = 0.000969686\n",
      "Epoka 23520: Loss = 0.000828110\n",
      "Epoka 23530: Loss = 0.000865039\n",
      "Epoka 23540: Loss = 0.000889792\n",
      "Epoka 23550: Loss = 0.000788737\n",
      "Epoka 23560: Loss = 0.001074150\n",
      "Epoka 23570: Loss = 0.000789589\n",
      "Epoka 23580: Loss = 0.000808751\n",
      "Epoka 23590: Loss = 0.000824722\n",
      "Epoka 23600: Loss = 0.000769724\n",
      "Epoka 23610: Loss = 0.000819054\n",
      "Epoka 23620: Loss = 0.000798662\n",
      "Epoka 23630: Loss = 0.000840686\n",
      "Epoka 23640: Loss = 0.000801358\n",
      "Epoka 23650: Loss = 0.000831475\n",
      "Epoka 23660: Loss = 0.000846173\n",
      "Epoka 23670: Loss = 0.000828337\n",
      "Epoka 23680: Loss = 0.000826258\n",
      "Epoka 23690: Loss = 0.000801326\n",
      "Epoka 23700: Loss = 0.000864074\n",
      "Epoka 23710: Loss = 0.000899676\n",
      "Epoka 23720: Loss = 0.000763213\n",
      "Epoka 23730: Loss = 0.000861712\n",
      "Epoka 23740: Loss = 0.000808051\n",
      "Epoka 23750: Loss = 0.000779578\n",
      "Epoka 23760: Loss = 0.000978186\n",
      "Epoka 23770: Loss = 0.000801980\n",
      "Epoka 23780: Loss = 0.000830315\n",
      "Epoka 23790: Loss = 0.000798142\n",
      "Epoka 23800: Loss = 0.000770369\n",
      "Epoka 23810: Loss = 0.000859701\n",
      "Epoka 23820: Loss = 0.000877425\n",
      "Epoka 23830: Loss = 0.000751469\n",
      "Epoka 23840: Loss = 0.000777041\n",
      "Epoka 23850: Loss = 0.000979965\n",
      "Epoka 23860: Loss = 0.000804917\n",
      "Epoka 23870: Loss = 0.000761974\n",
      "Epoka 23880: Loss = 0.000864803\n",
      "Epoka 23890: Loss = 0.000780926\n",
      "Epoka 23900: Loss = 0.000851169\n",
      "Epoka 23910: Loss = 0.000766835\n",
      "Epoka 23920: Loss = 0.000805167\n",
      "Epoka 23930: Loss = 0.000764175\n",
      "Epoka 23940: Loss = 0.000866023\n",
      "Epoka 23950: Loss = 0.000767189\n",
      "Epoka 23960: Loss = 0.000757590\n",
      "Epoka 23970: Loss = 0.000794267\n",
      "Epoka 23980: Loss = 0.000803716\n",
      "Epoka 23990: Loss = 0.000780179\n",
      "Epoka 24000: Loss = 0.000777337\n",
      "Epoka 24010: Loss = 0.000855945\n",
      "Epoka 24020: Loss = 0.000763830\n",
      "Epoka 24030: Loss = 0.001049744\n",
      "Epoka 24040: Loss = 0.000831622\n",
      "Epoka 24050: Loss = 0.000790934\n",
      "Epoka 24060: Loss = 0.000793158\n",
      "Epoka 24070: Loss = 0.000786483\n",
      "Epoka 24080: Loss = 0.000810862\n",
      "Epoka 24090: Loss = 0.000875189\n",
      "Epoka 24100: Loss = 0.000780282\n",
      "Epoka 24110: Loss = 0.000880588\n",
      "Epoka 24120: Loss = 0.000747943\n",
      "Epoka 24130: Loss = 0.000768644\n",
      "Epoka 24140: Loss = 0.000758172\n",
      "Epoka 24150: Loss = 0.000888094\n",
      "Epoka 24160: Loss = 0.000821048\n",
      "Epoka 24170: Loss = 0.000808523\n",
      "Epoka 24180: Loss = 0.000813228\n",
      "Epoka 24190: Loss = 0.000831118\n",
      "Epoka 24200: Loss = 0.000804470\n",
      "Epoka 24210: Loss = 0.000776033\n",
      "Epoka 24220: Loss = 0.000978824\n",
      "Epoka 24230: Loss = 0.000836372\n",
      "Epoka 24240: Loss = 0.000764801\n",
      "Epoka 24250: Loss = 0.000852129\n",
      "Epoka 24260: Loss = 0.000849801\n",
      "Epoka 24270: Loss = 0.000819358\n",
      "Epoka 24280: Loss = 0.000779692\n",
      "Epoka 24290: Loss = 0.000830601\n",
      "Epoka 24300: Loss = 0.000811094\n",
      "Epoka 24310: Loss = 0.000805334\n",
      "Epoka 24320: Loss = 0.000983618\n",
      "Epoka 24330: Loss = 0.000758083\n",
      "Epoka 24340: Loss = 0.000823245\n",
      "Epoka 24350: Loss = 0.000781018\n",
      "Epoka 24360: Loss = 0.001026156\n",
      "Epoka 24370: Loss = 0.001040549\n",
      "Epoka 24380: Loss = 0.000765428\n",
      "Epoka 24390: Loss = 0.000860610\n",
      "Epoka 24400: Loss = 0.000799676\n",
      "Epoka 24410: Loss = 0.000752666\n",
      "Epoka 24420: Loss = 0.001027972\n",
      "Epoka 24430: Loss = 0.000815692\n",
      "Epoka 24440: Loss = 0.000805543\n",
      "Epoka 24450: Loss = 0.000739854\n",
      "Epoka 24460: Loss = 0.000793624\n",
      "Epoka 24470: Loss = 0.000821134\n",
      "Epoka 24480: Loss = 0.000783093\n",
      "Epoka 24490: Loss = 0.000869387\n",
      "Epoka 24500: Loss = 0.000778218\n",
      "Epoka 24510: Loss = 0.000836102\n",
      "Epoka 24520: Loss = 0.000805124\n",
      "Epoka 24530: Loss = 0.000883841\n",
      "Epoka 24540: Loss = 0.000825180\n",
      "Epoka 24550: Loss = 0.000830834\n",
      "Epoka 24560: Loss = 0.000888440\n",
      "Epoka 24570: Loss = 0.000857713\n",
      "Epoka 24580: Loss = 0.000808137\n",
      "Epoka 24590: Loss = 0.001011181\n",
      "Epoka 24600: Loss = 0.000807944\n",
      "Epoka 24610: Loss = 0.000769509\n",
      "Epoka 24620: Loss = 0.000831054\n",
      "Epoka 24630: Loss = 0.000764722\n",
      "Epoka 24640: Loss = 0.000769592\n",
      "Epoka 24650: Loss = 0.000807390\n",
      "Epoka 24660: Loss = 0.000771517\n",
      "Epoka 24670: Loss = 0.000777805\n",
      "Epoka 24680: Loss = 0.000769837\n",
      "Epoka 24690: Loss = 0.000767820\n",
      "Epoka 24700: Loss = 0.000757142\n",
      "Epoka 24710: Loss = 0.000834075\n",
      "Epoka 24720: Loss = 0.000812077\n",
      "Epoka 24730: Loss = 0.000783624\n",
      "Epoka 24740: Loss = 0.000795839\n",
      "Epoka 24750: Loss = 0.000800121\n",
      "Epoka 24760: Loss = 0.000980786\n",
      "Epoka 24770: Loss = 0.001200492\n",
      "Epoka 24780: Loss = 0.000789442\n",
      "Epoka 24790: Loss = 0.000771283\n",
      "Epoka 24800: Loss = 0.000829388\n",
      "Epoka 24810: Loss = 0.000762598\n",
      "Epoka 24820: Loss = 0.000840785\n",
      "Epoka 24830: Loss = 0.000808453\n",
      "Epoka 24840: Loss = 0.000802153\n",
      "Epoka 24850: Loss = 0.000824450\n",
      "Epoka 24860: Loss = 0.000815282\n",
      "Epoka 24870: Loss = 0.000772249\n",
      "Epoka 24880: Loss = 0.000796632\n",
      "Epoka 24890: Loss = 0.000739836\n",
      "Epoka 24900: Loss = 0.000743467\n",
      "Epoka 24910: Loss = 0.000760021\n",
      "Epoka 24920: Loss = 0.000787533\n",
      "Epoka 24930: Loss = 0.000854377\n",
      "Epoka 24940: Loss = 0.000792946\n",
      "Epoka 24950: Loss = 0.000825334\n",
      "Epoka 24960: Loss = 0.000793448\n",
      "Epoka 24970: Loss = 0.000830761\n",
      "Epoka 24980: Loss = 0.000817441\n",
      "Epoka 24990: Loss = 0.000735364\n",
      "Epoka 25000: Loss = 0.000809592\n",
      "Epoka 25010: Loss = 0.000754445\n",
      "Epoka 25020: Loss = 0.000778215\n",
      "Epoka 25030: Loss = 0.000892306\n",
      "Epoka 25040: Loss = 0.000790108\n",
      "Epoka 25050: Loss = 0.000773304\n",
      "Epoka 25060: Loss = 0.000757001\n",
      "Epoka 25070: Loss = 0.000797282\n",
      "Epoka 25080: Loss = 0.000767931\n",
      "Epoka 25090: Loss = 0.000786910\n",
      "Epoka 25100: Loss = 0.000874355\n",
      "Epoka 25110: Loss = 0.000786089\n",
      "Epoka 25120: Loss = 0.000795751\n",
      "Epoka 25130: Loss = 0.000742634\n",
      "Epoka 25140: Loss = 0.000782049\n",
      "Epoka 25150: Loss = 0.000798092\n",
      "Epoka 25160: Loss = 0.001076704\n",
      "Epoka 25170: Loss = 0.000771714\n",
      "Epoka 25180: Loss = 0.000820340\n",
      "Epoka 25190: Loss = 0.000776751\n",
      "Epoka 25200: Loss = 0.000754707\n",
      "Epoka 25210: Loss = 0.000735878\n",
      "Epoka 25220: Loss = 0.000922664\n",
      "Epoka 25230: Loss = 0.000745510\n",
      "Epoka 25240: Loss = 0.000771270\n",
      "Epoka 25250: Loss = 0.000832473\n",
      "Epoka 25260: Loss = 0.000841561\n",
      "Epoka 25270: Loss = 0.000855795\n",
      "Epoka 25280: Loss = 0.000886210\n",
      "Epoka 25290: Loss = 0.000893527\n",
      "Epoka 25300: Loss = 0.000809998\n",
      "Epoka 25310: Loss = 0.000791231\n",
      "Epoka 25320: Loss = 0.000753413\n",
      "Epoka 25330: Loss = 0.000858624\n",
      "Epoka 25340: Loss = 0.000858837\n",
      "Epoka 25350: Loss = 0.000747122\n",
      "Epoka 25360: Loss = 0.000855683\n",
      "Epoka 25370: Loss = 0.000738764\n",
      "Epoka 25380: Loss = 0.000843617\n",
      "Epoka 25390: Loss = 0.000882297\n",
      "Epoka 25400: Loss = 0.000752368\n",
      "Epoka 25410: Loss = 0.000736091\n",
      "Epoka 25420: Loss = 0.000738645\n",
      "Epoka 25430: Loss = 0.000858501\n",
      "Epoka 25440: Loss = 0.000768156\n",
      "Epoka 25450: Loss = 0.000738113\n",
      "Epoka 25460: Loss = 0.000743345\n",
      "Epoka 25470: Loss = 0.000835417\n",
      "Epoka 25480: Loss = 0.001085429\n",
      "Epoka 25490: Loss = 0.000733642\n",
      "Epoka 25500: Loss = 0.000925125\n",
      "Epoka 25510: Loss = 0.000781512\n",
      "Epoka 25520: Loss = 0.000739294\n",
      "Epoka 25530: Loss = 0.000891625\n",
      "Epoka 25540: Loss = 0.000876527\n",
      "Epoka 25550: Loss = 0.000792810\n",
      "Epoka 25560: Loss = 0.000836764\n",
      "Epoka 25570: Loss = 0.000767541\n",
      "Epoka 25580: Loss = 0.000764807\n",
      "Epoka 25590: Loss = 0.000828670\n",
      "Epoka 25600: Loss = 0.000783626\n",
      "Epoka 25610: Loss = 0.000737460\n",
      "Epoka 25620: Loss = 0.000913487\n",
      "Epoka 25630: Loss = 0.000812961\n",
      "Epoka 25640: Loss = 0.000742352\n",
      "Epoka 25650: Loss = 0.000739128\n",
      "Epoka 25660: Loss = 0.000883126\n",
      "Epoka 25670: Loss = 0.000756702\n",
      "Epoka 25680: Loss = 0.001028033\n",
      "Epoka 25690: Loss = 0.000747358\n",
      "Epoka 25700: Loss = 0.000772161\n",
      "Epoka 25710: Loss = 0.000751968\n",
      "Epoka 25720: Loss = 0.000758731\n",
      "Epoka 25730: Loss = 0.000723395\n",
      "Epoka 25740: Loss = 0.000771692\n",
      "Epoka 25750: Loss = 0.000838536\n",
      "Epoka 25760: Loss = 0.000729722\n",
      "Epoka 25770: Loss = 0.000752172\n",
      "Epoka 25780: Loss = 0.000749073\n",
      "Epoka 25790: Loss = 0.000738761\n",
      "Epoka 25800: Loss = 0.000854724\n",
      "Epoka 25810: Loss = 0.000753648\n",
      "Epoka 25820: Loss = 0.000735862\n",
      "Epoka 25830: Loss = 0.000771842\n",
      "Epoka 25840: Loss = 0.000750313\n",
      "Epoka 25850: Loss = 0.000854002\n",
      "Epoka 25860: Loss = 0.000736345\n",
      "Epoka 25870: Loss = 0.000810737\n",
      "Epoka 25880: Loss = 0.000828796\n",
      "Epoka 25890: Loss = 0.000750940\n",
      "Epoka 25900: Loss = 0.000821578\n",
      "Epoka 25910: Loss = 0.000756444\n",
      "Epoka 25920: Loss = 0.000792915\n",
      "Epoka 25930: Loss = 0.000789285\n",
      "Epoka 25940: Loss = 0.000926753\n",
      "Epoka 25950: Loss = 0.000752105\n",
      "Epoka 25960: Loss = 0.000760026\n",
      "Epoka 25970: Loss = 0.000719673\n",
      "Epoka 25980: Loss = 0.000775817\n",
      "Epoka 25990: Loss = 0.000732212\n",
      "Epoka 26000: Loss = 0.000827378\n",
      "Epoka 26010: Loss = 0.000799854\n",
      "Epoka 26020: Loss = 0.000721194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 26030: Loss = 0.000792816\n",
      "Epoka 26040: Loss = 0.000750711\n",
      "Epoka 26050: Loss = 0.000825009\n",
      "Epoka 26060: Loss = 0.000892619\n",
      "Epoka 26070: Loss = 0.000738820\n",
      "Epoka 26080: Loss = 0.000747737\n",
      "Epoka 26090: Loss = 0.000803418\n",
      "Epoka 26100: Loss = 0.000756302\n",
      "Epoka 26110: Loss = 0.000813761\n",
      "Epoka 26120: Loss = 0.000729296\n",
      "Epoka 26130: Loss = 0.000813239\n",
      "Epoka 26140: Loss = 0.000771331\n",
      "Epoka 26150: Loss = 0.000817692\n",
      "Epoka 26160: Loss = 0.000724390\n",
      "Epoka 26170: Loss = 0.000749495\n",
      "Epoka 26180: Loss = 0.000783818\n",
      "Epoka 26190: Loss = 0.000760054\n",
      "Epoka 26200: Loss = 0.000745562\n",
      "Epoka 26210: Loss = 0.001036154\n",
      "Epoka 26220: Loss = 0.000757512\n",
      "Epoka 26230: Loss = 0.000799109\n",
      "Epoka 26240: Loss = 0.000890180\n",
      "Epoka 26250: Loss = 0.000743914\n",
      "Epoka 26260: Loss = 0.000724517\n",
      "Epoka 26270: Loss = 0.000882361\n",
      "Epoka 26280: Loss = 0.000871525\n",
      "Epoka 26290: Loss = 0.000763395\n",
      "Epoka 26300: Loss = 0.000849722\n",
      "Epoka 26310: Loss = 0.000732497\n",
      "Epoka 26320: Loss = 0.000883470\n",
      "Epoka 26330: Loss = 0.000728015\n",
      "Epoka 26340: Loss = 0.000713280\n",
      "Epoka 26350: Loss = 0.000752813\n",
      "Epoka 26360: Loss = 0.000726192\n",
      "Epoka 26370: Loss = 0.000808837\n",
      "Epoka 26380: Loss = 0.000754099\n",
      "Epoka 26390: Loss = 0.000832477\n",
      "Epoka 26400: Loss = 0.000742281\n",
      "Epoka 26410: Loss = 0.000728903\n",
      "Epoka 26420: Loss = 0.000729250\n",
      "Epoka 26430: Loss = 0.000854707\n",
      "Epoka 26440: Loss = 0.000828623\n",
      "Epoka 26450: Loss = 0.000796746\n",
      "Epoka 26460: Loss = 0.000947345\n",
      "Epoka 26470: Loss = 0.000805587\n",
      "Epoka 26480: Loss = 0.000855879\n",
      "Epoka 26490: Loss = 0.000740782\n",
      "Epoka 26500: Loss = 0.000726811\n",
      "Epoka 26510: Loss = 0.000741561\n",
      "Epoka 26520: Loss = 0.000830146\n",
      "Epoka 26530: Loss = 0.000824080\n",
      "Epoka 26540: Loss = 0.000767421\n",
      "Epoka 26550: Loss = 0.000728014\n",
      "Epoka 26560: Loss = 0.000783341\n",
      "Epoka 26570: Loss = 0.000741919\n",
      "Epoka 26580: Loss = 0.000720905\n",
      "Epoka 26590: Loss = 0.000754244\n",
      "Epoka 26600: Loss = 0.000730480\n",
      "Epoka 26610: Loss = 0.000762627\n",
      "Epoka 26620: Loss = 0.000733170\n",
      "Epoka 26630: Loss = 0.000796783\n",
      "Epoka 26640: Loss = 0.000795024\n",
      "Epoka 26650: Loss = 0.000753504\n",
      "Epoka 26660: Loss = 0.000796778\n",
      "Epoka 26670: Loss = 0.000760582\n",
      "Epoka 26680: Loss = 0.000826710\n",
      "Epoka 26690: Loss = 0.000809345\n",
      "Epoka 26700: Loss = 0.000725468\n",
      "Epoka 26710: Loss = 0.000753318\n",
      "Epoka 26720: Loss = 0.000779123\n",
      "Epoka 26730: Loss = 0.000777317\n",
      "Epoka 26740: Loss = 0.000786970\n",
      "Epoka 26750: Loss = 0.000709635\n",
      "Epoka 26760: Loss = 0.000851961\n",
      "Epoka 26770: Loss = 0.000856335\n",
      "Epoka 26780: Loss = 0.000738067\n",
      "Epoka 26790: Loss = 0.000774720\n",
      "Epoka 26800: Loss = 0.000724148\n",
      "Epoka 26810: Loss = 0.000840780\n",
      "Epoka 26820: Loss = 0.000787831\n",
      "Epoka 26830: Loss = 0.001061583\n",
      "Epoka 26840: Loss = 0.000709818\n",
      "Epoka 26850: Loss = 0.000818745\n",
      "Epoka 26860: Loss = 0.000892366\n",
      "Epoka 26870: Loss = 0.000859843\n",
      "Epoka 26880: Loss = 0.000753975\n",
      "Epoka 26890: Loss = 0.000739845\n",
      "Epoka 26900: Loss = 0.000719090\n",
      "Epoka 26910: Loss = 0.000774391\n",
      "Epoka 26920: Loss = 0.000810813\n",
      "Epoka 26930: Loss = 0.000840850\n",
      "Epoka 26940: Loss = 0.000807402\n",
      "Epoka 26950: Loss = 0.000770733\n",
      "Epoka 26960: Loss = 0.000797974\n",
      "Epoka 26970: Loss = 0.000702085\n",
      "Epoka 26980: Loss = 0.000921805\n",
      "Epoka 26990: Loss = 0.000766797\n",
      "Epoka 27000: Loss = 0.000768169\n",
      "Epoka 27010: Loss = 0.000711054\n",
      "Epoka 27020: Loss = 0.000766172\n",
      "Epoka 27030: Loss = 0.000714306\n",
      "Epoka 27040: Loss = 0.000732100\n",
      "Epoka 27050: Loss = 0.000832140\n",
      "Epoka 27060: Loss = 0.000827685\n",
      "Epoka 27070: Loss = 0.000769602\n",
      "Epoka 27080: Loss = 0.000703406\n",
      "Epoka 27090: Loss = 0.000795809\n",
      "Epoka 27100: Loss = 0.000952373\n",
      "Epoka 27110: Loss = 0.000768115\n",
      "Epoka 27120: Loss = 0.000756161\n",
      "Epoka 27130: Loss = 0.000704145\n",
      "Epoka 27140: Loss = 0.000781728\n",
      "Epoka 27150: Loss = 0.000773301\n",
      "Epoka 27160: Loss = 0.000745546\n",
      "Epoka 27170: Loss = 0.000742254\n",
      "Epoka 27180: Loss = 0.000746064\n",
      "Epoka 27190: Loss = 0.000732754\n",
      "Epoka 27200: Loss = 0.000793470\n",
      "Epoka 27210: Loss = 0.000720626\n",
      "Epoka 27220: Loss = 0.000768672\n",
      "Epoka 27230: Loss = 0.000751123\n",
      "Epoka 27240: Loss = 0.000704458\n",
      "Epoka 27250: Loss = 0.000742871\n",
      "Epoka 27260: Loss = 0.000728464\n",
      "Epoka 27270: Loss = 0.000719302\n",
      "Epoka 27280: Loss = 0.000739872\n",
      "Epoka 27290: Loss = 0.000759475\n",
      "Epoka 27300: Loss = 0.000707885\n",
      "Epoka 27310: Loss = 0.000784358\n",
      "Epoka 27320: Loss = 0.000793467\n",
      "Epoka 27330: Loss = 0.000911803\n",
      "Epoka 27340: Loss = 0.000714138\n",
      "Epoka 27350: Loss = 0.000744451\n",
      "Epoka 27360: Loss = 0.000779067\n",
      "Epoka 27370: Loss = 0.000755661\n",
      "Epoka 27380: Loss = 0.000732104\n",
      "Epoka 27390: Loss = 0.000735791\n",
      "Epoka 27400: Loss = 0.000696097\n",
      "Epoka 27410: Loss = 0.000713814\n",
      "Epoka 27420: Loss = 0.000726234\n",
      "Epoka 27430: Loss = 0.000714268\n",
      "Epoka 27440: Loss = 0.000816891\n",
      "Epoka 27450: Loss = 0.000723671\n",
      "Epoka 27460: Loss = 0.000922654\n",
      "Epoka 27470: Loss = 0.000697445\n",
      "Epoka 27480: Loss = 0.000711080\n",
      "Epoka 27490: Loss = 0.000716513\n",
      "Epoka 27500: Loss = 0.000810826\n",
      "Epoka 27510: Loss = 0.000727683\n",
      "Epoka 27520: Loss = 0.000738594\n",
      "Epoka 27530: Loss = 0.000740971\n",
      "Epoka 27540: Loss = 0.000718675\n",
      "Epoka 27550: Loss = 0.000881310\n",
      "Epoka 27560: Loss = 0.000726049\n",
      "Epoka 27570: Loss = 0.000707601\n",
      "Epoka 27580: Loss = 0.000714758\n",
      "Epoka 27590: Loss = 0.000800221\n",
      "Epoka 27600: Loss = 0.000715003\n",
      "Epoka 27610: Loss = 0.000752219\n",
      "Epoka 27620: Loss = 0.000709980\n",
      "Epoka 27630: Loss = 0.000697855\n",
      "Epoka 27640: Loss = 0.000707501\n",
      "Epoka 27650: Loss = 0.000731120\n",
      "Epoka 27660: Loss = 0.000849268\n",
      "Epoka 27670: Loss = 0.000721465\n",
      "Epoka 27680: Loss = 0.000720829\n",
      "Epoka 27690: Loss = 0.000713950\n",
      "Epoka 27700: Loss = 0.000798548\n",
      "Epoka 27710: Loss = 0.000730324\n",
      "Epoka 27720: Loss = 0.000703447\n",
      "Epoka 27730: Loss = 0.000734316\n",
      "Epoka 27740: Loss = 0.000764910\n",
      "Epoka 27750: Loss = 0.000754976\n",
      "Epoka 27760: Loss = 0.000962817\n",
      "Epoka 27770: Loss = 0.000729320\n",
      "Epoka 27780: Loss = 0.000774629\n",
      "Epoka 27790: Loss = 0.000893704\n",
      "Epoka 27800: Loss = 0.000737804\n",
      "Epoka 27810: Loss = 0.000719245\n",
      "Epoka 27820: Loss = 0.000701309\n",
      "Epoka 27830: Loss = 0.000825148\n",
      "Epoka 27840: Loss = 0.000741019\n",
      "Epoka 27850: Loss = 0.000709314\n",
      "Epoka 27860: Loss = 0.000742644\n",
      "Epoka 27870: Loss = 0.000708047\n",
      "Epoka 27880: Loss = 0.000742067\n",
      "Epoka 27890: Loss = 0.000823720\n",
      "Epoka 27900: Loss = 0.000755918\n",
      "Epoka 27910: Loss = 0.000782782\n",
      "Epoka 27920: Loss = 0.000772117\n",
      "Epoka 27930: Loss = 0.000699027\n",
      "Epoka 27940: Loss = 0.000732384\n",
      "Epoka 27950: Loss = 0.000738243\n",
      "Epoka 27960: Loss = 0.000744373\n",
      "Epoka 27970: Loss = 0.000718240\n",
      "Epoka 27980: Loss = 0.000716140\n",
      "Epoka 27990: Loss = 0.000725026\n",
      "Epoka 28000: Loss = 0.000734202\n",
      "Epoka 28010: Loss = 0.000723405\n",
      "Epoka 28020: Loss = 0.000829669\n",
      "Epoka 28030: Loss = 0.000723702\n",
      "Epoka 28040: Loss = 0.000822183\n",
      "Epoka 28050: Loss = 0.000706162\n",
      "Epoka 28060: Loss = 0.000756039\n",
      "Epoka 28070: Loss = 0.000787527\n",
      "Epoka 28080: Loss = 0.000852920\n",
      "Epoka 28090: Loss = 0.000734409\n",
      "Epoka 28100: Loss = 0.000691085\n",
      "Epoka 28110: Loss = 0.000710964\n",
      "Epoka 28120: Loss = 0.000712230\n",
      "Epoka 28130: Loss = 0.000841600\n",
      "Epoka 28140: Loss = 0.000743504\n",
      "Epoka 28150: Loss = 0.000700632\n",
      "Epoka 28160: Loss = 0.000761065\n",
      "Epoka 28170: Loss = 0.000745637\n",
      "Epoka 28180: Loss = 0.001015716\n",
      "Epoka 28190: Loss = 0.000761010\n",
      "Epoka 28200: Loss = 0.000768667\n",
      "Epoka 28210: Loss = 0.000749128\n",
      "Epoka 28220: Loss = 0.000690893\n",
      "Epoka 28230: Loss = 0.000795391\n",
      "Epoka 28240: Loss = 0.000694985\n",
      "Epoka 28250: Loss = 0.000719802\n",
      "Epoka 28260: Loss = 0.000697504\n",
      "Epoka 28270: Loss = 0.000729387\n",
      "Epoka 28280: Loss = 0.000767407\n",
      "Epoka 28290: Loss = 0.000701513\n",
      "Epoka 28300: Loss = 0.000695790\n",
      "Epoka 28310: Loss = 0.000699443\n",
      "Epoka 28320: Loss = 0.000735001\n",
      "Epoka 28330: Loss = 0.000828549\n",
      "Epoka 28340: Loss = 0.000777156\n",
      "Epoka 28350: Loss = 0.000693834\n",
      "Epoka 28360: Loss = 0.000687298\n",
      "Epoka 28370: Loss = 0.000723213\n",
      "Epoka 28380: Loss = 0.000701249\n",
      "Epoka 28390: Loss = 0.000691766\n",
      "Epoka 28400: Loss = 0.000733095\n",
      "Epoka 28410: Loss = 0.000715127\n",
      "Epoka 28420: Loss = 0.000696105\n",
      "Epoka 28430: Loss = 0.000738649\n",
      "Epoka 28440: Loss = 0.000944164\n",
      "Epoka 28450: Loss = 0.000773310\n",
      "Epoka 28460: Loss = 0.000742441\n",
      "Epoka 28470: Loss = 0.000810519\n",
      "Epoka 28480: Loss = 0.000813240\n",
      "Epoka 28490: Loss = 0.000687252\n",
      "Epoka 28500: Loss = 0.000715229\n",
      "Epoka 28510: Loss = 0.000740002\n",
      "Epoka 28520: Loss = 0.000712954\n",
      "Epoka 28530: Loss = 0.000744126\n",
      "Epoka 28540: Loss = 0.000765096\n",
      "Epoka 28550: Loss = 0.000746186\n",
      "Epoka 28560: Loss = 0.000749820\n",
      "Epoka 28570: Loss = 0.000747719\n",
      "Epoka 28580: Loss = 0.000773414\n",
      "Epoka 28590: Loss = 0.000722399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 28600: Loss = 0.000734503\n",
      "Epoka 28610: Loss = 0.000748491\n",
      "Epoka 28620: Loss = 0.000712346\n",
      "Epoka 28630: Loss = 0.000723668\n",
      "Epoka 28640: Loss = 0.000704316\n",
      "Epoka 28650: Loss = 0.000770869\n",
      "Epoka 28660: Loss = 0.000801493\n",
      "Epoka 28670: Loss = 0.000692261\n",
      "Epoka 28680: Loss = 0.000781856\n",
      "Epoka 28690: Loss = 0.000719212\n",
      "Epoka 28700: Loss = 0.000714178\n",
      "Epoka 28710: Loss = 0.000702977\n",
      "Epoka 28720: Loss = 0.000722042\n",
      "Epoka 28730: Loss = 0.000684370\n",
      "Epoka 28740: Loss = 0.000865335\n",
      "Epoka 28750: Loss = 0.000721163\n",
      "Epoka 28760: Loss = 0.000698115\n",
      "Epoka 28770: Loss = 0.000858224\n",
      "Epoka 28780: Loss = 0.000698119\n",
      "Epoka 28790: Loss = 0.000698012\n",
      "Epoka 28800: Loss = 0.000685899\n",
      "Epoka 28810: Loss = 0.000759062\n",
      "Epoka 28820: Loss = 0.000772683\n",
      "Epoka 28830: Loss = 0.000714944\n",
      "Epoka 28840: Loss = 0.000695106\n",
      "Epoka 28850: Loss = 0.000760198\n",
      "Epoka 28860: Loss = 0.000684905\n",
      "Epoka 28870: Loss = 0.000687641\n",
      "Epoka 28880: Loss = 0.000724230\n",
      "Epoka 28890: Loss = 0.000831475\n",
      "Epoka 28900: Loss = 0.000740020\n",
      "Epoka 28910: Loss = 0.000744805\n",
      "Epoka 28920: Loss = 0.000862481\n",
      "Epoka 28930: Loss = 0.000906473\n",
      "Epoka 28940: Loss = 0.000762573\n",
      "Epoka 28950: Loss = 0.000827228\n",
      "Epoka 28960: Loss = 0.000729778\n",
      "Epoka 28970: Loss = 0.000679967\n",
      "Epoka 28980: Loss = 0.000732479\n",
      "Epoka 28990: Loss = 0.000863194\n",
      "Epoka 29000: Loss = 0.000728253\n",
      "Epoka 29010: Loss = 0.000867059\n",
      "Epoka 29020: Loss = 0.000717083\n",
      "Epoka 29030: Loss = 0.000687772\n",
      "Epoka 29040: Loss = 0.000705018\n",
      "Epoka 29050: Loss = 0.000701503\n",
      "Epoka 29060: Loss = 0.000726353\n",
      "Epoka 29070: Loss = 0.000741689\n",
      "Epoka 29080: Loss = 0.000723601\n",
      "Epoka 29090: Loss = 0.000684138\n",
      "Epoka 29100: Loss = 0.000694081\n",
      "Epoka 29110: Loss = 0.000806451\n",
      "Epoka 29120: Loss = 0.000682611\n",
      "Epoka 29130: Loss = 0.000762558\n",
      "Epoka 29140: Loss = 0.000717426\n",
      "Epoka 29150: Loss = 0.000815990\n",
      "Epoka 29160: Loss = 0.000761319\n",
      "Epoka 29170: Loss = 0.000715879\n",
      "Epoka 29180: Loss = 0.000827402\n",
      "Epoka 29190: Loss = 0.000710873\n",
      "Epoka 29200: Loss = 0.001009830\n",
      "Epoka 29210: Loss = 0.000758664\n",
      "Epoka 29220: Loss = 0.000690091\n",
      "Epoka 29230: Loss = 0.000693999\n",
      "Epoka 29240: Loss = 0.000732107\n",
      "Epoka 29250: Loss = 0.000680973\n",
      "Epoka 29260: Loss = 0.000716029\n",
      "Epoka 29270: Loss = 0.000700346\n",
      "Epoka 29280: Loss = 0.000700011\n",
      "Epoka 29290: Loss = 0.000726793\n",
      "Epoka 29300: Loss = 0.000716448\n",
      "Epoka 29310: Loss = 0.000713658\n",
      "Epoka 29320: Loss = 0.000697894\n",
      "Epoka 29330: Loss = 0.000834291\n",
      "Epoka 29340: Loss = 0.000693835\n",
      "Epoka 29350: Loss = 0.000762480\n",
      "Epoka 29360: Loss = 0.000884608\n",
      "Epoka 29370: Loss = 0.000730337\n",
      "Epoka 29380: Loss = 0.000755254\n",
      "Epoka 29390: Loss = 0.000735733\n",
      "Epoka 29400: Loss = 0.000688527\n",
      "Epoka 29410: Loss = 0.000693268\n",
      "Epoka 29420: Loss = 0.000680467\n",
      "Epoka 29430: Loss = 0.000728926\n",
      "Epoka 29440: Loss = 0.000692563\n",
      "Epoka 29450: Loss = 0.000736366\n",
      "Epoka 29460: Loss = 0.000712634\n",
      "Epoka 29470: Loss = 0.000694753\n",
      "Epoka 29480: Loss = 0.000809986\n",
      "Epoka 29490: Loss = 0.000736516\n",
      "Epoka 29500: Loss = 0.000694203\n",
      "Epoka 29510: Loss = 0.000752075\n",
      "Epoka 29520: Loss = 0.000697269\n",
      "Epoka 29530: Loss = 0.000694768\n",
      "Epoka 29540: Loss = 0.000710905\n",
      "Epoka 29550: Loss = 0.000803882\n",
      "Epoka 29560: Loss = 0.000690044\n",
      "Epoka 29570: Loss = 0.000684338\n",
      "Epoka 29580: Loss = 0.000772196\n",
      "Epoka 29590: Loss = 0.000692492\n",
      "Epoka 29600: Loss = 0.000834985\n",
      "Epoka 29610: Loss = 0.000746927\n",
      "Epoka 29620: Loss = 0.000759132\n",
      "Epoka 29630: Loss = 0.000700597\n",
      "Epoka 29640: Loss = 0.000692193\n",
      "Epoka 29650: Loss = 0.000714109\n",
      "Epoka 29660: Loss = 0.000814262\n",
      "Epoka 29670: Loss = 0.000772976\n",
      "Epoka 29680: Loss = 0.000725702\n",
      "Epoka 29690: Loss = 0.000743241\n",
      "Epoka 29700: Loss = 0.000691042\n",
      "Epoka 29710: Loss = 0.000737694\n",
      "Epoka 29720: Loss = 0.000716728\n",
      "Epoka 29730: Loss = 0.000921844\n",
      "Epoka 29740: Loss = 0.000741747\n",
      "Epoka 29750: Loss = 0.000698629\n",
      "Epoka 29760: Loss = 0.000703343\n",
      "Epoka 29770: Loss = 0.000709222\n",
      "Epoka 29780: Loss = 0.000705502\n",
      "Epoka 29790: Loss = 0.000694126\n",
      "Epoka 29800: Loss = 0.000701616\n",
      "Epoka 29810: Loss = 0.000789150\n",
      "Epoka 29820: Loss = 0.000714069\n",
      "Epoka 29830: Loss = 0.000697031\n",
      "Epoka 29840: Loss = 0.001087548\n",
      "Epoka 29850: Loss = 0.000667177\n",
      "Epoka 29860: Loss = 0.000668729\n",
      "Epoka 29870: Loss = 0.000700237\n",
      "Epoka 29880: Loss = 0.000871688\n",
      "Epoka 29890: Loss = 0.000749224\n",
      "Epoka 29900: Loss = 0.000729257\n",
      "Epoka 29910: Loss = 0.000715241\n",
      "Epoka 29920: Loss = 0.000722499\n",
      "Epoka 29930: Loss = 0.000761732\n",
      "Epoka 29940: Loss = 0.000694965\n",
      "Epoka 29950: Loss = 0.000751553\n",
      "Epoka 29960: Loss = 0.000740572\n",
      "Epoka 29970: Loss = 0.000766735\n",
      "Epoka 29980: Loss = 0.000718679\n",
      "Epoka 29990: Loss = 0.000666725\n",
      "Epoka 30000: Loss = 0.000729893\n",
      "Epoka 30010: Loss = 0.000696464\n",
      "Epoka 30020: Loss = 0.000741288\n",
      "Epoka 30030: Loss = 0.000726545\n",
      "Epoka 30040: Loss = 0.000889711\n",
      "Epoka 30050: Loss = 0.000668707\n",
      "Epoka 30060: Loss = 0.000754299\n",
      "Epoka 30070: Loss = 0.000667294\n",
      "Epoka 30080: Loss = 0.000827277\n",
      "Epoka 30090: Loss = 0.000960939\n",
      "Epoka 30100: Loss = 0.000749061\n",
      "Epoka 30110: Loss = 0.000763708\n",
      "Epoka 30120: Loss = 0.000706534\n",
      "Epoka 30130: Loss = 0.000771539\n",
      "Epoka 30140: Loss = 0.000683163\n",
      "Epoka 30150: Loss = 0.000835108\n",
      "Epoka 30160: Loss = 0.000723337\n",
      "Epoka 30170: Loss = 0.000757411\n",
      "Epoka 30180: Loss = 0.000744772\n",
      "Epoka 30190: Loss = 0.000709920\n",
      "Epoka 30200: Loss = 0.000747829\n",
      "Epoka 30210: Loss = 0.000668974\n",
      "Epoka 30220: Loss = 0.000695384\n",
      "Epoka 30230: Loss = 0.000813829\n",
      "Epoka 30240: Loss = 0.000837470\n",
      "Epoka 30250: Loss = 0.000758390\n",
      "Epoka 30260: Loss = 0.000717224\n",
      "Epoka 30270: Loss = 0.000698503\n",
      "Epoka 30280: Loss = 0.000676394\n",
      "Epoka 30290: Loss = 0.000807306\n",
      "Epoka 30300: Loss = 0.000730347\n",
      "Epoka 30310: Loss = 0.000785309\n",
      "Epoka 30320: Loss = 0.000743517\n",
      "Epoka 30330: Loss = 0.000731595\n",
      "Epoka 30340: Loss = 0.000731025\n",
      "Epoka 30350: Loss = 0.000697090\n",
      "Epoka 30360: Loss = 0.000709184\n",
      "Epoka 30370: Loss = 0.000725664\n",
      "Epoka 30380: Loss = 0.000746244\n",
      "Epoka 30390: Loss = 0.000694018\n",
      "Epoka 30400: Loss = 0.000718827\n",
      "Epoka 30410: Loss = 0.000698717\n",
      "Epoka 30420: Loss = 0.000687588\n",
      "Epoka 30430: Loss = 0.000708948\n",
      "Epoka 30440: Loss = 0.000728523\n",
      "Epoka 30450: Loss = 0.000682989\n",
      "Epoka 30460: Loss = 0.000673072\n",
      "Epoka 30470: Loss = 0.000673576\n",
      "Epoka 30480: Loss = 0.000739948\n",
      "Epoka 30490: Loss = 0.000690255\n",
      "Epoka 30500: Loss = 0.000721665\n",
      "Epoka 30510: Loss = 0.000732579\n",
      "Epoka 30520: Loss = 0.000664544\n",
      "Epoka 30530: Loss = 0.000968514\n",
      "Epoka 30540: Loss = 0.000772287\n",
      "Epoka 30550: Loss = 0.000759122\n",
      "Epoka 30560: Loss = 0.000830224\n",
      "Epoka 30570: Loss = 0.000669711\n",
      "Epoka 30580: Loss = 0.000672930\n",
      "Epoka 30590: Loss = 0.000677021\n",
      "Epoka 30600: Loss = 0.000755926\n",
      "Epoka 30610: Loss = 0.000842842\n",
      "Epoka 30620: Loss = 0.000688903\n",
      "Epoka 30630: Loss = 0.000683383\n",
      "Epoka 30640: Loss = 0.000798268\n",
      "Epoka 30650: Loss = 0.000688810\n",
      "Epoka 30660: Loss = 0.000670044\n",
      "Epoka 30670: Loss = 0.000662973\n",
      "Epoka 30680: Loss = 0.000876774\n",
      "Epoka 30690: Loss = 0.000689722\n",
      "Epoka 30700: Loss = 0.000731762\n",
      "Epoka 30710: Loss = 0.000675950\n",
      "Epoka 30720: Loss = 0.000961510\n",
      "Epoka 30730: Loss = 0.000820840\n",
      "Epoka 30740: Loss = 0.000808512\n",
      "Epoka 30750: Loss = 0.000894654\n",
      "Epoka 30760: Loss = 0.000830158\n",
      "Epoka 30770: Loss = 0.000676183\n",
      "Epoka 30780: Loss = 0.000695605\n",
      "Epoka 30790: Loss = 0.000746367\n",
      "Epoka 30800: Loss = 0.000691076\n",
      "Epoka 30810: Loss = 0.000751556\n",
      "Epoka 30820: Loss = 0.000681778\n",
      "Epoka 30830: Loss = 0.000755626\n",
      "Epoka 30840: Loss = 0.000710328\n",
      "Epoka 30850: Loss = 0.000655233\n",
      "Epoka 30860: Loss = 0.000710276\n",
      "Epoka 30870: Loss = 0.000743248\n",
      "Epoka 30880: Loss = 0.000804699\n",
      "Epoka 30890: Loss = 0.000743878\n",
      "Epoka 30900: Loss = 0.000795826\n",
      "Epoka 30910: Loss = 0.000705267\n",
      "Epoka 30920: Loss = 0.000689606\n",
      "Epoka 30930: Loss = 0.000849209\n",
      "Epoka 30940: Loss = 0.000666724\n",
      "Epoka 30950: Loss = 0.000693285\n",
      "Epoka 30960: Loss = 0.000730553\n",
      "Epoka 30970: Loss = 0.000735270\n",
      "Epoka 30980: Loss = 0.000784087\n",
      "Epoka 30990: Loss = 0.000750015\n",
      "Epoka 31000: Loss = 0.000707650\n",
      "Epoka 31010: Loss = 0.000872438\n",
      "Epoka 31020: Loss = 0.000830908\n",
      "Epoka 31030: Loss = 0.000693882\n",
      "Epoka 31040: Loss = 0.000691647\n",
      "Epoka 31050: Loss = 0.000720359\n",
      "Epoka 31060: Loss = 0.000775856\n",
      "Epoka 31070: Loss = 0.000651311\n",
      "Epoka 31080: Loss = 0.000767079\n",
      "Epoka 31090: Loss = 0.000679897\n",
      "Epoka 31100: Loss = 0.000761307\n",
      "Epoka 31110: Loss = 0.000681819\n",
      "Epoka 31120: Loss = 0.000671859\n",
      "Epoka 31130: Loss = 0.000748278\n",
      "Epoka 31140: Loss = 0.000701970\n",
      "Epoka 31150: Loss = 0.000787278\n",
      "Epoka 31160: Loss = 0.000706258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 31170: Loss = 0.000744837\n",
      "Epoka 31180: Loss = 0.000855551\n",
      "Epoka 31190: Loss = 0.000695189\n",
      "Epoka 31200: Loss = 0.000666706\n",
      "Epoka 31210: Loss = 0.000677144\n",
      "Epoka 31220: Loss = 0.000659764\n",
      "Epoka 31230: Loss = 0.000913139\n",
      "Epoka 31240: Loss = 0.000658730\n",
      "Epoka 31250: Loss = 0.000766408\n",
      "Epoka 31260: Loss = 0.000677408\n",
      "Epoka 31270: Loss = 0.000767048\n",
      "Epoka 31280: Loss = 0.000672836\n",
      "Epoka 31290: Loss = 0.000702952\n",
      "Epoka 31300: Loss = 0.000666900\n",
      "Epoka 31310: Loss = 0.000863243\n",
      "Epoka 31320: Loss = 0.000886433\n",
      "Epoka 31330: Loss = 0.000693411\n",
      "Epoka 31340: Loss = 0.000722540\n",
      "Epoka 31350: Loss = 0.000683367\n",
      "Epoka 31360: Loss = 0.000650634\n",
      "Epoka 31370: Loss = 0.000705912\n",
      "Epoka 31380: Loss = 0.000744037\n",
      "Epoka 31390: Loss = 0.000688506\n",
      "Epoka 31400: Loss = 0.000740682\n",
      "Epoka 31410: Loss = 0.000695884\n",
      "Epoka 31420: Loss = 0.000724437\n",
      "Epoka 31430: Loss = 0.000773041\n",
      "Epoka 31440: Loss = 0.000719908\n",
      "Epoka 31450: Loss = 0.000711258\n",
      "Epoka 31460: Loss = 0.000718017\n",
      "Epoka 31470: Loss = 0.000802393\n",
      "Epoka 31480: Loss = 0.000671848\n",
      "Epoka 31490: Loss = 0.000711353\n",
      "Epoka 31500: Loss = 0.000677639\n",
      "Epoka 31510: Loss = 0.000677142\n",
      "Epoka 31520: Loss = 0.000863813\n",
      "Epoka 31530: Loss = 0.000683745\n",
      "Epoka 31540: Loss = 0.000680108\n",
      "Epoka 31550: Loss = 0.000653381\n",
      "Epoka 31560: Loss = 0.000656388\n",
      "Epoka 31570: Loss = 0.000689233\n",
      "Epoka 31580: Loss = 0.000694270\n",
      "Epoka 31590: Loss = 0.000656701\n",
      "Epoka 31600: Loss = 0.000687321\n",
      "Epoka 31610: Loss = 0.000676447\n",
      "Epoka 31620: Loss = 0.000651837\n",
      "Epoka 31630: Loss = 0.000650479\n",
      "Epoka 31640: Loss = 0.000698055\n",
      "Epoka 31650: Loss = 0.000704099\n",
      "Epoka 31660: Loss = 0.000709925\n",
      "Epoka 31670: Loss = 0.000720814\n",
      "Epoka 31680: Loss = 0.000660856\n",
      "Epoka 31690: Loss = 0.000796737\n",
      "Epoka 31700: Loss = 0.000749236\n",
      "Epoka 31710: Loss = 0.000669801\n",
      "Epoka 31720: Loss = 0.000806545\n",
      "Epoka 31730: Loss = 0.000676038\n",
      "Epoka 31740: Loss = 0.000649979\n",
      "Epoka 31750: Loss = 0.000664444\n",
      "Epoka 31760: Loss = 0.000684056\n",
      "Epoka 31770: Loss = 0.000759480\n",
      "Epoka 31780: Loss = 0.000682208\n",
      "Epoka 31790: Loss = 0.000676520\n",
      "Epoka 31800: Loss = 0.000662948\n",
      "Epoka 31810: Loss = 0.000659442\n",
      "Epoka 31820: Loss = 0.000771590\n",
      "Epoka 31830: Loss = 0.000733712\n",
      "Epoka 31840: Loss = 0.000712021\n",
      "Epoka 31850: Loss = 0.000647539\n",
      "Epoka 31860: Loss = 0.000688158\n",
      "Epoka 31870: Loss = 0.000817783\n",
      "Epoka 31880: Loss = 0.000747656\n",
      "Epoka 31890: Loss = 0.000670474\n",
      "Epoka 31900: Loss = 0.000666591\n",
      "Epoka 31910: Loss = 0.000654311\n",
      "Epoka 31920: Loss = 0.000750288\n",
      "Epoka 31930: Loss = 0.000735402\n",
      "Epoka 31940: Loss = 0.000663084\n",
      "Epoka 31950: Loss = 0.000749357\n",
      "Epoka 31960: Loss = 0.000725490\n",
      "Epoka 31970: Loss = 0.000797512\n",
      "Epoka 31980: Loss = 0.000761866\n",
      "Epoka 31990: Loss = 0.000658174\n",
      "Epoka 32000: Loss = 0.000693945\n",
      "Epoka 32010: Loss = 0.000791869\n",
      "Epoka 32020: Loss = 0.000716988\n",
      "Epoka 32030: Loss = 0.000652250\n",
      "Epoka 32040: Loss = 0.000671976\n",
      "Epoka 32050: Loss = 0.000673674\n",
      "Epoka 32060: Loss = 0.000796058\n",
      "Epoka 32070: Loss = 0.000707223\n",
      "Epoka 32080: Loss = 0.000698279\n",
      "Epoka 32090: Loss = 0.000703737\n",
      "Epoka 32100: Loss = 0.000656937\n",
      "Epoka 32110: Loss = 0.000702469\n",
      "Epoka 32120: Loss = 0.000695494\n",
      "Epoka 32130: Loss = 0.000796455\n",
      "Epoka 32140: Loss = 0.000731654\n",
      "Epoka 32150: Loss = 0.000696399\n",
      "Epoka 32160: Loss = 0.000653568\n",
      "Epoka 32170: Loss = 0.000666289\n",
      "Epoka 32180: Loss = 0.000668422\n",
      "Epoka 32190: Loss = 0.000766305\n",
      "Epoka 32200: Loss = 0.000773930\n",
      "Epoka 32210: Loss = 0.000797991\n",
      "Epoka 32220: Loss = 0.000714570\n",
      "Epoka 32230: Loss = 0.000637649\n",
      "Epoka 32240: Loss = 0.000657754\n",
      "Epoka 32250: Loss = 0.000657624\n",
      "Epoka 32260: Loss = 0.000671000\n",
      "Epoka 32270: Loss = 0.000652565\n",
      "Epoka 32280: Loss = 0.000785881\n",
      "Epoka 32290: Loss = 0.000673427\n",
      "Epoka 32300: Loss = 0.000888724\n",
      "Epoka 32310: Loss = 0.000667912\n",
      "Epoka 32320: Loss = 0.000707902\n",
      "Epoka 32330: Loss = 0.000834239\n",
      "Epoka 32340: Loss = 0.000689097\n",
      "Epoka 32350: Loss = 0.000784312\n",
      "Epoka 32360: Loss = 0.000680458\n",
      "Epoka 32370: Loss = 0.000675848\n",
      "Epoka 32380: Loss = 0.000682608\n",
      "Epoka 32390: Loss = 0.000888732\n",
      "Epoka 32400: Loss = 0.000721127\n",
      "Epoka 32410: Loss = 0.000652990\n",
      "Epoka 32420: Loss = 0.000753254\n",
      "Epoka 32430: Loss = 0.000645413\n",
      "Epoka 32440: Loss = 0.000679697\n",
      "Epoka 32450: Loss = 0.000663105\n",
      "Epoka 32460: Loss = 0.000673539\n",
      "Epoka 32470: Loss = 0.000671843\n",
      "Epoka 32480: Loss = 0.000661051\n",
      "Epoka 32490: Loss = 0.000675709\n",
      "Epoka 32500: Loss = 0.000828278\n",
      "Epoka 32510: Loss = 0.000748159\n",
      "Epoka 32520: Loss = 0.000654177\n",
      "Epoka 32530: Loss = 0.000713933\n",
      "Epoka 32540: Loss = 0.000692726\n",
      "Epoka 32550: Loss = 0.000714312\n",
      "Epoka 32560: Loss = 0.000893024\n",
      "Epoka 32570: Loss = 0.000670722\n",
      "Epoka 32580: Loss = 0.000641844\n",
      "Epoka 32590: Loss = 0.000743155\n",
      "Epoka 32600: Loss = 0.000677990\n",
      "Epoka 32610: Loss = 0.000736464\n",
      "Epoka 32620: Loss = 0.000743066\n",
      "Epoka 32630: Loss = 0.000649863\n",
      "Epoka 32640: Loss = 0.000650721\n",
      "Epoka 32650: Loss = 0.000655030\n",
      "Epoka 32660: Loss = 0.000719622\n",
      "Epoka 32670: Loss = 0.000641519\n",
      "Epoka 32680: Loss = 0.000696963\n",
      "Epoka 32690: Loss = 0.000672634\n",
      "Epoka 32700: Loss = 0.000686512\n",
      "Epoka 32710: Loss = 0.000636778\n",
      "Epoka 32720: Loss = 0.000782939\n",
      "Epoka 32730: Loss = 0.000657755\n",
      "Epoka 32740: Loss = 0.000708122\n",
      "Epoka 32750: Loss = 0.000694298\n",
      "Epoka 32760: Loss = 0.000658639\n",
      "Epoka 32770: Loss = 0.000788034\n",
      "Epoka 32780: Loss = 0.000677567\n",
      "Epoka 32790: Loss = 0.000708394\n",
      "Epoka 32800: Loss = 0.000674672\n",
      "Epoka 32810: Loss = 0.000668665\n",
      "Epoka 32820: Loss = 0.000671562\n",
      "Epoka 32830: Loss = 0.000708628\n",
      "Epoka 32840: Loss = 0.000713661\n",
      "Epoka 32850: Loss = 0.000757100\n",
      "Epoka 32860: Loss = 0.000658987\n",
      "Epoka 32870: Loss = 0.000710141\n",
      "Epoka 32880: Loss = 0.000716652\n",
      "Epoka 32890: Loss = 0.000749816\n",
      "Epoka 32900: Loss = 0.000646659\n",
      "Epoka 32910: Loss = 0.000688793\n",
      "Epoka 32920: Loss = 0.000875451\n",
      "Epoka 32930: Loss = 0.000848535\n",
      "Epoka 32940: Loss = 0.000705720\n",
      "Epoka 32950: Loss = 0.000717404\n",
      "Epoka 32960: Loss = 0.000700175\n",
      "Epoka 32970: Loss = 0.000705513\n",
      "Epoka 32980: Loss = 0.000698460\n",
      "Epoka 32990: Loss = 0.000810686\n",
      "Epoka 33000: Loss = 0.000682716\n",
      "Epoka 33010: Loss = 0.000669033\n",
      "Epoka 33020: Loss = 0.000686448\n",
      "Epoka 33030: Loss = 0.000673350\n",
      "Epoka 33040: Loss = 0.000692873\n",
      "Epoka 33050: Loss = 0.000687314\n",
      "Epoka 33060: Loss = 0.000703742\n",
      "Epoka 33070: Loss = 0.000633135\n",
      "Epoka 33080: Loss = 0.000683972\n",
      "Epoka 33090: Loss = 0.000804588\n",
      "Epoka 33100: Loss = 0.000699939\n",
      "Epoka 33110: Loss = 0.000720115\n",
      "Epoka 33120: Loss = 0.000738165\n",
      "Epoka 33130: Loss = 0.000724723\n",
      "Epoka 33140: Loss = 0.000742339\n",
      "Epoka 33150: Loss = 0.000637564\n",
      "Epoka 33160: Loss = 0.000707106\n",
      "Epoka 33170: Loss = 0.000678592\n",
      "Epoka 33180: Loss = 0.000722806\n",
      "Epoka 33190: Loss = 0.000911562\n",
      "Epoka 33200: Loss = 0.000685428\n",
      "Epoka 33210: Loss = 0.000636435\n",
      "Epoka 33220: Loss = 0.000787048\n",
      "Epoka 33230: Loss = 0.000634895\n",
      "Epoka 33240: Loss = 0.000699791\n",
      "Epoka 33250: Loss = 0.000701075\n",
      "Epoka 33260: Loss = 0.000639927\n",
      "Epoka 33270: Loss = 0.000715845\n",
      "Epoka 33280: Loss = 0.000664879\n",
      "Epoka 33290: Loss = 0.000747971\n",
      "Epoka 33300: Loss = 0.000666203\n",
      "Epoka 33310: Loss = 0.000845762\n",
      "Epoka 33320: Loss = 0.000734362\n",
      "Epoka 33330: Loss = 0.000798428\n",
      "Epoka 33340: Loss = 0.000710134\n",
      "Epoka 33350: Loss = 0.000640656\n",
      "Epoka 33360: Loss = 0.000699072\n",
      "Epoka 33370: Loss = 0.000632203\n",
      "Epoka 33380: Loss = 0.000705285\n",
      "Epoka 33390: Loss = 0.000642026\n",
      "Epoka 33400: Loss = 0.000669092\n",
      "Epoka 33410: Loss = 0.000741439\n",
      "Epoka 33420: Loss = 0.000695209\n",
      "Epoka 33430: Loss = 0.000653248\n",
      "Epoka 33440: Loss = 0.000683669\n",
      "Epoka 33450: Loss = 0.000811579\n",
      "Epoka 33460: Loss = 0.000657797\n",
      "Epoka 33470: Loss = 0.000677657\n",
      "Epoka 33480: Loss = 0.000693201\n",
      "Epoka 33490: Loss = 0.000736867\n",
      "Epoka 33500: Loss = 0.000699486\n",
      "Epoka 33510: Loss = 0.000627772\n",
      "Epoka 33520: Loss = 0.000650420\n",
      "Epoka 33530: Loss = 0.000744756\n",
      "Epoka 33540: Loss = 0.000636478\n",
      "Epoka 33550: Loss = 0.000628683\n",
      "Epoka 33560: Loss = 0.000636516\n",
      "Epoka 33570: Loss = 0.000851482\n",
      "Epoka 33580: Loss = 0.000708666\n",
      "Epoka 33590: Loss = 0.000753254\n",
      "Epoka 33600: Loss = 0.000723403\n",
      "Epoka 33610: Loss = 0.000787510\n",
      "Epoka 33620: Loss = 0.000632461\n",
      "Epoka 33630: Loss = 0.000699180\n",
      "Epoka 33640: Loss = 0.000650811\n",
      "Epoka 33650: Loss = 0.000689102\n",
      "Epoka 33660: Loss = 0.000744453\n",
      "Epoka 33670: Loss = 0.000702080\n",
      "Epoka 33680: Loss = 0.000701686\n",
      "Epoka 33690: Loss = 0.000689929\n",
      "Epoka 33700: Loss = 0.000652764\n",
      "Epoka 33710: Loss = 0.000684038\n",
      "Epoka 33720: Loss = 0.000678803\n",
      "Epoka 33730: Loss = 0.000746211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 33740: Loss = 0.000647271\n",
      "Epoka 33750: Loss = 0.000657241\n",
      "Epoka 33760: Loss = 0.000758462\n",
      "Epoka 33770: Loss = 0.000798752\n",
      "Epoka 33780: Loss = 0.000634183\n",
      "Epoka 33790: Loss = 0.000749324\n",
      "Epoka 33800: Loss = 0.000667084\n",
      "Epoka 33810: Loss = 0.000654249\n",
      "Epoka 33820: Loss = 0.000814581\n",
      "Epoka 33830: Loss = 0.000657574\n",
      "Epoka 33840: Loss = 0.000667349\n",
      "Epoka 33850: Loss = 0.000655347\n",
      "Epoka 33860: Loss = 0.000701886\n",
      "Epoka 33870: Loss = 0.000643880\n",
      "Epoka 33880: Loss = 0.000853577\n",
      "Epoka 33890: Loss = 0.000663561\n",
      "Epoka 33900: Loss = 0.000746987\n",
      "Epoka 33910: Loss = 0.000634390\n",
      "Epoka 33920: Loss = 0.000660655\n",
      "Epoka 33930: Loss = 0.000648842\n",
      "Epoka 33940: Loss = 0.000686849\n",
      "Epoka 33950: Loss = 0.000684476\n",
      "Epoka 33960: Loss = 0.000631243\n",
      "Epoka 33970: Loss = 0.000636497\n",
      "Epoka 33980: Loss = 0.000673149\n",
      "Epoka 33990: Loss = 0.000731400\n",
      "Epoka 34000: Loss = 0.000661500\n",
      "Epoka 34010: Loss = 0.000668662\n",
      "Epoka 34020: Loss = 0.000837673\n",
      "Epoka 34030: Loss = 0.000687835\n",
      "Epoka 34040: Loss = 0.000638073\n",
      "Epoka 34050: Loss = 0.000627366\n",
      "Epoka 34060: Loss = 0.000646972\n",
      "Epoka 34070: Loss = 0.000663413\n",
      "Epoka 34080: Loss = 0.000710803\n",
      "Epoka 34090: Loss = 0.000666388\n",
      "Epoka 34100: Loss = 0.000632899\n",
      "Epoka 34110: Loss = 0.000831929\n",
      "Epoka 34120: Loss = 0.000623538\n",
      "Epoka 34130: Loss = 0.000664905\n",
      "Epoka 34140: Loss = 0.000743183\n",
      "Epoka 34150: Loss = 0.000632189\n",
      "Epoka 34160: Loss = 0.000747205\n",
      "Epoka 34170: Loss = 0.000648373\n",
      "Epoka 34180: Loss = 0.000664355\n",
      "Epoka 34190: Loss = 0.000630017\n",
      "Epoka 34200: Loss = 0.000674602\n",
      "Epoka 34210: Loss = 0.000661442\n",
      "Epoka 34220: Loss = 0.000658366\n",
      "Epoka 34230: Loss = 0.000676900\n",
      "Epoka 34240: Loss = 0.000629114\n",
      "Epoka 34250: Loss = 0.000734726\n",
      "Epoka 34260: Loss = 0.000708727\n",
      "Epoka 34270: Loss = 0.000645657\n",
      "Epoka 34280: Loss = 0.000700897\n",
      "Epoka 34290: Loss = 0.000654312\n",
      "Epoka 34300: Loss = 0.000662119\n",
      "Epoka 34310: Loss = 0.000624754\n",
      "Epoka 34320: Loss = 0.000658342\n",
      "Epoka 34330: Loss = 0.000694908\n",
      "Epoka 34340: Loss = 0.000756351\n",
      "Epoka 34350: Loss = 0.000718542\n",
      "Epoka 34360: Loss = 0.000629759\n",
      "Epoka 34370: Loss = 0.000859632\n",
      "Epoka 34380: Loss = 0.000687883\n",
      "Epoka 34390: Loss = 0.000726600\n",
      "Epoka 34400: Loss = 0.000684328\n",
      "Epoka 34410: Loss = 0.000633690\n",
      "Epoka 34420: Loss = 0.000635275\n",
      "Epoka 34430: Loss = 0.000678935\n",
      "Epoka 34440: Loss = 0.000658690\n",
      "Epoka 34450: Loss = 0.000641895\n",
      "Epoka 34460: Loss = 0.000878988\n",
      "Epoka 34470: Loss = 0.000734964\n",
      "Epoka 34480: Loss = 0.000617468\n",
      "Epoka 34490: Loss = 0.000672196\n",
      "Epoka 34500: Loss = 0.000673341\n",
      "Epoka 34510: Loss = 0.000653195\n",
      "Epoka 34520: Loss = 0.000806606\n",
      "Epoka 34530: Loss = 0.000637960\n",
      "Epoka 34540: Loss = 0.000651548\n",
      "Epoka 34550: Loss = 0.000725037\n",
      "Epoka 34560: Loss = 0.000644169\n",
      "Epoka 34570: Loss = 0.000721525\n",
      "Epoka 34580: Loss = 0.000684233\n",
      "Epoka 34590: Loss = 0.000626737\n",
      "Epoka 34600: Loss = 0.000678249\n",
      "Epoka 34610: Loss = 0.000817751\n",
      "Epoka 34620: Loss = 0.000819213\n",
      "Epoka 34630: Loss = 0.000676318\n",
      "Epoka 34640: Loss = 0.000719585\n",
      "Epoka 34650: Loss = 0.000668399\n",
      "Epoka 34660: Loss = 0.000618410\n",
      "Epoka 34670: Loss = 0.000701268\n",
      "Epoka 34680: Loss = 0.000701525\n",
      "Epoka 34690: Loss = 0.000707112\n",
      "Epoka 34700: Loss = 0.000717109\n",
      "Epoka 34710: Loss = 0.000645132\n",
      "Epoka 34720: Loss = 0.000672091\n",
      "Epoka 34730: Loss = 0.000632020\n",
      "Epoka 34740: Loss = 0.000652519\n",
      "Epoka 34750: Loss = 0.000774303\n",
      "Epoka 34760: Loss = 0.000707580\n",
      "Epoka 34770: Loss = 0.000727786\n",
      "Epoka 34780: Loss = 0.000767720\n",
      "Epoka 34790: Loss = 0.000635292\n",
      "Epoka 34800: Loss = 0.000667058\n",
      "Epoka 34810: Loss = 0.000611395\n",
      "Epoka 34820: Loss = 0.000902382\n",
      "Epoka 34830: Loss = 0.000706260\n",
      "Epoka 34840: Loss = 0.000668332\n",
      "Epoka 34850: Loss = 0.000721716\n",
      "Epoka 34860: Loss = 0.000659336\n",
      "Epoka 34870: Loss = 0.000654918\n",
      "Epoka 34880: Loss = 0.000644678\n",
      "Epoka 34890: Loss = 0.000630798\n",
      "Epoka 34900: Loss = 0.000639312\n",
      "Epoka 34910: Loss = 0.000660386\n",
      "Epoka 34920: Loss = 0.000667945\n",
      "Epoka 34930: Loss = 0.000663311\n",
      "Epoka 34940: Loss = 0.000625602\n",
      "Epoka 34950: Loss = 0.000677387\n",
      "Epoka 34960: Loss = 0.000648303\n",
      "Epoka 34970: Loss = 0.000705920\n",
      "Epoka 34980: Loss = 0.000683132\n",
      "Epoka 34990: Loss = 0.000795014\n",
      "Czas wykonania: 1192.786255 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_stepsL = MLPNoBackprop(layer_sizes = [1, 15, 15, 1], weights_initialize_function ='uniform')\n",
    "start_time = time.time()\n",
    "mlp_stepsL.momentum(X_stepsL_train_normalized, Y_stepsL_train_normalized, epochs=35000, learning_rate=0.06, Lambda=0.9, batch_size=64)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "4720b091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.526579845059138\n"
     ]
    }
   ],
   "source": [
    "ypred_normalized = mlp_stepsL.predict(X_stepsL_test_normalized)\n",
    "ypred = ypred_normalized *np.std(Y_stepsL_train) +np.mean(Y_stepsL_train)\n",
    "print(mlp_stepsL.mse(ypred, Y_stepsL_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bc63ac",
   "metadata": {},
   "source": [
    "## RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "584b02ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 0.085678986\n",
      "Epoka 10: Loss = 0.063363360\n",
      "Epoka 20: Loss = 0.022024439\n",
      "Epoka 30: Loss = 0.034491857\n",
      "Epoka 40: Loss = 0.031292037\n",
      "Epoka 50: Loss = 0.026572034\n",
      "Epoka 60: Loss = 0.018336260\n",
      "Epoka 70: Loss = 0.029810098\n",
      "Epoka 80: Loss = 0.010886404\n",
      "Epoka 90: Loss = 0.009925581\n",
      "Epoka 100: Loss = 0.009238082\n",
      "Epoka 110: Loss = 0.015156596\n",
      "Epoka 120: Loss = 0.017106225\n",
      "Epoka 130: Loss = 0.009613703\n",
      "Epoka 140: Loss = 0.008193902\n",
      "Epoka 150: Loss = 0.013635610\n",
      "Epoka 160: Loss = 0.023391437\n",
      "Epoka 170: Loss = 0.010472829\n",
      "Epoka 180: Loss = 0.010047769\n",
      "Epoka 190: Loss = 0.008844738\n",
      "Epoka 200: Loss = 0.016686690\n",
      "Epoka 210: Loss = 0.013544834\n",
      "Epoka 220: Loss = 0.006205080\n",
      "Epoka 230: Loss = 0.019452292\n",
      "Epoka 240: Loss = 0.009879922\n",
      "Epoka 250: Loss = 0.011114200\n",
      "Epoka 260: Loss = 0.009088186\n",
      "Epoka 270: Loss = 0.009583756\n",
      "Epoka 280: Loss = 0.010567594\n",
      "Epoka 290: Loss = 0.007262199\n",
      "Epoka 300: Loss = 0.005503904\n",
      "Epoka 310: Loss = 0.010557006\n",
      "Epoka 320: Loss = 0.007544721\n",
      "Epoka 330: Loss = 0.015092080\n",
      "Epoka 340: Loss = 0.007524883\n",
      "Epoka 350: Loss = 0.009436984\n",
      "Epoka 360: Loss = 0.016483475\n",
      "Epoka 370: Loss = 0.010190784\n",
      "Epoka 380: Loss = 0.007002332\n",
      "Epoka 390: Loss = 0.013488584\n",
      "Epoka 400: Loss = 0.007681616\n",
      "Epoka 410: Loss = 0.012571077\n",
      "Epoka 420: Loss = 0.010041735\n",
      "Epoka 430: Loss = 0.009117429\n",
      "Epoka 440: Loss = 0.038117693\n",
      "Epoka 450: Loss = 0.006559022\n",
      "Epoka 460: Loss = 0.019237025\n",
      "Epoka 470: Loss = 0.019568227\n",
      "Epoka 480: Loss = 0.011553474\n",
      "Epoka 490: Loss = 0.004522126\n",
      "Epoka 500: Loss = 0.005696615\n",
      "Epoka 510: Loss = 0.009906894\n",
      "Epoka 520: Loss = 0.005555827\n",
      "Epoka 530: Loss = 0.016426704\n",
      "Epoka 540: Loss = 0.018407414\n",
      "Epoka 550: Loss = 0.014016481\n",
      "Epoka 560: Loss = 0.015422576\n",
      "Epoka 570: Loss = 0.006015337\n",
      "Epoka 580: Loss = 0.018655775\n",
      "Epoka 590: Loss = 0.013443504\n",
      "Epoka 600: Loss = 0.004371292\n",
      "Epoka 610: Loss = 0.005688121\n",
      "Epoka 620: Loss = 0.011165481\n",
      "Epoka 630: Loss = 0.011885625\n",
      "Epoka 640: Loss = 0.018737570\n",
      "Epoka 650: Loss = 0.008488308\n",
      "Epoka 660: Loss = 0.005634574\n",
      "Epoka 670: Loss = 0.012767652\n",
      "Epoka 680: Loss = 0.008782062\n",
      "Epoka 690: Loss = 0.013126499\n",
      "Epoka 700: Loss = 0.012364550\n",
      "Epoka 710: Loss = 0.028214361\n",
      "Epoka 720: Loss = 0.005311888\n",
      "Epoka 730: Loss = 0.005895349\n",
      "Epoka 740: Loss = 0.005668688\n",
      "Epoka 750: Loss = 0.005910804\n",
      "Epoka 760: Loss = 0.013949318\n",
      "Epoka 770: Loss = 0.016596530\n",
      "Epoka 780: Loss = 0.012846864\n",
      "Epoka 790: Loss = 0.010654859\n",
      "Epoka 800: Loss = 0.011799171\n",
      "Epoka 810: Loss = 0.006916648\n",
      "Epoka 820: Loss = 0.009221847\n",
      "Epoka 830: Loss = 0.014141309\n",
      "Epoka 840: Loss = 0.006067494\n",
      "Epoka 850: Loss = 0.010592232\n",
      "Epoka 860: Loss = 0.009564787\n",
      "Epoka 870: Loss = 0.009369998\n",
      "Epoka 880: Loss = 0.011006894\n",
      "Epoka 890: Loss = 0.006321672\n",
      "Epoka 900: Loss = 0.007421963\n",
      "Epoka 910: Loss = 0.017067600\n",
      "Epoka 920: Loss = 0.007893132\n",
      "Epoka 930: Loss = 0.010719680\n",
      "Epoka 940: Loss = 0.004220874\n",
      "Epoka 950: Loss = 0.011834410\n",
      "Epoka 960: Loss = 0.012307925\n",
      "Epoka 970: Loss = 0.006095695\n",
      "Epoka 980: Loss = 0.018000525\n",
      "Epoka 990: Loss = 0.008084746\n",
      "Czas wykonania: 66.129861 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_stepsL2 = MLPNoBackprop(layer_sizes = [1, 20, 1])\n",
    "start_time = time.time()\n",
    "mlp_stepsL2.RMSprop(X_stepsL_train_normalized, Y_stepsL_train_normalized, epochs = 1000, learning_rate=0.06, beta=0.85, epsilon=1e-7, batch_size=64)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "1eb3136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.57810812732854\n"
     ]
    }
   ],
   "source": [
    "ypred_normalized = mlp_stepsL2.predict(X_stepsL_test_normalized)\n",
    "ypred = ypred_normalized *np.std(Y_stepsL_train) +np.mean(Y_stepsL_train)\n",
    "print(mlp_stepsL2.mse(ypred, Y_stepsL_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "583d0b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.20981053075224\n"
     ]
    }
   ],
   "source": [
    "ypred_normalized = mlp_stepsL2.predict(X_stepsL_test_normalized)\n",
    "ypred = ypred_normalized *np.std(Y_stepsL_train) +np.mean(Y_stepsL_train)\n",
    "print(mlp_stepsL2.mse(ypred, Y_stepsL_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb0d143",
   "metadata": {},
   "source": [
    "# mlp for multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4555d3",
   "metadata": {},
   "source": [
    "## momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6f2c257d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 0.791971559\n",
      "Epoka 10: Loss = 0.485865130\n",
      "Epoka 20: Loss = 0.453360170\n",
      "Epoka 30: Loss = 0.422319837\n",
      "Epoka 40: Loss = 0.399245602\n",
      "Epoka 50: Loss = 0.384653972\n",
      "Epoka 60: Loss = 0.372851837\n",
      "Epoka 70: Loss = 0.360910261\n",
      "Epoka 80: Loss = 0.345408565\n",
      "Epoka 90: Loss = 0.326944201\n",
      "Epoka 100: Loss = 0.311648839\n",
      "Epoka 110: Loss = 0.298152557\n",
      "Epoka 120: Loss = 0.285960363\n",
      "Epoka 130: Loss = 0.273142326\n",
      "Epoka 140: Loss = 0.256422225\n",
      "Epoka 150: Loss = 0.231431179\n",
      "Epoka 160: Loss = 0.197515538\n",
      "Epoka 170: Loss = 0.166133943\n",
      "Epoka 180: Loss = 0.144404362\n",
      "Epoka 190: Loss = 0.132267470\n",
      "Epoka 200: Loss = 0.125546137\n",
      "Epoka 210: Loss = 0.120133775\n",
      "Epoka 220: Loss = 0.116422279\n",
      "Epoka 230: Loss = 0.113425162\n",
      "Epoka 240: Loss = 0.110017072\n",
      "Epoka 250: Loss = 0.108539046\n",
      "Epoka 260: Loss = 0.104671050\n",
      "Epoka 270: Loss = 0.102342295\n",
      "Epoka 280: Loss = 0.100391975\n",
      "Epoka 290: Loss = 0.098407972\n",
      "Epoka 300: Loss = 0.095617366\n",
      "Epoka 310: Loss = 0.093378431\n",
      "Epoka 320: Loss = 0.091422552\n",
      "Epoka 330: Loss = 0.089762509\n",
      "Epoka 340: Loss = 0.087993693\n",
      "Epoka 350: Loss = 0.085804915\n",
      "Epoka 360: Loss = 0.084347389\n",
      "Epoka 370: Loss = 0.082318234\n",
      "Epoka 380: Loss = 0.080294061\n",
      "Epoka 390: Loss = 0.078602705\n",
      "Epoka 400: Loss = 0.076442225\n",
      "Epoka 410: Loss = 0.074401690\n",
      "Epoka 420: Loss = 0.072643896\n",
      "Epoka 430: Loss = 0.070258669\n",
      "Epoka 440: Loss = 0.068578837\n",
      "Epoka 450: Loss = 0.066613911\n",
      "Epoka 460: Loss = 0.065190628\n",
      "Epoka 470: Loss = 0.064346853\n",
      "Epoka 480: Loss = 0.062737347\n",
      "Epoka 490: Loss = 0.061771118\n",
      "Epoka 500: Loss = 0.061153166\n",
      "Epoka 510: Loss = 0.061513317\n",
      "Epoka 520: Loss = 0.060343671\n",
      "Epoka 530: Loss = 0.059965323\n",
      "Epoka 540: Loss = 0.059646471\n",
      "Epoka 550: Loss = 0.059339987\n",
      "Epoka 560: Loss = 0.059519435\n",
      "Epoka 570: Loss = 0.059034895\n",
      "Epoka 580: Loss = 0.059041867\n",
      "Epoka 590: Loss = 0.058679427\n",
      "Epoka 600: Loss = 0.058555153\n",
      "Epoka 610: Loss = 0.058688891\n",
      "Epoka 620: Loss = 0.058452375\n",
      "Epoka 630: Loss = 0.058488002\n",
      "Epoka 640: Loss = 0.058304510\n",
      "Epoka 650: Loss = 0.058121127\n",
      "Epoka 660: Loss = 0.058367472\n",
      "Epoka 670: Loss = 0.057852791\n",
      "Epoka 680: Loss = 0.057899519\n",
      "Epoka 690: Loss = 0.057671336\n",
      "Epoka 700: Loss = 0.057648225\n",
      "Epoka 710: Loss = 0.057823742\n",
      "Epoka 720: Loss = 0.057434479\n",
      "Epoka 730: Loss = 0.057260148\n",
      "Epoka 740: Loss = 0.057232431\n",
      "Epoka 750: Loss = 0.057048890\n",
      "Epoka 760: Loss = 0.057036299\n",
      "Epoka 770: Loss = 0.056987453\n",
      "Epoka 780: Loss = 0.056703654\n",
      "Epoka 790: Loss = 0.056630917\n",
      "Epoka 800: Loss = 0.056522827\n",
      "Epoka 810: Loss = 0.056558876\n",
      "Epoka 820: Loss = 0.056368319\n",
      "Epoka 830: Loss = 0.056244998\n",
      "Epoka 840: Loss = 0.055990636\n",
      "Epoka 850: Loss = 0.056125057\n",
      "Epoka 860: Loss = 0.055813866\n",
      "Epoka 870: Loss = 0.055830369\n",
      "Epoka 880: Loss = 0.055473111\n",
      "Epoka 890: Loss = 0.055300294\n",
      "Epoka 900: Loss = 0.055374080\n",
      "Epoka 910: Loss = 0.055094701\n",
      "Epoka 920: Loss = 0.054908098\n",
      "Epoka 930: Loss = 0.054952142\n",
      "Epoka 940: Loss = 0.054982141\n",
      "Epoka 950: Loss = 0.055220280\n",
      "Epoka 960: Loss = 0.054847546\n",
      "Epoka 970: Loss = 0.054112419\n",
      "Epoka 980: Loss = 0.054084998\n",
      "Epoka 990: Loss = 0.054063002\n",
      "Epoka 1000: Loss = 0.054131624\n",
      "Epoka 1010: Loss = 0.053651748\n",
      "Epoka 1020: Loss = 0.053575270\n",
      "Epoka 1030: Loss = 0.053254232\n",
      "Epoka 1040: Loss = 0.053004456\n",
      "Epoka 1050: Loss = 0.052781663\n",
      "Epoka 1060: Loss = 0.052775210\n",
      "Epoka 1070: Loss = 0.052519307\n",
      "Epoka 1080: Loss = 0.052624282\n",
      "Epoka 1090: Loss = 0.052198780\n",
      "Epoka 1100: Loss = 0.052205184\n",
      "Epoka 1110: Loss = 0.052463312\n",
      "Epoka 1120: Loss = 0.051657307\n",
      "Epoka 1130: Loss = 0.051663675\n",
      "Epoka 1140: Loss = 0.051877392\n",
      "Epoka 1150: Loss = 0.051243618\n",
      "Epoka 1160: Loss = 0.051267086\n",
      "Epoka 1170: Loss = 0.051027721\n",
      "Epoka 1180: Loss = 0.051011840\n",
      "Epoka 1190: Loss = 0.050642185\n",
      "Epoka 1200: Loss = 0.050531979\n",
      "Epoka 1210: Loss = 0.050348489\n",
      "Epoka 1220: Loss = 0.050271834\n",
      "Epoka 1230: Loss = 0.050323286\n",
      "Epoka 1240: Loss = 0.049997363\n",
      "Epoka 1250: Loss = 0.050601175\n",
      "Epoka 1260: Loss = 0.050346059\n",
      "Epoka 1270: Loss = 0.049569693\n",
      "Epoka 1280: Loss = 0.049465365\n",
      "Epoka 1290: Loss = 0.049326264\n",
      "Epoka 1300: Loss = 0.049326841\n",
      "Epoka 1310: Loss = 0.049573362\n",
      "Epoka 1320: Loss = 0.048963038\n",
      "Epoka 1330: Loss = 0.048832948\n",
      "Epoka 1340: Loss = 0.048777941\n",
      "Epoka 1350: Loss = 0.048837646\n",
      "Epoka 1360: Loss = 0.048564016\n",
      "Epoka 1370: Loss = 0.048581990\n",
      "Epoka 1380: Loss = 0.048234446\n",
      "Epoka 1390: Loss = 0.048219444\n",
      "Epoka 1400: Loss = 0.048128299\n",
      "Epoka 1410: Loss = 0.048248461\n",
      "Epoka 1420: Loss = 0.047787328\n",
      "Epoka 1430: Loss = 0.047823581\n",
      "Epoka 1440: Loss = 0.047558079\n",
      "Epoka 1450: Loss = 0.047594083\n",
      "Epoka 1460: Loss = 0.047512690\n",
      "Epoka 1470: Loss = 0.047601972\n",
      "Epoka 1480: Loss = 0.047463732\n",
      "Epoka 1490: Loss = 0.047108700\n",
      "Epoka 1500: Loss = 0.047325625\n",
      "Epoka 1510: Loss = 0.046840600\n",
      "Epoka 1520: Loss = 0.046794532\n",
      "Epoka 1530: Loss = 0.046857072\n",
      "Epoka 1540: Loss = 0.046516534\n",
      "Epoka 1550: Loss = 0.046811654\n",
      "Epoka 1560: Loss = 0.046379831\n",
      "Epoka 1570: Loss = 0.046269894\n",
      "Epoka 1580: Loss = 0.046178441\n",
      "Epoka 1590: Loss = 0.046320513\n",
      "Epoka 1600: Loss = 0.046184377\n",
      "Epoka 1610: Loss = 0.045858600\n",
      "Epoka 1620: Loss = 0.045936437\n",
      "Epoka 1630: Loss = 0.045739029\n",
      "Epoka 1640: Loss = 0.045548657\n",
      "Epoka 1650: Loss = 0.045795299\n",
      "Epoka 1660: Loss = 0.045383487\n",
      "Epoka 1670: Loss = 0.045528729\n",
      "Epoka 1680: Loss = 0.045226688\n",
      "Epoka 1690: Loss = 0.045090278\n",
      "Epoka 1700: Loss = 0.045067536\n",
      "Epoka 1710: Loss = 0.044949473\n",
      "Epoka 1720: Loss = 0.044831177\n",
      "Epoka 1730: Loss = 0.045429992\n",
      "Epoka 1740: Loss = 0.044649975\n",
      "Epoka 1750: Loss = 0.045593847\n",
      "Epoka 1760: Loss = 0.044546574\n",
      "Epoka 1770: Loss = 0.044417991\n",
      "Epoka 1780: Loss = 0.044551702\n",
      "Epoka 1790: Loss = 0.044523863\n",
      "Epoka 1800: Loss = 0.044266423\n",
      "Epoka 1810: Loss = 0.044052873\n",
      "Epoka 1820: Loss = 0.043982333\n",
      "Epoka 1830: Loss = 0.044114676\n",
      "Epoka 1840: Loss = 0.043826337\n",
      "Epoka 1850: Loss = 0.043789919\n",
      "Epoka 1860: Loss = 0.043758024\n",
      "Epoka 1870: Loss = 0.043615904\n",
      "Epoka 1880: Loss = 0.043485619\n",
      "Epoka 1890: Loss = 0.043567616\n",
      "Epoka 1900: Loss = 0.043330968\n",
      "Epoka 1910: Loss = 0.043302686\n",
      "Epoka 1920: Loss = 0.043130465\n",
      "Epoka 1930: Loss = 0.043080169\n",
      "Epoka 1940: Loss = 0.043139756\n",
      "Epoka 1950: Loss = 0.043024842\n",
      "Epoka 1960: Loss = 0.043166064\n",
      "Epoka 1970: Loss = 0.042681499\n",
      "Epoka 1980: Loss = 0.042879246\n",
      "Epoka 1990: Loss = 0.042613908\n",
      "Epoka 2000: Loss = 0.042438306\n",
      "Epoka 2010: Loss = 0.042320871\n",
      "Epoka 2020: Loss = 0.042279162\n",
      "Epoka 2030: Loss = 0.042162602\n",
      "Epoka 2040: Loss = 0.042175407\n",
      "Epoka 2050: Loss = 0.042083665\n",
      "Epoka 2060: Loss = 0.041892393\n",
      "Epoka 2070: Loss = 0.041806609\n",
      "Epoka 2080: Loss = 0.041898032\n",
      "Epoka 2090: Loss = 0.041617352\n",
      "Epoka 2100: Loss = 0.041498851\n",
      "Epoka 2110: Loss = 0.041473067\n",
      "Epoka 2120: Loss = 0.041352704\n",
      "Epoka 2130: Loss = 0.041729880\n",
      "Epoka 2140: Loss = 0.041206434\n",
      "Epoka 2150: Loss = 0.041095955\n",
      "Epoka 2160: Loss = 0.041055175\n",
      "Epoka 2170: Loss = 0.040898892\n",
      "Epoka 2180: Loss = 0.040977996\n",
      "Epoka 2190: Loss = 0.040839825\n",
      "Epoka 2200: Loss = 0.040742284\n",
      "Epoka 2210: Loss = 0.040743787\n",
      "Epoka 2220: Loss = 0.040558446\n",
      "Epoka 2230: Loss = 0.040321987\n",
      "Epoka 2240: Loss = 0.040264057\n",
      "Epoka 2250: Loss = 0.040156841\n",
      "Epoka 2260: Loss = 0.040174198\n",
      "Epoka 2270: Loss = 0.040004355\n",
      "Epoka 2280: Loss = 0.039890302\n",
      "Epoka 2290: Loss = 0.039980873\n",
      "Epoka 2300: Loss = 0.040029755\n",
      "Epoka 2310: Loss = 0.039647399\n",
      "Epoka 2320: Loss = 0.039513703\n",
      "Epoka 2330: Loss = 0.039590934\n",
      "Epoka 2340: Loss = 0.039339496\n",
      "Epoka 2350: Loss = 0.039397417\n",
      "Epoka 2360: Loss = 0.039231398\n",
      "Epoka 2370: Loss = 0.039042788\n",
      "Epoka 2380: Loss = 0.039021038\n",
      "Epoka 2390: Loss = 0.038847721\n",
      "Epoka 2400: Loss = 0.039003716\n",
      "Epoka 2410: Loss = 0.038678514\n",
      "Epoka 2420: Loss = 0.038668494\n",
      "Epoka 2430: Loss = 0.038637124\n",
      "Epoka 2440: Loss = 0.038544456\n",
      "Epoka 2450: Loss = 0.038340819\n",
      "Epoka 2460: Loss = 0.038205197\n",
      "Epoka 2470: Loss = 0.038512198\n",
      "Epoka 2480: Loss = 0.037995564\n",
      "Epoka 2490: Loss = 0.037966600\n",
      "Epoka 2500: Loss = 0.037902098\n",
      "Epoka 2510: Loss = 0.037720371\n",
      "Epoka 2520: Loss = 0.037589600\n",
      "Epoka 2530: Loss = 0.037707303\n",
      "Epoka 2540: Loss = 0.037511243\n",
      "Epoka 2550: Loss = 0.037540517\n",
      "Epoka 2560: Loss = 0.037146907\n",
      "Epoka 2570: Loss = 0.037087560\n",
      "Epoka 2580: Loss = 0.037080071\n",
      "Epoka 2590: Loss = 0.036842501\n",
      "Epoka 2600: Loss = 0.036697492\n",
      "Epoka 2610: Loss = 0.036633129\n",
      "Epoka 2620: Loss = 0.037212774\n",
      "Epoka 2630: Loss = 0.036425918\n",
      "Epoka 2640: Loss = 0.036347133\n",
      "Epoka 2650: Loss = 0.036151203\n",
      "Epoka 2660: Loss = 0.036143824\n",
      "Epoka 2670: Loss = 0.035967384\n",
      "Epoka 2680: Loss = 0.035852274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 2690: Loss = 0.036046001\n",
      "Epoka 2700: Loss = 0.035586526\n",
      "Epoka 2710: Loss = 0.035614281\n",
      "Epoka 2720: Loss = 0.035783820\n",
      "Epoka 2730: Loss = 0.035327355\n",
      "Epoka 2740: Loss = 0.035126500\n",
      "Epoka 2750: Loss = 0.035065201\n",
      "Epoka 2760: Loss = 0.034907990\n",
      "Epoka 2770: Loss = 0.034912247\n",
      "Epoka 2780: Loss = 0.034677816\n",
      "Epoka 2790: Loss = 0.034588010\n",
      "Epoka 2800: Loss = 0.034496186\n",
      "Epoka 2810: Loss = 0.034536565\n",
      "Epoka 2820: Loss = 0.034241146\n",
      "Epoka 2830: Loss = 0.034146726\n",
      "Epoka 2840: Loss = 0.033969745\n",
      "Epoka 2850: Loss = 0.033881550\n",
      "Epoka 2860: Loss = 0.033993430\n",
      "Epoka 2870: Loss = 0.034103993\n",
      "Epoka 2880: Loss = 0.033479494\n",
      "Epoka 2890: Loss = 0.033370417\n",
      "Epoka 2900: Loss = 0.033342054\n",
      "Epoka 2910: Loss = 0.033336435\n",
      "Epoka 2920: Loss = 0.033063670\n",
      "Epoka 2930: Loss = 0.032934201\n",
      "Epoka 2940: Loss = 0.032903138\n",
      "Epoka 2950: Loss = 0.032851901\n",
      "Epoka 2960: Loss = 0.032655330\n",
      "Epoka 2970: Loss = 0.032394513\n",
      "Epoka 2980: Loss = 0.032358941\n",
      "Epoka 2990: Loss = 0.032158271\n",
      "Epoka 3000: Loss = 0.032204224\n",
      "Epoka 3010: Loss = 0.031932336\n",
      "Epoka 3020: Loss = 0.031941367\n",
      "Epoka 3030: Loss = 0.031741006\n",
      "Epoka 3040: Loss = 0.031536250\n",
      "Epoka 3050: Loss = 0.031380261\n",
      "Epoka 3060: Loss = 0.031343547\n",
      "Epoka 3070: Loss = 0.031147820\n",
      "Epoka 3080: Loss = 0.031015872\n",
      "Epoka 3090: Loss = 0.031003669\n",
      "Epoka 3100: Loss = 0.030756668\n",
      "Epoka 3110: Loss = 0.030698579\n",
      "Epoka 3120: Loss = 0.030557060\n",
      "Epoka 3130: Loss = 0.030431939\n",
      "Epoka 3140: Loss = 0.030424438\n",
      "Epoka 3150: Loss = 0.030266734\n",
      "Epoka 3160: Loss = 0.030078022\n",
      "Epoka 3170: Loss = 0.029916794\n",
      "Epoka 3180: Loss = 0.029863419\n",
      "Epoka 3190: Loss = 0.029734411\n",
      "Epoka 3200: Loss = 0.029723178\n",
      "Epoka 3210: Loss = 0.029462974\n",
      "Epoka 3220: Loss = 0.029373473\n",
      "Epoka 3230: Loss = 0.029332170\n",
      "Epoka 3240: Loss = 0.029126336\n",
      "Epoka 3250: Loss = 0.029013620\n",
      "Epoka 3260: Loss = 0.028843473\n",
      "Epoka 3270: Loss = 0.028734097\n",
      "Epoka 3280: Loss = 0.028757107\n",
      "Epoka 3290: Loss = 0.028533998\n",
      "Epoka 3300: Loss = 0.028310841\n",
      "Epoka 3310: Loss = 0.028273977\n",
      "Epoka 3320: Loss = 0.028149408\n",
      "Epoka 3330: Loss = 0.027976904\n",
      "Epoka 3340: Loss = 0.027844704\n",
      "Epoka 3350: Loss = 0.027695479\n",
      "Epoka 3360: Loss = 0.027637516\n",
      "Epoka 3370: Loss = 0.027487864\n",
      "Epoka 3380: Loss = 0.027387088\n",
      "Epoka 3390: Loss = 0.027215282\n",
      "Epoka 3400: Loss = 0.027474886\n",
      "Epoka 3410: Loss = 0.027014183\n",
      "Epoka 3420: Loss = 0.026919044\n",
      "Epoka 3430: Loss = 0.026889954\n",
      "Epoka 3440: Loss = 0.026627737\n",
      "Epoka 3450: Loss = 0.026637734\n",
      "Epoka 3460: Loss = 0.026383577\n",
      "Epoka 3470: Loss = 0.026310971\n",
      "Epoka 3480: Loss = 0.026307124\n",
      "Epoka 3490: Loss = 0.026479923\n",
      "Epoka 3500: Loss = 0.025970004\n",
      "Epoka 3510: Loss = 0.026009740\n",
      "Epoka 3520: Loss = 0.025688379\n",
      "Epoka 3530: Loss = 0.025852806\n",
      "Epoka 3540: Loss = 0.025462633\n",
      "Epoka 3550: Loss = 0.025366059\n",
      "Epoka 3560: Loss = 0.025274709\n",
      "Epoka 3570: Loss = 0.025178406\n",
      "Epoka 3580: Loss = 0.025018570\n",
      "Epoka 3590: Loss = 0.025177071\n",
      "Epoka 3600: Loss = 0.024825898\n",
      "Epoka 3610: Loss = 0.024716153\n",
      "Epoka 3620: Loss = 0.025010587\n",
      "Epoka 3630: Loss = 0.024571921\n",
      "Epoka 3640: Loss = 0.024421246\n",
      "Epoka 3650: Loss = 0.024290138\n",
      "Epoka 3660: Loss = 0.024261291\n",
      "Epoka 3670: Loss = 0.024057872\n",
      "Epoka 3680: Loss = 0.024020904\n",
      "Epoka 3690: Loss = 0.023791178\n",
      "Epoka 3700: Loss = 0.023709427\n",
      "Epoka 3710: Loss = 0.023636963\n",
      "Epoka 3720: Loss = 0.023507603\n",
      "Epoka 3730: Loss = 0.023391428\n",
      "Epoka 3740: Loss = 0.023425299\n",
      "Epoka 3750: Loss = 0.023327951\n",
      "Epoka 3760: Loss = 0.023068580\n",
      "Epoka 3770: Loss = 0.023181974\n",
      "Epoka 3780: Loss = 0.022883301\n",
      "Epoka 3790: Loss = 0.022852156\n",
      "Epoka 3800: Loss = 0.022637282\n",
      "Epoka 3810: Loss = 0.022555340\n",
      "Epoka 3820: Loss = 0.022432277\n",
      "Epoka 3830: Loss = 0.022379262\n",
      "Epoka 3840: Loss = 0.022224402\n",
      "Epoka 3850: Loss = 0.022160001\n",
      "Epoka 3860: Loss = 0.022122515\n",
      "Epoka 3870: Loss = 0.021984196\n",
      "Epoka 3880: Loss = 0.021927269\n",
      "Epoka 3890: Loss = 0.021790790\n",
      "Epoka 3900: Loss = 0.021648615\n",
      "Epoka 3910: Loss = 0.021637942\n",
      "Epoka 3920: Loss = 0.021440124\n",
      "Epoka 3930: Loss = 0.021732458\n",
      "Epoka 3940: Loss = 0.021286828\n",
      "Epoka 3950: Loss = 0.021328407\n",
      "Epoka 3960: Loss = 0.021055780\n",
      "Epoka 3970: Loss = 0.021061195\n",
      "Epoka 3980: Loss = 0.020935199\n",
      "Epoka 3990: Loss = 0.020916576\n",
      "Epoka 4000: Loss = 0.020757574\n",
      "Epoka 4010: Loss = 0.020570825\n",
      "Epoka 4020: Loss = 0.020653184\n",
      "Epoka 4030: Loss = 0.020462395\n",
      "Epoka 4040: Loss = 0.020483063\n",
      "Epoka 4050: Loss = 0.020287732\n",
      "Epoka 4060: Loss = 0.020430930\n",
      "Epoka 4070: Loss = 0.020030868\n",
      "Epoka 4080: Loss = 0.019977319\n",
      "Epoka 4090: Loss = 0.019904893\n",
      "Epoka 4100: Loss = 0.019806942\n",
      "Epoka 4110: Loss = 0.019800046\n",
      "Epoka 4120: Loss = 0.019823256\n",
      "Epoka 4130: Loss = 0.019592038\n",
      "Epoka 4140: Loss = 0.019479786\n",
      "Epoka 4150: Loss = 0.019311904\n",
      "Epoka 4160: Loss = 0.019221762\n",
      "Epoka 4170: Loss = 0.019240458\n",
      "Epoka 4180: Loss = 0.019091605\n",
      "Epoka 4190: Loss = 0.018986513\n",
      "Epoka 4200: Loss = 0.018939279\n",
      "Epoka 4210: Loss = 0.018775110\n",
      "Epoka 4220: Loss = 0.018795289\n",
      "Epoka 4230: Loss = 0.018630650\n",
      "Epoka 4240: Loss = 0.018544632\n",
      "Epoka 4250: Loss = 0.018474711\n",
      "Epoka 4260: Loss = 0.018463307\n",
      "Epoka 4270: Loss = 0.018259738\n",
      "Epoka 4280: Loss = 0.018450073\n",
      "Epoka 4290: Loss = 0.018144447\n",
      "Epoka 4300: Loss = 0.018051634\n",
      "Epoka 4310: Loss = 0.017964648\n",
      "Epoka 4320: Loss = 0.017973202\n",
      "Epoka 4330: Loss = 0.017793202\n",
      "Epoka 4340: Loss = 0.017734386\n",
      "Epoka 4350: Loss = 0.017725202\n",
      "Epoka 4360: Loss = 0.017544180\n",
      "Epoka 4370: Loss = 0.017491088\n",
      "Epoka 4380: Loss = 0.017362067\n",
      "Epoka 4390: Loss = 0.017307740\n",
      "Epoka 4400: Loss = 0.017299082\n",
      "Epoka 4410: Loss = 0.017181097\n",
      "Epoka 4420: Loss = 0.017181560\n",
      "Epoka 4430: Loss = 0.016977270\n",
      "Epoka 4440: Loss = 0.017008169\n",
      "Epoka 4450: Loss = 0.016803266\n",
      "Epoka 4460: Loss = 0.016904577\n",
      "Epoka 4470: Loss = 0.016825393\n",
      "Epoka 4480: Loss = 0.016573859\n",
      "Epoka 4490: Loss = 0.016577358\n",
      "Epoka 4500: Loss = 0.016428805\n",
      "Epoka 4510: Loss = 0.016365037\n",
      "Epoka 4520: Loss = 0.016353825\n",
      "Epoka 4530: Loss = 0.016196909\n",
      "Epoka 4540: Loss = 0.016176439\n",
      "Epoka 4550: Loss = 0.016088747\n",
      "Epoka 4560: Loss = 0.015980920\n",
      "Epoka 4570: Loss = 0.016082008\n",
      "Epoka 4580: Loss = 0.016021110\n",
      "Epoka 4590: Loss = 0.015874993\n",
      "Epoka 4600: Loss = 0.015721161\n",
      "Epoka 4610: Loss = 0.015648303\n",
      "Epoka 4620: Loss = 0.015588303\n",
      "Epoka 4630: Loss = 0.015469839\n",
      "Epoka 4640: Loss = 0.015412067\n",
      "Epoka 4650: Loss = 0.015403330\n",
      "Epoka 4660: Loss = 0.015352847\n",
      "Epoka 4670: Loss = 0.015270055\n",
      "Epoka 4680: Loss = 0.015137985\n",
      "Epoka 4690: Loss = 0.015369270\n",
      "Epoka 4700: Loss = 0.014988754\n",
      "Epoka 4710: Loss = 0.014969459\n",
      "Epoka 4720: Loss = 0.014983113\n",
      "Epoka 4730: Loss = 0.014800905\n",
      "Epoka 4740: Loss = 0.014757679\n",
      "Epoka 4750: Loss = 0.014810314\n",
      "Epoka 4760: Loss = 0.014812893\n",
      "Epoka 4770: Loss = 0.014620229\n",
      "Epoka 4780: Loss = 0.014518746\n",
      "Epoka 4790: Loss = 0.014415143\n",
      "Epoka 4800: Loss = 0.014350991\n",
      "Epoka 4810: Loss = 0.014296638\n",
      "Epoka 4820: Loss = 0.014259977\n",
      "Epoka 4830: Loss = 0.014202324\n",
      "Epoka 4840: Loss = 0.014120314\n",
      "Epoka 4850: Loss = 0.014153690\n",
      "Epoka 4860: Loss = 0.013997412\n",
      "Epoka 4870: Loss = 0.013909929\n",
      "Epoka 4880: Loss = 0.013893456\n",
      "Epoka 4890: Loss = 0.013824556\n",
      "Epoka 4900: Loss = 0.013870048\n",
      "Epoka 4910: Loss = 0.013688664\n",
      "Epoka 4920: Loss = 0.013707913\n",
      "Epoka 4930: Loss = 0.013627563\n",
      "Epoka 4940: Loss = 0.013555157\n",
      "Epoka 4950: Loss = 0.013574672\n",
      "Epoka 4960: Loss = 0.013420753\n",
      "Epoka 4970: Loss = 0.013445145\n",
      "Epoka 4980: Loss = 0.013434443\n",
      "Epoka 4990: Loss = 0.013304117\n",
      "Epoka 5000: Loss = 0.013218011\n",
      "Epoka 5010: Loss = 0.013301218\n",
      "Epoka 5020: Loss = 0.013131700\n",
      "Epoka 5030: Loss = 0.013030938\n",
      "Epoka 5040: Loss = 0.013153867\n",
      "Epoka 5050: Loss = 0.012961353\n",
      "Epoka 5060: Loss = 0.012919587\n",
      "Epoka 5070: Loss = 0.012846440\n",
      "Epoka 5080: Loss = 0.012918383\n",
      "Epoka 5090: Loss = 0.012892966\n",
      "Epoka 5100: Loss = 0.012724703\n",
      "Epoka 5110: Loss = 0.012791789\n",
      "Epoka 5120: Loss = 0.012713175\n",
      "Epoka 5130: Loss = 0.012553685\n",
      "Epoka 5140: Loss = 0.012536730\n",
      "Epoka 5150: Loss = 0.012526910\n",
      "Epoka 5160: Loss = 0.012468970\n",
      "Epoka 5170: Loss = 0.012414510\n",
      "Epoka 5180: Loss = 0.012376569\n",
      "Epoka 5190: Loss = 0.012436780\n",
      "Epoka 5200: Loss = 0.012231962\n",
      "Epoka 5210: Loss = 0.012238782\n",
      "Epoka 5220: Loss = 0.012133900\n",
      "Epoka 5230: Loss = 0.012177089\n",
      "Epoka 5240: Loss = 0.012102126\n",
      "Epoka 5250: Loss = 0.012077445\n",
      "Epoka 5260: Loss = 0.012022240\n",
      "Epoka 5270: Loss = 0.011905192\n",
      "Epoka 5280: Loss = 0.012114536\n",
      "Epoka 5290: Loss = 0.011962027\n",
      "Epoka 5300: Loss = 0.011804570\n",
      "Epoka 5310: Loss = 0.011957937\n",
      "Epoka 5320: Loss = 0.011703705\n",
      "Epoka 5330: Loss = 0.011705268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 5340: Loss = 0.011641926\n",
      "Epoka 5350: Loss = 0.011626308\n",
      "Epoka 5360: Loss = 0.011743902\n",
      "Epoka 5370: Loss = 0.011509701\n",
      "Epoka 5380: Loss = 0.011503060\n",
      "Epoka 5390: Loss = 0.011534739\n",
      "Epoka 5400: Loss = 0.011429469\n",
      "Epoka 5410: Loss = 0.011354955\n",
      "Epoka 5420: Loss = 0.011356739\n",
      "Epoka 5430: Loss = 0.011300502\n",
      "Epoka 5440: Loss = 0.011260430\n",
      "Epoka 5450: Loss = 0.011279253\n",
      "Epoka 5460: Loss = 0.011168159\n",
      "Epoka 5470: Loss = 0.011179692\n",
      "Epoka 5480: Loss = 0.011147260\n",
      "Epoka 5490: Loss = 0.011072452\n",
      "Epoka 5500: Loss = 0.011225015\n",
      "Epoka 5510: Loss = 0.011026981\n",
      "Epoka 5520: Loss = 0.010948986\n",
      "Epoka 5530: Loss = 0.010921639\n",
      "Epoka 5540: Loss = 0.010909660\n",
      "Epoka 5550: Loss = 0.010939291\n",
      "Epoka 5560: Loss = 0.011013679\n",
      "Epoka 5570: Loss = 0.010767631\n",
      "Epoka 5580: Loss = 0.010833904\n",
      "Epoka 5590: Loss = 0.010855736\n",
      "Epoka 5600: Loss = 0.010669968\n",
      "Epoka 5610: Loss = 0.010705399\n",
      "Epoka 5620: Loss = 0.010648125\n",
      "Epoka 5630: Loss = 0.010588109\n",
      "Epoka 5640: Loss = 0.010607513\n",
      "Epoka 5650: Loss = 0.010539500\n",
      "Epoka 5660: Loss = 0.010541538\n",
      "Epoka 5670: Loss = 0.010485233\n",
      "Epoka 5680: Loss = 0.010649194\n",
      "Epoka 5690: Loss = 0.010403166\n",
      "Epoka 5700: Loss = 0.010456286\n",
      "Epoka 5710: Loss = 0.010308463\n",
      "Epoka 5720: Loss = 0.010324097\n",
      "Epoka 5730: Loss = 0.010257179\n",
      "Epoka 5740: Loss = 0.010267320\n",
      "Epoka 5750: Loss = 0.010198552\n",
      "Epoka 5760: Loss = 0.010239335\n",
      "Epoka 5770: Loss = 0.010163849\n",
      "Epoka 5780: Loss = 0.010160134\n",
      "Epoka 5790: Loss = 0.010089445\n",
      "Epoka 5800: Loss = 0.010089516\n",
      "Epoka 5810: Loss = 0.010051095\n",
      "Epoka 5820: Loss = 0.009996031\n",
      "Epoka 5830: Loss = 0.009971414\n",
      "Epoka 5840: Loss = 0.009994528\n",
      "Epoka 5850: Loss = 0.010131045\n",
      "Epoka 5860: Loss = 0.009994683\n",
      "Epoka 5870: Loss = 0.009851809\n",
      "Epoka 5880: Loss = 0.009823672\n",
      "Epoka 5890: Loss = 0.009845569\n",
      "Epoka 5900: Loss = 0.009764838\n",
      "Epoka 5910: Loss = 0.009723276\n",
      "Epoka 5920: Loss = 0.009796978\n",
      "Epoka 5930: Loss = 0.009676723\n",
      "Epoka 5940: Loss = 0.009652027\n",
      "Epoka 5950: Loss = 0.009613410\n",
      "Epoka 5960: Loss = 0.009593556\n",
      "Epoka 5970: Loss = 0.009567982\n",
      "Epoka 5980: Loss = 0.009599231\n",
      "Epoka 5990: Loss = 0.009501155\n",
      "Epoka 6000: Loss = 0.009477523\n",
      "Epoka 6010: Loss = 0.009478434\n",
      "Epoka 6020: Loss = 0.009473094\n",
      "Epoka 6030: Loss = 0.009413477\n",
      "Epoka 6040: Loss = 0.009405178\n",
      "Epoka 6050: Loss = 0.009370500\n",
      "Epoka 6060: Loss = 0.009348819\n",
      "Epoka 6070: Loss = 0.009319225\n",
      "Epoka 6080: Loss = 0.009286375\n",
      "Epoka 6090: Loss = 0.009351173\n",
      "Epoka 6100: Loss = 0.009262950\n",
      "Epoka 6110: Loss = 0.009182843\n",
      "Epoka 6120: Loss = 0.009163645\n",
      "Epoka 6130: Loss = 0.009159291\n",
      "Epoka 6140: Loss = 0.009108812\n",
      "Epoka 6150: Loss = 0.009120951\n",
      "Epoka 6160: Loss = 0.009078688\n",
      "Epoka 6170: Loss = 0.009099160\n",
      "Epoka 6180: Loss = 0.009017103\n",
      "Epoka 6190: Loss = 0.009071130\n",
      "Epoka 6200: Loss = 0.008977103\n",
      "Epoka 6210: Loss = 0.008951037\n",
      "Epoka 6220: Loss = 0.009035953\n",
      "Epoka 6230: Loss = 0.008888259\n",
      "Epoka 6240: Loss = 0.008930118\n",
      "Epoka 6250: Loss = 0.008853616\n",
      "Epoka 6260: Loss = 0.008820655\n",
      "Epoka 6270: Loss = 0.008817628\n",
      "Epoka 6280: Loss = 0.008783950\n",
      "Epoka 6290: Loss = 0.008931861\n",
      "Epoka 6300: Loss = 0.008881052\n",
      "Epoka 6310: Loss = 0.008745338\n",
      "Epoka 6320: Loss = 0.008860665\n",
      "Epoka 6330: Loss = 0.008750281\n",
      "Epoka 6340: Loss = 0.008654116\n",
      "Epoka 6350: Loss = 0.008619625\n",
      "Epoka 6360: Loss = 0.008709189\n",
      "Epoka 6370: Loss = 0.008619929\n",
      "Epoka 6380: Loss = 0.008565804\n",
      "Epoka 6390: Loss = 0.008518831\n",
      "Epoka 6400: Loss = 0.008536286\n",
      "Epoka 6410: Loss = 0.008483989\n",
      "Epoka 6420: Loss = 0.008492813\n",
      "Epoka 6430: Loss = 0.008450945\n",
      "Epoka 6440: Loss = 0.008449141\n",
      "Epoka 6450: Loss = 0.008502227\n",
      "Epoka 6460: Loss = 0.008504961\n",
      "Epoka 6470: Loss = 0.008326081\n",
      "Epoka 6480: Loss = 0.008324648\n",
      "Epoka 6490: Loss = 0.008286024\n",
      "Epoka 6500: Loss = 0.008260711\n",
      "Epoka 6510: Loss = 0.008259200\n",
      "Epoka 6520: Loss = 0.008268541\n",
      "Epoka 6530: Loss = 0.008200663\n",
      "Epoka 6540: Loss = 0.008180843\n",
      "Epoka 6550: Loss = 0.008150000\n",
      "Epoka 6560: Loss = 0.008228464\n",
      "Epoka 6570: Loss = 0.008207991\n",
      "Epoka 6580: Loss = 0.008246071\n",
      "Epoka 6590: Loss = 0.008156734\n",
      "Epoka 6600: Loss = 0.008091859\n",
      "Epoka 6610: Loss = 0.008206776\n",
      "Epoka 6620: Loss = 0.008007274\n",
      "Epoka 6630: Loss = 0.008039802\n",
      "Epoka 6640: Loss = 0.007952960\n",
      "Epoka 6650: Loss = 0.007933689\n",
      "Epoka 6660: Loss = 0.007927941\n",
      "Epoka 6670: Loss = 0.007920541\n",
      "Epoka 6680: Loss = 0.007991863\n",
      "Epoka 6690: Loss = 0.007860532\n",
      "Epoka 6700: Loss = 0.007838108\n",
      "Epoka 6710: Loss = 0.007841307\n",
      "Epoka 6720: Loss = 0.007786648\n",
      "Epoka 6730: Loss = 0.007774945\n",
      "Epoka 6740: Loss = 0.007828880\n",
      "Epoka 6750: Loss = 0.007754682\n",
      "Epoka 6760: Loss = 0.007710750\n",
      "Epoka 6770: Loss = 0.007730398\n",
      "Epoka 6780: Loss = 0.007705889\n",
      "Epoka 6790: Loss = 0.007648446\n",
      "Epoka 6800: Loss = 0.007624521\n",
      "Epoka 6810: Loss = 0.007654723\n",
      "Epoka 6820: Loss = 0.007582467\n",
      "Epoka 6830: Loss = 0.007607167\n",
      "Epoka 6840: Loss = 0.007555619\n",
      "Epoka 6850: Loss = 0.007610510\n",
      "Epoka 6860: Loss = 0.007585652\n",
      "Epoka 6870: Loss = 0.007499285\n",
      "Epoka 6880: Loss = 0.007490373\n",
      "Epoka 6890: Loss = 0.007539287\n",
      "Epoka 6900: Loss = 0.007419695\n",
      "Epoka 6910: Loss = 0.007408414\n",
      "Epoka 6920: Loss = 0.007402011\n",
      "Epoka 6930: Loss = 0.007385613\n",
      "Epoka 6940: Loss = 0.007429000\n",
      "Epoka 6950: Loss = 0.007353506\n",
      "Epoka 6960: Loss = 0.007303142\n",
      "Epoka 6970: Loss = 0.007316287\n",
      "Epoka 6980: Loss = 0.007324448\n",
      "Epoka 6990: Loss = 0.007244332\n",
      "Epoka 7000: Loss = 0.007228506\n",
      "Epoka 7010: Loss = 0.007283417\n",
      "Epoka 7020: Loss = 0.007226537\n",
      "Epoka 7030: Loss = 0.007181047\n",
      "Epoka 7040: Loss = 0.007155658\n",
      "Epoka 7050: Loss = 0.007272962\n",
      "Epoka 7060: Loss = 0.007122658\n",
      "Epoka 7070: Loss = 0.007126168\n",
      "Epoka 7080: Loss = 0.007084418\n",
      "Epoka 7090: Loss = 0.007074420\n",
      "Epoka 7100: Loss = 0.007206953\n",
      "Epoka 7110: Loss = 0.007014802\n",
      "Epoka 7120: Loss = 0.007117640\n",
      "Epoka 7130: Loss = 0.006977694\n",
      "Epoka 7140: Loss = 0.007003156\n",
      "Epoka 7150: Loss = 0.006933888\n",
      "Epoka 7160: Loss = 0.006945538\n",
      "Epoka 7170: Loss = 0.006907968\n",
      "Epoka 7180: Loss = 0.006949031\n",
      "Epoka 7190: Loss = 0.006866382\n",
      "Epoka 7200: Loss = 0.006885572\n",
      "Epoka 7210: Loss = 0.006845047\n",
      "Epoka 7220: Loss = 0.006810386\n",
      "Epoka 7230: Loss = 0.006799329\n",
      "Epoka 7240: Loss = 0.006872358\n",
      "Epoka 7250: Loss = 0.006752699\n",
      "Epoka 7260: Loss = 0.006738324\n",
      "Epoka 7270: Loss = 0.006719721\n",
      "Epoka 7280: Loss = 0.006705116\n",
      "Epoka 7290: Loss = 0.006676531\n",
      "Epoka 7300: Loss = 0.006687129\n",
      "Epoka 7310: Loss = 0.006634221\n",
      "Epoka 7320: Loss = 0.006653936\n",
      "Epoka 7330: Loss = 0.006596488\n",
      "Epoka 7340: Loss = 0.006616928\n",
      "Epoka 7350: Loss = 0.006606325\n",
      "Epoka 7360: Loss = 0.006568173\n",
      "Epoka 7370: Loss = 0.006536652\n",
      "Epoka 7380: Loss = 0.006523960\n",
      "Epoka 7390: Loss = 0.006548407\n",
      "Epoka 7400: Loss = 0.006505238\n",
      "Epoka 7410: Loss = 0.006543024\n",
      "Epoka 7420: Loss = 0.006584972\n",
      "Epoka 7430: Loss = 0.006518028\n",
      "Epoka 7440: Loss = 0.006413845\n",
      "Epoka 7450: Loss = 0.006403690\n",
      "Epoka 7460: Loss = 0.006441707\n",
      "Epoka 7470: Loss = 0.006350983\n",
      "Epoka 7480: Loss = 0.006340712\n",
      "Epoka 7490: Loss = 0.006486193\n",
      "Epoka 7500: Loss = 0.006399403\n",
      "Epoka 7510: Loss = 0.006282715\n",
      "Epoka 7520: Loss = 0.006400187\n",
      "Epoka 7530: Loss = 0.006432435\n",
      "Epoka 7540: Loss = 0.006267394\n",
      "Epoka 7550: Loss = 0.006295635\n",
      "Epoka 7560: Loss = 0.006204511\n",
      "Epoka 7570: Loss = 0.006206290\n",
      "Epoka 7580: Loss = 0.006171852\n",
      "Epoka 7590: Loss = 0.006177534\n",
      "Epoka 7600: Loss = 0.006137334\n",
      "Epoka 7610: Loss = 0.006123602\n",
      "Epoka 7620: Loss = 0.006270782\n",
      "Epoka 7630: Loss = 0.006127292\n",
      "Epoka 7640: Loss = 0.006079863\n",
      "Epoka 7650: Loss = 0.006064409\n",
      "Epoka 7660: Loss = 0.006057172\n",
      "Epoka 7670: Loss = 0.006052653\n",
      "Epoka 7680: Loss = 0.006019842\n",
      "Epoka 7690: Loss = 0.006037243\n",
      "Epoka 7700: Loss = 0.006007736\n",
      "Epoka 7710: Loss = 0.006055394\n",
      "Epoka 7720: Loss = 0.005946122\n",
      "Epoka 7730: Loss = 0.005996218\n",
      "Epoka 7740: Loss = 0.005940329\n",
      "Epoka 7750: Loss = 0.005918220\n",
      "Epoka 7760: Loss = 0.005912605\n",
      "Epoka 7770: Loss = 0.005872753\n",
      "Epoka 7780: Loss = 0.005843448\n",
      "Epoka 7790: Loss = 0.005830158\n",
      "Epoka 7800: Loss = 0.005833078\n",
      "Epoka 7810: Loss = 0.005825285\n",
      "Epoka 7820: Loss = 0.005796029\n",
      "Epoka 7830: Loss = 0.005824483\n",
      "Epoka 7840: Loss = 0.005806579\n",
      "Epoka 7850: Loss = 0.005764333\n",
      "Epoka 7860: Loss = 0.005829263\n",
      "Epoka 7870: Loss = 0.005718767\n",
      "Epoka 7880: Loss = 0.006028886\n",
      "Epoka 7890: Loss = 0.005693090\n",
      "Epoka 7900: Loss = 0.005706576\n",
      "Epoka 7910: Loss = 0.005652588\n",
      "Epoka 7920: Loss = 0.005648086\n",
      "Epoka 7930: Loss = 0.005693494\n",
      "Epoka 7940: Loss = 0.005690929\n",
      "Epoka 7950: Loss = 0.005612631\n",
      "Epoka 7960: Loss = 0.005655133\n",
      "Epoka 7970: Loss = 0.005600551\n",
      "Epoka 7980: Loss = 0.005554677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 7990: Loss = 0.005547607\n",
      "Epoka 8000: Loss = 0.005555841\n",
      "Epoka 8010: Loss = 0.005525317\n",
      "Epoka 8020: Loss = 0.005510489\n",
      "Epoka 8030: Loss = 0.005491927\n",
      "Epoka 8040: Loss = 0.005510708\n",
      "Epoka 8050: Loss = 0.005479065\n",
      "Epoka 8060: Loss = 0.005473540\n",
      "Epoka 8070: Loss = 0.005449720\n",
      "Epoka 8080: Loss = 0.005464004\n",
      "Epoka 8090: Loss = 0.005425877\n",
      "Epoka 8100: Loss = 0.005456617\n",
      "Epoka 8110: Loss = 0.005402304\n",
      "Epoka 8120: Loss = 0.005423303\n",
      "Epoka 8130: Loss = 0.005369783\n",
      "Epoka 8140: Loss = 0.005381816\n",
      "Epoka 8150: Loss = 0.005337077\n",
      "Epoka 8160: Loss = 0.005407952\n",
      "Epoka 8170: Loss = 0.005341974\n",
      "Epoka 8180: Loss = 0.005309804\n",
      "Epoka 8190: Loss = 0.005315724\n",
      "Epoka 8200: Loss = 0.005352224\n",
      "Epoka 8210: Loss = 0.005271537\n",
      "Epoka 8220: Loss = 0.005270656\n",
      "Epoka 8230: Loss = 0.005239038\n",
      "Epoka 8240: Loss = 0.005258378\n",
      "Epoka 8250: Loss = 0.005214073\n",
      "Epoka 8260: Loss = 0.005203598\n",
      "Epoka 8270: Loss = 0.005450241\n",
      "Epoka 8280: Loss = 0.005189852\n",
      "Epoka 8290: Loss = 0.005210249\n",
      "Epoka 8300: Loss = 0.005160944\n",
      "Epoka 8310: Loss = 0.005160804\n",
      "Epoka 8320: Loss = 0.005151833\n",
      "Epoka 8330: Loss = 0.005146520\n",
      "Epoka 8340: Loss = 0.005110083\n",
      "Epoka 8350: Loss = 0.005097182\n",
      "Epoka 8360: Loss = 0.005128286\n",
      "Epoka 8370: Loss = 0.005073143\n",
      "Epoka 8380: Loss = 0.005095028\n",
      "Epoka 8390: Loss = 0.005060902\n",
      "Epoka 8400: Loss = 0.005046270\n",
      "Epoka 8410: Loss = 0.005034404\n",
      "Epoka 8420: Loss = 0.005027920\n",
      "Epoka 8430: Loss = 0.005017238\n",
      "Epoka 8440: Loss = 0.004999887\n",
      "Epoka 8450: Loss = 0.005008121\n",
      "Epoka 8460: Loss = 0.004992951\n",
      "Epoka 8470: Loss = 0.004994796\n",
      "Epoka 8480: Loss = 0.004982037\n",
      "Epoka 8490: Loss = 0.005007678\n",
      "Epoka 8500: Loss = 0.004993962\n",
      "Epoka 8510: Loss = 0.004948871\n",
      "Epoka 8520: Loss = 0.004915000\n",
      "Epoka 8530: Loss = 0.004928365\n",
      "Epoka 8540: Loss = 0.004918940\n",
      "Epoka 8550: Loss = 0.004899061\n",
      "Epoka 8560: Loss = 0.004911363\n",
      "Epoka 8570: Loss = 0.004912207\n",
      "Epoka 8580: Loss = 0.004862789\n",
      "Epoka 8590: Loss = 0.004847446\n",
      "Epoka 8600: Loss = 0.004868721\n",
      "Epoka 8610: Loss = 0.004854461\n",
      "Epoka 8620: Loss = 0.004860261\n",
      "Epoka 8630: Loss = 0.004979440\n",
      "Epoka 8640: Loss = 0.004839427\n",
      "Epoka 8650: Loss = 0.004804933\n",
      "Epoka 8660: Loss = 0.004796652\n",
      "Epoka 8670: Loss = 0.004779513\n",
      "Epoka 8680: Loss = 0.004781846\n",
      "Epoka 8690: Loss = 0.004742210\n",
      "Epoka 8700: Loss = 0.004752465\n",
      "Epoka 8710: Loss = 0.004729280\n",
      "Epoka 8720: Loss = 0.004716364\n",
      "Epoka 8730: Loss = 0.004708673\n",
      "Epoka 8740: Loss = 0.004710373\n",
      "Epoka 8750: Loss = 0.004693643\n",
      "Epoka 8760: Loss = 0.004673860\n",
      "Epoka 8770: Loss = 0.004752712\n",
      "Epoka 8780: Loss = 0.004676067\n",
      "Epoka 8790: Loss = 0.004740571\n",
      "Epoka 8800: Loss = 0.004735998\n",
      "Epoka 8810: Loss = 0.004678109\n",
      "Epoka 8820: Loss = 0.004645922\n",
      "Epoka 8830: Loss = 0.004637145\n",
      "Epoka 8840: Loss = 0.004628649\n",
      "Epoka 8850: Loss = 0.004674232\n",
      "Epoka 8860: Loss = 0.004642525\n",
      "Epoka 8870: Loss = 0.004599852\n",
      "Epoka 8880: Loss = 0.004594758\n",
      "Epoka 8890: Loss = 0.004567379\n",
      "Epoka 8900: Loss = 0.004604259\n",
      "Epoka 8910: Loss = 0.004565792\n",
      "Epoka 8920: Loss = 0.004558585\n",
      "Epoka 8930: Loss = 0.004519670\n",
      "Epoka 8940: Loss = 0.004511073\n",
      "Epoka 8950: Loss = 0.004522495\n",
      "Epoka 8960: Loss = 0.004572438\n",
      "Epoka 8970: Loss = 0.004490688\n",
      "Epoka 8980: Loss = 0.004486075\n",
      "Epoka 8990: Loss = 0.004477219\n",
      "Epoka 9000: Loss = 0.004499010\n",
      "Epoka 9010: Loss = 0.004513461\n",
      "Epoka 9020: Loss = 0.004443857\n",
      "Epoka 9030: Loss = 0.004440205\n",
      "Epoka 9040: Loss = 0.004424137\n",
      "Epoka 9050: Loss = 0.004418085\n",
      "Epoka 9060: Loss = 0.004436631\n",
      "Epoka 9070: Loss = 0.004405808\n",
      "Epoka 9080: Loss = 0.004384431\n",
      "Epoka 9090: Loss = 0.004423591\n",
      "Epoka 9100: Loss = 0.004366316\n",
      "Epoka 9110: Loss = 0.004421568\n",
      "Epoka 9120: Loss = 0.004359590\n",
      "Epoka 9130: Loss = 0.004345492\n",
      "Epoka 9140: Loss = 0.004355629\n",
      "Epoka 9150: Loss = 0.004327859\n",
      "Epoka 9160: Loss = 0.004325728\n",
      "Epoka 9170: Loss = 0.004327236\n",
      "Epoka 9180: Loss = 0.004362703\n",
      "Epoka 9190: Loss = 0.004290274\n",
      "Epoka 9200: Loss = 0.004310011\n",
      "Epoka 9210: Loss = 0.004310519\n",
      "Epoka 9220: Loss = 0.004273628\n",
      "Epoka 9230: Loss = 0.004270506\n",
      "Epoka 9240: Loss = 0.004240631\n",
      "Epoka 9250: Loss = 0.004251054\n",
      "Epoka 9260: Loss = 0.004222693\n",
      "Epoka 9270: Loss = 0.004234201\n",
      "Epoka 9280: Loss = 0.004263566\n",
      "Epoka 9290: Loss = 0.004211796\n",
      "Epoka 9300: Loss = 0.004215870\n",
      "Epoka 9310: Loss = 0.004179875\n",
      "Epoka 9320: Loss = 0.004181935\n",
      "Epoka 9330: Loss = 0.004181833\n",
      "Epoka 9340: Loss = 0.004173801\n",
      "Epoka 9350: Loss = 0.004158446\n",
      "Epoka 9360: Loss = 0.004137512\n",
      "Epoka 9370: Loss = 0.004150380\n",
      "Epoka 9380: Loss = 0.004103373\n",
      "Epoka 9390: Loss = 0.004093992\n",
      "Epoka 9400: Loss = 0.004116379\n",
      "Epoka 9410: Loss = 0.004090034\n",
      "Epoka 9420: Loss = 0.004091357\n",
      "Epoka 9430: Loss = 0.004102001\n",
      "Epoka 9440: Loss = 0.004084697\n",
      "Epoka 9450: Loss = 0.004045190\n",
      "Epoka 9460: Loss = 0.004075480\n",
      "Epoka 9470: Loss = 0.004024670\n",
      "Epoka 9480: Loss = 0.003998516\n",
      "Epoka 9490: Loss = 0.003974761\n",
      "Epoka 9500: Loss = 0.003974658\n",
      "Epoka 9510: Loss = 0.003969900\n",
      "Epoka 9520: Loss = 0.003930508\n",
      "Epoka 9530: Loss = 0.003909540\n",
      "Epoka 9540: Loss = 0.003936593\n",
      "Epoka 9550: Loss = 0.003905721\n",
      "Epoka 9560: Loss = 0.003868706\n",
      "Epoka 9570: Loss = 0.003893596\n",
      "Epoka 9580: Loss = 0.003849681\n",
      "Epoka 9590: Loss = 0.003825521\n",
      "Epoka 9600: Loss = 0.003816314\n",
      "Epoka 9610: Loss = 0.003813273\n",
      "Epoka 9620: Loss = 0.003783231\n",
      "Epoka 9630: Loss = 0.003796452\n",
      "Epoka 9640: Loss = 0.003759600\n",
      "Epoka 9650: Loss = 0.003797911\n",
      "Epoka 9660: Loss = 0.003743768\n",
      "Epoka 9670: Loss = 0.003709441\n",
      "Epoka 9680: Loss = 0.003687641\n",
      "Epoka 9690: Loss = 0.003715912\n",
      "Epoka 9700: Loss = 0.003682881\n",
      "Epoka 9710: Loss = 0.003696808\n",
      "Epoka 9720: Loss = 0.003640171\n",
      "Epoka 9730: Loss = 0.003722999\n",
      "Epoka 9740: Loss = 0.003622560\n",
      "Epoka 9750: Loss = 0.003654261\n",
      "Epoka 9760: Loss = 0.003657846\n",
      "Epoka 9770: Loss = 0.003568722\n",
      "Epoka 9780: Loss = 0.003557505\n",
      "Epoka 9790: Loss = 0.003559083\n",
      "Epoka 9800: Loss = 0.003526750\n",
      "Epoka 9810: Loss = 0.003524166\n",
      "Epoka 9820: Loss = 0.003509652\n",
      "Epoka 9830: Loss = 0.003501246\n",
      "Epoka 9840: Loss = 0.003540379\n",
      "Epoka 9850: Loss = 0.003485355\n",
      "Epoka 9860: Loss = 0.003460446\n",
      "Epoka 9870: Loss = 0.003454820\n",
      "Epoka 9880: Loss = 0.003436714\n",
      "Epoka 9890: Loss = 0.003442673\n",
      "Epoka 9900: Loss = 0.003428523\n",
      "Epoka 9910: Loss = 0.003425483\n",
      "Epoka 9920: Loss = 0.003394906\n",
      "Epoka 9930: Loss = 0.003387064\n",
      "Epoka 9940: Loss = 0.003407046\n",
      "Epoka 9950: Loss = 0.003391338\n",
      "Epoka 9960: Loss = 0.003370691\n",
      "Epoka 9970: Loss = 0.003370392\n",
      "Epoka 9980: Loss = 0.003335490\n",
      "Epoka 9990: Loss = 0.003328126\n",
      "Epoka 10000: Loss = 0.003380624\n",
      "Epoka 10010: Loss = 0.003316890\n",
      "Epoka 10020: Loss = 0.003301075\n",
      "Epoka 10030: Loss = 0.003292478\n",
      "Epoka 10040: Loss = 0.003310260\n",
      "Epoka 10050: Loss = 0.003317147\n",
      "Epoka 10060: Loss = 0.003269097\n",
      "Epoka 10070: Loss = 0.003259703\n",
      "Epoka 10080: Loss = 0.003270118\n",
      "Epoka 10090: Loss = 0.003254957\n",
      "Epoka 10100: Loss = 0.003278445\n",
      "Epoka 10110: Loss = 0.003247839\n",
      "Epoka 10120: Loss = 0.003233799\n",
      "Epoka 10130: Loss = 0.003231830\n",
      "Epoka 10140: Loss = 0.003204573\n",
      "Epoka 10150: Loss = 0.003205082\n",
      "Epoka 10160: Loss = 0.003301941\n",
      "Epoka 10170: Loss = 0.003193490\n",
      "Epoka 10180: Loss = 0.003226319\n",
      "Epoka 10190: Loss = 0.003173753\n",
      "Epoka 10200: Loss = 0.003194292\n",
      "Epoka 10210: Loss = 0.003159172\n",
      "Epoka 10220: Loss = 0.003159732\n",
      "Epoka 10230: Loss = 0.003188181\n",
      "Epoka 10240: Loss = 0.003164409\n",
      "Epoka 10250: Loss = 0.003154281\n",
      "Epoka 10260: Loss = 0.003137551\n",
      "Epoka 10270: Loss = 0.003119530\n",
      "Epoka 10280: Loss = 0.003162568\n",
      "Epoka 10290: Loss = 0.003134227\n",
      "Epoka 10300: Loss = 0.003114694\n",
      "Epoka 10310: Loss = 0.003098537\n",
      "Epoka 10320: Loss = 0.003121282\n",
      "Epoka 10330: Loss = 0.003091612\n",
      "Epoka 10340: Loss = 0.003131490\n",
      "Epoka 10350: Loss = 0.003101753\n",
      "Epoka 10360: Loss = 0.003100894\n",
      "Epoka 10370: Loss = 0.003117251\n",
      "Epoka 10380: Loss = 0.003053071\n",
      "Epoka 10390: Loss = 0.003046685\n",
      "Epoka 10400: Loss = 0.003102377\n",
      "Epoka 10410: Loss = 0.003095903\n",
      "Epoka 10420: Loss = 0.003030545\n",
      "Epoka 10430: Loss = 0.003047882\n",
      "Epoka 10440: Loss = 0.003017124\n",
      "Epoka 10450: Loss = 0.003018090\n",
      "Epoka 10460: Loss = 0.003091966\n",
      "Epoka 10470: Loss = 0.003011687\n",
      "Epoka 10480: Loss = 0.003015761\n",
      "Epoka 10490: Loss = 0.003011270\n",
      "Epoka 10500: Loss = 0.003000384\n",
      "Epoka 10510: Loss = 0.002980843\n",
      "Epoka 10520: Loss = 0.002973099\n",
      "Epoka 10530: Loss = 0.002974210\n",
      "Epoka 10540: Loss = 0.002962059\n",
      "Epoka 10550: Loss = 0.002973438\n",
      "Epoka 10560: Loss = 0.002965071\n",
      "Epoka 10570: Loss = 0.002960486\n",
      "Epoka 10580: Loss = 0.002959099\n",
      "Epoka 10590: Loss = 0.002941815\n",
      "Epoka 10600: Loss = 0.002968590\n",
      "Epoka 10610: Loss = 0.002954371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 10620: Loss = 0.002931693\n",
      "Epoka 10630: Loss = 0.002936784\n",
      "Epoka 10640: Loss = 0.002920807\n",
      "Epoka 10650: Loss = 0.002918487\n",
      "Epoka 10660: Loss = 0.002916304\n",
      "Epoka 10670: Loss = 0.002895753\n",
      "Epoka 10680: Loss = 0.002965729\n",
      "Epoka 10690: Loss = 0.002914660\n",
      "Epoka 10700: Loss = 0.002931005\n",
      "Epoka 10710: Loss = 0.002895880\n",
      "Epoka 10720: Loss = 0.002915094\n",
      "Epoka 10730: Loss = 0.002876250\n",
      "Epoka 10740: Loss = 0.002872325\n",
      "Epoka 10750: Loss = 0.002860157\n",
      "Epoka 10760: Loss = 0.002914154\n",
      "Epoka 10770: Loss = 0.002901303\n",
      "Epoka 10780: Loss = 0.002851874\n",
      "Epoka 10790: Loss = 0.002842968\n",
      "Epoka 10800: Loss = 0.002835060\n",
      "Epoka 10810: Loss = 0.002851745\n",
      "Epoka 10820: Loss = 0.002865476\n",
      "Epoka 10830: Loss = 0.002871519\n",
      "Epoka 10840: Loss = 0.002841323\n",
      "Epoka 10850: Loss = 0.002849187\n",
      "Epoka 10860: Loss = 0.002836822\n",
      "Epoka 10870: Loss = 0.002818823\n",
      "Epoka 10880: Loss = 0.002837305\n",
      "Epoka 10890: Loss = 0.002809382\n",
      "Epoka 10900: Loss = 0.002811187\n",
      "Epoka 10910: Loss = 0.002802322\n",
      "Epoka 10920: Loss = 0.002794038\n",
      "Epoka 10930: Loss = 0.002801283\n",
      "Epoka 10940: Loss = 0.002786285\n",
      "Epoka 10950: Loss = 0.002784428\n",
      "Epoka 10960: Loss = 0.002826906\n",
      "Epoka 10970: Loss = 0.002764073\n",
      "Epoka 10980: Loss = 0.002763322\n",
      "Epoka 10990: Loss = 0.002765708\n",
      "Epoka 11000: Loss = 0.002775166\n",
      "Epoka 11010: Loss = 0.002760053\n",
      "Epoka 11020: Loss = 0.002808052\n",
      "Epoka 11030: Loss = 0.002743376\n",
      "Epoka 11040: Loss = 0.002749254\n",
      "Epoka 11050: Loss = 0.002758679\n",
      "Epoka 11060: Loss = 0.002737038\n",
      "Epoka 11070: Loss = 0.002731581\n",
      "Epoka 11080: Loss = 0.002760913\n",
      "Epoka 11090: Loss = 0.002780831\n",
      "Epoka 11100: Loss = 0.002722054\n",
      "Epoka 11110: Loss = 0.002709561\n",
      "Epoka 11120: Loss = 0.002721845\n",
      "Epoka 11130: Loss = 0.002712551\n",
      "Epoka 11140: Loss = 0.002712197\n",
      "Epoka 11150: Loss = 0.002726592\n",
      "Epoka 11160: Loss = 0.002697131\n",
      "Epoka 11170: Loss = 0.002704850\n",
      "Epoka 11180: Loss = 0.002701396\n",
      "Epoka 11190: Loss = 0.002701315\n",
      "Epoka 11200: Loss = 0.002680495\n",
      "Epoka 11210: Loss = 0.002687520\n",
      "Epoka 11220: Loss = 0.002720481\n",
      "Epoka 11230: Loss = 0.002690675\n",
      "Epoka 11240: Loss = 0.002661477\n",
      "Epoka 11250: Loss = 0.002713683\n",
      "Epoka 11260: Loss = 0.002677930\n",
      "Epoka 11270: Loss = 0.002687151\n",
      "Epoka 11280: Loss = 0.002652967\n",
      "Epoka 11290: Loss = 0.002653681\n",
      "Epoka 11300: Loss = 0.002658665\n",
      "Epoka 11310: Loss = 0.002648326\n",
      "Epoka 11320: Loss = 0.002636451\n",
      "Epoka 11330: Loss = 0.002637684\n",
      "Epoka 11340: Loss = 0.002628659\n",
      "Epoka 11350: Loss = 0.002639939\n",
      "Epoka 11360: Loss = 0.002642686\n",
      "Epoka 11370: Loss = 0.002619637\n",
      "Epoka 11380: Loss = 0.002672404\n",
      "Epoka 11390: Loss = 0.002615971\n",
      "Epoka 11400: Loss = 0.002621979\n",
      "Epoka 11410: Loss = 0.002638961\n",
      "Epoka 11420: Loss = 0.002622309\n",
      "Epoka 11430: Loss = 0.002655390\n",
      "Epoka 11440: Loss = 0.002595323\n",
      "Epoka 11450: Loss = 0.002602482\n",
      "Epoka 11460: Loss = 0.002614863\n",
      "Epoka 11470: Loss = 0.002591506\n",
      "Epoka 11480: Loss = 0.002592173\n",
      "Epoka 11490: Loss = 0.002580410\n",
      "Epoka 11500: Loss = 0.002590584\n",
      "Epoka 11510: Loss = 0.002607578\n",
      "Epoka 11520: Loss = 0.002579056\n",
      "Epoka 11530: Loss = 0.002567974\n",
      "Epoka 11540: Loss = 0.002621087\n",
      "Epoka 11550: Loss = 0.002570911\n",
      "Epoka 11560: Loss = 0.002570588\n",
      "Epoka 11570: Loss = 0.002561089\n",
      "Epoka 11580: Loss = 0.002563319\n",
      "Epoka 11590: Loss = 0.002585933\n",
      "Epoka 11600: Loss = 0.002567881\n",
      "Epoka 11610: Loss = 0.002550152\n",
      "Epoka 11620: Loss = 0.002542578\n",
      "Epoka 11630: Loss = 0.002538078\n",
      "Epoka 11640: Loss = 0.002549862\n",
      "Epoka 11650: Loss = 0.002573918\n",
      "Epoka 11660: Loss = 0.002527383\n",
      "Epoka 11670: Loss = 0.002537257\n",
      "Epoka 11680: Loss = 0.002537791\n",
      "Epoka 11690: Loss = 0.002520751\n",
      "Epoka 11700: Loss = 0.002556822\n",
      "Epoka 11710: Loss = 0.002524314\n",
      "Epoka 11720: Loss = 0.002517828\n",
      "Epoka 11730: Loss = 0.002523729\n",
      "Epoka 11740: Loss = 0.002509232\n",
      "Epoka 11750: Loss = 0.002533650\n",
      "Epoka 11760: Loss = 0.002516773\n",
      "Epoka 11770: Loss = 0.002522955\n",
      "Epoka 11780: Loss = 0.002522543\n",
      "Epoka 11790: Loss = 0.002513651\n",
      "Epoka 11800: Loss = 0.002495164\n",
      "Epoka 11810: Loss = 0.002501389\n",
      "Epoka 11820: Loss = 0.002496681\n",
      "Epoka 11830: Loss = 0.002507045\n",
      "Epoka 11840: Loss = 0.002498504\n",
      "Epoka 11850: Loss = 0.002507588\n",
      "Epoka 11860: Loss = 0.002474255\n",
      "Epoka 11870: Loss = 0.002474542\n",
      "Epoka 11880: Loss = 0.002486548\n",
      "Epoka 11890: Loss = 0.002470876\n",
      "Epoka 11900: Loss = 0.002483681\n",
      "Epoka 11910: Loss = 0.002463791\n",
      "Epoka 11920: Loss = 0.002472866\n",
      "Epoka 11930: Loss = 0.002460552\n",
      "Epoka 11940: Loss = 0.002459124\n",
      "Epoka 11950: Loss = 0.002473450\n",
      "Epoka 11960: Loss = 0.002462673\n",
      "Epoka 11970: Loss = 0.002453396\n",
      "Epoka 11980: Loss = 0.002445394\n",
      "Epoka 11990: Loss = 0.002443192\n",
      "Epoka 12000: Loss = 0.002449351\n",
      "Epoka 12010: Loss = 0.002437889\n",
      "Epoka 12020: Loss = 0.002465327\n",
      "Epoka 12030: Loss = 0.002447171\n",
      "Epoka 12040: Loss = 0.002433064\n",
      "Epoka 12050: Loss = 0.002467830\n",
      "Epoka 12060: Loss = 0.002448282\n",
      "Epoka 12070: Loss = 0.002430096\n",
      "Epoka 12080: Loss = 0.002466393\n",
      "Epoka 12090: Loss = 0.002423005\n",
      "Epoka 12100: Loss = 0.002465641\n",
      "Epoka 12110: Loss = 0.002447502\n",
      "Epoka 12120: Loss = 0.002415250\n",
      "Epoka 12130: Loss = 0.002408028\n",
      "Epoka 12140: Loss = 0.002433187\n",
      "Epoka 12150: Loss = 0.002402419\n",
      "Epoka 12160: Loss = 0.002400521\n",
      "Epoka 12170: Loss = 0.002404345\n",
      "Epoka 12180: Loss = 0.002404135\n",
      "Epoka 12190: Loss = 0.002394737\n",
      "Epoka 12200: Loss = 0.002412161\n",
      "Epoka 12210: Loss = 0.002389912\n",
      "Epoka 12220: Loss = 0.002391261\n",
      "Epoka 12230: Loss = 0.002404412\n",
      "Epoka 12240: Loss = 0.002391454\n",
      "Epoka 12250: Loss = 0.002391255\n",
      "Epoka 12260: Loss = 0.002428705\n",
      "Epoka 12270: Loss = 0.002396297\n",
      "Epoka 12280: Loss = 0.002381924\n",
      "Epoka 12290: Loss = 0.002376687\n",
      "Epoka 12300: Loss = 0.002372174\n",
      "Epoka 12310: Loss = 0.002372722\n",
      "Epoka 12320: Loss = 0.002380885\n",
      "Epoka 12330: Loss = 0.002380495\n",
      "Epoka 12340: Loss = 0.002386860\n",
      "Epoka 12350: Loss = 0.002364604\n",
      "Epoka 12360: Loss = 0.002357908\n",
      "Epoka 12370: Loss = 0.002362720\n",
      "Epoka 12380: Loss = 0.002379270\n",
      "Epoka 12390: Loss = 0.002361616\n",
      "Epoka 12400: Loss = 0.002357250\n",
      "Epoka 12410: Loss = 0.002346280\n",
      "Epoka 12420: Loss = 0.002348269\n",
      "Epoka 12430: Loss = 0.002345411\n",
      "Epoka 12440: Loss = 0.002351883\n",
      "Epoka 12450: Loss = 0.002356834\n",
      "Epoka 12460: Loss = 0.002349148\n",
      "Epoka 12470: Loss = 0.002393996\n",
      "Epoka 12480: Loss = 0.002338246\n",
      "Epoka 12490: Loss = 0.002342480\n",
      "Epoka 12500: Loss = 0.002339373\n",
      "Epoka 12510: Loss = 0.002329809\n",
      "Epoka 12520: Loss = 0.002402548\n",
      "Epoka 12530: Loss = 0.002327136\n",
      "Epoka 12540: Loss = 0.002326662\n",
      "Epoka 12550: Loss = 0.002320302\n",
      "Epoka 12560: Loss = 0.002331201\n",
      "Epoka 12570: Loss = 0.002340651\n",
      "Epoka 12580: Loss = 0.002332739\n",
      "Epoka 12590: Loss = 0.002373728\n",
      "Epoka 12600: Loss = 0.002309715\n",
      "Epoka 12610: Loss = 0.002319861\n",
      "Epoka 12620: Loss = 0.002318538\n",
      "Epoka 12630: Loss = 0.002302738\n",
      "Epoka 12640: Loss = 0.002312109\n",
      "Epoka 12650: Loss = 0.002313316\n",
      "Epoka 12660: Loss = 0.002303970\n",
      "Epoka 12670: Loss = 0.002313867\n",
      "Epoka 12680: Loss = 0.002296042\n",
      "Epoka 12690: Loss = 0.002302985\n",
      "Epoka 12700: Loss = 0.002304210\n",
      "Epoka 12710: Loss = 0.002308158\n",
      "Epoka 12720: Loss = 0.002298901\n",
      "Epoka 12730: Loss = 0.002341929\n",
      "Epoka 12740: Loss = 0.002328899\n",
      "Epoka 12750: Loss = 0.002290541\n",
      "Epoka 12760: Loss = 0.002282463\n",
      "Epoka 12770: Loss = 0.002289983\n",
      "Epoka 12780: Loss = 0.002288774\n",
      "Epoka 12790: Loss = 0.002276523\n",
      "Epoka 12800: Loss = 0.002301322\n",
      "Epoka 12810: Loss = 0.002280895\n",
      "Epoka 12820: Loss = 0.002273047\n",
      "Epoka 12830: Loss = 0.002278714\n",
      "Epoka 12840: Loss = 0.002271262\n",
      "Epoka 12850: Loss = 0.002303301\n",
      "Epoka 12860: Loss = 0.002284019\n",
      "Epoka 12870: Loss = 0.002292022\n",
      "Epoka 12880: Loss = 0.002268197\n",
      "Epoka 12890: Loss = 0.002286398\n",
      "Epoka 12900: Loss = 0.002259801\n",
      "Epoka 12910: Loss = 0.002263347\n",
      "Epoka 12920: Loss = 0.002272032\n",
      "Epoka 12930: Loss = 0.002255767\n",
      "Epoka 12940: Loss = 0.002279992\n",
      "Epoka 12950: Loss = 0.002263403\n",
      "Epoka 12960: Loss = 0.002258632\n",
      "Epoka 12970: Loss = 0.002253033\n",
      "Epoka 12980: Loss = 0.002296888\n",
      "Epoka 12990: Loss = 0.002246070\n",
      "Czas wykonania: 266.124675 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_multimodalL = MLPNoBackprop(layer_sizes = [1, 26, 1], hidden_activation='tanh')\n",
    "start_time = time.time()\n",
    "mlp_multimodalL.momentum(X_multimodalL_train_normalized, Y_multimodalL_train_normalized, batch_size = 64, epochs=13000, learning_rate=0.001, Lambda=0.9)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "38d27707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.006999112315732\n"
     ]
    }
   ],
   "source": [
    "ypred_normalized = mlp_multimodalL.predict(X_multimodalL_test_normalized)\n",
    "ypred = ypred_normalized *np.std(Y_multimodalL_train) +np.mean(Y_multimodalL_train)\n",
    "print(mlp_multimodalL.mse(ypred, Y_multimodalL_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249824a",
   "metadata": {},
   "source": [
    "# RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ab038046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 0.804955008\n",
      "Epoka 10: Loss = 0.452662808\n",
      "Epoka 20: Loss = 0.376357911\n",
      "Epoka 30: Loss = 0.311642682\n",
      "Epoka 40: Loss = 0.288987279\n",
      "Epoka 50: Loss = 0.144267448\n",
      "Epoka 60: Loss = 0.063924578\n",
      "Epoka 70: Loss = 0.072429208\n",
      "Epoka 80: Loss = 0.061552724\n",
      "Epoka 90: Loss = 0.058028732\n",
      "Epoka 100: Loss = 0.057023539\n",
      "Epoka 110: Loss = 0.056425979\n",
      "Epoka 120: Loss = 0.054013323\n",
      "Epoka 130: Loss = 0.059552942\n",
      "Epoka 140: Loss = 0.055351545\n",
      "Epoka 150: Loss = 0.057984379\n",
      "Epoka 160: Loss = 0.052423385\n",
      "Epoka 170: Loss = 0.053173257\n",
      "Epoka 180: Loss = 0.074217168\n",
      "Epoka 190: Loss = 0.061502156\n",
      "Epoka 200: Loss = 0.059682764\n",
      "Epoka 210: Loss = 0.048008648\n",
      "Epoka 220: Loss = 0.046520767\n",
      "Epoka 230: Loss = 0.045111179\n",
      "Epoka 240: Loss = 0.048076525\n",
      "Epoka 250: Loss = 0.046389262\n",
      "Epoka 260: Loss = 0.042653051\n",
      "Epoka 270: Loss = 0.041097445\n",
      "Epoka 280: Loss = 0.042874806\n",
      "Epoka 290: Loss = 0.038670141\n",
      "Epoka 300: Loss = 0.042144805\n",
      "Epoka 310: Loss = 0.042650948\n",
      "Epoka 320: Loss = 0.038263397\n",
      "Epoka 330: Loss = 0.035860645\n",
      "Epoka 340: Loss = 0.039166252\n",
      "Epoka 350: Loss = 0.044587359\n",
      "Epoka 360: Loss = 0.039538448\n",
      "Epoka 370: Loss = 0.030830004\n",
      "Epoka 380: Loss = 0.032648117\n",
      "Epoka 390: Loss = 0.041269029\n",
      "Epoka 400: Loss = 0.033392233\n",
      "Epoka 410: Loss = 0.037227675\n",
      "Epoka 420: Loss = 0.026748839\n",
      "Epoka 430: Loss = 0.027294798\n",
      "Epoka 440: Loss = 0.027382870\n",
      "Epoka 450: Loss = 0.024725620\n",
      "Epoka 460: Loss = 0.024641756\n",
      "Epoka 470: Loss = 0.023414358\n",
      "Epoka 480: Loss = 0.023752464\n",
      "Epoka 490: Loss = 0.022658783\n",
      "Epoka 500: Loss = 0.027519158\n",
      "Epoka 510: Loss = 0.024111683\n",
      "Epoka 520: Loss = 0.021666017\n",
      "Epoka 530: Loss = 0.032142813\n",
      "Epoka 540: Loss = 0.021639363\n",
      "Epoka 550: Loss = 0.021457439\n",
      "Epoka 560: Loss = 0.021931402\n",
      "Epoka 570: Loss = 0.021477522\n",
      "Epoka 580: Loss = 0.020950146\n",
      "Epoka 590: Loss = 0.020295986\n",
      "Epoka 600: Loss = 0.022722778\n",
      "Epoka 610: Loss = 0.028482815\n",
      "Epoka 620: Loss = 0.019400501\n",
      "Epoka 630: Loss = 0.019002429\n",
      "Epoka 640: Loss = 0.018002668\n",
      "Epoka 650: Loss = 0.026412231\n",
      "Epoka 660: Loss = 0.019336969\n",
      "Epoka 670: Loss = 0.022060383\n",
      "Epoka 680: Loss = 0.018887922\n",
      "Epoka 690: Loss = 0.017361448\n",
      "Epoka 700: Loss = 0.025288559\n",
      "Epoka 710: Loss = 0.017615240\n",
      "Epoka 720: Loss = 0.018221105\n",
      "Epoka 730: Loss = 0.019293025\n",
      "Epoka 740: Loss = 0.017843059\n",
      "Epoka 750: Loss = 0.018809222\n",
      "Epoka 760: Loss = 0.016266716\n",
      "Epoka 770: Loss = 0.018307255\n",
      "Epoka 780: Loss = 0.019464338\n",
      "Epoka 790: Loss = 0.019340713\n",
      "Epoka 800: Loss = 0.015973308\n",
      "Epoka 810: Loss = 0.016132670\n",
      "Epoka 820: Loss = 0.021274461\n",
      "Epoka 830: Loss = 0.020530101\n",
      "Epoka 840: Loss = 0.017311844\n",
      "Epoka 850: Loss = 0.015303839\n",
      "Epoka 860: Loss = 0.019440871\n",
      "Epoka 870: Loss = 0.017413337\n",
      "Epoka 880: Loss = 0.014993565\n",
      "Epoka 890: Loss = 0.015264654\n",
      "Epoka 900: Loss = 0.019271757\n",
      "Epoka 910: Loss = 0.015565498\n",
      "Epoka 920: Loss = 0.015432524\n",
      "Epoka 930: Loss = 0.018897347\n",
      "Epoka 940: Loss = 0.018875348\n",
      "Epoka 950: Loss = 0.015347257\n",
      "Epoka 960: Loss = 0.019032306\n",
      "Epoka 970: Loss = 0.015633056\n",
      "Epoka 980: Loss = 0.016186994\n",
      "Epoka 990: Loss = 0.013362907\n",
      "Epoka 1000: Loss = 0.016152531\n",
      "Epoka 1010: Loss = 0.013142944\n",
      "Epoka 1020: Loss = 0.013058118\n",
      "Epoka 1030: Loss = 0.015653604\n",
      "Epoka 1040: Loss = 0.015361298\n",
      "Epoka 1050: Loss = 0.017835521\n",
      "Epoka 1060: Loss = 0.012395511\n",
      "Epoka 1070: Loss = 0.012974268\n",
      "Epoka 1080: Loss = 0.014534673\n",
      "Epoka 1090: Loss = 0.012673501\n",
      "Epoka 1100: Loss = 0.013157680\n",
      "Epoka 1110: Loss = 0.014362045\n",
      "Epoka 1120: Loss = 0.010814870\n",
      "Epoka 1130: Loss = 0.012864212\n",
      "Epoka 1140: Loss = 0.012075373\n",
      "Epoka 1150: Loss = 0.012396489\n",
      "Epoka 1160: Loss = 0.011690492\n",
      "Epoka 1170: Loss = 0.009681913\n",
      "Epoka 1180: Loss = 0.011727157\n",
      "Epoka 1190: Loss = 0.010481033\n",
      "Epoka 1200: Loss = 0.011254356\n",
      "Epoka 1210: Loss = 0.011474982\n",
      "Epoka 1220: Loss = 0.008528678\n",
      "Epoka 1230: Loss = 0.011808816\n",
      "Epoka 1240: Loss = 0.008335707\n",
      "Epoka 1250: Loss = 0.013051347\n",
      "Epoka 1260: Loss = 0.007892421\n",
      "Epoka 1270: Loss = 0.011584205\n",
      "Epoka 1280: Loss = 0.007323380\n",
      "Epoka 1290: Loss = 0.009523486\n",
      "Epoka 1300: Loss = 0.009717944\n",
      "Epoka 1310: Loss = 0.009209931\n",
      "Epoka 1320: Loss = 0.009910566\n",
      "Epoka 1330: Loss = 0.007791693\n",
      "Epoka 1340: Loss = 0.007573202\n",
      "Epoka 1350: Loss = 0.006686703\n",
      "Epoka 1360: Loss = 0.007074363\n",
      "Epoka 1370: Loss = 0.007607437\n",
      "Epoka 1380: Loss = 0.009659534\n",
      "Epoka 1390: Loss = 0.006107878\n",
      "Epoka 1400: Loss = 0.005724639\n",
      "Epoka 1410: Loss = 0.009940993\n",
      "Epoka 1420: Loss = 0.009376314\n",
      "Epoka 1430: Loss = 0.006632097\n",
      "Epoka 1440: Loss = 0.004467070\n",
      "Epoka 1450: Loss = 0.006773876\n",
      "Epoka 1460: Loss = 0.004269440\n",
      "Epoka 1470: Loss = 0.004895147\n",
      "Epoka 1480: Loss = 0.004128482\n",
      "Epoka 1490: Loss = 0.004064788\n",
      "Epoka 1500: Loss = 0.004532528\n",
      "Epoka 1510: Loss = 0.005790857\n",
      "Epoka 1520: Loss = 0.006001037\n",
      "Epoka 1530: Loss = 0.004020909\n",
      "Epoka 1540: Loss = 0.003853664\n",
      "Epoka 1550: Loss = 0.005055027\n",
      "Epoka 1560: Loss = 0.003927012\n",
      "Epoka 1570: Loss = 0.004986388\n",
      "Epoka 1580: Loss = 0.004732985\n",
      "Epoka 1590: Loss = 0.003911802\n",
      "Epoka 1600: Loss = 0.006515742\n",
      "Epoka 1610: Loss = 0.007130580\n",
      "Epoka 1620: Loss = 0.004203085\n",
      "Epoka 1630: Loss = 0.004694266\n",
      "Epoka 1640: Loss = 0.003320638\n",
      "Epoka 1650: Loss = 0.006790891\n",
      "Epoka 1660: Loss = 0.003228882\n",
      "Epoka 1670: Loss = 0.004664350\n",
      "Epoka 1680: Loss = 0.003286511\n",
      "Epoka 1690: Loss = 0.003251550\n",
      "Epoka 1700: Loss = 0.002823690\n",
      "Epoka 1710: Loss = 0.003828505\n",
      "Epoka 1720: Loss = 0.003322287\n",
      "Epoka 1730: Loss = 0.006129164\n",
      "Epoka 1740: Loss = 0.006474849\n",
      "Epoka 1750: Loss = 0.004619061\n",
      "Epoka 1760: Loss = 0.005735269\n",
      "Epoka 1770: Loss = 0.003602700\n",
      "Epoka 1780: Loss = 0.003815056\n",
      "Epoka 1790: Loss = 0.007342123\n",
      "Epoka 1800: Loss = 0.005167954\n",
      "Epoka 1810: Loss = 0.002926281\n",
      "Epoka 1820: Loss = 0.002926922\n",
      "Epoka 1830: Loss = 0.004239979\n",
      "Epoka 1840: Loss = 0.005472788\n",
      "Epoka 1850: Loss = 0.003384863\n",
      "Epoka 1860: Loss = 0.003695954\n",
      "Epoka 1870: Loss = 0.003203108\n",
      "Epoka 1880: Loss = 0.003706266\n",
      "Epoka 1890: Loss = 0.005079608\n",
      "Epoka 1900: Loss = 0.005481001\n",
      "Epoka 1910: Loss = 0.006007388\n",
      "Epoka 1920: Loss = 0.003038149\n",
      "Epoka 1930: Loss = 0.005297256\n",
      "Epoka 1940: Loss = 0.004705710\n",
      "Epoka 1950: Loss = 0.004273089\n",
      "Epoka 1960: Loss = 0.004296505\n",
      "Epoka 1970: Loss = 0.003718766\n",
      "Epoka 1980: Loss = 0.002837724\n",
      "Epoka 1990: Loss = 0.005495399\n",
      "Epoka 2000: Loss = 0.005082275\n",
      "Epoka 2010: Loss = 0.002879981\n",
      "Epoka 2020: Loss = 0.003560290\n",
      "Epoka 2030: Loss = 0.004251179\n",
      "Epoka 2040: Loss = 0.002621619\n",
      "Epoka 2050: Loss = 0.002530104\n",
      "Epoka 2060: Loss = 0.005204435\n",
      "Epoka 2070: Loss = 0.004430092\n",
      "Epoka 2080: Loss = 0.003855988\n",
      "Epoka 2090: Loss = 0.009642838\n",
      "Epoka 2100: Loss = 0.003298927\n",
      "Epoka 2110: Loss = 0.004922927\n",
      "Epoka 2120: Loss = 0.002961028\n",
      "Epoka 2130: Loss = 0.008467727\n",
      "Epoka 2140: Loss = 0.005039488\n",
      "Epoka 2150: Loss = 0.003448231\n",
      "Epoka 2160: Loss = 0.002718764\n",
      "Epoka 2170: Loss = 0.003532591\n",
      "Epoka 2180: Loss = 0.003032303\n",
      "Epoka 2190: Loss = 0.002551291\n",
      "Epoka 2200: Loss = 0.003367079\n",
      "Epoka 2210: Loss = 0.003100526\n",
      "Epoka 2220: Loss = 0.008187012\n",
      "Epoka 2230: Loss = 0.004316878\n",
      "Epoka 2240: Loss = 0.002897301\n",
      "Epoka 2250: Loss = 0.003301811\n",
      "Epoka 2260: Loss = 0.002850555\n",
      "Epoka 2270: Loss = 0.002373630\n",
      "Epoka 2280: Loss = 0.002936267\n",
      "Epoka 2290: Loss = 0.004720408\n",
      "Epoka 2300: Loss = 0.004332540\n",
      "Epoka 2310: Loss = 0.002712622\n",
      "Epoka 2320: Loss = 0.005071454\n",
      "Epoka 2330: Loss = 0.003188044\n",
      "Epoka 2340: Loss = 0.004094573\n",
      "Epoka 2350: Loss = 0.002713565\n",
      "Epoka 2360: Loss = 0.002699838\n",
      "Epoka 2370: Loss = 0.006897524\n",
      "Epoka 2380: Loss = 0.004817244\n",
      "Epoka 2390: Loss = 0.003501868\n",
      "Epoka 2400: Loss = 0.004916082\n",
      "Epoka 2410: Loss = 0.004225751\n",
      "Epoka 2420: Loss = 0.002756124\n",
      "Epoka 2430: Loss = 0.002801722\n",
      "Epoka 2440: Loss = 0.002365527\n",
      "Epoka 2450: Loss = 0.002946731\n",
      "Epoka 2460: Loss = 0.002701129\n",
      "Epoka 2470: Loss = 0.005053557\n",
      "Epoka 2480: Loss = 0.005397552\n",
      "Epoka 2490: Loss = 0.003466598\n",
      "Epoka 2500: Loss = 0.004181974\n",
      "Epoka 2510: Loss = 0.002290485\n",
      "Epoka 2520: Loss = 0.003013839\n",
      "Epoka 2530: Loss = 0.002514419\n",
      "Epoka 2540: Loss = 0.003383652\n",
      "Epoka 2550: Loss = 0.004045079\n",
      "Epoka 2560: Loss = 0.003170203\n",
      "Epoka 2570: Loss = 0.002987370\n",
      "Epoka 2580: Loss = 0.002292938\n",
      "Epoka 2590: Loss = 0.002267030\n",
      "Epoka 2600: Loss = 0.006545893\n",
      "Epoka 2610: Loss = 0.003863919\n",
      "Epoka 2620: Loss = 0.003221932\n",
      "Epoka 2630: Loss = 0.003353103\n",
      "Epoka 2640: Loss = 0.002910860\n",
      "Epoka 2650: Loss = 0.002783463\n",
      "Epoka 2660: Loss = 0.002702172\n",
      "Epoka 2670: Loss = 0.002947823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 2680: Loss = 0.002144082\n",
      "Epoka 2690: Loss = 0.002365396\n",
      "Epoka 2700: Loss = 0.002531736\n",
      "Epoka 2710: Loss = 0.002162654\n",
      "Epoka 2720: Loss = 0.002818397\n",
      "Epoka 2730: Loss = 0.002538301\n",
      "Epoka 2740: Loss = 0.002472511\n",
      "Epoka 2750: Loss = 0.002643692\n",
      "Epoka 2760: Loss = 0.002399039\n",
      "Epoka 2770: Loss = 0.003845578\n",
      "Epoka 2780: Loss = 0.003908963\n",
      "Epoka 2790: Loss = 0.005680544\n",
      "Epoka 2800: Loss = 0.003033207\n",
      "Epoka 2810: Loss = 0.003931096\n",
      "Epoka 2820: Loss = 0.002484902\n",
      "Epoka 2830: Loss = 0.003076902\n",
      "Epoka 2840: Loss = 0.002986013\n",
      "Epoka 2850: Loss = 0.003916268\n",
      "Epoka 2860: Loss = 0.002328089\n",
      "Epoka 2870: Loss = 0.005113280\n",
      "Epoka 2880: Loss = 0.002732747\n",
      "Epoka 2890: Loss = 0.003166079\n",
      "Epoka 2900: Loss = 0.002348496\n",
      "Epoka 2910: Loss = 0.003655618\n",
      "Epoka 2920: Loss = 0.004259592\n",
      "Epoka 2930: Loss = 0.002711396\n",
      "Epoka 2940: Loss = 0.002079664\n",
      "Epoka 2950: Loss = 0.002334754\n",
      "Epoka 2960: Loss = 0.003366963\n",
      "Epoka 2970: Loss = 0.004638348\n",
      "Epoka 2980: Loss = 0.002389704\n",
      "Epoka 2990: Loss = 0.002328095\n",
      "Epoka 3000: Loss = 0.002313566\n",
      "Epoka 3010: Loss = 0.003165526\n",
      "Epoka 3020: Loss = 0.003292827\n",
      "Epoka 3030: Loss = 0.003538933\n",
      "Epoka 3040: Loss = 0.003545810\n",
      "Epoka 3050: Loss = 0.002709574\n",
      "Epoka 3060: Loss = 0.002313887\n",
      "Epoka 3070: Loss = 0.003432146\n",
      "Epoka 3080: Loss = 0.002796280\n",
      "Epoka 3090: Loss = 0.002284547\n",
      "Epoka 3100: Loss = 0.003722865\n",
      "Epoka 3110: Loss = 0.002370325\n",
      "Epoka 3120: Loss = 0.002765339\n",
      "Epoka 3130: Loss = 0.002249846\n",
      "Epoka 3140: Loss = 0.003311420\n",
      "Epoka 3150: Loss = 0.002396041\n",
      "Epoka 3160: Loss = 0.003996981\n",
      "Epoka 3170: Loss = 0.003251691\n",
      "Epoka 3180: Loss = 0.005148106\n",
      "Epoka 3190: Loss = 0.002189638\n",
      "Epoka 3200: Loss = 0.002337084\n",
      "Epoka 3210: Loss = 0.002590735\n",
      "Epoka 3220: Loss = 0.002697372\n",
      "Epoka 3230: Loss = 0.003045413\n",
      "Epoka 3240: Loss = 0.002701179\n",
      "Epoka 3250: Loss = 0.005097701\n",
      "Epoka 3260: Loss = 0.003052771\n",
      "Epoka 3270: Loss = 0.002899077\n",
      "Epoka 3280: Loss = 0.001990329\n",
      "Epoka 3290: Loss = 0.002762371\n",
      "Epoka 3300: Loss = 0.002869596\n",
      "Epoka 3310: Loss = 0.003135167\n",
      "Epoka 3320: Loss = 0.004018468\n",
      "Epoka 3330: Loss = 0.002785569\n",
      "Epoka 3340: Loss = 0.002046880\n",
      "Epoka 3350: Loss = 0.007018786\n",
      "Epoka 3360: Loss = 0.002469112\n",
      "Epoka 3370: Loss = 0.002511531\n",
      "Epoka 3380: Loss = 0.002588263\n",
      "Epoka 3390: Loss = 0.002116514\n",
      "Epoka 3400: Loss = 0.002583849\n",
      "Epoka 3410: Loss = 0.002200750\n",
      "Epoka 3420: Loss = 0.006771059\n",
      "Epoka 3430: Loss = 0.005235874\n",
      "Epoka 3440: Loss = 0.003351773\n",
      "Epoka 3450: Loss = 0.004072939\n",
      "Epoka 3460: Loss = 0.002383489\n",
      "Epoka 3470: Loss = 0.003892627\n",
      "Epoka 3480: Loss = 0.002745207\n",
      "Epoka 3490: Loss = 0.003779903\n",
      "Epoka 3500: Loss = 0.002109807\n",
      "Epoka 3510: Loss = 0.002591764\n",
      "Epoka 3520: Loss = 0.002223576\n",
      "Epoka 3530: Loss = 0.003593544\n",
      "Epoka 3540: Loss = 0.002124164\n",
      "Epoka 3550: Loss = 0.003074465\n",
      "Epoka 3560: Loss = 0.002650775\n",
      "Epoka 3570: Loss = 0.002333168\n",
      "Epoka 3580: Loss = 0.002659978\n",
      "Epoka 3590: Loss = 0.002101338\n",
      "Epoka 3600: Loss = 0.002821093\n",
      "Epoka 3610: Loss = 0.002197035\n",
      "Epoka 3620: Loss = 0.001947583\n",
      "Epoka 3630: Loss = 0.002227315\n",
      "Epoka 3640: Loss = 0.001973906\n",
      "Epoka 3650: Loss = 0.002366868\n",
      "Epoka 3660: Loss = 0.003031698\n",
      "Epoka 3670: Loss = 0.002494170\n",
      "Epoka 3680: Loss = 0.006889877\n",
      "Epoka 3690: Loss = 0.002245746\n",
      "Epoka 3700: Loss = 0.002180326\n",
      "Epoka 3710: Loss = 0.002161969\n",
      "Epoka 3720: Loss = 0.001924837\n",
      "Epoka 3730: Loss = 0.003892144\n",
      "Epoka 3740: Loss = 0.004992747\n",
      "Epoka 3750: Loss = 0.002961195\n",
      "Epoka 3760: Loss = 0.001954170\n",
      "Epoka 3770: Loss = 0.003613721\n",
      "Epoka 3780: Loss = 0.002405418\n",
      "Epoka 3790: Loss = 0.002105875\n",
      "Epoka 3800: Loss = 0.002120676\n",
      "Epoka 3810: Loss = 0.002551088\n",
      "Epoka 3820: Loss = 0.003310850\n",
      "Epoka 3830: Loss = 0.002165626\n",
      "Epoka 3840: Loss = 0.002011562\n",
      "Epoka 3850: Loss = 0.002949790\n",
      "Epoka 3860: Loss = 0.003307080\n",
      "Epoka 3870: Loss = 0.001889369\n",
      "Epoka 3880: Loss = 0.001895147\n",
      "Epoka 3890: Loss = 0.005620467\n",
      "Epoka 3900: Loss = 0.006048052\n",
      "Epoka 3910: Loss = 0.002718949\n",
      "Epoka 3920: Loss = 0.002609094\n",
      "Epoka 3930: Loss = 0.002979558\n",
      "Epoka 3940: Loss = 0.001890782\n",
      "Epoka 3950: Loss = 0.002397826\n",
      "Epoka 3960: Loss = 0.002323243\n",
      "Epoka 3970: Loss = 0.001910911\n",
      "Epoka 3980: Loss = 0.003916008\n",
      "Epoka 3990: Loss = 0.002923468\n",
      "Epoka 4000: Loss = 0.002062920\n",
      "Epoka 4010: Loss = 0.003686826\n",
      "Epoka 4020: Loss = 0.002003338\n",
      "Epoka 4030: Loss = 0.004183219\n",
      "Epoka 4040: Loss = 0.001823195\n",
      "Epoka 4050: Loss = 0.002011885\n",
      "Epoka 4060: Loss = 0.003777995\n",
      "Epoka 4070: Loss = 0.002714468\n",
      "Epoka 4080: Loss = 0.002056554\n",
      "Epoka 4090: Loss = 0.002991016\n",
      "Epoka 4100: Loss = 0.002109426\n",
      "Epoka 4110: Loss = 0.002196324\n",
      "Epoka 4120: Loss = 0.002150335\n",
      "Epoka 4130: Loss = 0.005088580\n",
      "Epoka 4140: Loss = 0.001894000\n",
      "Epoka 4150: Loss = 0.001817815\n",
      "Epoka 4160: Loss = 0.001913788\n",
      "Epoka 4170: Loss = 0.002981506\n",
      "Epoka 4180: Loss = 0.002957448\n",
      "Epoka 4190: Loss = 0.002503790\n",
      "Epoka 4200: Loss = 0.003015264\n",
      "Epoka 4210: Loss = 0.002887140\n",
      "Epoka 4220: Loss = 0.003653328\n",
      "Epoka 4230: Loss = 0.004614406\n",
      "Epoka 4240: Loss = 0.002182986\n",
      "Epoka 4250: Loss = 0.002628346\n",
      "Epoka 4260: Loss = 0.002075546\n",
      "Epoka 4270: Loss = 0.002252864\n",
      "Epoka 4280: Loss = 0.002051873\n",
      "Epoka 4290: Loss = 0.002107908\n",
      "Epoka 4300: Loss = 0.003256304\n",
      "Epoka 4310: Loss = 0.003690185\n",
      "Epoka 4320: Loss = 0.002762539\n",
      "Epoka 4330: Loss = 0.002481045\n",
      "Epoka 4340: Loss = 0.002645568\n",
      "Epoka 4350: Loss = 0.002060779\n",
      "Epoka 4360: Loss = 0.002258435\n",
      "Epoka 4370: Loss = 0.001785525\n",
      "Epoka 4380: Loss = 0.002594664\n",
      "Epoka 4390: Loss = 0.002382633\n",
      "Epoka 4400: Loss = 0.002200882\n",
      "Epoka 4410: Loss = 0.001885758\n",
      "Epoka 4420: Loss = 0.002728455\n",
      "Epoka 4430: Loss = 0.002007228\n",
      "Epoka 4440: Loss = 0.005862212\n",
      "Epoka 4450: Loss = 0.001885968\n",
      "Epoka 4460: Loss = 0.005481390\n",
      "Epoka 4470: Loss = 0.004125448\n",
      "Epoka 4480: Loss = 0.002019706\n",
      "Epoka 4490: Loss = 0.002498674\n",
      "Epoka 4500: Loss = 0.002037820\n",
      "Epoka 4510: Loss = 0.002456510\n",
      "Epoka 4520: Loss = 0.001776021\n",
      "Epoka 4530: Loss = 0.001908282\n",
      "Epoka 4540: Loss = 0.001838574\n",
      "Epoka 4550: Loss = 0.003458567\n",
      "Epoka 4560: Loss = 0.004980657\n",
      "Epoka 4570: Loss = 0.002339112\n",
      "Epoka 4580: Loss = 0.002498627\n",
      "Epoka 4590: Loss = 0.002497283\n",
      "Epoka 4600: Loss = 0.002195660\n",
      "Epoka 4610: Loss = 0.002731029\n",
      "Epoka 4620: Loss = 0.002101392\n",
      "Epoka 4630: Loss = 0.003986038\n",
      "Epoka 4640: Loss = 0.002323312\n",
      "Epoka 4650: Loss = 0.001849071\n",
      "Epoka 4660: Loss = 0.001874275\n",
      "Epoka 4670: Loss = 0.002349057\n",
      "Epoka 4680: Loss = 0.001867578\n",
      "Epoka 4690: Loss = 0.007481484\n",
      "Epoka 4700: Loss = 0.002861894\n",
      "Epoka 4710: Loss = 0.001841769\n",
      "Epoka 4720: Loss = 0.004781505\n",
      "Epoka 4730: Loss = 0.003486660\n",
      "Epoka 4740: Loss = 0.001833372\n",
      "Epoka 4750: Loss = 0.002591344\n",
      "Epoka 4760: Loss = 0.002671884\n",
      "Epoka 4770: Loss = 0.003275067\n",
      "Epoka 4780: Loss = 0.002072313\n",
      "Epoka 4790: Loss = 0.002047048\n",
      "Epoka 4800: Loss = 0.002210485\n",
      "Epoka 4810: Loss = 0.001886621\n",
      "Epoka 4820: Loss = 0.002240833\n",
      "Epoka 4830: Loss = 0.001867912\n",
      "Epoka 4840: Loss = 0.003922228\n",
      "Epoka 4850: Loss = 0.001806432\n",
      "Epoka 4860: Loss = 0.003184012\n",
      "Epoka 4870: Loss = 0.001746560\n",
      "Epoka 4880: Loss = 0.002248683\n",
      "Epoka 4890: Loss = 0.003126303\n",
      "Epoka 4900: Loss = 0.002609655\n",
      "Epoka 4910: Loss = 0.001771894\n",
      "Epoka 4920: Loss = 0.001724471\n",
      "Epoka 4930: Loss = 0.002143722\n",
      "Epoka 4940: Loss = 0.002277975\n",
      "Epoka 4950: Loss = 0.002101827\n",
      "Epoka 4960: Loss = 0.008217809\n",
      "Epoka 4970: Loss = 0.002695825\n",
      "Epoka 4980: Loss = 0.001810850\n",
      "Epoka 4990: Loss = 0.002038813\n",
      "Epoka 5000: Loss = 0.005724237\n",
      "Epoka 5010: Loss = 0.002055619\n",
      "Epoka 5020: Loss = 0.001772122\n",
      "Epoka 5030: Loss = 0.002664979\n",
      "Epoka 5040: Loss = 0.002255957\n",
      "Epoka 5050: Loss = 0.002090534\n",
      "Epoka 5060: Loss = 0.001942245\n",
      "Epoka 5070: Loss = 0.002785042\n",
      "Epoka 5080: Loss = 0.001998238\n",
      "Epoka 5090: Loss = 0.002658861\n",
      "Epoka 5100: Loss = 0.001917466\n",
      "Epoka 5110: Loss = 0.001960378\n",
      "Epoka 5120: Loss = 0.001851755\n",
      "Epoka 5130: Loss = 0.001854122\n",
      "Epoka 5140: Loss = 0.002820862\n",
      "Epoka 5150: Loss = 0.001788226\n",
      "Epoka 5160: Loss = 0.001940416\n",
      "Epoka 5170: Loss = 0.002296808\n",
      "Epoka 5180: Loss = 0.003053720\n",
      "Epoka 5190: Loss = 0.001771750\n",
      "Epoka 5200: Loss = 0.002379410\n",
      "Epoka 5210: Loss = 0.001964266\n",
      "Epoka 5220: Loss = 0.002355088\n",
      "Epoka 5230: Loss = 0.001987457\n",
      "Epoka 5240: Loss = 0.002326757\n",
      "Epoka 5250: Loss = 0.002613889\n",
      "Epoka 5260: Loss = 0.003141620\n",
      "Epoka 5270: Loss = 0.002059409\n",
      "Epoka 5280: Loss = 0.004605600\n",
      "Epoka 5290: Loss = 0.002349751\n",
      "Epoka 5300: Loss = 0.001720197\n",
      "Epoka 5310: Loss = 0.001965380\n",
      "Epoka 5320: Loss = 0.002600931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 5330: Loss = 0.003595361\n",
      "Epoka 5340: Loss = 0.002319037\n",
      "Epoka 5350: Loss = 0.002004392\n",
      "Epoka 5360: Loss = 0.001993043\n",
      "Epoka 5370: Loss = 0.002709242\n",
      "Epoka 5380: Loss = 0.002006585\n",
      "Epoka 5390: Loss = 0.003294760\n",
      "Epoka 5400: Loss = 0.002411212\n",
      "Epoka 5410: Loss = 0.003051735\n",
      "Epoka 5420: Loss = 0.005331193\n",
      "Epoka 5430: Loss = 0.001714937\n",
      "Epoka 5440: Loss = 0.002836843\n",
      "Epoka 5450: Loss = 0.002953944\n",
      "Epoka 5460: Loss = 0.002067288\n",
      "Epoka 5470: Loss = 0.001961073\n",
      "Epoka 5480: Loss = 0.003202825\n",
      "Epoka 5490: Loss = 0.002472653\n",
      "Epoka 5500: Loss = 0.001900475\n",
      "Epoka 5510: Loss = 0.002307113\n",
      "Epoka 5520: Loss = 0.002444045\n",
      "Epoka 5530: Loss = 0.002482708\n",
      "Epoka 5540: Loss = 0.001999020\n",
      "Epoka 5550: Loss = 0.002700692\n",
      "Epoka 5560: Loss = 0.002311399\n",
      "Epoka 5570: Loss = 0.001817429\n",
      "Epoka 5580: Loss = 0.001797672\n",
      "Epoka 5590: Loss = 0.002782256\n",
      "Epoka 5600: Loss = 0.002626163\n",
      "Epoka 5610: Loss = 0.003603137\n",
      "Epoka 5620: Loss = 0.002699293\n",
      "Epoka 5630: Loss = 0.002299449\n",
      "Epoka 5640: Loss = 0.001847388\n",
      "Epoka 5650: Loss = 0.003908755\n",
      "Epoka 5660: Loss = 0.002519699\n",
      "Epoka 5670: Loss = 0.004064771\n",
      "Epoka 5680: Loss = 0.001764445\n",
      "Epoka 5690: Loss = 0.002798444\n",
      "Epoka 5700: Loss = 0.002494973\n",
      "Epoka 5710: Loss = 0.002142261\n",
      "Epoka 5720: Loss = 0.004801419\n",
      "Epoka 5730: Loss = 0.002027672\n",
      "Epoka 5740: Loss = 0.002318452\n",
      "Epoka 5750: Loss = 0.007387067\n",
      "Epoka 5760: Loss = 0.001720766\n",
      "Epoka 5770: Loss = 0.002673500\n",
      "Epoka 5780: Loss = 0.001986982\n",
      "Epoka 5790: Loss = 0.003654454\n",
      "Epoka 5800: Loss = 0.001904444\n",
      "Epoka 5810: Loss = 0.001878764\n",
      "Epoka 5820: Loss = 0.002840389\n",
      "Epoka 5830: Loss = 0.002263465\n",
      "Epoka 5840: Loss = 0.001906996\n",
      "Epoka 5850: Loss = 0.001999734\n",
      "Epoka 5860: Loss = 0.001970390\n",
      "Epoka 5870: Loss = 0.002198855\n",
      "Epoka 5880: Loss = 0.001755133\n",
      "Epoka 5890: Loss = 0.003184663\n",
      "Epoka 5900: Loss = 0.002219546\n",
      "Epoka 5910: Loss = 0.002024253\n",
      "Epoka 5920: Loss = 0.003261052\n",
      "Epoka 5930: Loss = 0.002085051\n",
      "Epoka 5940: Loss = 0.002203040\n",
      "Epoka 5950: Loss = 0.002899503\n",
      "Epoka 5960: Loss = 0.001933863\n",
      "Epoka 5970: Loss = 0.001781312\n",
      "Epoka 5980: Loss = 0.001851707\n",
      "Epoka 5990: Loss = 0.002209648\n",
      "Epoka 6000: Loss = 0.002381871\n",
      "Epoka 6010: Loss = 0.001733901\n",
      "Epoka 6020: Loss = 0.001954697\n",
      "Epoka 6030: Loss = 0.001725477\n",
      "Epoka 6040: Loss = 0.002443385\n",
      "Epoka 6050: Loss = 0.002130844\n",
      "Epoka 6060: Loss = 0.002480783\n",
      "Epoka 6070: Loss = 0.002556111\n",
      "Epoka 6080: Loss = 0.002225386\n",
      "Epoka 6090: Loss = 0.002311460\n",
      "Epoka 6100: Loss = 0.002386017\n",
      "Epoka 6110: Loss = 0.001851772\n",
      "Epoka 6120: Loss = 0.002183283\n",
      "Epoka 6130: Loss = 0.002522757\n",
      "Epoka 6140: Loss = 0.001734224\n",
      "Epoka 6150: Loss = 0.003251503\n",
      "Epoka 6160: Loss = 0.004170055\n",
      "Epoka 6170: Loss = 0.002462854\n",
      "Epoka 6180: Loss = 0.001729041\n",
      "Epoka 6190: Loss = 0.001818363\n",
      "Epoka 6200: Loss = 0.001960362\n",
      "Epoka 6210: Loss = 0.001915371\n",
      "Epoka 6220: Loss = 0.001733160\n",
      "Epoka 6230: Loss = 0.003294856\n",
      "Epoka 6240: Loss = 0.001708289\n",
      "Epoka 6250: Loss = 0.003535608\n",
      "Epoka 6260: Loss = 0.002767501\n",
      "Epoka 6270: Loss = 0.001725325\n",
      "Epoka 6280: Loss = 0.003863895\n",
      "Epoka 6290: Loss = 0.001811150\n",
      "Epoka 6300: Loss = 0.002228066\n",
      "Epoka 6310: Loss = 0.002077989\n",
      "Epoka 6320: Loss = 0.002227086\n",
      "Epoka 6330: Loss = 0.002160269\n",
      "Epoka 6340: Loss = 0.001695133\n",
      "Epoka 6350: Loss = 0.002326849\n",
      "Epoka 6360: Loss = 0.001860211\n",
      "Epoka 6370: Loss = 0.002119466\n",
      "Epoka 6380: Loss = 0.004928205\n",
      "Epoka 6390: Loss = 0.003910074\n",
      "Epoka 6400: Loss = 0.002275775\n",
      "Epoka 6410: Loss = 0.001783692\n",
      "Epoka 6420: Loss = 0.003358930\n",
      "Epoka 6430: Loss = 0.001769291\n",
      "Epoka 6440: Loss = 0.002153624\n",
      "Epoka 6450: Loss = 0.002019089\n",
      "Epoka 6460: Loss = 0.002861066\n",
      "Epoka 6470: Loss = 0.001968617\n",
      "Epoka 6480: Loss = 0.001728676\n",
      "Epoka 6490: Loss = 0.002023726\n",
      "Epoka 6500: Loss = 0.001615868\n",
      "Epoka 6510: Loss = 0.003855957\n",
      "Epoka 6520: Loss = 0.001773871\n",
      "Epoka 6530: Loss = 0.002068666\n",
      "Epoka 6540: Loss = 0.001997309\n",
      "Epoka 6550: Loss = 0.004844586\n",
      "Epoka 6560: Loss = 0.001803516\n",
      "Epoka 6570: Loss = 0.002550444\n",
      "Epoka 6580: Loss = 0.001852634\n",
      "Epoka 6590: Loss = 0.003266275\n",
      "Epoka 6600: Loss = 0.003026457\n",
      "Epoka 6610: Loss = 0.001896157\n",
      "Epoka 6620: Loss = 0.002104635\n",
      "Epoka 6630: Loss = 0.001760215\n",
      "Epoka 6640: Loss = 0.001612508\n",
      "Epoka 6650: Loss = 0.002552120\n",
      "Epoka 6660: Loss = 0.001874228\n",
      "Epoka 6670: Loss = 0.003320487\n",
      "Epoka 6680: Loss = 0.001616469\n",
      "Epoka 6690: Loss = 0.002084174\n",
      "Epoka 6700: Loss = 0.002154938\n",
      "Epoka 6710: Loss = 0.001633861\n",
      "Epoka 6720: Loss = 0.002421402\n",
      "Epoka 6730: Loss = 0.002078758\n",
      "Epoka 6740: Loss = 0.001958089\n",
      "Epoka 6750: Loss = 0.002376840\n",
      "Epoka 6760: Loss = 0.002184152\n",
      "Epoka 6770: Loss = 0.002283122\n",
      "Epoka 6780: Loss = 0.001668230\n",
      "Epoka 6790: Loss = 0.001827657\n",
      "Epoka 6800: Loss = 0.002739416\n",
      "Epoka 6810: Loss = 0.001703210\n",
      "Epoka 6820: Loss = 0.001665659\n",
      "Epoka 6830: Loss = 0.002380730\n",
      "Epoka 6840: Loss = 0.001783985\n",
      "Epoka 6850: Loss = 0.002192381\n",
      "Epoka 6860: Loss = 0.003222723\n",
      "Epoka 6870: Loss = 0.002762381\n",
      "Epoka 6880: Loss = 0.002329890\n",
      "Epoka 6890: Loss = 0.001892215\n",
      "Epoka 6900: Loss = 0.002079020\n",
      "Epoka 6910: Loss = 0.002623675\n",
      "Epoka 6920: Loss = 0.002015338\n",
      "Epoka 6930: Loss = 0.002406919\n",
      "Epoka 6940: Loss = 0.001651340\n",
      "Epoka 6950: Loss = 0.002254577\n",
      "Epoka 6960: Loss = 0.001757925\n",
      "Epoka 6970: Loss = 0.001687887\n",
      "Epoka 6980: Loss = 0.001758707\n",
      "Epoka 6990: Loss = 0.001655724\n",
      "Epoka 7000: Loss = 0.003088070\n",
      "Epoka 7010: Loss = 0.001769018\n",
      "Epoka 7020: Loss = 0.001875092\n",
      "Epoka 7030: Loss = 0.002020576\n",
      "Epoka 7040: Loss = 0.002450951\n",
      "Epoka 7050: Loss = 0.001934937\n",
      "Epoka 7060: Loss = 0.002005085\n",
      "Epoka 7070: Loss = 0.001579422\n",
      "Epoka 7080: Loss = 0.001786752\n",
      "Epoka 7090: Loss = 0.002116340\n",
      "Epoka 7100: Loss = 0.001934364\n",
      "Epoka 7110: Loss = 0.001645653\n",
      "Epoka 7120: Loss = 0.001638339\n",
      "Epoka 7130: Loss = 0.002039098\n",
      "Epoka 7140: Loss = 0.001450492\n",
      "Epoka 7150: Loss = 0.001620801\n",
      "Epoka 7160: Loss = 0.001535020\n",
      "Epoka 7170: Loss = 0.001586203\n",
      "Epoka 7180: Loss = 0.001589631\n",
      "Epoka 7190: Loss = 0.002608021\n",
      "Epoka 7200: Loss = 0.001497440\n",
      "Epoka 7210: Loss = 0.002972859\n",
      "Epoka 7220: Loss = 0.006711943\n",
      "Epoka 7230: Loss = 0.001460194\n",
      "Epoka 7240: Loss = 0.003235328\n",
      "Epoka 7250: Loss = 0.001664386\n",
      "Epoka 7260: Loss = 0.001543427\n",
      "Epoka 7270: Loss = 0.001534137\n",
      "Epoka 7280: Loss = 0.001584152\n",
      "Epoka 7290: Loss = 0.001489301\n",
      "Epoka 7300: Loss = 0.001959149\n",
      "Epoka 7310: Loss = 0.001837240\n",
      "Epoka 7320: Loss = 0.001427941\n",
      "Epoka 7330: Loss = 0.002036276\n",
      "Epoka 7340: Loss = 0.002297336\n",
      "Epoka 7350: Loss = 0.002025280\n",
      "Epoka 7360: Loss = 0.001459819\n",
      "Epoka 7370: Loss = 0.001565848\n",
      "Epoka 7380: Loss = 0.001647373\n",
      "Epoka 7390: Loss = 0.001507476\n",
      "Epoka 7400: Loss = 0.003618365\n",
      "Epoka 7410: Loss = 0.001556525\n",
      "Epoka 7420: Loss = 0.001828129\n",
      "Epoka 7430: Loss = 0.001941032\n",
      "Epoka 7440: Loss = 0.003914949\n",
      "Epoka 7450: Loss = 0.002220182\n",
      "Epoka 7460: Loss = 0.001659523\n",
      "Epoka 7470: Loss = 0.001403691\n",
      "Epoka 7480: Loss = 0.001364865\n",
      "Epoka 7490: Loss = 0.001505493\n",
      "Epoka 7500: Loss = 0.001961594\n",
      "Epoka 7510: Loss = 0.001816086\n",
      "Epoka 7520: Loss = 0.003215805\n",
      "Epoka 7530: Loss = 0.001450013\n",
      "Epoka 7540: Loss = 0.001410452\n",
      "Epoka 7550: Loss = 0.001681084\n",
      "Epoka 7560: Loss = 0.001536385\n",
      "Epoka 7570: Loss = 0.001773229\n",
      "Epoka 7580: Loss = 0.001561808\n",
      "Epoka 7590: Loss = 0.001595962\n",
      "Epoka 7600: Loss = 0.001598898\n",
      "Epoka 7610: Loss = 0.001675200\n",
      "Epoka 7620: Loss = 0.001396053\n",
      "Epoka 7630: Loss = 0.002511428\n",
      "Epoka 7640: Loss = 0.001478563\n",
      "Epoka 7650: Loss = 0.001819180\n",
      "Epoka 7660: Loss = 0.002291215\n",
      "Epoka 7670: Loss = 0.004028019\n",
      "Epoka 7680: Loss = 0.001499242\n",
      "Epoka 7690: Loss = 0.001475027\n",
      "Epoka 7700: Loss = 0.005438778\n",
      "Epoka 7710: Loss = 0.001947987\n",
      "Epoka 7720: Loss = 0.002294607\n",
      "Epoka 7730: Loss = 0.001401892\n",
      "Epoka 7740: Loss = 0.001366801\n",
      "Epoka 7750: Loss = 0.002290115\n",
      "Epoka 7760: Loss = 0.002063184\n",
      "Epoka 7770: Loss = 0.001999719\n",
      "Epoka 7780: Loss = 0.002197249\n",
      "Epoka 7790: Loss = 0.001597303\n",
      "Epoka 7800: Loss = 0.001402268\n",
      "Epoka 7810: Loss = 0.001933671\n",
      "Epoka 7820: Loss = 0.001568130\n",
      "Epoka 7830: Loss = 0.001393924\n",
      "Epoka 7840: Loss = 0.001835037\n",
      "Epoka 7850: Loss = 0.001566865\n",
      "Epoka 7860: Loss = 0.004494933\n",
      "Epoka 7870: Loss = 0.001755026\n",
      "Epoka 7880: Loss = 0.001486168\n",
      "Epoka 7890: Loss = 0.002199915\n",
      "Epoka 7900: Loss = 0.001945354\n",
      "Epoka 7910: Loss = 0.001546583\n",
      "Epoka 7920: Loss = 0.001351179\n",
      "Epoka 7930: Loss = 0.001586039\n",
      "Epoka 7940: Loss = 0.002339439\n",
      "Epoka 7950: Loss = 0.001798773\n",
      "Epoka 7960: Loss = 0.002321122\n",
      "Epoka 7970: Loss = 0.001453419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 7980: Loss = 0.001588924\n",
      "Epoka 7990: Loss = 0.001990069\n",
      "Epoka 8000: Loss = 0.002526625\n",
      "Epoka 8010: Loss = 0.001557659\n",
      "Epoka 8020: Loss = 0.001889030\n",
      "Epoka 8030: Loss = 0.001813014\n",
      "Epoka 8040: Loss = 0.001928475\n",
      "Epoka 8050: Loss = 0.002508136\n",
      "Epoka 8060: Loss = 0.001470938\n",
      "Epoka 8070: Loss = 0.002490486\n",
      "Epoka 8080: Loss = 0.001429020\n",
      "Epoka 8090: Loss = 0.001350700\n",
      "Epoka 8100: Loss = 0.001770431\n",
      "Epoka 8110: Loss = 0.001965969\n",
      "Epoka 8120: Loss = 0.002707378\n",
      "Epoka 8130: Loss = 0.001336547\n",
      "Epoka 8140: Loss = 0.001390970\n",
      "Epoka 8150: Loss = 0.001755681\n",
      "Epoka 8160: Loss = 0.001412780\n",
      "Epoka 8170: Loss = 0.001587927\n",
      "Epoka 8180: Loss = 0.005563418\n",
      "Epoka 8190: Loss = 0.001360392\n",
      "Epoka 8200: Loss = 0.001712378\n",
      "Epoka 8210: Loss = 0.003563342\n",
      "Epoka 8220: Loss = 0.002839429\n",
      "Epoka 8230: Loss = 0.002919117\n",
      "Epoka 8240: Loss = 0.002433518\n",
      "Epoka 8250: Loss = 0.001614545\n",
      "Epoka 8260: Loss = 0.002818567\n",
      "Epoka 8270: Loss = 0.002874826\n",
      "Epoka 8280: Loss = 0.001578929\n",
      "Epoka 8290: Loss = 0.001605567\n",
      "Epoka 8300: Loss = 0.001670513\n",
      "Epoka 8310: Loss = 0.003838133\n",
      "Epoka 8320: Loss = 0.002124429\n",
      "Epoka 8330: Loss = 0.001619712\n",
      "Epoka 8340: Loss = 0.001391530\n",
      "Epoka 8350: Loss = 0.001413219\n",
      "Epoka 8360: Loss = 0.001628759\n",
      "Epoka 8370: Loss = 0.001640656\n",
      "Epoka 8380: Loss = 0.001688132\n",
      "Epoka 8390: Loss = 0.001386146\n",
      "Epoka 8400: Loss = 0.001697160\n",
      "Epoka 8410: Loss = 0.001624332\n",
      "Epoka 8420: Loss = 0.001686071\n",
      "Epoka 8430: Loss = 0.001496153\n",
      "Epoka 8440: Loss = 0.001753220\n",
      "Epoka 8450: Loss = 0.001858271\n",
      "Epoka 8460: Loss = 0.001449482\n",
      "Epoka 8470: Loss = 0.001828194\n",
      "Epoka 8480: Loss = 0.004502508\n",
      "Epoka 8490: Loss = 0.001984216\n",
      "Epoka 8500: Loss = 0.001470890\n",
      "Epoka 8510: Loss = 0.001820771\n",
      "Epoka 8520: Loss = 0.001740434\n",
      "Epoka 8530: Loss = 0.003556348\n",
      "Epoka 8540: Loss = 0.002414288\n",
      "Epoka 8550: Loss = 0.001895729\n",
      "Epoka 8560: Loss = 0.001628346\n",
      "Epoka 8570: Loss = 0.001469819\n",
      "Epoka 8580: Loss = 0.002299026\n",
      "Epoka 8590: Loss = 0.001900529\n",
      "Epoka 8600: Loss = 0.001619387\n",
      "Epoka 8610: Loss = 0.004305846\n",
      "Epoka 8620: Loss = 0.001528026\n",
      "Epoka 8630: Loss = 0.004885158\n",
      "Epoka 8640: Loss = 0.001385337\n",
      "Epoka 8650: Loss = 0.001822237\n",
      "Epoka 8660: Loss = 0.001475795\n",
      "Epoka 8670: Loss = 0.001919520\n",
      "Epoka 8680: Loss = 0.001793704\n",
      "Epoka 8690: Loss = 0.001779745\n",
      "Epoka 8700: Loss = 0.002483236\n",
      "Epoka 8710: Loss = 0.001494895\n",
      "Epoka 8720: Loss = 0.001753286\n",
      "Epoka 8730: Loss = 0.001511151\n",
      "Epoka 8740: Loss = 0.001615631\n",
      "Epoka 8750: Loss = 0.001506270\n",
      "Epoka 8760: Loss = 0.001457409\n",
      "Epoka 8770: Loss = 0.001530566\n",
      "Epoka 8780: Loss = 0.003348877\n",
      "Epoka 8790: Loss = 0.002058617\n",
      "Epoka 8800: Loss = 0.001497633\n",
      "Epoka 8810: Loss = 0.002846250\n",
      "Epoka 8820: Loss = 0.004062318\n",
      "Epoka 8830: Loss = 0.001429246\n",
      "Epoka 8840: Loss = 0.001651286\n",
      "Epoka 8850: Loss = 0.001593247\n",
      "Epoka 8860: Loss = 0.001484404\n",
      "Epoka 8870: Loss = 0.001672463\n",
      "Epoka 8880: Loss = 0.001925660\n",
      "Epoka 8890: Loss = 0.001564203\n",
      "Epoka 8900: Loss = 0.001966477\n",
      "Epoka 8910: Loss = 0.001514536\n",
      "Epoka 8920: Loss = 0.002257992\n",
      "Epoka 8930: Loss = 0.001416418\n",
      "Epoka 8940: Loss = 0.001583234\n",
      "Epoka 8950: Loss = 0.001424738\n",
      "Epoka 8960: Loss = 0.001622250\n",
      "Epoka 8970: Loss = 0.001468139\n",
      "Epoka 8980: Loss = 0.002585023\n",
      "Epoka 8990: Loss = 0.001390120\n",
      "Epoka 9000: Loss = 0.002503700\n",
      "Epoka 9010: Loss = 0.002218163\n",
      "Epoka 9020: Loss = 0.001927322\n",
      "Epoka 9030: Loss = 0.001834014\n",
      "Epoka 9040: Loss = 0.001711318\n",
      "Epoka 9050: Loss = 0.001513142\n",
      "Epoka 9060: Loss = 0.002072026\n",
      "Epoka 9070: Loss = 0.001432121\n",
      "Epoka 9080: Loss = 0.001430214\n",
      "Epoka 9090: Loss = 0.002738114\n",
      "Epoka 9100: Loss = 0.001462377\n",
      "Epoka 9110: Loss = 0.001716737\n",
      "Epoka 9120: Loss = 0.001475828\n",
      "Epoka 9130: Loss = 0.001760774\n",
      "Epoka 9140: Loss = 0.001634171\n",
      "Epoka 9150: Loss = 0.001514466\n",
      "Epoka 9160: Loss = 0.002337307\n",
      "Epoka 9170: Loss = 0.001511807\n",
      "Epoka 9180: Loss = 0.001968687\n",
      "Epoka 9190: Loss = 0.002788788\n",
      "Epoka 9200: Loss = 0.002579298\n",
      "Epoka 9210: Loss = 0.002233110\n",
      "Epoka 9220: Loss = 0.002438133\n",
      "Epoka 9230: Loss = 0.001486146\n",
      "Epoka 9240: Loss = 0.002727132\n",
      "Epoka 9250: Loss = 0.001636507\n",
      "Epoka 9260: Loss = 0.002109435\n",
      "Epoka 9270: Loss = 0.002561438\n",
      "Epoka 9280: Loss = 0.001827422\n",
      "Epoka 9290: Loss = 0.001710129\n",
      "Epoka 9300: Loss = 0.002539735\n",
      "Epoka 9310: Loss = 0.001462599\n",
      "Epoka 9320: Loss = 0.001368672\n",
      "Epoka 9330: Loss = 0.001521543\n",
      "Epoka 9340: Loss = 0.001445090\n",
      "Epoka 9350: Loss = 0.001406215\n",
      "Epoka 9360: Loss = 0.002197977\n",
      "Epoka 9370: Loss = 0.002108329\n",
      "Epoka 9380: Loss = 0.001631242\n",
      "Epoka 9390: Loss = 0.001580033\n",
      "Epoka 9400: Loss = 0.001890267\n",
      "Epoka 9410: Loss = 0.002227295\n",
      "Epoka 9420: Loss = 0.002193673\n",
      "Epoka 9430: Loss = 0.002108485\n",
      "Epoka 9440: Loss = 0.001558549\n",
      "Epoka 9450: Loss = 0.005661661\n",
      "Epoka 9460: Loss = 0.001404810\n",
      "Epoka 9470: Loss = 0.002648625\n",
      "Epoka 9480: Loss = 0.001352210\n",
      "Epoka 9490: Loss = 0.001955775\n",
      "Epoka 9500: Loss = 0.001610974\n",
      "Epoka 9510: Loss = 0.001434262\n",
      "Epoka 9520: Loss = 0.003625933\n",
      "Epoka 9530: Loss = 0.003348503\n",
      "Epoka 9540: Loss = 0.001543590\n",
      "Epoka 9550: Loss = 0.001420913\n",
      "Epoka 9560: Loss = 0.002013444\n",
      "Epoka 9570: Loss = 0.001482159\n",
      "Epoka 9580: Loss = 0.001981938\n",
      "Epoka 9590: Loss = 0.002830883\n",
      "Epoka 9600: Loss = 0.001403658\n",
      "Epoka 9610: Loss = 0.003275387\n",
      "Epoka 9620: Loss = 0.001748271\n",
      "Epoka 9630: Loss = 0.001357587\n",
      "Epoka 9640: Loss = 0.002692635\n",
      "Epoka 9650: Loss = 0.001426743\n",
      "Epoka 9660: Loss = 0.001550875\n",
      "Epoka 9670: Loss = 0.001787325\n",
      "Epoka 9680: Loss = 0.001378173\n",
      "Epoka 9690: Loss = 0.001564944\n",
      "Epoka 9700: Loss = 0.001961775\n",
      "Epoka 9710: Loss = 0.001554536\n",
      "Epoka 9720: Loss = 0.002116452\n",
      "Epoka 9730: Loss = 0.002385616\n",
      "Epoka 9740: Loss = 0.002005376\n",
      "Epoka 9750: Loss = 0.002031594\n",
      "Epoka 9760: Loss = 0.001874754\n",
      "Epoka 9770: Loss = 0.001433306\n",
      "Epoka 9780: Loss = 0.001479985\n",
      "Epoka 9790: Loss = 0.002192140\n",
      "Epoka 9800: Loss = 0.001312360\n",
      "Epoka 9810: Loss = 0.002413589\n",
      "Epoka 9820: Loss = 0.002232013\n",
      "Epoka 9830: Loss = 0.001462091\n",
      "Epoka 9840: Loss = 0.001749281\n",
      "Epoka 9850: Loss = 0.001376741\n",
      "Epoka 9860: Loss = 0.001521397\n",
      "Epoka 9870: Loss = 0.001501841\n",
      "Epoka 9880: Loss = 0.002396043\n",
      "Epoka 9890: Loss = 0.001286178\n",
      "Epoka 9900: Loss = 0.001307838\n",
      "Epoka 9910: Loss = 0.001532415\n",
      "Epoka 9920: Loss = 0.003356858\n",
      "Epoka 9930: Loss = 0.001679764\n",
      "Epoka 9940: Loss = 0.001577880\n",
      "Epoka 9950: Loss = 0.001324660\n",
      "Epoka 9960: Loss = 0.002158210\n",
      "Epoka 9970: Loss = 0.001744173\n",
      "Epoka 9980: Loss = 0.001471087\n",
      "Epoka 9990: Loss = 0.001398737\n",
      "Epoka 10000: Loss = 0.001350173\n",
      "Epoka 10010: Loss = 0.002483852\n",
      "Epoka 10020: Loss = 0.002041758\n",
      "Epoka 10030: Loss = 0.001301811\n",
      "Epoka 10040: Loss = 0.002008792\n",
      "Epoka 10050: Loss = 0.001438073\n",
      "Epoka 10060: Loss = 0.001392051\n",
      "Epoka 10070: Loss = 0.001570180\n",
      "Epoka 10080: Loss = 0.001723779\n",
      "Epoka 10090: Loss = 0.003968205\n",
      "Epoka 10100: Loss = 0.001821490\n",
      "Epoka 10110: Loss = 0.001446780\n",
      "Epoka 10120: Loss = 0.001805832\n",
      "Epoka 10130: Loss = 0.001380327\n",
      "Epoka 10140: Loss = 0.001383242\n",
      "Epoka 10150: Loss = 0.001452575\n",
      "Epoka 10160: Loss = 0.001901021\n",
      "Epoka 10170: Loss = 0.001539965\n",
      "Epoka 10180: Loss = 0.001315680\n",
      "Epoka 10190: Loss = 0.001557605\n",
      "Epoka 10200: Loss = 0.001324876\n",
      "Epoka 10210: Loss = 0.002399832\n",
      "Epoka 10220: Loss = 0.001573661\n",
      "Epoka 10230: Loss = 0.001364830\n",
      "Epoka 10240: Loss = 0.001891772\n",
      "Epoka 10250: Loss = 0.001651087\n",
      "Epoka 10260: Loss = 0.001720028\n",
      "Epoka 10270: Loss = 0.002524816\n",
      "Epoka 10280: Loss = 0.001254129\n",
      "Epoka 10290: Loss = 0.003933434\n",
      "Epoka 10300: Loss = 0.001362872\n",
      "Epoka 10310: Loss = 0.001559821\n",
      "Epoka 10320: Loss = 0.002280891\n",
      "Epoka 10330: Loss = 0.001440979\n",
      "Epoka 10340: Loss = 0.001332553\n",
      "Epoka 10350: Loss = 0.001316542\n",
      "Epoka 10360: Loss = 0.001786270\n",
      "Epoka 10370: Loss = 0.001508937\n",
      "Epoka 10380: Loss = 0.002026451\n",
      "Epoka 10390: Loss = 0.003064617\n",
      "Epoka 10400: Loss = 0.001305993\n",
      "Epoka 10410: Loss = 0.001547307\n",
      "Epoka 10420: Loss = 0.002065312\n",
      "Epoka 10430: Loss = 0.001437345\n",
      "Epoka 10440: Loss = 0.001348522\n",
      "Epoka 10450: Loss = 0.001996809\n",
      "Epoka 10460: Loss = 0.002748020\n",
      "Epoka 10470: Loss = 0.001442251\n",
      "Epoka 10480: Loss = 0.001465497\n",
      "Epoka 10490: Loss = 0.001693918\n",
      "Epoka 10500: Loss = 0.001367406\n",
      "Epoka 10510: Loss = 0.002306590\n",
      "Epoka 10520: Loss = 0.001846560\n",
      "Epoka 10530: Loss = 0.001335198\n",
      "Epoka 10540: Loss = 0.002696464\n",
      "Epoka 10550: Loss = 0.001313177\n",
      "Epoka 10560: Loss = 0.001459389\n",
      "Epoka 10570: Loss = 0.001411184\n",
      "Epoka 10580: Loss = 0.003516019\n",
      "Epoka 10590: Loss = 0.001854321\n",
      "Epoka 10600: Loss = 0.001423612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 10610: Loss = 0.001439167\n",
      "Epoka 10620: Loss = 0.001446745\n",
      "Epoka 10630: Loss = 0.001464909\n",
      "Epoka 10640: Loss = 0.002567650\n",
      "Epoka 10650: Loss = 0.001491940\n",
      "Epoka 10660: Loss = 0.001599757\n",
      "Epoka 10670: Loss = 0.002463433\n",
      "Epoka 10680: Loss = 0.002558957\n",
      "Epoka 10690: Loss = 0.001686534\n",
      "Epoka 10700: Loss = 0.001607684\n",
      "Epoka 10710: Loss = 0.002396621\n",
      "Epoka 10720: Loss = 0.001374358\n",
      "Epoka 10730: Loss = 0.001954919\n",
      "Epoka 10740: Loss = 0.001374159\n",
      "Epoka 10750: Loss = 0.002158893\n",
      "Epoka 10760: Loss = 0.001336562\n",
      "Epoka 10770: Loss = 0.002202740\n",
      "Epoka 10780: Loss = 0.001273009\n",
      "Epoka 10790: Loss = 0.001244696\n",
      "Epoka 10800: Loss = 0.001616371\n",
      "Epoka 10810: Loss = 0.001583513\n",
      "Epoka 10820: Loss = 0.001324006\n",
      "Epoka 10830: Loss = 0.001755225\n",
      "Epoka 10840: Loss = 0.001265828\n",
      "Epoka 10850: Loss = 0.001408223\n",
      "Epoka 10860: Loss = 0.001356459\n",
      "Epoka 10870: Loss = 0.001528337\n",
      "Epoka 10880: Loss = 0.001396888\n",
      "Epoka 10890: Loss = 0.001485032\n",
      "Epoka 10900: Loss = 0.001969408\n",
      "Epoka 10910: Loss = 0.002865955\n",
      "Epoka 10920: Loss = 0.001388297\n",
      "Epoka 10930: Loss = 0.001555609\n",
      "Epoka 10940: Loss = 0.002524727\n",
      "Epoka 10950: Loss = 0.001352680\n",
      "Epoka 10960: Loss = 0.001576233\n",
      "Epoka 10970: Loss = 0.001568948\n",
      "Epoka 10980: Loss = 0.001356457\n",
      "Epoka 10990: Loss = 0.001326446\n",
      "Epoka 11000: Loss = 0.001281159\n",
      "Epoka 11010: Loss = 0.002937992\n",
      "Epoka 11020: Loss = 0.002082883\n",
      "Epoka 11030: Loss = 0.001477160\n",
      "Epoka 11040: Loss = 0.001489890\n",
      "Epoka 11050: Loss = 0.001306835\n",
      "Epoka 11060: Loss = 0.001661224\n",
      "Epoka 11070: Loss = 0.001344891\n",
      "Epoka 11080: Loss = 0.001506989\n",
      "Epoka 11090: Loss = 0.001227831\n",
      "Epoka 11100: Loss = 0.002190083\n",
      "Epoka 11110: Loss = 0.001482215\n",
      "Epoka 11120: Loss = 0.001324177\n",
      "Epoka 11130: Loss = 0.001398873\n",
      "Epoka 11140: Loss = 0.001320680\n",
      "Epoka 11150: Loss = 0.001440991\n",
      "Epoka 11160: Loss = 0.001901528\n",
      "Epoka 11170: Loss = 0.001338130\n",
      "Epoka 11180: Loss = 0.001395165\n",
      "Epoka 11190: Loss = 0.002383840\n",
      "Epoka 11200: Loss = 0.001571263\n",
      "Epoka 11210: Loss = 0.002692611\n",
      "Epoka 11220: Loss = 0.002501926\n",
      "Epoka 11230: Loss = 0.001282666\n",
      "Epoka 11240: Loss = 0.001934913\n",
      "Epoka 11250: Loss = 0.001248895\n",
      "Epoka 11260: Loss = 0.001920874\n",
      "Epoka 11270: Loss = 0.001394436\n",
      "Epoka 11280: Loss = 0.001377941\n",
      "Epoka 11290: Loss = 0.001379030\n",
      "Epoka 11300: Loss = 0.001696403\n",
      "Epoka 11310: Loss = 0.001413272\n",
      "Epoka 11320: Loss = 0.001421487\n",
      "Epoka 11330: Loss = 0.001245589\n",
      "Epoka 11340: Loss = 0.001394745\n",
      "Epoka 11350: Loss = 0.001466165\n",
      "Epoka 11360: Loss = 0.001276409\n",
      "Epoka 11370: Loss = 0.001231204\n",
      "Epoka 11380: Loss = 0.001292280\n",
      "Epoka 11390: Loss = 0.001369282\n",
      "Epoka 11400: Loss = 0.001351734\n",
      "Epoka 11410: Loss = 0.001309358\n",
      "Epoka 11420: Loss = 0.001865124\n",
      "Epoka 11430: Loss = 0.001462662\n",
      "Epoka 11440: Loss = 0.001217855\n",
      "Epoka 11450: Loss = 0.001324444\n",
      "Epoka 11460: Loss = 0.001969727\n",
      "Epoka 11470: Loss = 0.003108256\n",
      "Epoka 11480: Loss = 0.001311382\n",
      "Epoka 11490: Loss = 0.001257482\n",
      "Epoka 11500: Loss = 0.002324018\n",
      "Epoka 11510: Loss = 0.003012603\n",
      "Epoka 11520: Loss = 0.001304211\n",
      "Epoka 11530: Loss = 0.002854678\n",
      "Epoka 11540: Loss = 0.001405289\n",
      "Epoka 11550: Loss = 0.001226782\n",
      "Epoka 11560: Loss = 0.001626997\n",
      "Epoka 11570: Loss = 0.002297453\n",
      "Epoka 11580: Loss = 0.001547397\n",
      "Epoka 11590: Loss = 0.001355835\n",
      "Epoka 11600: Loss = 0.001279089\n",
      "Epoka 11610: Loss = 0.001880138\n",
      "Epoka 11620: Loss = 0.001872841\n",
      "Epoka 11630: Loss = 0.001652948\n",
      "Epoka 11640: Loss = 0.001347680\n",
      "Epoka 11650: Loss = 0.001340401\n",
      "Epoka 11660: Loss = 0.001854104\n",
      "Epoka 11670: Loss = 0.001397214\n",
      "Epoka 11680: Loss = 0.001201955\n",
      "Epoka 11690: Loss = 0.001200362\n",
      "Epoka 11700: Loss = 0.001193947\n",
      "Epoka 11710: Loss = 0.001440315\n",
      "Epoka 11720: Loss = 0.002653130\n",
      "Epoka 11730: Loss = 0.001215025\n",
      "Epoka 11740: Loss = 0.001872486\n",
      "Epoka 11750: Loss = 0.001344924\n",
      "Epoka 11760: Loss = 0.001384209\n",
      "Epoka 11770: Loss = 0.001639606\n",
      "Epoka 11780: Loss = 0.001240692\n",
      "Epoka 11790: Loss = 0.001337283\n",
      "Epoka 11800: Loss = 0.003147594\n",
      "Epoka 11810: Loss = 0.001544996\n",
      "Epoka 11820: Loss = 0.001364367\n",
      "Epoka 11830: Loss = 0.001255918\n",
      "Epoka 11840: Loss = 0.001912516\n",
      "Epoka 11850: Loss = 0.001170759\n",
      "Epoka 11860: Loss = 0.001330985\n",
      "Epoka 11870: Loss = 0.001216326\n",
      "Epoka 11880: Loss = 0.001260503\n",
      "Epoka 11890: Loss = 0.001467071\n",
      "Epoka 11900: Loss = 0.001175309\n",
      "Epoka 11910: Loss = 0.001391820\n",
      "Epoka 11920: Loss = 0.001305053\n",
      "Epoka 11930: Loss = 0.003843771\n",
      "Epoka 11940: Loss = 0.001233173\n",
      "Epoka 11950: Loss = 0.002041704\n",
      "Epoka 11960: Loss = 0.001221595\n",
      "Epoka 11970: Loss = 0.003740974\n",
      "Epoka 11980: Loss = 0.001401441\n",
      "Epoka 11990: Loss = 0.001403943\n",
      "Epoka 12000: Loss = 0.001660127\n",
      "Epoka 12010: Loss = 0.001680115\n",
      "Epoka 12020: Loss = 0.001894693\n",
      "Epoka 12030: Loss = 0.002209403\n",
      "Epoka 12040: Loss = 0.001436095\n",
      "Epoka 12050: Loss = 0.001262110\n",
      "Epoka 12060: Loss = 0.001627933\n",
      "Epoka 12070: Loss = 0.001759372\n",
      "Epoka 12080: Loss = 0.001355840\n",
      "Epoka 12090: Loss = 0.001696976\n",
      "Epoka 12100: Loss = 0.001208965\n",
      "Epoka 12110: Loss = 0.001309719\n",
      "Epoka 12120: Loss = 0.001220652\n",
      "Epoka 12130: Loss = 0.001727668\n",
      "Epoka 12140: Loss = 0.001426135\n",
      "Epoka 12150: Loss = 0.001656094\n",
      "Epoka 12160: Loss = 0.003523472\n",
      "Epoka 12170: Loss = 0.001423044\n",
      "Epoka 12180: Loss = 0.002790350\n",
      "Epoka 12190: Loss = 0.001616716\n",
      "Epoka 12200: Loss = 0.001352190\n",
      "Epoka 12210: Loss = 0.001173826\n",
      "Epoka 12220: Loss = 0.001581673\n",
      "Epoka 12230: Loss = 0.001208553\n",
      "Epoka 12240: Loss = 0.001305209\n",
      "Epoka 12250: Loss = 0.001306095\n",
      "Epoka 12260: Loss = 0.001244647\n",
      "Epoka 12270: Loss = 0.001252875\n",
      "Epoka 12280: Loss = 0.001333019\n",
      "Epoka 12290: Loss = 0.002851930\n",
      "Epoka 12300: Loss = 0.001639216\n",
      "Epoka 12310: Loss = 0.001403743\n",
      "Epoka 12320: Loss = 0.001247071\n",
      "Epoka 12330: Loss = 0.001240762\n",
      "Epoka 12340: Loss = 0.001941157\n",
      "Epoka 12350: Loss = 0.001220043\n",
      "Epoka 12360: Loss = 0.002116120\n",
      "Epoka 12370: Loss = 0.001190940\n",
      "Epoka 12380: Loss = 0.001601847\n",
      "Epoka 12390: Loss = 0.001327965\n",
      "Epoka 12400: Loss = 0.002994028\n",
      "Epoka 12410: Loss = 0.001235540\n",
      "Epoka 12420: Loss = 0.001327843\n",
      "Epoka 12430: Loss = 0.001462120\n",
      "Epoka 12440: Loss = 0.001481894\n",
      "Epoka 12450: Loss = 0.002036829\n",
      "Epoka 12460: Loss = 0.003159818\n",
      "Epoka 12470: Loss = 0.001308230\n",
      "Epoka 12480: Loss = 0.001365530\n",
      "Epoka 12490: Loss = 0.001166794\n",
      "Epoka 12500: Loss = 0.001471616\n",
      "Epoka 12510: Loss = 0.001274698\n",
      "Epoka 12520: Loss = 0.001980635\n",
      "Epoka 12530: Loss = 0.001188785\n",
      "Epoka 12540: Loss = 0.002035833\n",
      "Epoka 12550: Loss = 0.001324618\n",
      "Epoka 12560: Loss = 0.001222554\n",
      "Epoka 12570: Loss = 0.001414273\n",
      "Epoka 12580: Loss = 0.001324928\n",
      "Epoka 12590: Loss = 0.001862142\n",
      "Epoka 12600: Loss = 0.001320911\n",
      "Epoka 12610: Loss = 0.001341238\n",
      "Epoka 12620: Loss = 0.001186473\n",
      "Epoka 12630: Loss = 0.001301450\n",
      "Epoka 12640: Loss = 0.001206568\n",
      "Epoka 12650: Loss = 0.003545846\n",
      "Epoka 12660: Loss = 0.001210589\n",
      "Epoka 12670: Loss = 0.001357324\n",
      "Epoka 12680: Loss = 0.002646957\n",
      "Epoka 12690: Loss = 0.001209062\n",
      "Epoka 12700: Loss = 0.001604081\n",
      "Epoka 12710: Loss = 0.001532408\n",
      "Epoka 12720: Loss = 0.001517762\n",
      "Epoka 12730: Loss = 0.001592473\n",
      "Epoka 12740: Loss = 0.001523667\n",
      "Epoka 12750: Loss = 0.001309251\n",
      "Epoka 12760: Loss = 0.001578051\n",
      "Epoka 12770: Loss = 0.001352823\n",
      "Epoka 12780: Loss = 0.001412899\n",
      "Epoka 12790: Loss = 0.001309024\n",
      "Epoka 12800: Loss = 0.001362719\n",
      "Epoka 12810: Loss = 0.001445530\n",
      "Epoka 12820: Loss = 0.001231880\n",
      "Epoka 12830: Loss = 0.003535441\n",
      "Epoka 12840: Loss = 0.002866504\n",
      "Epoka 12850: Loss = 0.001454509\n",
      "Epoka 12860: Loss = 0.001271338\n",
      "Epoka 12870: Loss = 0.001413411\n",
      "Epoka 12880: Loss = 0.003869176\n",
      "Epoka 12890: Loss = 0.001651440\n",
      "Epoka 12900: Loss = 0.001454803\n",
      "Epoka 12910: Loss = 0.001179883\n",
      "Epoka 12920: Loss = 0.001155786\n",
      "Epoka 12930: Loss = 0.003553089\n",
      "Epoka 12940: Loss = 0.002233127\n",
      "Epoka 12950: Loss = 0.001186974\n",
      "Epoka 12960: Loss = 0.001219062\n",
      "Epoka 12970: Loss = 0.001591468\n",
      "Epoka 12980: Loss = 0.001790752\n",
      "Epoka 12990: Loss = 0.001167133\n",
      "Czas wykonania: 325.101375 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_multimodalL2 = MLPNoBackprop(layer_sizes = [1, 26, 1])\n",
    "start_time = time.time()\n",
    "mlp_multimodalL2.RMSprop(X_multimodalL_train_normalized, Y_multimodalL_train_normalized, epochs = 13000, learning_rate=0.005, beta=0.8, epsilon=1e-7, batch_size=64)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "3c986729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.241974818875493\n"
     ]
    }
   ],
   "source": [
    "ypred_normalized = mlp_multimodalL2.predict(X_multimodalL_test_normalized)\n",
    "ypred = ypred_normalized *np.std(Y_multimodalL_train) +np.mean(Y_multimodalL_train)\n",
    "print(mlp_multimodalL.mse(ypred, Y_multimodalL_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf3956",
   "metadata": {},
   "source": [
    "# --------------------------------------------NN4-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e9e6b",
   "metadata": {},
   "source": [
    "For this checkpoint I will be working on classification tasks.  \n",
    "My goal is to implement the softmax activation function and the F-measure. I will be testing my implementation on the following datasets:\n",
    "- rings3-regular\n",
    "- easy\n",
    "- xor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb52d5",
   "metadata": {},
   "source": [
    "## Rings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb24c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ringsR_train = pd.read_csv('rings3-regular-training.csv')\n",
    "df_ringsR_test = pd.read_csv('rings3-regular-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59f7f817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-93.563317</td>\n",
       "      <td>-76.345110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.060114</td>\n",
       "      <td>-16.727040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.396099</td>\n",
       "      <td>40.358822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-94.595137</td>\n",
       "      <td>-97.889250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-85.331382</td>\n",
       "      <td>-56.736933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y  c\n",
       "0 -93.563317 -76.345110  0\n",
       "1   1.060114 -16.727040  0\n",
       "2  24.396099  40.358822  0\n",
       "3 -94.595137 -97.889250  0\n",
       "4 -85.331382 -56.736933  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ringsR_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "948e1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ringsR_train = np.array(df_ringsR_train[['x', 'y']])\n",
    "Y_ringsR_train = np.array(df_ringsR_train[['c']])\n",
    "X_ringsR_test = np.array(df_ringsR_test[['x', 'y']])\n",
    "Y_ringsR_test = np.array(df_ringsR_test[['c']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dfd37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ringsR_train_normalized = (X_ringsR_train - np.mean(X_ringsR_train))/np.std(X_ringsR_train)\n",
    "X_ringsR_test_normalized = (X_ringsR_test - np.mean(X_ringsR_train))/np.std(X_ringsR_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2911d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_ringsR_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a002d7b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(Y_ringsR_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cfd5f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ringsR_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd18cc",
   "metadata": {},
   "source": [
    "### 3 classes = 3 output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "62950e18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 0.345832389\n",
      "Epoka 10: Loss = 0.487297847\n",
      "Epoka 20: Loss = 0.515250248\n",
      "Epoka 30: Loss = 0.586956605\n",
      "Epoka 40: Loss = 0.673377072\n",
      "Epoka 50: Loss = 0.665696699\n",
      "Epoka 60: Loss = 0.728956351\n",
      "Epoka 70: Loss = 0.766794820\n",
      "Epoka 80: Loss = 0.796551723\n",
      "Epoka 90: Loss = 0.815065282\n",
      "Epoka 100: Loss = 0.814810098\n",
      "Epoka 110: Loss = 0.817860277\n",
      "Epoka 120: Loss = 0.827107554\n",
      "Epoka 130: Loss = 0.833424927\n",
      "Epoka 140: Loss = 0.832154282\n",
      "Epoka 150: Loss = 0.830196838\n",
      "Epoka 160: Loss = 0.841095375\n",
      "Epoka 170: Loss = 0.851527329\n",
      "Epoka 180: Loss = 0.854931869\n",
      "Epoka 190: Loss = 0.864061882\n",
      "Epoka 200: Loss = 0.869062719\n",
      "Epoka 210: Loss = 0.876959817\n",
      "Epoka 220: Loss = 0.882142740\n",
      "Epoka 230: Loss = 0.883355413\n",
      "Epoka 240: Loss = 0.892072471\n",
      "Epoka 250: Loss = 0.892854051\n",
      "Epoka 260: Loss = 0.893379089\n",
      "Epoka 270: Loss = 0.887339519\n",
      "Epoka 280: Loss = 0.896877297\n",
      "Epoka 290: Loss = 0.884918168\n",
      "Epoka 300: Loss = 0.897540590\n",
      "Epoka 310: Loss = 0.902773472\n",
      "Epoka 320: Loss = 0.902230342\n",
      "Epoka 330: Loss = 0.903344462\n",
      "Epoka 340: Loss = 0.910093690\n",
      "Epoka 350: Loss = 0.903383403\n",
      "Epoka 360: Loss = 0.899877576\n",
      "Epoka 370: Loss = 0.909167043\n",
      "Epoka 380: Loss = 0.913306478\n",
      "Epoka 390: Loss = 0.911485312\n",
      "Epoka 400: Loss = 0.909294752\n",
      "Epoka 410: Loss = 0.924059757\n",
      "Epoka 420: Loss = 0.918583439\n",
      "Epoka 430: Loss = 0.916129746\n",
      "Epoka 440: Loss = 0.929999799\n",
      "Epoka 450: Loss = 0.924659713\n",
      "Epoka 460: Loss = 0.926497372\n",
      "Epoka 470: Loss = 0.925144147\n",
      "Epoka 480: Loss = 0.928057459\n",
      "Epoka 490: Loss = 0.927341243\n",
      "Epoka 500: Loss = 0.920033746\n",
      "Epoka 510: Loss = 0.932683163\n",
      "Epoka 520: Loss = 0.930002880\n",
      "Epoka 530: Loss = 0.932524972\n",
      "Epoka 540: Loss = 0.934019453\n",
      "Epoka 550: Loss = 0.927586615\n",
      "Epoka 560: Loss = 0.935996784\n",
      "Epoka 570: Loss = 0.928218358\n",
      "Epoka 580: Loss = 0.926568624\n",
      "Epoka 590: Loss = 0.924217206\n",
      "Epoka 600: Loss = 0.922404792\n",
      "Epoka 610: Loss = 0.940012105\n",
      "Epoka 620: Loss = 0.934599004\n",
      "Epoka 630: Loss = 0.939428202\n",
      "Epoka 640: Loss = 0.933456482\n",
      "Epoka 650: Loss = 0.940082895\n",
      "Epoka 660: Loss = 0.938779980\n",
      "Epoka 670: Loss = 0.944615909\n",
      "Epoka 680: Loss = 0.941362414\n",
      "Epoka 690: Loss = 0.941920254\n",
      "Epoka 700: Loss = 0.933456406\n",
      "Epoka 710: Loss = 0.941974085\n",
      "Epoka 720: Loss = 0.934676221\n",
      "Epoka 730: Loss = 0.948038079\n",
      "Epoka 740: Loss = 0.944696030\n",
      "Epoka 750: Loss = 0.936088591\n",
      "Epoka 760: Loss = 0.930013693\n",
      "Epoka 770: Loss = 0.946057803\n",
      "Epoka 780: Loss = 0.939941189\n",
      "Epoka 790: Loss = 0.943367279\n",
      "Epoka 800: Loss = 0.950009544\n",
      "Epoka 810: Loss = 0.938041155\n",
      "Epoka 820: Loss = 0.943953055\n",
      "Epoka 830: Loss = 0.948026635\n",
      "Epoka 840: Loss = 0.935372547\n",
      "Epoka 850: Loss = 0.938113916\n",
      "Epoka 860: Loss = 0.947991342\n",
      "Epoka 870: Loss = 0.941956232\n",
      "Epoka 880: Loss = 0.924800847\n",
      "Epoka 890: Loss = 0.941175619\n",
      "Epoka 900: Loss = 0.945882357\n",
      "Epoka 910: Loss = 0.948118807\n",
      "Epoka 920: Loss = 0.946059740\n",
      "Epoka 930: Loss = 0.940736556\n",
      "Epoka 940: Loss = 0.939897633\n",
      "Epoka 950: Loss = 0.939355618\n",
      "Epoka 960: Loss = 0.939373702\n",
      "Epoka 970: Loss = 0.950015026\n",
      "Epoka 980: Loss = 0.948762009\n",
      "Epoka 990: Loss = 0.946695344\n",
      "Czas wykonania: 9.731229 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_ringsR = MLPNoBackprop(layer_sizes = [X_ringsR_train.shape[1], 10, len(np.unique(Y_ringsR_train))], \n",
    "                           output_activation='softmax')\n",
    "start_time = time.time()\n",
    "mlp_ringsR.classifiaction_train(X_ringsR_train_normalized, Y_ringsR_train, epochs = 1000, learning_rate=0.01, batch_size=10)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24eff698",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = mlp_ringsR.predict_classification(X_ringsR_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "05d145e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344786081912858"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_ringsR.f1_score(Y_ringsR_test, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5300f5",
   "metadata": {},
   "source": [
    "# easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8799adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_easy_train = pd.read_csv('easy-training.csv')\n",
    "df_easy_test = pd.read_csv('easy-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15a9c578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-72.829461</td>\n",
       "      <td>-40.239391</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-65.464396</td>\n",
       "      <td>-60.501516</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.389589</td>\n",
       "      <td>74.223994</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-92.335628</td>\n",
       "      <td>17.466916</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-61.058421</td>\n",
       "      <td>-16.761820</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y      c\n",
       "0 -72.829461 -40.239391  False\n",
       "1 -65.464396 -60.501516  False\n",
       "2  14.389589  74.223994  False\n",
       "3 -92.335628  17.466916  False\n",
       "4 -61.058421 -16.761820  False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_easy_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca7703",
   "metadata": {},
   "source": [
    "### False = 0, True = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c1ea163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x          y  c\n",
      "0 -72.829461 -40.239391  0\n",
      "1 -65.464396 -60.501516  0\n",
      "2  14.389589  74.223994  0\n",
      "3 -92.335628  17.466916  0\n",
      "4 -61.058421 -16.761820  0\n"
     ]
    }
   ],
   "source": [
    "df_easy_train['c'] = df_easy_train['c'].replace({True: 1, False: 0})\n",
    "print(df_easy_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0ca60f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x          y  c\n",
      "0  88.836312  35.105689  1\n",
      "1   8.454690  57.210448  0\n",
      "2 -57.221426  29.312467  0\n",
      "3 -11.922723 -88.264355  1\n",
      "4   8.885765   6.605795  1\n"
     ]
    }
   ],
   "source": [
    "df_easy_test['c'] = df_easy_test['c'].replace({True: 1, False: 0})\n",
    "print(df_easy_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93599b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_easy_train = np.array(df_easy_train[['x', 'y']])\n",
    "X_easy_test = np.array(df_easy_test[['x', 'y']])\n",
    "Y_easy_train = np.array(df_easy_train[['c']])\n",
    "Y_easy_test = np.array(df_easy_test[['c']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6250d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_easy_train_normalized = (X_easy_train - np.mean(X_easy_train))/np.std(X_easy_train)\n",
    "X_easy_test_normalized = (X_easy_test - np.mean(X_easy_train))/np.std(X_easy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2339e3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(Y_easy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "caeacaa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 0.869867916\n",
      "Epoka 10: Loss = 0.981999352\n",
      "Epoka 20: Loss = 0.993999784\n",
      "Epoka 30: Loss = 0.997999992\n",
      "Epoka 40: Loss = 0.996000000\n",
      "Epoka 50: Loss = 0.989999000\n",
      "Epoka 60: Loss = 0.997999992\n",
      "Epoka 70: Loss = 0.995999936\n",
      "Epoka 80: Loss = 0.991999488\n",
      "Epoka 90: Loss = 0.991999488\n",
      "Epoka 100: Loss = 0.997999992\n",
      "Epoka 110: Loss = 0.993999784\n",
      "Epoka 120: Loss = 0.995999936\n",
      "Epoka 130: Loss = 0.997999992\n",
      "Epoka 140: Loss = 0.997999992\n",
      "Epoka 150: Loss = 0.997999992\n",
      "Epoka 160: Loss = 0.997999992\n",
      "Epoka 170: Loss = 0.997999992\n",
      "Epoka 180: Loss = 0.997999992\n",
      "Epoka 190: Loss = 0.995999936\n",
      "Epoka 200: Loss = 0.997999992\n",
      "Epoka 210: Loss = 0.995999936\n",
      "Epoka 220: Loss = 0.997999992\n",
      "Epoka 230: Loss = 0.997999992\n",
      "Epoka 240: Loss = 0.997999992\n",
      "Epoka 250: Loss = 0.995999936\n",
      "Epoka 260: Loss = 0.995999936\n",
      "Epoka 270: Loss = 0.995999936\n",
      "Epoka 280: Loss = 0.995999936\n",
      "Epoka 290: Loss = 0.997999992\n",
      "Epoka 300: Loss = 0.995999936\n",
      "Epoka 310: Loss = 0.995999936\n",
      "Epoka 320: Loss = 0.997999992\n",
      "Epoka 330: Loss = 0.997999992\n",
      "Epoka 340: Loss = 0.995999936\n",
      "Epoka 350: Loss = 0.997999992\n",
      "Epoka 360: Loss = 0.997999992\n",
      "Epoka 370: Loss = 1.000000000\n",
      "Epoka 380: Loss = 1.000000000\n",
      "Epoka 390: Loss = 0.995999936\n",
      "Epoka 400: Loss = 0.997999992\n",
      "Epoka 410: Loss = 0.995999936\n",
      "Epoka 420: Loss = 0.997999992\n",
      "Epoka 430: Loss = 0.997999992\n",
      "Epoka 440: Loss = 1.000000000\n",
      "Epoka 450: Loss = 1.000000000\n",
      "Epoka 460: Loss = 1.000000000\n",
      "Epoka 470: Loss = 1.000000000\n",
      "Epoka 480: Loss = 1.000000000\n",
      "Epoka 490: Loss = 0.997999992\n",
      "Epoka 500: Loss = 0.997999992\n",
      "Epoka 510: Loss = 1.000000000\n",
      "Epoka 520: Loss = 1.000000000\n",
      "Epoka 530: Loss = 1.000000000\n",
      "Epoka 540: Loss = 0.997999992\n",
      "Epoka 550: Loss = 0.997999992\n",
      "Epoka 560: Loss = 1.000000000\n",
      "Epoka 570: Loss = 1.000000000\n",
      "Epoka 580: Loss = 0.995999936\n",
      "Epoka 590: Loss = 1.000000000\n",
      "Epoka 600: Loss = 1.000000000\n",
      "Epoka 610: Loss = 0.997999992\n",
      "Epoka 620: Loss = 0.997999992\n",
      "Epoka 630: Loss = 1.000000000\n",
      "Epoka 640: Loss = 1.000000000\n",
      "Epoka 650: Loss = 0.997999992\n",
      "Epoka 660: Loss = 0.997999992\n",
      "Epoka 670: Loss = 0.997999992\n",
      "Epoka 680: Loss = 1.000000000\n",
      "Epoka 690: Loss = 0.997999992\n",
      "Epoka 700: Loss = 1.000000000\n",
      "Epoka 710: Loss = 1.000000000\n",
      "Epoka 720: Loss = 1.000000000\n",
      "Epoka 730: Loss = 1.000000000\n",
      "Epoka 740: Loss = 0.997999992\n",
      "Epoka 750: Loss = 1.000000000\n",
      "Epoka 760: Loss = 1.000000000\n",
      "Epoka 770: Loss = 1.000000000\n",
      "Epoka 780: Loss = 1.000000000\n",
      "Epoka 790: Loss = 1.000000000\n",
      "Epoka 800: Loss = 1.000000000\n",
      "Epoka 810: Loss = 1.000000000\n",
      "Epoka 820: Loss = 1.000000000\n",
      "Epoka 830: Loss = 1.000000000\n",
      "Epoka 840: Loss = 1.000000000\n",
      "Epoka 850: Loss = 1.000000000\n",
      "Epoka 860: Loss = 1.000000000\n",
      "Epoka 870: Loss = 1.000000000\n",
      "Epoka 880: Loss = 1.000000000\n",
      "Epoka 890: Loss = 0.997999992\n",
      "Epoka 900: Loss = 1.000000000\n",
      "Epoka 910: Loss = 1.000000000\n",
      "Epoka 920: Loss = 1.000000000\n",
      "Epoka 930: Loss = 1.000000000\n",
      "Epoka 940: Loss = 1.000000000\n",
      "Epoka 950: Loss = 1.000000000\n",
      "Epoka 960: Loss = 1.000000000\n",
      "Epoka 970: Loss = 1.000000000\n",
      "Epoka 980: Loss = 0.997999992\n",
      "Epoka 990: Loss = 1.000000000\n",
      "Epoka 1000: Loss = 1.000000000\n",
      "Epoka 1010: Loss = 1.000000000\n",
      "Epoka 1020: Loss = 1.000000000\n",
      "Epoka 1030: Loss = 1.000000000\n",
      "Epoka 1040: Loss = 1.000000000\n",
      "Epoka 1050: Loss = 1.000000000\n",
      "Epoka 1060: Loss = 1.000000000\n",
      "Epoka 1070: Loss = 1.000000000\n",
      "Epoka 1080: Loss = 1.000000000\n",
      "Epoka 1090: Loss = 1.000000000\n",
      "Epoka 1100: Loss = 1.000000000\n",
      "Epoka 1110: Loss = 1.000000000\n",
      "Epoka 1120: Loss = 1.000000000\n",
      "Epoka 1130: Loss = 1.000000000\n",
      "Epoka 1140: Loss = 1.000000000\n",
      "Epoka 1150: Loss = 1.000000000\n",
      "Epoka 1160: Loss = 1.000000000\n",
      "Epoka 1170: Loss = 1.000000000\n",
      "Epoka 1180: Loss = 1.000000000\n",
      "Epoka 1190: Loss = 1.000000000\n",
      "Epoka 1200: Loss = 1.000000000\n",
      "Epoka 1210: Loss = 1.000000000\n",
      "Epoka 1220: Loss = 1.000000000\n",
      "Epoka 1230: Loss = 1.000000000\n",
      "Epoka 1240: Loss = 1.000000000\n",
      "Epoka 1250: Loss = 1.000000000\n",
      "Epoka 1260: Loss = 1.000000000\n",
      "Epoka 1270: Loss = 1.000000000\n",
      "Epoka 1280: Loss = 1.000000000\n",
      "Epoka 1290: Loss = 1.000000000\n",
      "Epoka 1300: Loss = 1.000000000\n",
      "Epoka 1310: Loss = 1.000000000\n",
      "Epoka 1320: Loss = 1.000000000\n",
      "Epoka 1330: Loss = 1.000000000\n",
      "Epoka 1340: Loss = 1.000000000\n",
      "Epoka 1350: Loss = 1.000000000\n",
      "Epoka 1360: Loss = 1.000000000\n",
      "Epoka 1370: Loss = 1.000000000\n",
      "Epoka 1380: Loss = 1.000000000\n",
      "Epoka 1390: Loss = 1.000000000\n",
      "Epoka 1400: Loss = 1.000000000\n",
      "Epoka 1410: Loss = 1.000000000\n",
      "Epoka 1420: Loss = 1.000000000\n",
      "Epoka 1430: Loss = 1.000000000\n",
      "Epoka 1440: Loss = 1.000000000\n",
      "Epoka 1450: Loss = 1.000000000\n",
      "Epoka 1460: Loss = 1.000000000\n",
      "Epoka 1470: Loss = 1.000000000\n",
      "Epoka 1480: Loss = 1.000000000\n",
      "Epoka 1490: Loss = 1.000000000\n",
      "Czas wykonania: 6.761494 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_easy = MLPNoBackprop(layer_sizes = [X_easy_train.shape[1], 10, len(np.unique(Y_easy_train))], \n",
    "                           output_activation='softmax')\n",
    "start_time = time.time()\n",
    "mlp_easy.classifiaction_train(X_easy_train_normalized, Y_easy_train, epochs = 1500, learning_rate=0.015, batch_size=24)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9b7df4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = mlp_easy.predict_classification(X_easy_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7cea1b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979999279974079"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_ringsR.f1_score(Y_easy_test, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db8447",
   "metadata": {},
   "source": [
    "# XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "976f6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xor3_train = pd.read_csv('xor3-training.csv')\n",
    "df_xor3_test = pd.read_csv('xor3-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "341f8ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.720316</td>\n",
       "      <td>18.198653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.039419</td>\n",
       "      <td>-71.390360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.072781</td>\n",
       "      <td>-76.340256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.434100</td>\n",
       "      <td>-21.863272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.198218</td>\n",
       "      <td>-24.730234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y  c\n",
       "0  -5.720316  18.198653  0\n",
       "1  50.039419 -71.390360  0\n",
       "2  93.072781 -76.340256  0\n",
       "3  10.434100 -21.863272  0\n",
       "4  30.198218 -24.730234  0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xor3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91e04784",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xor3_train = np.array(df_xor3_train[['x', 'y']])\n",
    "X_xor3_test = np.array(df_xor3_test[['x', 'y']])\n",
    "Y_xor3_train = np.array(df_xor3_train[['c']])\n",
    "Y_xor3_test = np.array(df_xor3_test[['c']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0c075b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xor3_train_normalized = (X_xor3_train - np.mean(X_xor3_train))/np.std( X_xor3_train)\n",
    "X_xor3_test_normalized = (X_xor3_test - np.mean(X_xor3_train))/np.std( X_xor3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50d6158d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 0.333333333\n",
      "Epoka 10: Loss = 0.333333333\n",
      "Epoka 20: Loss = 0.333333333\n",
      "Epoka 30: Loss = 0.333333333\n",
      "Epoka 40: Loss = 0.333333333\n",
      "Epoka 50: Loss = 0.573383966\n",
      "Epoka 60: Loss = 0.520403041\n",
      "Epoka 70: Loss = 0.333333333\n",
      "Epoka 80: Loss = 0.495537072\n",
      "Epoka 90: Loss = 0.600612937\n",
      "Epoka 100: Loss = 0.328337104\n",
      "Epoka 110: Loss = 0.684317884\n",
      "Epoka 120: Loss = 0.766351375\n",
      "Epoka 130: Loss = 0.772470089\n",
      "Epoka 140: Loss = 0.699779570\n",
      "Epoka 150: Loss = 0.774408224\n",
      "Epoka 160: Loss = 0.775641026\n",
      "Epoka 170: Loss = 0.776777634\n",
      "Epoka 180: Loss = 0.777028737\n",
      "Epoka 190: Loss = 0.783378885\n",
      "Epoka 200: Loss = 0.783378885\n",
      "Epoka 210: Loss = 0.786190315\n",
      "Epoka 220: Loss = 0.788965933\n",
      "Epoka 230: Loss = 0.783510882\n",
      "Epoka 240: Loss = 0.790916109\n",
      "Epoka 250: Loss = 0.790521923\n",
      "Epoka 260: Loss = 0.789357703\n",
      "Epoka 270: Loss = 0.792002391\n",
      "Epoka 280: Loss = 0.788080334\n",
      "Epoka 290: Loss = 0.788961039\n",
      "Epoka 300: Loss = 0.789513265\n",
      "Epoka 310: Loss = 0.800909782\n",
      "Epoka 320: Loss = 0.805151239\n",
      "Epoka 330: Loss = 0.831932773\n",
      "Epoka 340: Loss = 0.836792920\n",
      "Epoka 350: Loss = 0.851712916\n",
      "Epoka 360: Loss = 0.867788462\n",
      "Epoka 370: Loss = 0.867864693\n",
      "Epoka 380: Loss = 0.879506458\n",
      "Epoka 390: Loss = 0.874941505\n",
      "Epoka 400: Loss = 0.893989399\n",
      "Epoka 410: Loss = 0.901911721\n",
      "Epoka 420: Loss = 0.917855096\n",
      "Epoka 430: Loss = 0.915837061\n",
      "Epoka 440: Loss = 0.931960809\n",
      "Epoka 450: Loss = 0.931972789\n",
      "Epoka 460: Loss = 0.933883370\n",
      "Epoka 470: Loss = 0.933997624\n",
      "Epoka 480: Loss = 0.941997912\n",
      "Epoka 490: Loss = 0.949954959\n",
      "Epoka 500: Loss = 0.951987709\n",
      "Epoka 510: Loss = 0.967995391\n",
      "Epoka 520: Loss = 0.957991766\n",
      "Epoka 530: Loss = 0.961998632\n",
      "Epoka 540: Loss = 0.969979706\n",
      "Epoka 550: Loss = 0.967997952\n",
      "Epoka 560: Loss = 0.977995687\n",
      "Epoka 570: Loss = 0.975999616\n",
      "Epoka 580: Loss = 0.979997120\n",
      "Epoka 590: Loss = 0.981999352\n",
      "Epoka 600: Loss = 0.973997400\n",
      "Epoka 610: Loss = 0.975999616\n",
      "Epoka 620: Loss = 0.983998976\n",
      "Epoka 630: Loss = 0.971998208\n",
      "Epoka 640: Loss = 0.977999912\n",
      "Epoka 650: Loss = 0.981996471\n",
      "Epoka 660: Loss = 0.979999680\n",
      "Epoka 670: Loss = 0.971978031\n",
      "Epoka 680: Loss = 0.975999616\n",
      "Epoka 690: Loss = 0.983998976\n",
      "Epoka 700: Loss = 0.987999232\n",
      "Epoka 710: Loss = 0.983999744\n",
      "Epoka 720: Loss = 0.973999064\n",
      "Epoka 730: Loss = 0.983997696\n",
      "Epoka 740: Loss = 0.973994903\n",
      "Epoka 750: Loss = 0.981998200\n",
      "Epoka 760: Loss = 0.981999928\n",
      "Epoka 770: Loss = 0.993999784\n",
      "Epoka 780: Loss = 0.987999232\n",
      "Epoka 790: Loss = 0.983998976\n",
      "Czas wykonania: 4.964230 sekundy\n"
     ]
    }
   ],
   "source": [
    "mlp_xor3 = MLPNoBackprop(layer_sizes = [X_xor3_train.shape[1], 20, 20,len(np.unique(Y_xor3_train))], \n",
    "                           output_activation='softmax')\n",
    "start_time = time.time()\n",
    "mlp_xor3.classifiaction_train(X_xor3_train_normalized, Y_xor3_train, epochs = 800, learning_rate=0.01, batch_size=64)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "623e64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = mlp_xor3.predict_classification(X_xor3_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ae96ae6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9712643678160919"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_xor3.f1_score(Y_xor3_test, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c0530",
   "metadata": {},
   "source": [
    "# --------------------------------------NN5---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932aabd9",
   "metadata": {},
   "source": [
    "Now, I need to compare the performance and learning speed of neural networks with varying numbers of neurons in hidden layers and different activation functions. The objective is to evaluate how different activation functions affect the effectiveness and training time of networks with one, two, and three hidden layers. It is essential to take into account that various activation functions may lead to different outcomes depending on the number of neurons and layers used in the network.\n",
    "\n",
    "The first part of this analysis will focus on preliminary tests using the multimodal-large dataset for regression. I will compare the performance of networks with different architectures (one, two, and three hidden layers) and four different activation functions. Afterward, I will select the two best performing architectures for further testing on other datasets.\n",
    "\n",
    "The datasets I will use for the additional testing are:\n",
    "\n",
    "Regression: steps-large\n",
    "\n",
    "Classification: rings5-regular and rings3-regular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58514b03",
   "metadata": {},
   "source": [
    "multimodal Large is already loaded and normalized\n",
    "X_multimodalL_train_normalized = (X_multimodalL_train- np.mean(X_multimodalL_train))/(np.std(X_multimodalL_train))\n",
    "Y_multimodalL_train_normalized = (Y_multimodalL_train- np.mean(Y_multimodalL_train))/(np.std(Y_multimodalL_train))\n",
    "X_multimodalL_test_normalized = (X_multimodalL_test- np.mean(X_multimodalL_train))/(np.std(X_multimodalL_train))\n",
    "Y_multimodalL_test_normalized = (Y_multimodalL_test- np.mean(Y_multimodalL_train))/(np.std(Y_multimodalL_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35ca92",
   "metadata": {},
   "source": [
    "## testing diffrent architektures and activation functions for multimodal Large "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c03f5b",
   "metadata": {},
   "source": [
    "## One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1ccdf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 61.855260 seconds\n",
      "            for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "3575.611735447458\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.495157 seconds\n",
      "            for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "3573.342154682163\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.048052 seconds\n",
      "            for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "3573.5144308695963\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 75.686884 seconds\n",
      "            for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "3573.511788537501\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 79.550264 seconds\n",
      "            for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "3573.097388850761\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 83.449688 seconds\n",
      "            for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "3573.337738432998\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 80.435521 seconds\n",
      "            for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "3573.117124474574\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.506746 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "1103.774841460628\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.010366 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "500.3762746577972\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.016020 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "502.6383942728361\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.821543 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "1084.0592536011056\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.408084 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "582.0691406502041\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.626583 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "526.2377820800252\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 26.284785 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "532.3894027992469\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 19.476298 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "1324.8147538098985\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 20.329746 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "1605.8184648900244\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 22.346225 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "819.8636217214761\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 23.467721 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "1608.4154882223754\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 23.854836 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "1607.765270836222\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 25.851096 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "1612.0914529996787\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 26.951613 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "1614.3595239890828\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 18.544343 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "3542.6925787373657\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 20.054889 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "3550.9651612488024\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 21.601101 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "3499.852261346214\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 23.621046 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "3505.0230106720805\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 24.055429 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "3522.5437925953133\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 25.132796 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "3521.6202184447243\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 26.306851 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "3524.1336847359257\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 17.462850 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "3560.358189026437\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 17.558969 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "3560.354249075601\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 19.317115 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "3560.3532435165903\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 21.962413 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "3560.3319549680605\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 27.579331 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "3560.2956123000226\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.568055 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "3560.2931517447764\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.472312 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "3560.270204600186\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 38.344748 seconds\n",
      "            for one layer with linear hidden activation and linear output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "4435.9400051844195\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.304127 seconds\n",
      "            for one layer with linear hidden activation and linear output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "4435.375385783639\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.648562 seconds\n",
      "            for one layer with linear hidden activation and linear output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "4434.107928602078\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.413913 seconds\n",
      "            for one layer with linear hidden activation and linear output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "4438.058191213062\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.899209 seconds\n",
      "            for one layer with linear hidden activation and linear output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "4435.929708549725\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.820727 seconds\n",
      "            for one layer with linear hidden activation and linear output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "4435.898541819194\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.265923 seconds\n",
      "            for one layer with linear hidden activation and linear output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "4447.780269671973\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.632144 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "3335.8511655693937\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.751114 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "3335.8494390747455\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.971772 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "3335.852653419109\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.073294 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "3335.8489622014213\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.420949 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "3335.851635320168\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.502052 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "3335.852120976975\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.419051 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "3335.8382376859086\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.224376 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "3886.388097541342\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.048741 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "3887.7368588774893\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.940840 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "3886.53085546072\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.608793 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "3886.498652144784\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.411846 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "3888.1657916545696\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.357097 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "3886.6635531212864\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.800035 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "3891.1411657818935\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.469004 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "3560.4063375916417\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.934672 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "3560.3980207774366\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.096150 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "3560.392418293744\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.292370 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "3560.3366650202247\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.158851 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "3560.3020933697253\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 76.131916 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "3560.251705905781\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 80.294879 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "3560.2370342724284\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.656283 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "1081.3510487774297\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 48.619278 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "436.6073282956269\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.265607 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "219.11147372485905\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.979923 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "217.5243125533719\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.375017 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "140.02646790855755\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.852149 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "238.7517874992998\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 68.589499 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "249.78282693043508\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.745462 seconds\n",
      "            for one layer with tanh hidden activation and tanh output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "1210.8793768881135\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.351587 seconds\n",
      "            for one layer with tanh hidden activation and tanh output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "712.2243902287364\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.136701 seconds\n",
      "            for one layer with tanh hidden activation and tanh output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "3335.8858745469915\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.523560 seconds\n",
      "            for one layer with tanh hidden activation and tanh output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "3335.873757680067\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.177573 seconds\n",
      "            for one layer with tanh hidden activation and tanh output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "3335.8656037965916\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.227854 seconds\n",
      "            for one layer with tanh hidden activation and tanh output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "3335.857109774909\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.757594 seconds\n",
      "            for one layer with tanh hidden activation and tanh output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "3335.849053799537\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.672096 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "3276.7637024563037\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.357213 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "3272.425132223458\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.433625 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "3294.738999313896\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.984690 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "3308.1756362596266\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.549326 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "3306.55365266228\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.481482 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "3356.0783293685195\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 389.423187 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "3370.9573082980687\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 18.442112 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "3562.18437246696\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 19.379630 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "3562.1749163847194\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 20.804917 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "3562.163694827779\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 22.094187 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "3562.127059984068\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 20.926043 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "3562.0852497763167\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 22.129513 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "3561.5300841390394\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 23.149967 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "3562.064295146975\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 15.075908 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "3261.2647692266733\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 16.111743 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "2891.2834117533425\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 17.036476 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "2812.3008407298953\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 18.405018 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "2804.1204064192493\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 17.962111 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "2689.684389028565\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 19.361424 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "2792.988794461785\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 19.372368 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "2801.4973528231403\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 16.290415 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "2627.9531407602917\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 17.025429 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "2628.0858998946233\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 19.273302 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "2627.988981841981\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 20.301609 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "2627.948149939829\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 19.549095 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "1845.1535137620479\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 20.412464 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "1845.3649062329064\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 20.462232 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "1845.0985345161553\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 16.256140 seconds\n",
      "            for one layer with relu hidden activation and relu output activation\n",
      "            one layer with 3 neurons\n",
      "mse:\n",
      "3887.212030275402\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 16.372443 seconds\n",
      "            for one layer with relu hidden activation and relu output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "3887.629131305049\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 18.121195 seconds\n",
      "            for one layer with relu hidden activation and relu output activation\n",
      "            one layer with 8 neurons\n",
      "mse:\n",
      "3888.8710138100396\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 19.314014 seconds\n",
      "            for one layer with relu hidden activation and relu output activation\n",
      "            one layer with 11 neurons\n",
      "mse:\n",
      "3393.0203765695383\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 19.376518 seconds\n",
      "            for one layer with relu hidden activation and relu output activation\n",
      "            one layer with 19 neurons\n",
      "mse:\n",
      "3560.825301016964\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 19.840494 seconds\n",
      "            for one layer with relu hidden activation and relu output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "3624.315677572534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 20.320291 seconds\n",
      "            for one layer with relu hidden activation and relu output activation\n",
      "            one layer with 30 neurons\n",
      "mse:\n",
      "3180.979467282476\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "activation_functions =['sigmoid', 'linear', 'tanh', 'relu']\n",
    "num_neurons = [3, 5, 8, 11, 19, 25, 30]\n",
    "\n",
    "for hidden_function in activation_functions:\n",
    "    for output_function in activation_functions:\n",
    "        for neurons in num_neurons:\n",
    "            mlp_multimodal = MLPNoBackprop(layer_sizes = [1, neurons, 1], hidden_activation=hidden_function, output_activation=output_function)\n",
    "            start_time = time.time()\n",
    "            mlp_multimodal.mini_batch_GD(X_multimodalL_train_normalized, Y_multimodalL_train_normalized, epochs = 1000, learning_rate = 0.01, batch_size=32)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            print(f\"\"\"Execution time: {execution_time:.6f} seconds\n",
    "            for one layer with {hidden_function} hidden activation and {output_function} output activation\n",
    "            one layer with {neurons} neurons\"\"\")\n",
    "            Ypred_normalized = mlp_multimodal.predict(X_multimodalL_test_normalized)\n",
    "            Ypred = (Ypred_normalized * np.std(Y_multimodalL_train)) + np.mean(Y_multimodalL_train)\n",
    "            print('mse:')\n",
    "            print(mlp_multimodal.mse(Ypred, Y_multimodalL_test))\n",
    "            print('--------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e36c7",
   "metadata": {},
   "source": [
    "BEST PARAMETERS = 19 NEURONS, hidden activation tanh, output activation linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf4a17",
   "metadata": {},
   "source": [
    "## two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afd26730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 37.289423 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.594444563065\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.123062 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.530269448439\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.787863 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.515827180531\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.402138 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "10358.490697833087\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.682791 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.518667133537\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.935812 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.4953411316055\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.960862 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "10359.894367982772\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.500454 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "10359.886460524116\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.673579 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.358626526474\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.706063 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.366476984377\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.499086 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.34725948895\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 63.810621 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "10359.89773522103\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.159431 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.330388569257\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.573710 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.344667110251\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.915375 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "10359.895311086306\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 69.033874 seconds\n",
      "                for one layer with sigmoid hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "10359.89806166586\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 34.982362 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "296.26131772259816\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.145852 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "311.83695114207603\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.937467 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "291.0733906266787\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.381117 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "346.39759895627736\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.172559 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "362.71767896755097\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.396671 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "275.47780355717464\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.426684 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "373.92797433978177\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.704494 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "403.49148901061375\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.841847 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "465.95444686717457\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.562762 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "462.69451978789436\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 57.710276 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "479.5986843679383\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.568743 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "454.45014857775465\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.652165 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "444.86971146844\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.795386 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "500.29565118288536\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.457371 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "460.4478788199677\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 63.996250 seconds\n",
      "                for one layer with sigmoid hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "508.5469307846045\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 35.894114 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "1411.049185982165\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.271217 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "1598.1252580828743\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.532322 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "10359.899356704616\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.818242 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "10359.899356871485\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.340019 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "741.3071286441174\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.629898 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "10359.8962646556\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.741723 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "10359.899355960733\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.607898 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "10359.899356889571\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.204959 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "764.0746804982564\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.953121 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "10359.89349768824\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.603510 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "10359.899356849412\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.833862 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "10359.899356888141\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.326426 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "1224.719404693974\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.991001 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "10359.889598546812\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.361311 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "10359.899352824024\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.752645 seconds\n",
      "                for one layer with sigmoid hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "10359.89935688116\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 35.276892 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.254028 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.818841 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.465086 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 40.756397 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.784639 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.908736 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.045397 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.042675 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.892950 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.126632 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.680077 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.474254 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.249152 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.972369 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.477596 seconds\n",
      "                for one layer with sigmoid hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 28.096870 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3557.688241720547\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 33.547491 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3557.650548196584\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 34.246637 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3557.6333498411486\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 36.300224 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3557.6283900889403\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 34.070051 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3557.6540497876335\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 36.052221 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3557.6341903437415\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.880494 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3557.6393252514463\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.507566 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3557.6595506278945\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 34.519501 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3557.635621115368\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.816554 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3557.6078100433506\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.609004 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3557.667289773116\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.341607 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3557.629956596682\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 35.998528 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3557.6299741799626\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.207244 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3557.6284472698467\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 49.594914 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3557.6023029195107\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.927688 seconds\n",
      "                for one layer with linear hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3557.6397615249602\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 25.005977 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "4435.471971998568\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:105: RuntimeWarning: overflow encountered in matmul\n",
      "  z = activation @ self.weights[i] + self.biases[i]\n",
      "C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:189: RuntimeWarning: overflow encountered in matmul\n",
      "  delta = (delta @ self.weights[i+1].T) * self.hidden_derivative(activations[i] @ self.weights[i] + self.biases[i])\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:190: RuntimeWarning: invalid value encountered in matmul\n",
      "  gradient = activations[i].T @ delta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 29.471925 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 31.825626 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:185: RuntimeWarning: overflow encountered in matmul\n",
      "  last_gradient_descent = activations[-2].T @ delta\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:190: RuntimeWarning: overflow encountered in matmul\n",
      "  gradient = activations[i].T @ delta\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  delta = (delta @ self.weights[i+1].T) * self.hidden_derivative(activations[i] @ self.weights[i] + self.biases[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 31.840608 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 29.836609 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 30.724278 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 37.455591 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.905378 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 31.061810 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 36.647365 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.396813 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:108: RuntimeWarning: overflow encountered in matmul\n",
      "  z = activation @ self.weights[-1] + self.biases[-1]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:108: RuntimeWarning: invalid value encountered in matmul\n",
      "  z = activation @ self.weights[-1] + self.biases[-1]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:184: RuntimeWarning: overflow encountered in matmul\n",
      "  delta = error * self.output_derivative(activations[-2] @ self.weights[-1] + self.biases[-1])\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:184: RuntimeWarning: invalid value encountered in matmul\n",
      "  delta = error * self.output_derivative(activations[-2] @ self.weights[-1] + self.biases[-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 46.160653 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 32.815435 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.688262 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.839473 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.050282 seconds\n",
      "                for one layer with linear hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 26.185753 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3335.8524501761917\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 31.804043 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3335.82643946612\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 32.306345 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3335.8392252950475\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 33.568935 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3335.822256683838\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 32.208676 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3335.8695917856903\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 32.933319 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3335.8222980893083\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.895700 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3335.8561412175086\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.676591 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3335.840383966195\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 32.679380 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3335.840291899921\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 38.832018 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3335.869538068124\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.943335 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3335.8190082915553\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.569340 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3335.8719910255822\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 33.520351 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3335.9250638585427\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.361299 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3335.8881339326886\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.608678 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3335.819010059354\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.905788 seconds\n",
      "                for one layer with linear hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3336.168488242069\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 26.153566 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 30.784710 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 32.068619 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 33.132520 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 31.930070 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 32.959535 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:185: RuntimeWarning: invalid value encountered in matmul\n",
      "  last_gradient_descent = activations[-2].T @ delta\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:105: RuntimeWarning: invalid value encountered in add\n",
      "  z = activation @ self.weights[i] + self.biases[i]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:189: RuntimeWarning: invalid value encountered in add\n",
      "  delta = (delta @ self.weights[i+1].T) * self.hidden_derivative(activations[i] @ self.weights[i] + self.biases[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 38.544827 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.986253 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 31.995055 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 38.135017 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.171499 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.303461 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 33.592100 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.843874 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:105: RuntimeWarning: invalid value encountered in matmul\n",
      "  z = activation @ self.weights[i] + self.biases[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 45.666873 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.136383 seconds\n",
      "                for one layer with linear hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "nan\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 35.307399 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3557.7086451344653\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.878374 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3557.718180723902\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.121349 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3557.687168862228\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.674891 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3557.63527286594\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.911226 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3557.7486368027444\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.909811 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3557.678588681191\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.794397 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3557.6401233163333\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.250300 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3557.6616813114433\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.195879 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3557.7086810403684\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.153453 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3557.703202568158\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.796226 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3557.6308184943273\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.481094 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3557.6510039319814\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.948347 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3557.7228724942875\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.019667 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3557.7097100301057\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.116805 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3557.621674703499\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 72.989281 seconds\n",
      "                for one layer with tanh hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3557.6672547965495\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 34.371805 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "70.42394818615917\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.598376 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "1118.7471594249475\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.908705 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "110.0245103867537\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.681424 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "46.304405018899864\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.727785 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "1447.2177262276966\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.353382 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "1597.5710583636496\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.577852 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "72.95370535153077\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.001293 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "114.70711620297051\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 44.964857 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "1655.3978217396964\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.694923 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "1591.2107291337982\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.990112 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "1593.5493265502848\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.588783 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "1328.6704230484772\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.400522 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "1587.1262189423207\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.621292 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "1586.629770849019\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.376552 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "1592.935344263799\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 71.167232 seconds\n",
      "                for one layer with tanh hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "1434.6896274828985\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 33.463871 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3335.950602751445\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 38.713642 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3335.9904841559833\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.383347 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3335.909236848938\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.244165 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3336.083629679046\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.538813 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3336.014237523022\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.943424 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3335.9387896544154\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.343028 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3335.8570966409816\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.689513 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3336.197494318891\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.074129 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "1851.854099143094\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.712361 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "1868.225573950369\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.932562 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3335.7197249358196\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.012472 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3335.650039510709\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.853687 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "1847.6450859747686\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.923881 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3335.7438734203706\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 63.467073 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3335.734473210845\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 68.891530 seconds\n",
      "                for one layer with tanh hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3335.7374059182375\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 34.353439 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3177.1598140224824\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.779915 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3175.779834353562\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 44.403322 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "4377.498603553673\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.641886 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "4370.751698676899\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.416201 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3484.455070069463\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.328756 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "4369.922370214511\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.017864 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3174.426359527972\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.956146 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "4370.159363595895\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.640642 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3487.3338135793824\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.444178 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3179.1388332874317\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.885244 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3178.997550058598\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.868173 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3176.0244617664393\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.564251 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3487.132916657286\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.117014 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3486.9998842168247\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.737475 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3488.936930776626\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.751207 seconds\n",
      "                for one layer with tanh hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3178.3704707267307\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 31.631564 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3559.348416829615\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 35.608935 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3559.3347057888604\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 37.401410 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3559.2830963297197\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.907345 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3559.278652100685\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 35.494263 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3559.3350963230446\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 38.293990 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3559.3041538551647\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.899145 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3559.259816708125\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.325366 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3559.2629461312104\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 37.861904 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3559.3104512672285\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.768182 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3559.2873498184526\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.975999 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3559.2549441841115\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.889901 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3559.235949204642\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 40.354622 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3559.293544714184\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.561067 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "3558.47278257001\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.906898 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "3559.2332837061463\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.465761 seconds\n",
      "                for one layer with relu hidden activation and sigmoid output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "3559.2263355731898\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 28.734590 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "737.570064305674\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 32.963719 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "1186.5876999242828\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 34.140229 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.6631570918025\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 35.474817 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.391101762949\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 32.291870 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.627637260647\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 34.264099 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.381727638383\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.315884 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "4258.045442662289\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.239133 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.50508593968\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 34.253315 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5222.860915891245\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.889278 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.642618339868\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.757702 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.32511207902\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.874350 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.7717639309485\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 36.394876 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5225.101295090698\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.421034 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5222.295633315956\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.318206 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5224.249878285667\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.791938 seconds\n",
      "                for one layer with relu hidden activation and linear output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5222.978112315716\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 30.266476 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "2627.7233502685663\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 35.340786 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "2627.623877784433\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 36.988328 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "2628.227255797395\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.632102 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "2627.5986447541786\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 35.289773 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "2627.7138963980988\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 37.534533 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "2627.703013073407\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 43.621181 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "2627.628011374906\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.240605 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "1844.632299615596\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 37.933081 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "1845.1543030056032\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.599078 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "1844.507877416622\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.754393 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "1844.5505072170508\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.947596 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "2627.303743292909\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.330730 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "1844.74933205648\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.763628 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "1844.3561215822003\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.307151 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "2627.296818541241\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.712605 seconds\n",
      "                for one layer with relu hidden activation and tanh output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "2477.7196160224166\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 31.561950 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "3190.2571105728334\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 36.185720 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "4850.274649587592\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 38.039360 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.039994 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 10 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 36.075107 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 38.927092 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.280324 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.155097 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 15 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.683604 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.679713 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.268645 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.762588 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 25 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.310601 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 10 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.957569 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 15 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.492028 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 25 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.319496 seconds\n",
      "                for one layer with relu hidden activation and relu output activation\n",
      "                one layer with 30 neurons in first hidden layer and 30 in second hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "activation_functions =['sigmoid', 'linear', 'tanh', 'relu']\n",
    "num_neurons = [10, 15, 25, 30]\n",
    "\n",
    "for hidden_function in activation_functions:\n",
    "    for output_function in activation_functions:\n",
    "        for neuron1 in num_neurons:\n",
    "            for neuron2 in num_neurons:\n",
    "                mlp_multimodal = MLPNoBackprop(layer_sizes = [1, neuron1, neuron2, 1], hidden_activation=hidden_function, output_activation=output_function)\n",
    "                start_time = time.time()\n",
    "                mlp_multimodal.mini_batch_GD(X_multimodalL_train_normalized, Y_multimodalL_train_normalized, epochs = 1000, learning_rate = 0.01, batch_size=32)\n",
    "                end_time = time.time()\n",
    "                execution_time = end_time - start_time\n",
    "                print(f\"\"\"Execution time: {execution_time:.6f} seconds\n",
    "                for one layer with {hidden_function} hidden activation and {output_function} output activation\n",
    "                one layer with {neuron1} neurons in first hidden layer and {neuron2} in second hidden layer\"\"\")\n",
    "                Ypred_normalized = mlp_multimodal.predict(X_multimodalL_test_normalized)\n",
    "                Ypred = (Ypred_normalized * np.std(Y_multimodalL_train)) + np.mean(Y_multimodalL_train)\n",
    "                print('mse:')\n",
    "                print(mlp_multimodal.mse(Ypred, Y_multimodalL_test))\n",
    "                print('--------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f5c0e",
   "metadata": {},
   "source": [
    "BEST PARAMETERS: 10 neurons in first hidden layer, 30 neuronos in second hidden layer, tanh hidden activation, linear output activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a32ad",
   "metadata": {},
   "source": [
    "## three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f345ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 53.965802 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "424.130045113064\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.162102 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "425.0017848756298\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.448978 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "448.27902738757416\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.691800 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "376.5628806863682\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.003945 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "420.2470193816448\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.060384 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "446.7587557418127\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.361863 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "427.2629596079755\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.032741 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "540.1857786955073\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.785109 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "451.90120032345595\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.306782 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "449.0576742637686\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.974283 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "451.77830239700086\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.221125 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "446.0848527768655\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.837608 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "392.1810576899072\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.364317 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1637.564380416083\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.547320 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "533.3693830522336\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.653297 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "460.7147275474422\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.550079 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "336.1187652353253\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.383076 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "300.10413735873254\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.607317 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "358.1962742916222\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.734634 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "334.09594178809596\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.553137 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "346.5978566931718\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.108037 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "321.5831344505268\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 59.905518 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "310.7727873850894\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.973827 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "309.4081851475596\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.792895 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "696.9368084490321\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.116158 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "391.24802885418575\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 63.953707 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "449.8126663945782\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.758313 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "393.53153377860053\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.805117 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1690.445279892367\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.182231 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1732.761300475948\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 68.681808 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "471.00497367844076\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.870235 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "457.43086760571225\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.210170 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "312.87894769964703\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.180205 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "281.92805200600424\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.519298 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "415.40465058339385\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.560123 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "318.6185595771453\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.885147 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "335.39058522830254\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.832236 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "305.53399936969623\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.086937 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "371.54927173689947\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.303700 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "370.0984499401408\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.728945 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "336.43883708941394\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 63.694387 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "5181.6377762646325\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.227817 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "382.6444114345421\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.411590 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "381.7077150047714\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 65.299707 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "5249.14897328369\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 68.535875 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "5224.36040978385\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 72.184076 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2549.1976150605924\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 76.322527 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "5221.5960896056795\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.850861 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "468.31628818216166\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.354125 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "442.2969903465141\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.991749 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "471.7719633590914\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.983646 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "473.28148903389473\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.162999 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "531.7495294168845\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.068367 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "447.18465237684416\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.729660 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "494.79950006764955\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.365934 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "487.86386546494833\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.449296 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "5236.664299764078\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.680449 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "5223.5154312937475\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.493691 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3098.47891769038\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 74.554952 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "5532.325964297703\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.443773 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "5223.156321909825\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.868584 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "5288.427111031783\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 76.991152 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "5277.604871635519\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 78.517080 seconds\n",
      "                    for one layer with sigmoid hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "5230.879974974266\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.748474 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5990170741197\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.908363 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6216315589863\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 44.529261 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.605744344822\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.428116 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5819053989712\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.729731 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.582346364997\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.857118 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6159246822963\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.837259 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5961769080573\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.755179 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.581389195145\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.950760 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.599210081813\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.494945 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5890884846267\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.492040 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6033526327956\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.606462 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6063790798366\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.156110 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.589288096132\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.784275 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.583532780735\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.477658 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5820592268183\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.722724 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.609422144157\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.267861 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.596729431433\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.036796 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6207632438054\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.285044 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6091243344795\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.597003 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.583577057078\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.898235 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6200947960847\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.205940 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6384953210522\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.600502 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6725847203106\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.969903 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.617543917129\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 47.895679 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.581326905652\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.271102 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6156685802007\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.056175 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6600122309683\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.129286 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.913840668209\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.332580 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5880285590606\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.794826 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5830670341393\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.492018 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5967147478686\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.264876 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.588238636245\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.412633 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6035814371185\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.855705 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.597267051278\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.467379 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.654945834103\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.134789 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5812670028145\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.928175 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5944955992995\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.192498 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6501920564147\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.762905 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.584596231098\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.053112 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.633583074215\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.277479 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.674060909665\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.619244 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.601970204096\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.189925 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.703311362702\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.986353 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.750771843384\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.901783 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.644041122146\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.450599 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.603786747276\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15336\\2693131919.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 58.896792 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.8931593032617\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 63.395206 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.739889121701\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.188435 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5961532084066\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.550078 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.583318891353\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.005785 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5828151285573\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.281860 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.668529003634\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.051913 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5814953458867\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.148850 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.641090715765\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.339142 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.609393522221\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.977701 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6533172725635\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.745814 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.5975162097384\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.860077 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6402149855394\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.837547 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.603184957715\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.055196 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3558.6196636093996\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.035597 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.605596364794\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.555518 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.593148622446\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.893185 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6269273352664\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.410490 seconds\n",
      "                    for one layer with linear hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3560.93150798631\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 37.445308 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8281200995993\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 38.430412 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.818192909763\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.499812 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3336.117394427223\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.663757 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8235961435576\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 38.743745 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8163558785113\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.140582 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8507976571714\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.766987 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.940424268509\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.840328 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8729718941936\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.658156 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.819754479358\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.388919 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8723180452034\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.393684 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.819886164482\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.309554 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.847400557734\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.561816 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3336.0766613383526\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.872131 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.858390865353\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.936466 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.9265583511224\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.337289 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3336.157886353932\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 38.443473 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.907923145193\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 39.511864 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.9192136949832\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.356318 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3336.034644584559\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.415623 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3336.0703875604263\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 40.267395 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.82140477917\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.342308 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.899672186792\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.827321 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.9245375921673\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.466236 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.813491054154\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.335461 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.829384614815\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.362821 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8287037629884\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 48.840312 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.9954772617957\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.207165 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.870745883517\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.736737 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.868239417172\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.147931 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.9397177501132\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.958799 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8270748832406\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.126809 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8401132538047\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.729664 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8362427051843\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.868170 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.816788637018\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.114129 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8433121746602\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.630692 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8704686922933\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.815048 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8284485734875\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.710997 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8592581768007\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.626093 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3336.005876455895\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.710614 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3336.314874056356\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.944345 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8410312845676\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.243783 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.817126606018\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.574593 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8450698681377\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.195854 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8339423088582\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.484363 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8323698532386\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.793685 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8354951371357\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.987083 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.839634477613\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.061263 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.819832786751\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 41.858786 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3336.033582043394\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.323119 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8409091540793\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.465425 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.816793759497\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.743101 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.839354214098\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.891149 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.817573712709\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.742194 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.9543514603497\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.944421 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8206230602823\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.448529 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8167511222946\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.380659 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.886680301198\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.028564 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.819411298748\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.974764 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8181872026603\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.392403 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8623988312565\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.923757 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3335.8370073014125\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.096553 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3335.9521215683426\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.504825 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3335.821610585033\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.691513 seconds\n",
      "                    for one layer with linear hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3390.491428552335\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.958832 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.840031342427\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.227083 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7785574095064\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.079360 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.713210191617\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.222270 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7058744595984\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.278898 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.843161970621\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.436185 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.8425623603216\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 58.532979 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.8294852027298\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.868432 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.772815690345\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.523970 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.953336071155\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.179786 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.862428253913\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.020609 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.811936214247\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.359935 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7073826425594\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.534053 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.85456596204\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.363173 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.76711071792\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.408461 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7727099603044\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 69.387035 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.708083879787\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.467437 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7847004765795\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.641967 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7827044145056\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.291701 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.756318352796\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.785859 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6925112281506\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.982695 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.806942100402\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.686832 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.8047626035277\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.401254 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7290560548145\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.582114 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.8974757788924\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.056339 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.643090880642\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.062505 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.755776653248\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.884528 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.790883302086\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 71.630294 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7314548319464\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 60.780211 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.163888313148\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.734955 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.802937550508\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 71.646237 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.760233621737\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 73.372011 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7089209343226\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.678760 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.8263457806743\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.555627 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7844063051084\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.346487 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.727616981952\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.743402 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.8085146252074\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.724208 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.596412336916\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.045515 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.82667176388\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 63.972988 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6821953170825\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 69.091758 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.814301327452\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.145398 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.1849168262797\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.647567 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7490200298303\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 69.013615 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.82669492253\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 74.475262 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6858682927345\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.504730 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.421663746285\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.933713 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6227823704558\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 75.332721 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6362601110823\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 80.286970 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.654098137241\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.849313 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.722422578028\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.866993 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.799323702758\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 60.719742 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.778149456589\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.505141 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.681506325819\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.441160 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6447555801983\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.490003 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.724825024897\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.988038 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7337033140593\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 69.479130 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.7673684554566\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.492663 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3557.2469491314273\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 69.293925 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.693604047589\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 73.380523 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.788813752392\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 78.127740 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.626050734394\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 68.939270 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3556.7357925216725\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 73.608561 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3557.3884672147224\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 80.554393 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.6193364913806\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 82.723299 seconds\n",
      "                    for one layer with tanh hidden activation and sigmoid output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3557.503536204556\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.332494 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "54.309223538211185\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.070117 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3.776318578885831\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.578781 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2.7570474255530053\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.273215 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2.414594584388581\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.392883 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1588.140903821256\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.795464 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "24.31695722893476\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.148015 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "14.273722784754911\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.092718 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "11.932388655793707\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 51.723110 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1665.3282189037145\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.397024 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1585.8076134541561\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.651181 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1586.8433325362619\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.489398 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1610.5776205908442\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.024666 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1656.284001893414\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.875223 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1582.7733409792875\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.979825 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1612.4310499582593\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 68.381733 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1589.5929435221801\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.553343 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1584.1222020370626\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.112269 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "14.093487544946809\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.070620 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "27.016252245307605\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.453082 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "10.26948204726066\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.605774 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1584.037093749324\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.154879 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1262.0537012753207\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.244790 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "9.754557590800125\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.541757 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "8.39634123075945\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.380428 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1654.945140523003\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.496018 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1597.329217238797\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 63.908089 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1606.2845754248772\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 68.949867 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1654.0981617378281\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.203109 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1653.8634726181076\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.990655 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1582.7472741602553\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 69.124771 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1581.9663943704786\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 71.998750 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1588.0895438477244\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.366231 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "417.7302439365594\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.752903 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1438.5834777346727\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.694558 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1131.046944765091\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.415352 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1119.2538987725368\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.523626 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1653.8827824217706\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.377607 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1587.5839668290785\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.209500 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1119.2445117604816\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.241106 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1430.5008154074667\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.787274 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1652.775500056624\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.456288 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1266.9972052595285\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.246798 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1598.5860090758827\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 71.209676 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1583.4921329827089\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.511543 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1653.8243293070561\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.584968 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1587.050674797267\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 73.051061 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1671.2978883097544\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 77.626693 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1585.0351088352431\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.567155 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1441.6584894988282\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.794312 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "56.31944967382259\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.837398 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1444.5167127973828\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.124425 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1438.7322208835083\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 55.781426 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1667.308259946593\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.731164 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1595.4615624268215\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.439628 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1583.6399370170805\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.988019 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "40.345013900579126\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.157849 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1589.9795496448564\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.705853 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1585.335404013402\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.977369 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1598.8045051178196\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 75.633746 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1663.8136468476384\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.965277 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1659.324371239186\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.628941 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "1662.401723015997\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 77.445664 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "1654.5882722776678\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 79.897305 seconds\n",
      "                    for one layer with tanh hidden activation and linear output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "1660.972546059118\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.219209 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3174.9801424823477\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.145664 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "4371.632911185549\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.544936 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3174.2061667324383\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.867736 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 48.391051 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3485.6184437619336\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.231427 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3174.3955764770776\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.327068 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3174.380411865562\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.922872 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "4369.096803456586\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.207981 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3482.962118823004\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.435953 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3174.476786374008\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 61.536808 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3174.2358440127964\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.049291 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.111127 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3482.975822456698\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.000637 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3174.4713902286935\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 65.283963 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "4369.110044749622\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.916725 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.046240 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3174.5557986023473\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.647081 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3174.211017856528\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.519766 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3493.424689883115\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.312961 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "5221.396095604534\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.136935 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3554.743286759614\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.289277 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3174.316619378522\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.227038 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3174.218087316258\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.351729 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3174.3559184065984\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.628890 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3558.811694960923\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.796267 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3174.4174684277077\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.190120 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3175.071119543826\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.035938 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3174.2062905337466\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.960253 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3553.7062439274814\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 63.096217 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3484.4336505396914\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.479212 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3488.00308293674\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 72.740604 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3174.3949435966547\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 51.551700 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3175.4324818717605\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.024923 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3174.5098105721668\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.276991 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3174.1083845397793\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.248355 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3176.6444843925237\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.418099 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3483.331118124965\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.110655 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3489.904635266071\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.737352 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3174.423361958017\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.034246 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3174.4842774085637\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.635541 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3553.475502632983\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.333084 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3483.1218843523843\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.889971 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3483.2639816079336\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 72.791203 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3174.2336574711717\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.610828 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3554.051836944273\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 69.050502 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3559.0562452109066\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 74.044262 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3557.051012797681\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 78.639269 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3553.856243854181\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.440286 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3175.1786771095503\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.815093 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3176.495365176001\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.048206 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3175.499679345296\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.108448 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3485.542045631894\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.998430 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3175.1223751797256\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.870217 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3174.7090812154124\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 66.585597 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3483.408369777318\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 68.497440 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3174.1648036118754\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 63.814703 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3553.759224009\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.865928 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3553.076571407197\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 71.579435 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3482.0823825394186\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 76.080323 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3482.929924042199\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 67.387814 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "3553.344653315772\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 71.498899 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "3553.684736190558\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 78.481096 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "3553.526789573636\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 81.088513 seconds\n",
      "                    for one layer with tanh hidden activation and relu output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "3555.580210339918\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.622247 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.6551604201522\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.106085 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.7123079917783\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.120135 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.6406469921067\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.145159 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.559434257469\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 43.410766 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.69431414052\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.229626 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.577943830084\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.211050 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.8049195032127\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.036561 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.76864592018\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.062372 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.5281268040258\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.791773 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.686501289077\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.822473 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.32123543591\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.976982 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.408870196169\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 47.512144 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.513688665959\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.285292 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3835663191167\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.623044 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.5608462135974\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 56.840412 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 5 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3324853913737\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.968595 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2628.050600010686\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 44.142959 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2628.006153756765\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.818693 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.567685663921\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.001996 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.398710999814\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.232484 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.4657599217203\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.170524 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3811598945626\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.007972 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.5221583233943\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.109514 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.577799647833\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.809648 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2628.1213858788105\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.889175 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3777205022857\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.157173 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.2932792320908\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.716333 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.5080095358257\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.596252 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.648008722091\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.545314 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.721589446424\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.466610 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3124771063876\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.386335 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 10 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3085052933347\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.801759 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "1845.3019084002362\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.037318 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.395744135272\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 47.975680 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3087606754543\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.871406 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.604707083229\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.736534 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.349604994899\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.278299 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3113216192282\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.051766 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3300587099993\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.311511 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.794869718855\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.480021 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.624680893688\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 54.559561 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.419111554164\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.064977 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3008297530264\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.488276 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.4354899068817\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.593800 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3319677184177\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 58.393057 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.5420285555665\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 61.375639 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.322321037391\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 64.717383 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 15 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.2893602713348\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 45.499900 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.935905953943\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 47.187872 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.371620170686\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.252135 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.3265651452366\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 50.360653 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 5 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.317506784786\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 49.552495 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.375674556558\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 51.234167 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.296041605032\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.125865 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.366654103092\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 55.642191 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 10 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.511597139364\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 54.813377 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.34679737233\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.426910 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.312040122603\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 59.046901 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.7517897840385\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 8437.072088 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 15 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.4063306810635\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.912139 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 5 neurons in third hidden layer\n",
      "mse:\n",
      "2627.338068513373\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 60.839791 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 10 neurons in third hidden layer\n",
      "mse:\n",
      "2627.693583703929\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 68.799251 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 15 neurons in third hidden layer\n",
      "mse:\n",
      "2627.7072257685504\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 70.804664 seconds\n",
      "                    for one layer with relu hidden activation and tanh output activation\n",
      "                    one layer with 20 neurons in first hidden layer and 20 in second hidden layer\n",
      "                    and 20 neurons in third hidden layer\n",
      "mse:\n",
      "2627.371082076456\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "activation_functions =['sigmoid', 'linear', 'tanh', 'relu']\n",
    "num_neurons = [5, 10, 15, 20]\n",
    "\n",
    "for hidden_function in activation_functions:\n",
    "    for output_function in activation_functions:\n",
    "        if hidden_function == output_function:\n",
    "            continue\n",
    "        if hidden_function =='sigmoid' and (output_function =='tanh' or output_function == 'relu'):\n",
    "            continue\n",
    "        if hidden_function =='relu' and (output_function =='sigmoid' or output_function =='linear'):\n",
    "            continue \n",
    "        if hidden_function =='linear' and output_function =='relu':\n",
    "            continue            \n",
    "        for neuron1 in num_neurons:\n",
    "            for neuron2 in num_neurons:\n",
    "                for neuron3 in num_neurons:\n",
    "                    mlp_multimodal = MLPNoBackprop(layer_sizes = [1, neuron1, neuron2, neuron3, 1], hidden_activation=hidden_function, output_activation=output_function)\n",
    "                    start_time = time.time()\n",
    "                    mlp_multimodal.mini_batch_GD(X_multimodalL_train_normalized, Y_multimodalL_train_normalized, epochs = 1000, learning_rate = 0.01, batch_size=32)\n",
    "                    end_time = time.time()\n",
    "                    execution_time = end_time - start_time\n",
    "                    print(f\"\"\"Execution time: {execution_time:.6f} seconds\n",
    "                    for one layer with {hidden_function} hidden activation and {output_function} output activation\n",
    "                    one layer with {neuron1} neurons in first hidden layer and {neuron2} in second hidden layer\n",
    "                    and {neuron3} neurons in third hidden layer\"\"\")\n",
    "                    Ypred_normalized = mlp_multimodal.predict(X_multimodalL_test_normalized)\n",
    "                    Ypred = (Ypred_normalized * np.std(Y_multimodalL_train)) + np.mean(Y_multimodalL_train)\n",
    "                    print('mse:')\n",
    "                    print(mlp_multimodal.mse(Ypred, Y_multimodalL_test))\n",
    "                    print('--------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddbbec4",
   "metadata": {},
   "source": [
    "BEST PARAMETRS: 5 NEURONS in first hidden layer, 5 neurons in second hidden layer, 20 neourns in third hidden layer, tanh hidden activation\n",
    "linear output activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f2df2",
   "metadata": {},
   "source": [
    "## BEST MSE WAS ACHIVED ON MLP WITH 3 HIDDEN LAYERS, 5,5,20. TANH HIDDEN ACTIVATION AND LINEAR OUTPUT ACTIVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16643040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wykonania: 125.875894 sekundy\n",
      "mse:\n",
      "2.663257009847435\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mlp_multimodal = MLPNoBackprop(layer_sizes = [1, 5, 5, 20, 1], hidden_activation='tanh')\n",
    "start_time = time.time()\n",
    "mlp_multimodal.mini_batch_GD(X_multimodalL_train_normalized, Y_multimodalL_train_normalized, batch_size = 32, epochs=2000, learning_rate=0.01)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {execution_time:.6f} sekundy\")\n",
    "Ypred_normalized = mlp_multimodal.predict(X_multimodalL_test_normalized)\n",
    "Ypred = (Ypred_normalized * np.std(Y_multimodalL_train)) + np.mean(Y_multimodalL_train)\n",
    "print('mse:')\n",
    "print(mlp_multimodal.mse(Ypred, Y_multimodalL_test))\n",
    "print('--------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3600cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_value = mlp_multimodal.mse(Ypred, Y_multimodalL_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "199407cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_multimodalL_test, Y_multimodalL_test, label='True Data', color='blue', alpha=0.5)\n",
    "plt.scatter(X_multimodalL_test, Ypred, label=f'Predicted Data (MSE: {mse_value:.4f})', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Interactive MLP Regression for Square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751cfc1",
   "metadata": {},
   "source": [
    "# now lets move on to additional testing on step-large and rings5-regular and ring3-regular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19d27e",
   "metadata": {},
   "source": [
    "stepsL and rings3-regular are already loaded a normalized.  \n",
    "X_stepsL_train_normalized = (X_stepsL_train- np.mean(X_stepsL_train))/(np.std(X_stepsL_train))\n",
    "Y_stepsL_train_normalized =(Y_stepsL_train - np.mean(Y_stepsL_train))/(np.std(Y_stepsL_train))\n",
    "X_stepsL_test_normalized = (X_stepsL_test - np.mean(X_stepsL_train))/(np.std(X_stepsL_train))\n",
    "Y_stepsL_test_normalized =(Y_stepsL_test - np.mean(Y_stepsL_train))/(np.std(Y_stepsL_train)) \n",
    "\n",
    "X_ringsR_train = np.array(df_ringsR_train[['x', 'y']])  \n",
    "Y_ringsR_train = np.array(df_ringsR_train[['c']])  \n",
    "X_ringsR_test = np.array(df_ringsR_test[['x', 'y']])  \n",
    "Y_ringsR_test = np.array(df_ringsR_test[['c']])  \n",
    "X_ringsR_train_normalized = (X_ringsR_train - np.mean(X_ringsR_train))/np.std(X_ringsR_train)  \n",
    "X_ringsR_test_normalized = (X_ringsR_test - np.mean(X_ringsR_train))/np.std(X_ringsR_train)    \n",
    "\n",
    "Lets load ring5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1528f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ringsR5_train = pd.read_csv('rings5-regular-training.csv')\n",
    "df_ringsR5_test = pd.read_csv('rings5-regular-test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49166c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.926121</td>\n",
       "      <td>-16.588451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-77.438767</td>\n",
       "      <td>95.159464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-98.650099</td>\n",
       "      <td>94.923714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.241184</td>\n",
       "      <td>-5.447678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.843637</td>\n",
       "      <td>-21.496457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y  c\n",
       "0  26.926121 -16.588451  0\n",
       "1 -77.438767  95.159464  0\n",
       "2 -98.650099  94.923714  0\n",
       "3  22.241184  -5.447678  0\n",
       "4  12.843637 -21.496457  0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ringsR5_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca047813",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ringsR5_train = np.array(df_ringsR5_train[['x', 'y']])  \n",
    "Y_ringsR5_train = np.array(df_ringsR5_train[['c']])  \n",
    "X_ringsR5_test = np.array(df_ringsR5_test[['x', 'y']])  \n",
    "Y_ringsR5_test = np.array(df_ringsR5_test[['c']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d934cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ringsR5_train_normalized = (X_ringsR5_train - np.mean(X_ringsR5_train))/np.std(X_ringsR5_train)  \n",
    "X_ringsR5_test_normalized = (X_ringsR5_test - np.mean(X_ringsR5_train))/np.std(X_ringsR5_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863f59c",
   "metadata": {},
   "source": [
    "## stepsLarge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ce187",
   "metadata": {},
   "source": [
    "lets test in on one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2c45a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 37.009719 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7302.438220727504\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 41.592634 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7301.556950814843\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 42.604982 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7302.4268297343\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 46.742369 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7301.789860376223\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 22.376419 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7333.8320100199335\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 16.102063 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7333.939161850611\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 16.763377 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7333.745593361773\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 18.709317 seconds\n",
      "            for one layer with sigmoid hidden activation and tanh output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7333.708384377928\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 13.993636 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7354.884432272471\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 15.710971 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7353.817017109094\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 16.249216 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7355.843508201676\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 17.787510 seconds\n",
      "            for one layer with sigmoid hidden activation and relu output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7355.180143951703\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 11.550500 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7373.295202068209\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 12.247978 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7373.295435672588\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 13.370682 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7373.282732952036\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 13.922421 seconds\n",
      "            for one layer with linear hidden activation and sigmoid output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7373.269258539557\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 11.195593 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7333.904318876222\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 11.286225 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7333.691492969575\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 12.490950 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7333.8314874447715\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 12.532033 seconds\n",
      "            for one layer with linear hidden activation and tanh output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7333.644649709946\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 10.741201 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7353.821985996511\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 11.413301 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7354.153578717258\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 13.343090 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7353.833689664244\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 12.584725 seconds\n",
      "            for one layer with linear hidden activation and relu output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7354.2092203307975\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 13.320374 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7374.211825246615\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 14.878159 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7373.876700839953\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 16.757057 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7373.49293509288\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 17.916065 seconds\n",
      "            for one layer with tanh hidden activation and sigmoid output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7373.793194121249\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 11.661602 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7302.658464511785\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 12.836465 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7301.805239710781\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 14.329523 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7301.951658125148\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 16.431169 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7296.615226511429\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 11.726496 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7352.44870299836\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 13.157080 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7353.383112641035\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 14.855235 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7353.220439348105\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 16.414217 seconds\n",
      "            for one layer with tanh hidden activation and relu output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7353.072177128797\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 13.087386 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7373.345614138287\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 13.678770 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7373.3227509467215\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 14.820816 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7373.3820619521175\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 15.025726 seconds\n",
      "            for one layer with relu hidden activation and sigmoid output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7373.317092977839\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 11.147145 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7301.004943357428\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 11.875747 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7288.624889847698\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 13.050653 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7296.138379112154\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 13.445200 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7302.95794428137\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 11.695537 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 5 neurons\n",
      "mse:\n",
      "7332.174673374247\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 12.500647 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7329.116708569311\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 14.128877 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7328.718311602413\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 14.434961 seconds\n",
      "            for one layer with relu hidden activation and tanh output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7329.432534688135\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "activation_functions =['sigmoid', 'linear', 'tanh', 'relu']\n",
    "num_neurons = [5, 10, 15, 20]\n",
    "\n",
    "for hidden_function in activation_functions:\n",
    "    for output_function in activation_functions:\n",
    "        if hidden_function == output_function:\n",
    "            continue\n",
    "        for neurons in num_neurons:\n",
    "            mlp_stepsL = MLPNoBackprop(layer_sizes = [1, neurons, 1], hidden_activation=hidden_function, output_activation=output_function)\n",
    "            start_time = time.time()\n",
    "            mlp_stepsL.mini_batch_GD(X_stepsL_train_normalized,Y_stepsL_train_normalized , epochs = 1000, learning_rate = 0.01, batch_size=64)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            print(f\"\"\"Execution time: {execution_time:.6f} seconds\n",
    "            for one layer with {hidden_function} hidden activation and {output_function} output activation\n",
    "            one layer with {neurons} neurons\"\"\")\n",
    "            Ypred_normalized = mlp_stepsL.predict(X_stepsL_test_normalized)\n",
    "            Ypred = (Ypred_normalized * np.std(Y_stepsL_train_normalized)) + np.mean(Y_stepsL_train_normalized)\n",
    "            print('mse:')\n",
    "            print(mlp_stepsL.mse(Ypred, Y_stepsL_test))\n",
    "            print('--------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e324174d",
   "metadata": {},
   "source": [
    "### dalsze testy na większej ilości epok dla 3 najlepszych par funkcji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f982797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 65.576581 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7292.0775721280925\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 66.860545 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7294.113757896469\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 73.373752 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7297.369598197659\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 84.676295 seconds\n",
      "            for one layer with sigmoid hidden activation and linear output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "7297.207003175\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 68.732314 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7294.657339583981\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 72.513673 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7291.554013279096\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 79.057299 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7294.090621265384\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 86.871156 seconds\n",
      "            for one layer with tanh hidden activation and linear output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "7287.807848006986\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 52.138093 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 10 neurons\n",
      "mse:\n",
      "7282.50261692859\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 53.015202 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 15 neurons\n",
      "mse:\n",
      "7299.626517601918\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 57.545756 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 20 neurons\n",
      "mse:\n",
      "7299.754295369038\n",
      "--------------------------------------------------------------------------------\n",
      "Execution time: 62.042658 seconds\n",
      "            for one layer with relu hidden activation and linear output activation\n",
      "            one layer with 25 neurons\n",
      "mse:\n",
      "7296.003122903846\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "activation_functions =[['sigmoid', 'linear'], ['tanh', 'linear'], ['relu', 'linear']]\n",
    "num_neurons = [10, 15, 20, 25]\n",
    "\n",
    "for el in activation_functions:\n",
    "    for neurons in num_neurons:\n",
    "            mlp_stepsL = MLPNoBackprop(layer_sizes = [1, neurons, 1], hidden_activation = el[0], output_activation = el[1])\n",
    "            start_time = time.time()\n",
    "            mlp_stepsL.mini_batch_GD(X_stepsL_train_normalized,Y_stepsL_train_normalized , epochs = 5000, learning_rate = 0.05, batch_size=64)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            print(f\"\"\"Execution time: {execution_time:.6f} seconds\n",
    "            for one layer with {el[0]} hidden activation and {el[1]} output activation\n",
    "            one layer with {neurons} neurons\"\"\")\n",
    "            Ypred_normalized = mlp_stepsL.predict(X_stepsL_test_normalized)\n",
    "            Ypred = (Ypred_normalized * np.std(Y_stepsL_train_normalized)) + np.mean(Y_stepsL_train_normalized)\n",
    "            print('mse:')\n",
    "            print(mlp_stepsL.mse(Ypred, Y_stepsL_test))\n",
    "            print('--------------------------------------------------------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec399a",
   "metadata": {},
   "source": [
    "tanh and linear seems the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "639e10a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 1.649514118\n",
      "Epoka 10: Loss = 1.420651906\n",
      "Epoka 20: Loss = 1.388463435\n",
      "Epoka 30: Loss = 1.362160155\n",
      "Epoka 40: Loss = 1.342018226\n",
      "Epoka 50: Loss = 1.325254574\n",
      "Epoka 60: Loss = 1.309956604\n",
      "Epoka 70: Loss = 1.297049848\n",
      "Epoka 80: Loss = 1.286197924\n",
      "Epoka 90: Loss = 1.278763383\n",
      "Epoka 100: Loss = 1.266834194\n",
      "Epoka 110: Loss = 1.263989856\n",
      "Epoka 120: Loss = 1.255354675\n",
      "Epoka 130: Loss = 1.247458000\n",
      "Epoka 140: Loss = 1.245196018\n",
      "Epoka 150: Loss = 1.240658921\n",
      "Epoka 160: Loss = 1.237764573\n",
      "Epoka 170: Loss = 1.232415432\n",
      "Epoka 180: Loss = 1.227446683\n",
      "Epoka 190: Loss = 1.233429340\n",
      "Epoka 200: Loss = 1.222805689\n",
      "Epoka 210: Loss = 1.221602680\n",
      "Epoka 220: Loss = 1.221766837\n",
      "Epoka 230: Loss = 1.217913079\n",
      "Epoka 240: Loss = 1.217460046\n",
      "Epoka 250: Loss = 1.214243330\n",
      "Epoka 260: Loss = 1.208968750\n",
      "Epoka 270: Loss = 1.205120803\n",
      "Epoka 280: Loss = 1.211090280\n",
      "Epoka 290: Loss = 1.206385692\n",
      "Epoka 300: Loss = 1.207040220\n",
      "Epoka 310: Loss = 1.202323790\n",
      "Epoka 320: Loss = 1.202562732\n",
      "Epoka 330: Loss = 1.201269244\n",
      "Epoka 340: Loss = 1.201649508\n",
      "Epoka 350: Loss = 1.200403342\n",
      "Epoka 360: Loss = 1.194937359\n",
      "Epoka 370: Loss = 1.198214024\n",
      "Epoka 380: Loss = 1.197337554\n",
      "Epoka 390: Loss = 1.193625657\n",
      "Epoka 400: Loss = 1.192523358\n",
      "Epoka 410: Loss = 1.200282935\n",
      "Epoka 420: Loss = 1.192357621\n",
      "Epoka 430: Loss = 1.190885771\n",
      "Epoka 440: Loss = 1.193248188\n",
      "Epoka 450: Loss = 1.198370815\n",
      "Epoka 460: Loss = 1.194505239\n",
      "Epoka 470: Loss = 1.194986202\n",
      "Epoka 480: Loss = 1.195104337\n",
      "Epoka 490: Loss = 1.191238074\n",
      "Epoka 500: Loss = 1.186463460\n",
      "Epoka 510: Loss = 1.190077342\n",
      "Epoka 520: Loss = 1.189168405\n",
      "Epoka 530: Loss = 1.184408520\n",
      "Epoka 540: Loss = 1.185140589\n",
      "Epoka 550: Loss = 1.187676008\n",
      "Epoka 560: Loss = 1.184111373\n",
      "Epoka 570: Loss = 1.186300542\n",
      "Epoka 580: Loss = 1.182363798\n",
      "Epoka 590: Loss = 1.181875038\n",
      "Epoka 600: Loss = 1.179963310\n",
      "Epoka 610: Loss = 1.185016033\n",
      "Epoka 620: Loss = 1.187954783\n",
      "Epoka 630: Loss = 1.187096541\n",
      "Epoka 640: Loss = 1.184445119\n",
      "Epoka 650: Loss = 1.182110844\n",
      "Epoka 660: Loss = 1.182359765\n",
      "Epoka 670: Loss = 1.180218970\n",
      "Epoka 680: Loss = 1.181012395\n",
      "Epoka 690: Loss = 1.185420014\n",
      "Epoka 700: Loss = 1.185178644\n",
      "Epoka 710: Loss = 1.181171190\n",
      "Epoka 720: Loss = 1.180928736\n",
      "Epoka 730: Loss = 1.182949739\n",
      "Epoka 740: Loss = 1.183990472\n",
      "Epoka 750: Loss = 1.181924653\n",
      "Epoka 760: Loss = 1.181978653\n",
      "Epoka 770: Loss = 1.180108553\n",
      "Epoka 780: Loss = 1.178482295\n",
      "Epoka 790: Loss = 1.179755232\n",
      "Epoka 800: Loss = 1.170361324\n",
      "Epoka 810: Loss = 1.178339954\n",
      "Epoka 820: Loss = 1.179602980\n",
      "Epoka 830: Loss = 1.177742770\n",
      "Epoka 840: Loss = 1.176819135\n",
      "Epoka 850: Loss = 1.181805058\n",
      "Epoka 860: Loss = 1.177007113\n",
      "Epoka 870: Loss = 1.180146993\n",
      "Epoka 880: Loss = 1.178269760\n",
      "Epoka 890: Loss = 1.180555319\n",
      "Epoka 900: Loss = 1.181230317\n",
      "Epoka 910: Loss = 1.181600420\n",
      "Epoka 920: Loss = 1.173963701\n",
      "Epoka 930: Loss = 1.185085398\n",
      "Epoka 940: Loss = 1.177284264\n",
      "Epoka 950: Loss = 1.177049523\n",
      "Epoka 960: Loss = 1.177203168\n",
      "Epoka 970: Loss = 1.176081598\n",
      "Epoka 980: Loss = 1.175304164\n",
      "Epoka 990: Loss = 1.180436886\n",
      "mse:\n",
      "7302.84163919958\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mlp_stepsL = MLPNoBackprop(layer_sizes = [1, 6, 6, 1], hidden_activation = 'tanh', output_activation = 'linear')\n",
    "start_time = time.time()\n",
    "mlp_stepsL.mini_batch_GD(X_stepsL_train_normalized,Y_stepsL_train_normalized , epochs = 1000, learning_rate = 0.001, batch_size=64)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "Ypred_normalized = mlp_stepsL.predict(X_stepsL_test_normalized)\n",
    "Ypred = (Ypred_normalized * np.std(Y_stepsL_train_normalized)) + np.mean(Y_stepsL_train_normalized)\n",
    "print('mse:')\n",
    "print(mlp_stepsL.mse(Ypred, Y_stepsL_test))\n",
    "print('--------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2fcaa",
   "metadata": {},
   "source": [
    "## Rings3-Regular\n",
    "będę testować rózne funkcje aktywacji w warstwie ukrytej, w output pozostaje softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2da61c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 0.325316030\n",
      "Epoka 10: Loss = 0.438041431\n",
      "Epoka 20: Loss = 0.434231987\n",
      "Epoka 30: Loss = 0.537188154\n",
      "Epoka 40: Loss = 0.618863268\n",
      "Epoka 50: Loss = 0.677081301\n",
      "Epoka 60: Loss = 0.705475452\n",
      "Epoka 70: Loss = 0.741406690\n",
      "Epoka 80: Loss = 0.732148083\n",
      "Epoka 90: Loss = 0.764778032\n",
      "Epoka 100: Loss = 0.766476618\n",
      "Epoka 110: Loss = 0.812211121\n",
      "Epoka 120: Loss = 0.828766769\n",
      "Epoka 130: Loss = 0.859876662\n",
      "Epoka 140: Loss = 0.871527343\n",
      "Epoka 150: Loss = 0.836352188\n",
      "Epoka 160: Loss = 0.872765171\n",
      "Epoka 170: Loss = 0.867900375\n",
      "Epoka 180: Loss = 0.882727617\n",
      "Epoka 190: Loss = 0.875086590\n",
      "Epoka 200: Loss = 0.869732327\n",
      "Epoka 210: Loss = 0.872215915\n",
      "Epoka 220: Loss = 0.878452458\n",
      "Epoka 230: Loss = 0.882003372\n",
      "Epoka 240: Loss = 0.879794647\n",
      "Epoka 250: Loss = 0.883919536\n",
      "Epoka 260: Loss = 0.881385387\n",
      "Epoka 270: Loss = 0.889949111\n",
      "Epoka 280: Loss = 0.876982466\n",
      "Epoka 290: Loss = 0.879758183\n",
      "Epoka 300: Loss = 0.882615564\n",
      "Epoka 310: Loss = 0.879896718\n",
      "Epoka 320: Loss = 0.886635116\n",
      "Epoka 330: Loss = 0.886186310\n",
      "Epoka 340: Loss = 0.883485204\n",
      "Epoka 350: Loss = 0.888034542\n",
      "Epoka 360: Loss = 0.885155519\n",
      "Epoka 370: Loss = 0.890177948\n",
      "Epoka 380: Loss = 0.881068632\n",
      "Epoka 390: Loss = 0.885297784\n",
      "Epoka 400: Loss = 0.885106483\n",
      "Epoka 410: Loss = 0.890775442\n",
      "Epoka 420: Loss = 0.897610715\n",
      "Epoka 430: Loss = 0.889600264\n",
      "Epoka 440: Loss = 0.883362051\n",
      "Epoka 450: Loss = 0.888816569\n",
      "Epoka 460: Loss = 0.883090236\n",
      "Epoka 470: Loss = 0.885928304\n",
      "Epoka 480: Loss = 0.885405004\n",
      "Epoka 490: Loss = 0.888795658\n",
      "Epoka 500: Loss = 0.885208145\n",
      "Epoka 510: Loss = 0.890357499\n",
      "Epoka 520: Loss = 0.891393490\n",
      "Epoka 530: Loss = 0.886670353\n",
      "Epoka 540: Loss = 0.889212339\n",
      "Epoka 550: Loss = 0.890611862\n",
      "Epoka 560: Loss = 0.882279489\n",
      "Epoka 570: Loss = 0.890639757\n",
      "Epoka 580: Loss = 0.883885719\n",
      "Epoka 590: Loss = 0.892758269\n",
      "Epoka 600: Loss = 0.887383780\n",
      "Epoka 610: Loss = 0.891958140\n",
      "Epoka 620: Loss = 0.892896505\n",
      "Epoka 630: Loss = 0.892784465\n",
      "Epoka 640: Loss = 0.892110504\n",
      "Epoka 650: Loss = 0.890716799\n",
      "Epoka 660: Loss = 0.885932066\n",
      "Epoka 670: Loss = 0.895438436\n",
      "Epoka 680: Loss = 0.891375156\n",
      "Epoka 690: Loss = 0.887841470\n",
      "Epoka 700: Loss = 0.887752313\n",
      "Epoka 710: Loss = 0.894689052\n",
      "Epoka 720: Loss = 0.893426607\n",
      "Epoka 730: Loss = 0.889532577\n",
      "Epoka 740: Loss = 0.892119966\n",
      "Epoka 750: Loss = 0.884939850\n",
      "Epoka 760: Loss = 0.890655774\n",
      "Epoka 770: Loss = 0.889971978\n",
      "Epoka 780: Loss = 0.885749597\n",
      "Epoka 790: Loss = 0.890507286\n",
      "Epoka 800: Loss = 0.895722814\n",
      "Epoka 810: Loss = 0.894074570\n",
      "Epoka 820: Loss = 0.891394467\n",
      "Epoka 830: Loss = 0.890718205\n",
      "Epoka 840: Loss = 0.881724706\n",
      "Epoka 850: Loss = 0.889846932\n",
      "Epoka 860: Loss = 0.888502031\n",
      "Epoka 870: Loss = 0.888516781\n",
      "Epoka 880: Loss = 0.880142510\n",
      "Epoka 890: Loss = 0.893947067\n",
      "Epoka 900: Loss = 0.892592267\n",
      "Epoka 910: Loss = 0.896065311\n",
      "Epoka 920: Loss = 0.893379835\n",
      "Epoka 930: Loss = 0.885899003\n",
      "Epoka 940: Loss = 0.885524782\n",
      "Epoka 950: Loss = 0.898060506\n",
      "Epoka 960: Loss = 0.887272923\n",
      "Epoka 970: Loss = 0.895982845\n",
      "Epoka 980: Loss = 0.893649859\n",
      "Epoka 990: Loss = 0.889876342\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 9.112942 sekundy dla sigmoid w warstwie ukrytej i 5 neuronów\n",
      "f1 score:\n",
      "0.8897656960487561\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.332783736\n",
      "Epoka 10: Loss = 0.488303599\n",
      "Epoka 20: Loss = 0.560631103\n",
      "Epoka 30: Loss = 0.585971992\n",
      "Epoka 40: Loss = 0.640381584\n",
      "Epoka 50: Loss = 0.727882262\n",
      "Epoka 60: Loss = 0.789536212\n",
      "Epoka 70: Loss = 0.826525480\n",
      "Epoka 80: Loss = 0.858119895\n",
      "Epoka 90: Loss = 0.863457737\n",
      "Epoka 100: Loss = 0.877885091\n",
      "Epoka 110: Loss = 0.892418926\n",
      "Epoka 120: Loss = 0.897986928\n",
      "Epoka 130: Loss = 0.892892728\n",
      "Epoka 140: Loss = 0.905230721\n",
      "Epoka 150: Loss = 0.903319164\n",
      "Epoka 160: Loss = 0.905233825\n",
      "Epoka 170: Loss = 0.907202317\n",
      "Epoka 180: Loss = 0.909794985\n",
      "Epoka 190: Loss = 0.909762235\n",
      "Epoka 200: Loss = 0.919133591\n",
      "Epoka 210: Loss = 0.920036829\n",
      "Epoka 220: Loss = 0.920692258\n",
      "Epoka 230: Loss = 0.923155433\n",
      "Epoka 240: Loss = 0.924593268\n",
      "Epoka 250: Loss = 0.930645449\n",
      "Epoka 260: Loss = 0.930661586\n",
      "Epoka 270: Loss = 0.934583077\n",
      "Epoka 280: Loss = 0.929250378\n",
      "Epoka 290: Loss = 0.935238950\n",
      "Epoka 300: Loss = 0.931620555\n",
      "Epoka 310: Loss = 0.941335742\n",
      "Epoka 320: Loss = 0.936969067\n",
      "Epoka 330: Loss = 0.936025352\n",
      "Epoka 340: Loss = 0.943971005\n",
      "Epoka 350: Loss = 0.941343971\n",
      "Epoka 360: Loss = 0.941345176\n",
      "Epoka 370: Loss = 0.934705212\n",
      "Epoka 380: Loss = 0.941399396\n",
      "Epoka 390: Loss = 0.944442526\n",
      "Epoka 400: Loss = 0.947281006\n",
      "Epoka 410: Loss = 0.942597087\n",
      "Epoka 420: Loss = 0.943275348\n",
      "Epoka 430: Loss = 0.947339107\n",
      "Epoka 440: Loss = 0.949294981\n",
      "Epoka 450: Loss = 0.941148754\n",
      "Epoka 460: Loss = 0.942443482\n",
      "Epoka 470: Loss = 0.937871716\n",
      "Epoka 480: Loss = 0.944510918\n",
      "Epoka 490: Loss = 0.948648887\n",
      "Epoka 500: Loss = 0.950630275\n",
      "Epoka 510: Loss = 0.948575788\n",
      "Epoka 520: Loss = 0.949993121\n",
      "Epoka 530: Loss = 0.940544211\n",
      "Epoka 540: Loss = 0.945394292\n",
      "Epoka 550: Loss = 0.948018095\n",
      "Epoka 560: Loss = 0.950006257\n",
      "Epoka 570: Loss = 0.946060981\n",
      "Epoka 580: Loss = 0.945340789\n",
      "Epoka 590: Loss = 0.944456749\n",
      "Epoka 600: Loss = 0.946718378\n",
      "Epoka 610: Loss = 0.945194217\n",
      "Epoka 620: Loss = 0.946724002\n",
      "Epoka 630: Loss = 0.947137267\n",
      "Epoka 640: Loss = 0.947246050\n",
      "Epoka 650: Loss = 0.949377586\n",
      "Epoka 660: Loss = 0.949346454\n",
      "Epoka 670: Loss = 0.944466864\n",
      "Epoka 680: Loss = 0.946510325\n",
      "Epoka 690: Loss = 0.946543751\n",
      "Epoka 700: Loss = 0.947328523\n",
      "Epoka 710: Loss = 0.950555340\n",
      "Epoka 720: Loss = 0.950645715\n",
      "Epoka 730: Loss = 0.955286087\n",
      "Epoka 740: Loss = 0.951236009\n",
      "Epoka 750: Loss = 0.951247395\n",
      "Epoka 760: Loss = 0.952573608\n",
      "Epoka 770: Loss = 0.955264275\n",
      "Epoka 780: Loss = 0.952526269\n",
      "Epoka 790: Loss = 0.956023478\n",
      "Epoka 800: Loss = 0.951902909\n",
      "Epoka 810: Loss = 0.954035501\n",
      "Epoka 820: Loss = 0.949984247\n",
      "Epoka 830: Loss = 0.951105183\n",
      "Epoka 840: Loss = 0.954592506\n",
      "Epoka 850: Loss = 0.955896670\n",
      "Epoka 860: Loss = 0.958612097\n",
      "Epoka 870: Loss = 0.955989126\n",
      "Epoka 880: Loss = 0.949937808\n",
      "Epoka 890: Loss = 0.957275272\n",
      "Epoka 900: Loss = 0.957360934\n",
      "Epoka 910: Loss = 0.952510737\n",
      "Epoka 920: Loss = 0.952520736\n",
      "Epoka 930: Loss = 0.953372279\n",
      "Epoka 940: Loss = 0.956012235\n",
      "Epoka 950: Loss = 0.955315817\n",
      "Epoka 960: Loss = 0.959321448\n",
      "Epoka 970: Loss = 0.958572843\n",
      "Epoka 980: Loss = 0.955378663\n",
      "Epoka 990: Loss = 0.954654258\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 9.352325 sekundy dla sigmoid w warstwie ukrytej i 10 neuronów\n",
      "f1 score:\n",
      "0.9399838717452639\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.481166536\n",
      "Epoka 10: Loss = 0.512465987\n",
      "Epoka 20: Loss = 0.602153000\n",
      "Epoka 30: Loss = 0.622240176\n",
      "Epoka 40: Loss = 0.684201809\n",
      "Epoka 50: Loss = 0.705682107\n",
      "Epoka 60: Loss = 0.818309326\n",
      "Epoka 70: Loss = 0.838008825\n",
      "Epoka 80: Loss = 0.837284988\n",
      "Epoka 90: Loss = 0.864617313\n",
      "Epoka 100: Loss = 0.867940761\n",
      "Epoka 110: Loss = 0.883348482\n",
      "Epoka 120: Loss = 0.896654942\n",
      "Epoka 130: Loss = 0.894662855\n",
      "Epoka 140: Loss = 0.906006005\n",
      "Epoka 150: Loss = 0.903962489\n",
      "Epoka 160: Loss = 0.911308273\n",
      "Epoka 170: Loss = 0.918669105\n",
      "Epoka 180: Loss = 0.920688889\n",
      "Epoka 190: Loss = 0.914636930\n",
      "Epoka 200: Loss = 0.909826292\n",
      "Epoka 210: Loss = 0.920695989\n",
      "Epoka 220: Loss = 0.929100260\n",
      "Epoka 230: Loss = 0.923996854\n",
      "Epoka 240: Loss = 0.929368046\n",
      "Epoka 250: Loss = 0.933323483\n",
      "Epoka 260: Loss = 0.938046552\n",
      "Epoka 270: Loss = 0.935326342\n",
      "Epoka 280: Loss = 0.937926854\n",
      "Epoka 290: Loss = 0.943258984\n",
      "Epoka 300: Loss = 0.937877284\n",
      "Epoka 310: Loss = 0.941914200\n",
      "Epoka 320: Loss = 0.940611536\n",
      "Epoka 330: Loss = 0.946014152\n",
      "Epoka 340: Loss = 0.941171909\n",
      "Epoka 350: Loss = 0.948086419\n",
      "Epoka 360: Loss = 0.950623783\n",
      "Epoka 370: Loss = 0.955426395\n",
      "Epoka 380: Loss = 0.958716668\n",
      "Epoka 390: Loss = 0.951307968\n",
      "Epoka 400: Loss = 0.949196555\n",
      "Epoka 410: Loss = 0.953327901\n",
      "Epoka 420: Loss = 0.956690518\n",
      "Epoka 430: Loss = 0.949945820\n",
      "Epoka 440: Loss = 0.948635017\n",
      "Epoka 450: Loss = 0.952619573\n",
      "Epoka 460: Loss = 0.955978515\n",
      "Epoka 470: Loss = 0.960007929\n",
      "Epoka 480: Loss = 0.958653794\n",
      "Epoka 490: Loss = 0.957995973\n",
      "Epoka 500: Loss = 0.957954958\n",
      "Epoka 510: Loss = 0.952551413\n",
      "Epoka 520: Loss = 0.961324921\n",
      "Epoka 530: Loss = 0.956675991\n",
      "Epoka 540: Loss = 0.959921851\n",
      "Epoka 550: Loss = 0.957308324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 560: Loss = 0.954635647\n",
      "Epoka 570: Loss = 0.951965618\n",
      "Epoka 580: Loss = 0.955971449\n",
      "Epoka 590: Loss = 0.953267785\n",
      "Epoka 600: Loss = 0.959308843\n",
      "Epoka 610: Loss = 0.955904953\n",
      "Epoka 620: Loss = 0.963276282\n",
      "Epoka 630: Loss = 0.966005372\n",
      "Epoka 640: Loss = 0.960631398\n",
      "Epoka 650: Loss = 0.964666017\n",
      "Epoka 660: Loss = 0.955939479\n",
      "Epoka 670: Loss = 0.965992683\n",
      "Epoka 680: Loss = 0.961969292\n",
      "Epoka 690: Loss = 0.964647650\n",
      "Epoka 700: Loss = 0.967325073\n",
      "Epoka 710: Loss = 0.968011494\n",
      "Epoka 720: Loss = 0.965990555\n",
      "Epoka 730: Loss = 0.967361887\n",
      "Epoka 740: Loss = 0.965395393\n",
      "Epoka 750: Loss = 0.963999329\n",
      "Epoka 760: Loss = 0.967957954\n",
      "Epoka 770: Loss = 0.967369405\n",
      "Epoka 780: Loss = 0.971361150\n",
      "Epoka 790: Loss = 0.964593498\n",
      "Epoka 800: Loss = 0.966630483\n",
      "Epoka 810: Loss = 0.966662498\n",
      "Epoka 820: Loss = 0.970661980\n",
      "Epoka 830: Loss = 0.966038403\n",
      "Epoka 840: Loss = 0.968104306\n",
      "Epoka 850: Loss = 0.971373127\n",
      "Epoka 860: Loss = 0.970016773\n",
      "Epoka 870: Loss = 0.971353717\n",
      "Epoka 880: Loss = 0.973342482\n",
      "Epoka 890: Loss = 0.964621000\n",
      "Epoka 900: Loss = 0.967971302\n",
      "Epoka 910: Loss = 0.970729240\n",
      "Epoka 920: Loss = 0.973397695\n",
      "Epoka 930: Loss = 0.965315428\n",
      "Epoka 940: Loss = 0.972064670\n",
      "Epoka 950: Loss = 0.967294717\n",
      "Epoka 960: Loss = 0.965334449\n",
      "Epoka 970: Loss = 0.968630215\n",
      "Epoka 980: Loss = 0.971415917\n",
      "Epoka 990: Loss = 0.967295477\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 9.555746 sekundy dla sigmoid w warstwie ukrytej i 15 neuronów\n",
      "f1 score:\n",
      "0.9503251877921555\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.436242093\n",
      "Epoka 10: Loss = 0.444368799\n",
      "Epoka 20: Loss = 0.602497408\n",
      "Epoka 30: Loss = 0.639699754\n",
      "Epoka 40: Loss = 0.683406339\n",
      "Epoka 50: Loss = 0.791821460\n",
      "Epoka 60: Loss = 0.842820352\n",
      "Epoka 70: Loss = 0.852612770\n",
      "Epoka 80: Loss = 0.876095264\n",
      "Epoka 90: Loss = 0.874822024\n",
      "Epoka 100: Loss = 0.896230728\n",
      "Epoka 110: Loss = 0.914006154\n",
      "Epoka 120: Loss = 0.914913389\n",
      "Epoka 130: Loss = 0.929486155\n",
      "Epoka 140: Loss = 0.934090229\n",
      "Epoka 150: Loss = 0.935428865\n",
      "Epoka 160: Loss = 0.934663353\n",
      "Epoka 170: Loss = 0.933345462\n",
      "Epoka 180: Loss = 0.932722799\n",
      "Epoka 190: Loss = 0.929974077\n",
      "Epoka 200: Loss = 0.933443122\n",
      "Epoka 210: Loss = 0.933396487\n",
      "Epoka 220: Loss = 0.938765830\n",
      "Epoka 230: Loss = 0.936594870\n",
      "Epoka 240: Loss = 0.930461175\n",
      "Epoka 250: Loss = 0.943962244\n",
      "Epoka 260: Loss = 0.940099738\n",
      "Epoka 270: Loss = 0.935871125\n",
      "Epoka 280: Loss = 0.947329903\n",
      "Epoka 290: Loss = 0.944615226\n",
      "Epoka 300: Loss = 0.944652404\n",
      "Epoka 310: Loss = 0.936738355\n",
      "Epoka 320: Loss = 0.950041314\n",
      "Epoka 330: Loss = 0.953321760\n",
      "Epoka 340: Loss = 0.949428606\n",
      "Epoka 350: Loss = 0.951302663\n",
      "Epoka 360: Loss = 0.955231948\n",
      "Epoka 370: Loss = 0.944775457\n",
      "Epoka 380: Loss = 0.952712703\n",
      "Epoka 390: Loss = 0.948097349\n",
      "Epoka 400: Loss = 0.953293891\n",
      "Epoka 410: Loss = 0.954684972\n",
      "Epoka 420: Loss = 0.953243519\n",
      "Epoka 430: Loss = 0.958665975\n",
      "Epoka 440: Loss = 0.959299981\n",
      "Epoka 450: Loss = 0.955329611\n",
      "Epoka 460: Loss = 0.957264580\n",
      "Epoka 470: Loss = 0.957281188\n",
      "Epoka 480: Loss = 0.956665235\n",
      "Epoka 490: Loss = 0.952069798\n",
      "Epoka 500: Loss = 0.959333333\n",
      "Epoka 510: Loss = 0.956649317\n",
      "Epoka 520: Loss = 0.956603508\n",
      "Epoka 530: Loss = 0.959352021\n",
      "Epoka 540: Loss = 0.961956931\n",
      "Epoka 550: Loss = 0.959893413\n",
      "Epoka 560: Loss = 0.962050805\n",
      "Epoka 570: Loss = 0.958612905\n",
      "Epoka 580: Loss = 0.959385937\n",
      "Epoka 590: Loss = 0.964029490\n",
      "Epoka 600: Loss = 0.959983501\n",
      "Epoka 610: Loss = 0.967980373\n",
      "Epoka 620: Loss = 0.956106631\n",
      "Epoka 630: Loss = 0.964662141\n",
      "Epoka 640: Loss = 0.960588838\n",
      "Epoka 650: Loss = 0.961290404\n",
      "Epoka 660: Loss = 0.961285943\n",
      "Epoka 670: Loss = 0.959268299\n",
      "Epoka 680: Loss = 0.963364901\n",
      "Epoka 690: Loss = 0.968012728\n",
      "Epoka 700: Loss = 0.959942274\n",
      "Epoka 710: Loss = 0.961292595\n",
      "Epoka 720: Loss = 0.960088982\n",
      "Epoka 730: Loss = 0.965969488\n",
      "Epoka 740: Loss = 0.960739437\n",
      "Epoka 750: Loss = 0.966005841\n",
      "Epoka 760: Loss = 0.959264570\n",
      "Epoka 770: Loss = 0.958705990\n",
      "Epoka 780: Loss = 0.964672415\n",
      "Epoka 790: Loss = 0.959904426\n",
      "Epoka 800: Loss = 0.956666361\n",
      "Epoka 810: Loss = 0.967351141\n",
      "Epoka 820: Loss = 0.966039076\n",
      "Epoka 830: Loss = 0.964037700\n",
      "Epoka 840: Loss = 0.962665925\n",
      "Epoka 850: Loss = 0.956605154\n",
      "Epoka 860: Loss = 0.963242042\n",
      "Epoka 870: Loss = 0.967961652\n",
      "Epoka 880: Loss = 0.965980388\n",
      "Epoka 890: Loss = 0.966597307\n",
      "Epoka 900: Loss = 0.966665972\n",
      "Epoka 910: Loss = 0.969385841\n",
      "Epoka 920: Loss = 0.966652499\n",
      "Epoka 930: Loss = 0.960671181\n",
      "Epoka 940: Loss = 0.969281396\n",
      "Epoka 950: Loss = 0.969281877\n",
      "Epoka 960: Loss = 0.965979768\n",
      "Epoka 970: Loss = 0.967254666\n",
      "Epoka 980: Loss = 0.966723929\n",
      "Epoka 990: Loss = 0.967966335\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 10.759083 sekundy dla sigmoid w warstwie ukrytej i 20 neuronów\n",
      "f1 score:\n",
      "0.9490319797093957\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.382188782\n",
      "Epoka 10: Loss = 0.365746927\n",
      "Epoka 20: Loss = 0.383345489\n",
      "Epoka 30: Loss = 0.455436793\n",
      "Epoka 40: Loss = 0.446370133\n",
      "Epoka 50: Loss = 0.464401650\n",
      "Epoka 60: Loss = 0.411354860\n",
      "Epoka 70: Loss = 0.387892752\n",
      "Epoka 80: Loss = 0.381178587\n",
      "Epoka 90: Loss = 0.425787926\n",
      "Epoka 100: Loss = 0.463661308\n",
      "Epoka 110: Loss = 0.415963851\n",
      "Epoka 120: Loss = 0.396960643\n",
      "Epoka 130: Loss = 0.410932300\n",
      "Epoka 140: Loss = 0.377803751\n",
      "Epoka 150: Loss = 0.407359196\n",
      "Epoka 160: Loss = 0.420810586\n",
      "Epoka 170: Loss = 0.417052103\n",
      "Epoka 180: Loss = 0.379951320\n",
      "Epoka 190: Loss = 0.418670512\n",
      "Epoka 200: Loss = 0.441363019\n",
      "Epoka 210: Loss = 0.436502642\n",
      "Epoka 220: Loss = 0.460681561\n",
      "Epoka 230: Loss = 0.385763793\n",
      "Epoka 240: Loss = 0.404967978\n",
      "Epoka 250: Loss = 0.489263087\n",
      "Epoka 260: Loss = 0.337708978\n",
      "Epoka 270: Loss = 0.393321274\n",
      "Epoka 280: Loss = 0.416467222\n",
      "Epoka 290: Loss = 0.426994699\n",
      "Epoka 300: Loss = 0.352290761\n",
      "Epoka 310: Loss = 0.395553986\n",
      "Epoka 320: Loss = 0.380817820\n",
      "Epoka 330: Loss = 0.428066867\n",
      "Epoka 340: Loss = 0.382972415\n",
      "Epoka 350: Loss = 0.472775225\n",
      "Epoka 360: Loss = 0.382215084\n",
      "Epoka 370: Loss = 0.478966366\n",
      "Epoka 380: Loss = 0.422164013\n",
      "Epoka 390: Loss = 0.437673042\n",
      "Epoka 400: Loss = 0.491465571\n",
      "Epoka 410: Loss = 0.449495950\n",
      "Epoka 420: Loss = 0.399731985\n",
      "Epoka 430: Loss = 0.381152399\n",
      "Epoka 440: Loss = 0.402335658\n",
      "Epoka 450: Loss = 0.502583491\n",
      "Epoka 460: Loss = 0.443168743\n",
      "Epoka 470: Loss = 0.362385470\n",
      "Epoka 480: Loss = 0.380818489\n",
      "Epoka 490: Loss = 0.468746608\n",
      "Epoka 500: Loss = 0.375303139\n",
      "Epoka 510: Loss = 0.357767540\n",
      "Epoka 520: Loss = 0.411033419\n",
      "Epoka 530: Loss = 0.380709585\n",
      "Epoka 540: Loss = 0.439553093\n",
      "Epoka 550: Loss = 0.381351727\n",
      "Epoka 560: Loss = 0.448225926\n",
      "Epoka 570: Loss = 0.381587130\n",
      "Epoka 580: Loss = 0.456661489\n",
      "Epoka 590: Loss = 0.454578483\n",
      "Epoka 600: Loss = 0.424486034\n",
      "Epoka 610: Loss = 0.416380418\n",
      "Epoka 620: Loss = 0.423552340\n",
      "Epoka 630: Loss = 0.400907345\n",
      "Epoka 640: Loss = 0.477084399\n",
      "Epoka 650: Loss = 0.386973925\n",
      "Epoka 660: Loss = 0.430335892\n",
      "Epoka 670: Loss = 0.494412062\n",
      "Epoka 680: Loss = 0.391247340\n",
      "Epoka 690: Loss = 0.431762608\n",
      "Epoka 700: Loss = 0.365080519\n",
      "Epoka 710: Loss = 0.364962915\n",
      "Epoka 720: Loss = 0.416415091\n",
      "Epoka 730: Loss = 0.468012689\n",
      "Epoka 740: Loss = 0.352564030\n",
      "Epoka 750: Loss = 0.407524745\n",
      "Epoka 760: Loss = 0.396606365\n",
      "Epoka 770: Loss = 0.396520404\n",
      "Epoka 780: Loss = 0.444129091\n",
      "Epoka 790: Loss = 0.419445155\n",
      "Epoka 800: Loss = 0.487505043\n",
      "Epoka 810: Loss = 0.394672573\n",
      "Epoka 820: Loss = 0.423321441\n",
      "Epoka 830: Loss = 0.495130111\n",
      "Epoka 840: Loss = 0.439276948\n",
      "Epoka 850: Loss = 0.489693208\n",
      "Epoka 860: Loss = 0.400484656\n",
      "Epoka 870: Loss = 0.385378204\n",
      "Epoka 880: Loss = 0.351099521\n",
      "Epoka 890: Loss = 0.408299358\n",
      "Epoka 900: Loss = 0.472546001\n",
      "Epoka 910: Loss = 0.376307612\n",
      "Epoka 920: Loss = 0.506495712\n",
      "Epoka 930: Loss = 0.438272560\n",
      "Epoka 940: Loss = 0.455901235\n",
      "Epoka 950: Loss = 0.466368479\n",
      "Epoka 960: Loss = 0.347139732\n",
      "Epoka 970: Loss = 0.444067220\n",
      "Epoka 980: Loss = 0.409684756\n",
      "Epoka 990: Loss = 0.488617899\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 7.180176 sekundy dla linear w warstwie ukrytej i 5 neuronów\n",
      "f1 score:\n",
      "0.3719168060771529\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.346197089\n",
      "Epoka 10: Loss = 0.437076606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 20: Loss = 0.380720908\n",
      "Epoka 30: Loss = 0.359070991\n",
      "Epoka 40: Loss = 0.423781372\n",
      "Epoka 50: Loss = 0.437063122\n",
      "Epoka 60: Loss = 0.445602979\n",
      "Epoka 70: Loss = 0.357689059\n",
      "Epoka 80: Loss = 0.429186392\n",
      "Epoka 90: Loss = 0.428721500\n",
      "Epoka 100: Loss = 0.354815554\n",
      "Epoka 110: Loss = 0.448357262\n",
      "Epoka 120: Loss = 0.404734225\n",
      "Epoka 130: Loss = 0.348807519\n",
      "Epoka 140: Loss = 0.357201300\n",
      "Epoka 150: Loss = 0.338915419\n",
      "Epoka 160: Loss = 0.350873713\n",
      "Epoka 170: Loss = 0.506391358\n",
      "Epoka 180: Loss = 0.388574869\n",
      "Epoka 190: Loss = 0.384518214\n",
      "Epoka 200: Loss = 0.458424869\n",
      "Epoka 210: Loss = 0.367603456\n",
      "Epoka 220: Loss = 0.392194074\n",
      "Epoka 230: Loss = 0.392401680\n",
      "Epoka 240: Loss = 0.474491133\n",
      "Epoka 250: Loss = 0.409885121\n",
      "Epoka 260: Loss = 0.462291787\n",
      "Epoka 270: Loss = 0.452162979\n",
      "Epoka 280: Loss = 0.435323482\n",
      "Epoka 290: Loss = 0.501836136\n",
      "Epoka 300: Loss = 0.503524207\n",
      "Epoka 310: Loss = 0.376706584\n",
      "Epoka 320: Loss = 0.487803506\n",
      "Epoka 330: Loss = 0.460639801\n",
      "Epoka 340: Loss = 0.404464332\n",
      "Epoka 350: Loss = 0.416130851\n",
      "Epoka 360: Loss = 0.437865803\n",
      "Epoka 370: Loss = 0.452930722\n",
      "Epoka 380: Loss = 0.375720227\n",
      "Epoka 390: Loss = 0.399048928\n",
      "Epoka 400: Loss = 0.483594865\n",
      "Epoka 410: Loss = 0.365434414\n",
      "Epoka 420: Loss = 0.378789784\n",
      "Epoka 430: Loss = 0.356407943\n",
      "Epoka 440: Loss = 0.397986640\n",
      "Epoka 450: Loss = 0.424391031\n",
      "Epoka 460: Loss = 0.383826709\n",
      "Epoka 470: Loss = 0.428773853\n",
      "Epoka 480: Loss = 0.468893125\n",
      "Epoka 490: Loss = 0.434760862\n",
      "Epoka 500: Loss = 0.382901313\n",
      "Epoka 510: Loss = 0.417540089\n",
      "Epoka 520: Loss = 0.394442271\n",
      "Epoka 530: Loss = 0.337174493\n",
      "Epoka 540: Loss = 0.416243272\n",
      "Epoka 550: Loss = 0.455373019\n",
      "Epoka 560: Loss = 0.377816717\n",
      "Epoka 570: Loss = 0.484894124\n",
      "Epoka 580: Loss = 0.389828297\n",
      "Epoka 590: Loss = 0.411164399\n",
      "Epoka 600: Loss = 0.469339983\n",
      "Epoka 610: Loss = 0.360128409\n",
      "Epoka 620: Loss = 0.413981809\n",
      "Epoka 630: Loss = 0.470732891\n",
      "Epoka 640: Loss = 0.421740031\n",
      "Epoka 650: Loss = 0.447282971\n",
      "Epoka 660: Loss = 0.351751492\n",
      "Epoka 670: Loss = 0.456859297\n",
      "Epoka 680: Loss = 0.408714713\n",
      "Epoka 690: Loss = 0.423510562\n",
      "Epoka 700: Loss = 0.384704417\n",
      "Epoka 710: Loss = 0.412317801\n",
      "Epoka 720: Loss = 0.384734824\n",
      "Epoka 730: Loss = 0.391188363\n",
      "Epoka 740: Loss = 0.420354377\n",
      "Epoka 750: Loss = 0.374958234\n",
      "Epoka 760: Loss = 0.358225473\n",
      "Epoka 770: Loss = 0.365485140\n",
      "Epoka 780: Loss = 0.428855785\n",
      "Epoka 790: Loss = 0.472626703\n",
      "Epoka 800: Loss = 0.395242229\n",
      "Epoka 810: Loss = 0.480143052\n",
      "Epoka 820: Loss = 0.464938569\n",
      "Epoka 830: Loss = 0.410635343\n",
      "Epoka 840: Loss = 0.504640186\n",
      "Epoka 850: Loss = 0.343855639\n",
      "Epoka 860: Loss = 0.442562975\n",
      "Epoka 870: Loss = 0.426526244\n",
      "Epoka 880: Loss = 0.388731647\n",
      "Epoka 890: Loss = 0.425883264\n",
      "Epoka 900: Loss = 0.343850892\n",
      "Epoka 910: Loss = 0.399256863\n",
      "Epoka 920: Loss = 0.402605720\n",
      "Epoka 930: Loss = 0.380675299\n",
      "Epoka 940: Loss = 0.406359494\n",
      "Epoka 950: Loss = 0.468526829\n",
      "Epoka 960: Loss = 0.471593880\n",
      "Epoka 970: Loss = 0.370026448\n",
      "Epoka 980: Loss = 0.376297188\n",
      "Epoka 990: Loss = 0.348280530\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 7.286283 sekundy dla linear w warstwie ukrytej i 10 neuronów\n",
      "f1 score:\n",
      "0.4629423815269221\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.452086756\n",
      "Epoka 10: Loss = 0.433464972\n",
      "Epoka 20: Loss = 0.447542263\n",
      "Epoka 30: Loss = 0.357588325\n",
      "Epoka 40: Loss = 0.367594490\n",
      "Epoka 50: Loss = 0.498851172\n",
      "Epoka 60: Loss = 0.378567890\n",
      "Epoka 70: Loss = 0.455366550\n",
      "Epoka 80: Loss = 0.363557972\n",
      "Epoka 90: Loss = 0.391699490\n",
      "Epoka 100: Loss = 0.369598682\n",
      "Epoka 110: Loss = 0.444769223\n",
      "Epoka 120: Loss = 0.397877367\n",
      "Epoka 130: Loss = 0.366118337\n",
      "Epoka 140: Loss = 0.488343567\n",
      "Epoka 150: Loss = 0.496662296\n",
      "Epoka 160: Loss = 0.395248064\n",
      "Epoka 170: Loss = 0.413511128\n",
      "Epoka 180: Loss = 0.355557106\n",
      "Epoka 190: Loss = 0.382173789\n",
      "Epoka 200: Loss = 0.476336658\n",
      "Epoka 210: Loss = 0.387340452\n",
      "Epoka 220: Loss = 0.449138512\n",
      "Epoka 230: Loss = 0.515318620\n",
      "Epoka 240: Loss = 0.493402073\n",
      "Epoka 250: Loss = 0.483083786\n",
      "Epoka 260: Loss = 0.428058671\n",
      "Epoka 270: Loss = 0.354367898\n",
      "Epoka 280: Loss = 0.436508506\n",
      "Epoka 290: Loss = 0.442507729\n",
      "Epoka 300: Loss = 0.385972911\n",
      "Epoka 310: Loss = 0.368944273\n",
      "Epoka 320: Loss = 0.410846649\n",
      "Epoka 330: Loss = 0.415124873\n",
      "Epoka 340: Loss = 0.463964743\n",
      "Epoka 350: Loss = 0.378379908\n",
      "Epoka 360: Loss = 0.445537923\n",
      "Epoka 370: Loss = 0.434342034\n",
      "Epoka 380: Loss = 0.439641113\n",
      "Epoka 390: Loss = 0.334518465\n",
      "Epoka 400: Loss = 0.475085762\n",
      "Epoka 410: Loss = 0.490676084\n",
      "Epoka 420: Loss = 0.440444756\n",
      "Epoka 430: Loss = 0.451929922\n",
      "Epoka 440: Loss = 0.410152659\n",
      "Epoka 450: Loss = 0.429228846\n",
      "Epoka 460: Loss = 0.505604429\n",
      "Epoka 470: Loss = 0.444364503\n",
      "Epoka 480: Loss = 0.489089249\n",
      "Epoka 490: Loss = 0.342577326\n",
      "Epoka 500: Loss = 0.384340492\n",
      "Epoka 510: Loss = 0.427450504\n",
      "Epoka 520: Loss = 0.391200027\n",
      "Epoka 530: Loss = 0.400457570\n",
      "Epoka 540: Loss = 0.398379318\n",
      "Epoka 550: Loss = 0.375048764\n",
      "Epoka 560: Loss = 0.415930354\n",
      "Epoka 570: Loss = 0.428136484\n",
      "Epoka 580: Loss = 0.421818174\n",
      "Epoka 590: Loss = 0.506420822\n",
      "Epoka 600: Loss = 0.431880106\n",
      "Epoka 610: Loss = 0.396545921\n",
      "Epoka 620: Loss = 0.439985349\n",
      "Epoka 630: Loss = 0.446009666\n",
      "Epoka 640: Loss = 0.395404796\n",
      "Epoka 650: Loss = 0.368506402\n",
      "Epoka 660: Loss = 0.447118922\n",
      "Epoka 670: Loss = 0.436743656\n",
      "Epoka 680: Loss = 0.426086505\n",
      "Epoka 690: Loss = 0.373794433\n",
      "Epoka 700: Loss = 0.368479394\n",
      "Epoka 710: Loss = 0.449180051\n",
      "Epoka 720: Loss = 0.366527309\n",
      "Epoka 730: Loss = 0.433998186\n",
      "Epoka 740: Loss = 0.382880747\n",
      "Epoka 750: Loss = 0.335245617\n",
      "Epoka 760: Loss = 0.410670138\n",
      "Epoka 770: Loss = 0.377892029\n",
      "Epoka 780: Loss = 0.365993756\n",
      "Epoka 790: Loss = 0.393580092\n",
      "Epoka 800: Loss = 0.428692024\n",
      "Epoka 810: Loss = 0.423744235\n",
      "Epoka 820: Loss = 0.425624630\n",
      "Epoka 830: Loss = 0.421279702\n",
      "Epoka 840: Loss = 0.490483691\n",
      "Epoka 850: Loss = 0.388319481\n",
      "Epoka 860: Loss = 0.500691037\n",
      "Epoka 870: Loss = 0.356499836\n",
      "Epoka 880: Loss = 0.441901561\n",
      "Epoka 890: Loss = 0.393142274\n",
      "Epoka 900: Loss = 0.403309996\n",
      "Epoka 910: Loss = 0.463738280\n",
      "Epoka 920: Loss = 0.452027344\n",
      "Epoka 930: Loss = 0.365474506\n",
      "Epoka 940: Loss = 0.348208357\n",
      "Epoka 950: Loss = 0.398960585\n",
      "Epoka 960: Loss = 0.501048519\n",
      "Epoka 970: Loss = 0.462010774\n",
      "Epoka 980: Loss = 0.390718496\n",
      "Epoka 990: Loss = 0.406376939\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 7.669590 sekundy dla linear w warstwie ukrytej i 15 neuronów\n",
      "f1 score:\n",
      "0.385526988001174\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.435884014\n",
      "Epoka 10: Loss = 0.353583411\n",
      "Epoka 20: Loss = 0.447930609\n",
      "Epoka 30: Loss = 0.391364833\n",
      "Epoka 40: Loss = 0.444398157\n",
      "Epoka 50: Loss = 0.413412225\n",
      "Epoka 60: Loss = 0.435455072\n",
      "Epoka 70: Loss = 0.415080712\n",
      "Epoka 80: Loss = 0.367396505\n",
      "Epoka 90: Loss = 0.439811773\n",
      "Epoka 100: Loss = 0.394744637\n",
      "Epoka 110: Loss = 0.388699229\n",
      "Epoka 120: Loss = 0.367891237\n",
      "Epoka 130: Loss = 0.469025047\n",
      "Epoka 140: Loss = 0.430411725\n",
      "Epoka 150: Loss = 0.432792641\n",
      "Epoka 160: Loss = 0.445520286\n",
      "Epoka 170: Loss = 0.457382261\n",
      "Epoka 180: Loss = 0.349446842\n",
      "Epoka 190: Loss = 0.382161690\n",
      "Epoka 200: Loss = 0.374613172\n",
      "Epoka 210: Loss = 0.368758353\n",
      "Epoka 220: Loss = 0.440201609\n",
      "Epoka 230: Loss = 0.415337164\n",
      "Epoka 240: Loss = 0.404637750\n",
      "Epoka 250: Loss = 0.458314809\n",
      "Epoka 260: Loss = 0.415221664\n",
      "Epoka 270: Loss = 0.458932874\n",
      "Epoka 280: Loss = 0.359053011\n",
      "Epoka 290: Loss = 0.468181678\n",
      "Epoka 300: Loss = 0.403867487\n",
      "Epoka 310: Loss = 0.415493201\n",
      "Epoka 320: Loss = 0.395919838\n",
      "Epoka 330: Loss = 0.456315956\n",
      "Epoka 340: Loss = 0.434509513\n",
      "Epoka 350: Loss = 0.377279989\n",
      "Epoka 360: Loss = 0.395535980\n",
      "Epoka 370: Loss = 0.431764267\n",
      "Epoka 380: Loss = 0.491928725\n",
      "Epoka 390: Loss = 0.447119291\n",
      "Epoka 400: Loss = 0.421401308\n",
      "Epoka 410: Loss = 0.350958994\n",
      "Epoka 420: Loss = 0.347922075\n",
      "Epoka 430: Loss = 0.430791923\n",
      "Epoka 440: Loss = 0.483549707\n",
      "Epoka 450: Loss = 0.350372490\n",
      "Epoka 460: Loss = 0.409240161\n",
      "Epoka 470: Loss = 0.365355106\n",
      "Epoka 480: Loss = 0.423783515\n",
      "Epoka 490: Loss = 0.427912902\n",
      "Epoka 500: Loss = 0.418549305\n",
      "Epoka 510: Loss = 0.353892120\n",
      "Epoka 520: Loss = 0.493623920\n",
      "Epoka 530: Loss = 0.393539952\n",
      "Epoka 540: Loss = 0.462221219\n",
      "Epoka 550: Loss = 0.410769654\n",
      "Epoka 560: Loss = 0.401128462\n",
      "Epoka 570: Loss = 0.417395209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 580: Loss = 0.384925584\n",
      "Epoka 590: Loss = 0.408589286\n",
      "Epoka 600: Loss = 0.370609722\n",
      "Epoka 610: Loss = 0.451457638\n",
      "Epoka 620: Loss = 0.426557384\n",
      "Epoka 630: Loss = 0.431859624\n",
      "Epoka 640: Loss = 0.378163823\n",
      "Epoka 650: Loss = 0.430311041\n",
      "Epoka 660: Loss = 0.430805285\n",
      "Epoka 670: Loss = 0.496696762\n",
      "Epoka 680: Loss = 0.363091192\n",
      "Epoka 690: Loss = 0.399223698\n",
      "Epoka 700: Loss = 0.418345656\n",
      "Epoka 710: Loss = 0.426472693\n",
      "Epoka 720: Loss = 0.454061754\n",
      "Epoka 730: Loss = 0.360242820\n",
      "Epoka 740: Loss = 0.351278442\n",
      "Epoka 750: Loss = 0.366339162\n",
      "Epoka 760: Loss = 0.353587912\n",
      "Epoka 770: Loss = 0.503786579\n",
      "Epoka 780: Loss = 0.457578990\n",
      "Epoka 790: Loss = 0.377352245\n",
      "Epoka 800: Loss = 0.423066047\n",
      "Epoka 810: Loss = 0.433695902\n",
      "Epoka 820: Loss = 0.391770072\n",
      "Epoka 830: Loss = 0.488731884\n",
      "Epoka 840: Loss = 0.418378916\n",
      "Epoka 850: Loss = 0.440350921\n",
      "Epoka 860: Loss = 0.380627368\n",
      "Epoka 870: Loss = 0.380839455\n",
      "Epoka 880: Loss = 0.434604279\n",
      "Epoka 890: Loss = 0.382086913\n",
      "Epoka 900: Loss = 0.465860104\n",
      "Epoka 910: Loss = 0.451424785\n",
      "Epoka 920: Loss = 0.375405563\n",
      "Epoka 930: Loss = 0.402148446\n",
      "Epoka 940: Loss = 0.480223828\n",
      "Epoka 950: Loss = 0.507397695\n",
      "Epoka 960: Loss = 0.352409691\n",
      "Epoka 970: Loss = 0.418832217\n",
      "Epoka 980: Loss = 0.400608603\n",
      "Epoka 990: Loss = 0.488940326\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 8.275800 sekundy dla linear w warstwie ukrytej i 20 neuronów\n",
      "f1 score:\n",
      "0.36889101627851945\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.333489011\n",
      "Epoka 10: Loss = 0.705250410\n",
      "Epoka 20: Loss = 0.764487858\n",
      "Epoka 30: Loss = 0.833793065\n",
      "Epoka 40: Loss = 0.874951548\n",
      "Epoka 50: Loss = 0.840632139\n",
      "Epoka 60: Loss = 0.876201318\n",
      "Epoka 70: Loss = 0.874457327\n",
      "Epoka 80: Loss = 0.880707343\n",
      "Epoka 90: Loss = 0.853891475\n",
      "Epoka 100: Loss = 0.883331851\n",
      "Epoka 110: Loss = 0.867758693\n",
      "Epoka 120: Loss = 0.872355197\n",
      "Epoka 130: Loss = 0.880322631\n",
      "Epoka 140: Loss = 0.864512210\n",
      "Epoka 150: Loss = 0.873280417\n",
      "Epoka 160: Loss = 0.876685490\n",
      "Epoka 170: Loss = 0.860273594\n",
      "Epoka 180: Loss = 0.880760533\n",
      "Epoka 190: Loss = 0.870592138\n",
      "Epoka 200: Loss = 0.866793187\n",
      "Epoka 210: Loss = 0.881608757\n",
      "Epoka 220: Loss = 0.872090497\n",
      "Epoka 230: Loss = 0.876836822\n",
      "Epoka 240: Loss = 0.881722178\n",
      "Epoka 250: Loss = 0.871903376\n",
      "Epoka 260: Loss = 0.875133431\n",
      "Epoka 270: Loss = 0.868090104\n",
      "Epoka 280: Loss = 0.863066164\n",
      "Epoka 290: Loss = 0.892572731\n",
      "Epoka 300: Loss = 0.882464892\n",
      "Epoka 310: Loss = 0.869732122\n",
      "Epoka 320: Loss = 0.875514921\n",
      "Epoka 330: Loss = 0.834268962\n",
      "Epoka 340: Loss = 0.868488486\n",
      "Epoka 350: Loss = 0.871652236\n",
      "Epoka 360: Loss = 0.878044468\n",
      "Epoka 370: Loss = 0.861268693\n",
      "Epoka 380: Loss = 0.875573822\n",
      "Epoka 390: Loss = 0.862706846\n",
      "Epoka 400: Loss = 0.872925413\n",
      "Epoka 410: Loss = 0.853150059\n",
      "Epoka 420: Loss = 0.883494126\n",
      "Epoka 430: Loss = 0.882040824\n",
      "Epoka 440: Loss = 0.866448377\n",
      "Epoka 450: Loss = 0.880521488\n",
      "Epoka 460: Loss = 0.883520145\n",
      "Epoka 470: Loss = 0.879800062\n",
      "Epoka 480: Loss = 0.875462219\n",
      "Epoka 490: Loss = 0.887278886\n",
      "Epoka 500: Loss = 0.877942683\n",
      "Epoka 510: Loss = 0.884150329\n",
      "Epoka 520: Loss = 0.874561483\n",
      "Epoka 530: Loss = 0.875368136\n",
      "Epoka 540: Loss = 0.869066375\n",
      "Epoka 550: Loss = 0.884034203\n",
      "Epoka 560: Loss = 0.857158267\n",
      "Epoka 570: Loss = 0.852204710\n",
      "Epoka 580: Loss = 0.876378899\n",
      "Epoka 590: Loss = 0.869422026\n",
      "Epoka 600: Loss = 0.859301354\n",
      "Epoka 610: Loss = 0.872612115\n",
      "Epoka 620: Loss = 0.868681070\n",
      "Epoka 630: Loss = 0.880859651\n",
      "Epoka 640: Loss = 0.872541624\n",
      "Epoka 650: Loss = 0.871911723\n",
      "Epoka 660: Loss = 0.872995605\n",
      "Epoka 670: Loss = 0.871211501\n",
      "Epoka 680: Loss = 0.877986407\n",
      "Epoka 690: Loss = 0.873517151\n",
      "Epoka 700: Loss = 0.851391903\n",
      "Epoka 710: Loss = 0.886866773\n",
      "Epoka 720: Loss = 0.870034801\n",
      "Epoka 730: Loss = 0.863059913\n",
      "Epoka 740: Loss = 0.869728267\n",
      "Epoka 750: Loss = 0.881573316\n",
      "Epoka 760: Loss = 0.871891010\n",
      "Epoka 770: Loss = 0.870229959\n",
      "Epoka 780: Loss = 0.877635592\n",
      "Epoka 790: Loss = 0.880165133\n",
      "Epoka 800: Loss = 0.859889175\n",
      "Epoka 810: Loss = 0.879627233\n",
      "Epoka 820: Loss = 0.857783807\n",
      "Epoka 830: Loss = 0.858102841\n",
      "Epoka 840: Loss = 0.887200859\n",
      "Epoka 850: Loss = 0.877030769\n",
      "Epoka 860: Loss = 0.871592802\n",
      "Epoka 870: Loss = 0.880483675\n",
      "Epoka 880: Loss = 0.885375021\n",
      "Epoka 890: Loss = 0.855795844\n",
      "Epoka 900: Loss = 0.873739198\n",
      "Epoka 910: Loss = 0.873943981\n",
      "Epoka 920: Loss = 0.860647048\n",
      "Epoka 930: Loss = 0.872615568\n",
      "Epoka 940: Loss = 0.860487800\n",
      "Epoka 950: Loss = 0.872935731\n",
      "Epoka 960: Loss = 0.855535372\n",
      "Epoka 970: Loss = 0.863696545\n",
      "Epoka 980: Loss = 0.863953754\n",
      "Epoka 990: Loss = 0.871672717\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 8.364477 sekundy dla tanh w warstwie ukrytej i 5 neuronów\n",
      "f1 score:\n",
      "0.8530091318568708\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.449560782\n",
      "Epoka 10: Loss = 0.805392364\n",
      "Epoka 20: Loss = 0.862336259\n",
      "Epoka 30: Loss = 0.897383007\n",
      "Epoka 40: Loss = 0.892985126\n",
      "Epoka 50: Loss = 0.919251191\n",
      "Epoka 60: Loss = 0.914488041\n",
      "Epoka 70: Loss = 0.916597820\n",
      "Epoka 80: Loss = 0.921971346\n",
      "Epoka 90: Loss = 0.936626989\n",
      "Epoka 100: Loss = 0.929020166\n",
      "Epoka 110: Loss = 0.935641712\n",
      "Epoka 120: Loss = 0.946675993\n",
      "Epoka 130: Loss = 0.921582645\n",
      "Epoka 140: Loss = 0.937912690\n",
      "Epoka 150: Loss = 0.939321778\n",
      "Epoka 160: Loss = 0.945235231\n",
      "Epoka 170: Loss = 0.942576637\n",
      "Epoka 180: Loss = 0.940335846\n",
      "Epoka 190: Loss = 0.944012410\n",
      "Epoka 200: Loss = 0.941392401\n",
      "Epoka 210: Loss = 0.942107866\n",
      "Epoka 220: Loss = 0.937077185\n",
      "Epoka 230: Loss = 0.946637821\n",
      "Epoka 240: Loss = 0.955992650\n",
      "Epoka 250: Loss = 0.945784581\n",
      "Epoka 260: Loss = 0.939807518\n",
      "Epoka 270: Loss = 0.933789597\n",
      "Epoka 280: Loss = 0.944315456\n",
      "Epoka 290: Loss = 0.953360897\n",
      "Epoka 300: Loss = 0.951872301\n",
      "Epoka 310: Loss = 0.952680835\n",
      "Epoka 320: Loss = 0.950065518\n",
      "Epoka 330: Loss = 0.954734550\n",
      "Epoka 340: Loss = 0.932508141\n",
      "Epoka 350: Loss = 0.939476271\n",
      "Epoka 360: Loss = 0.952045190\n",
      "Epoka 370: Loss = 0.950009795\n",
      "Epoka 380: Loss = 0.936765739\n",
      "Epoka 390: Loss = 0.940459904\n",
      "Epoka 400: Loss = 0.956689253\n",
      "Epoka 410: Loss = 0.953344472\n",
      "Epoka 420: Loss = 0.954408618\n",
      "Epoka 430: Loss = 0.937402263\n",
      "Epoka 440: Loss = 0.953123696\n",
      "Epoka 450: Loss = 0.951042111\n",
      "Epoka 460: Loss = 0.946457730\n",
      "Epoka 470: Loss = 0.930912331\n",
      "Epoka 480: Loss = 0.933407937\n",
      "Epoka 490: Loss = 0.953300699\n",
      "Epoka 500: Loss = 0.954558613\n",
      "Epoka 510: Loss = 0.957930439\n",
      "Epoka 520: Loss = 0.939455702\n",
      "Epoka 530: Loss = 0.953443659\n",
      "Epoka 540: Loss = 0.959929393\n",
      "Epoka 550: Loss = 0.955894243\n",
      "Epoka 560: Loss = 0.943143243\n",
      "Epoka 570: Loss = 0.944054171\n",
      "Epoka 580: Loss = 0.937389753\n",
      "Epoka 590: Loss = 0.952497121\n",
      "Epoka 600: Loss = 0.951747707\n",
      "Epoka 610: Loss = 0.957385021\n",
      "Epoka 620: Loss = 0.941230755\n",
      "Epoka 630: Loss = 0.949760516\n",
      "Epoka 640: Loss = 0.951690678\n",
      "Epoka 650: Loss = 0.944558905\n",
      "Epoka 660: Loss = 0.952427852\n",
      "Epoka 670: Loss = 0.956792654\n",
      "Epoka 680: Loss = 0.955210590\n",
      "Epoka 690: Loss = 0.948527541\n",
      "Epoka 700: Loss = 0.942664699\n",
      "Epoka 710: Loss = 0.952321606\n",
      "Epoka 720: Loss = 0.955374392\n",
      "Epoka 730: Loss = 0.951970739\n",
      "Epoka 740: Loss = 0.958649368\n",
      "Epoka 750: Loss = 0.942578395\n",
      "Epoka 760: Loss = 0.931272459\n",
      "Epoka 770: Loss = 0.949457573\n",
      "Epoka 780: Loss = 0.930202162\n",
      "Epoka 790: Loss = 0.947431807\n",
      "Epoka 800: Loss = 0.951456010\n",
      "Epoka 810: Loss = 0.955316606\n",
      "Epoka 820: Loss = 0.957223035\n",
      "Epoka 830: Loss = 0.952450377\n",
      "Epoka 840: Loss = 0.940439373\n",
      "Epoka 850: Loss = 0.957903263\n",
      "Epoka 860: Loss = 0.961332846\n",
      "Epoka 870: Loss = 0.953303385\n",
      "Epoka 880: Loss = 0.945637099\n",
      "Epoka 890: Loss = 0.933649199\n",
      "Epoka 900: Loss = 0.952684005\n",
      "Epoka 910: Loss = 0.944113602\n",
      "Epoka 920: Loss = 0.961313620\n",
      "Epoka 930: Loss = 0.955824998\n",
      "Epoka 940: Loss = 0.942836434\n",
      "Epoka 950: Loss = 0.951515152\n",
      "Epoka 960: Loss = 0.943455494\n",
      "Epoka 970: Loss = 0.953863655\n",
      "Epoka 980: Loss = 0.958023675\n",
      "Epoka 990: Loss = 0.958749954\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 8.451949 sekundy dla tanh w warstwie ukrytej i 10 neuronów\n",
      "f1 score:\n",
      "0.9219254247564551\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.421965414\n",
      "Epoka 10: Loss = 0.804761801\n",
      "Epoka 20: Loss = 0.852985029\n",
      "Epoka 30: Loss = 0.879568185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 40: Loss = 0.908913334\n",
      "Epoka 50: Loss = 0.934167163\n",
      "Epoka 60: Loss = 0.926241518\n",
      "Epoka 70: Loss = 0.912151437\n",
      "Epoka 80: Loss = 0.941376763\n",
      "Epoka 90: Loss = 0.937783460\n",
      "Epoka 100: Loss = 0.933427087\n",
      "Epoka 110: Loss = 0.946580093\n",
      "Epoka 120: Loss = 0.935033624\n",
      "Epoka 130: Loss = 0.954014028\n",
      "Epoka 140: Loss = 0.959326339\n",
      "Epoka 150: Loss = 0.952594394\n",
      "Epoka 160: Loss = 0.963997599\n",
      "Epoka 170: Loss = 0.960086387\n",
      "Epoka 180: Loss = 0.964628618\n",
      "Epoka 190: Loss = 0.961907779\n",
      "Epoka 200: Loss = 0.958078817\n",
      "Epoka 210: Loss = 0.957877550\n",
      "Epoka 220: Loss = 0.966675715\n",
      "Epoka 230: Loss = 0.971969770\n",
      "Epoka 240: Loss = 0.958732480\n",
      "Epoka 250: Loss = 0.959243493\n",
      "Epoka 260: Loss = 0.970009434\n",
      "Epoka 270: Loss = 0.959228011\n",
      "Epoka 280: Loss = 0.973348807\n",
      "Epoka 290: Loss = 0.970665526\n",
      "Epoka 300: Loss = 0.967371313\n",
      "Epoka 310: Loss = 0.957285390\n",
      "Epoka 320: Loss = 0.965401226\n",
      "Epoka 330: Loss = 0.961378331\n",
      "Epoka 340: Loss = 0.953035437\n",
      "Epoka 350: Loss = 0.968734390\n",
      "Epoka 360: Loss = 0.974689856\n",
      "Epoka 370: Loss = 0.957387391\n",
      "Epoka 380: Loss = 0.964668321\n",
      "Epoka 390: Loss = 0.962427731\n",
      "Epoka 400: Loss = 0.965378995\n",
      "Epoka 410: Loss = 0.969271374\n",
      "Epoka 420: Loss = 0.967236595\n",
      "Epoka 430: Loss = 0.970651371\n",
      "Epoka 440: Loss = 0.959391606\n",
      "Epoka 450: Loss = 0.967259160\n",
      "Epoka 460: Loss = 0.965986129\n",
      "Epoka 470: Loss = 0.966524333\n",
      "Epoka 480: Loss = 0.967399594\n",
      "Epoka 490: Loss = 0.950966101\n",
      "Epoka 500: Loss = 0.972064214\n",
      "Epoka 510: Loss = 0.970049781\n",
      "Epoka 520: Loss = 0.965279833\n",
      "Epoka 530: Loss = 0.974013021\n",
      "Epoka 540: Loss = 0.975295433\n",
      "Epoka 550: Loss = 0.971365206\n",
      "Epoka 560: Loss = 0.974698628\n",
      "Epoka 570: Loss = 0.977989014\n",
      "Epoka 580: Loss = 0.968693676\n",
      "Epoka 590: Loss = 0.964536565\n",
      "Epoka 600: Loss = 0.975352852\n",
      "Epoka 610: Loss = 0.971330038\n",
      "Epoka 620: Loss = 0.967265349\n",
      "Epoka 630: Loss = 0.965901179\n",
      "Epoka 640: Loss = 0.965993990\n",
      "Epoka 650: Loss = 0.972687469\n",
      "Epoka 660: Loss = 0.962630544\n",
      "Epoka 670: Loss = 0.979342933\n",
      "Epoka 680: Loss = 0.979339822\n",
      "Epoka 690: Loss = 0.966662056\n",
      "Epoka 700: Loss = 0.978672085\n",
      "Epoka 710: Loss = 0.961209813\n",
      "Epoka 720: Loss = 0.973303886\n",
      "Epoka 730: Loss = 0.974627339\n",
      "Epoka 740: Loss = 0.978674613\n",
      "Epoka 750: Loss = 0.972649281\n",
      "Epoka 760: Loss = 0.975359485\n",
      "Epoka 770: Loss = 0.970565011\n",
      "Epoka 780: Loss = 0.972691841\n",
      "Epoka 790: Loss = 0.966630476\n",
      "Epoka 800: Loss = 0.975976640\n",
      "Epoka 810: Loss = 0.960431079\n",
      "Epoka 820: Loss = 0.974685343\n",
      "Epoka 830: Loss = 0.967251214\n",
      "Epoka 840: Loss = 0.962042429\n",
      "Epoka 850: Loss = 0.967298844\n",
      "Epoka 860: Loss = 0.974671419\n",
      "Epoka 870: Loss = 0.971262764\n",
      "Epoka 880: Loss = 0.974683657\n",
      "Epoka 890: Loss = 0.970692851\n",
      "Epoka 900: Loss = 0.978011525\n",
      "Epoka 910: Loss = 0.970618377\n",
      "Epoka 920: Loss = 0.971323928\n",
      "Epoka 930: Loss = 0.967932916\n",
      "Epoka 940: Loss = 0.972612879\n",
      "Epoka 950: Loss = 0.974015069\n",
      "Epoka 960: Loss = 0.971997718\n",
      "Epoka 970: Loss = 0.975351649\n",
      "Epoka 980: Loss = 0.980671835\n",
      "Epoka 990: Loss = 0.973303632\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 8.813730 sekundy dla tanh w warstwie ukrytej i 15 neuronów\n",
      "f1 score:\n",
      "0.9457121265920853\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.460814228\n",
      "Epoka 10: Loss = 0.820738967\n",
      "Epoka 20: Loss = 0.886398808\n",
      "Epoka 30: Loss = 0.900719261\n",
      "Epoka 40: Loss = 0.915642931\n",
      "Epoka 50: Loss = 0.932664009\n",
      "Epoka 60: Loss = 0.933843127\n",
      "Epoka 70: Loss = 0.942141239\n",
      "Epoka 80: Loss = 0.953379773\n",
      "Epoka 90: Loss = 0.950891351\n",
      "Epoka 100: Loss = 0.940605743\n",
      "Epoka 110: Loss = 0.947225550\n",
      "Epoka 120: Loss = 0.946615957\n",
      "Epoka 130: Loss = 0.958049152\n",
      "Epoka 140: Loss = 0.957932281\n",
      "Epoka 150: Loss = 0.960053899\n",
      "Epoka 160: Loss = 0.960002461\n",
      "Epoka 170: Loss = 0.963372157\n",
      "Epoka 180: Loss = 0.966758853\n",
      "Epoka 190: Loss = 0.959481306\n",
      "Epoka 200: Loss = 0.958570856\n",
      "Epoka 210: Loss = 0.963438198\n",
      "Epoka 220: Loss = 0.965316373\n",
      "Epoka 230: Loss = 0.961891291\n",
      "Epoka 240: Loss = 0.967968971\n",
      "Epoka 250: Loss = 0.952483137\n",
      "Epoka 260: Loss = 0.965255543\n",
      "Epoka 270: Loss = 0.969982548\n",
      "Epoka 280: Loss = 0.976669419\n",
      "Epoka 290: Loss = 0.953989786\n",
      "Epoka 300: Loss = 0.972668108\n",
      "Epoka 310: Loss = 0.963966054\n",
      "Epoka 320: Loss = 0.977333035\n",
      "Epoka 330: Loss = 0.967404366\n",
      "Epoka 340: Loss = 0.966693085\n",
      "Epoka 350: Loss = 0.973322431\n",
      "Epoka 360: Loss = 0.965264029\n",
      "Epoka 370: Loss = 0.963827393\n",
      "Epoka 380: Loss = 0.978677719\n",
      "Epoka 390: Loss = 0.973347552\n",
      "Epoka 400: Loss = 0.969903362\n",
      "Epoka 410: Loss = 0.975312958\n",
      "Epoka 420: Loss = 0.974637481\n",
      "Epoka 430: Loss = 0.965727124\n",
      "Epoka 440: Loss = 0.969228536\n",
      "Epoka 450: Loss = 0.976004488\n",
      "Epoka 460: Loss = 0.980671959\n",
      "Epoka 470: Loss = 0.963904438\n",
      "Epoka 480: Loss = 0.975276702\n",
      "Epoka 490: Loss = 0.979336100\n",
      "Epoka 500: Loss = 0.970574756\n",
      "Epoka 510: Loss = 0.979381163\n",
      "Epoka 520: Loss = 0.982646575\n",
      "Epoka 530: Loss = 0.975289279\n",
      "Epoka 540: Loss = 0.975906541\n",
      "Epoka 550: Loss = 0.974597996\n",
      "Epoka 560: Loss = 0.977332056\n",
      "Epoka 570: Loss = 0.978734281\n",
      "Epoka 580: Loss = 0.981300690\n",
      "Epoka 590: Loss = 0.976026857\n",
      "Epoka 600: Loss = 0.977339391\n",
      "Epoka 610: Loss = 0.979961848\n",
      "Epoka 620: Loss = 0.979979543\n",
      "Epoka 630: Loss = 0.982019079\n",
      "Epoka 640: Loss = 0.975378835\n",
      "Epoka 650: Loss = 0.978026725\n",
      "Epoka 660: Loss = 0.977279307\n",
      "Epoka 670: Loss = 0.979997016\n",
      "Epoka 680: Loss = 0.977990762\n",
      "Epoka 690: Loss = 0.974547686\n",
      "Epoka 700: Loss = 0.983346294\n",
      "Epoka 710: Loss = 0.980612497\n",
      "Epoka 720: Loss = 0.982664554\n",
      "Epoka 730: Loss = 0.971262375\n",
      "Epoka 740: Loss = 0.982639070\n",
      "Epoka 750: Loss = 0.981984421\n",
      "Epoka 760: Loss = 0.981269991\n",
      "Epoka 770: Loss = 0.978643430\n",
      "Epoka 780: Loss = 0.975360900\n",
      "Epoka 790: Loss = 0.984014836\n",
      "Epoka 800: Loss = 0.978074236\n",
      "Epoka 810: Loss = 0.980601631\n",
      "Epoka 820: Loss = 0.983958590\n",
      "Epoka 830: Loss = 0.981310238\n",
      "Epoka 840: Loss = 0.982652865\n",
      "Epoka 850: Loss = 0.984040764\n",
      "Epoka 860: Loss = 0.977335185\n",
      "Epoka 870: Loss = 0.983345448\n",
      "Epoka 880: Loss = 0.987319539\n",
      "Epoka 890: Loss = 0.987330528\n",
      "Epoka 900: Loss = 0.977304094\n",
      "Epoka 910: Loss = 0.978608498\n",
      "Epoka 920: Loss = 0.983312331\n",
      "Epoka 930: Loss = 0.980007715\n",
      "Epoka 940: Loss = 0.983346560\n",
      "Epoka 950: Loss = 0.985998487\n",
      "Epoka 960: Loss = 0.985990596\n",
      "Epoka 970: Loss = 0.978628079\n",
      "Epoka 980: Loss = 0.984652928\n",
      "Epoka 990: Loss = 0.985321299\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 10.139333 sekundy dla tanh w warstwie ukrytej i 20 neuronów\n",
      "f1 score:\n",
      "0.9632497886044065\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.392882748\n",
      "Epoka 10: Loss = 0.588841012\n",
      "Epoka 20: Loss = 0.713986192\n",
      "Epoka 30: Loss = 0.719120184\n",
      "Epoka 40: Loss = 0.764033259\n",
      "Epoka 50: Loss = 0.732289941\n",
      "Epoka 60: Loss = 0.747674421\n",
      "Epoka 70: Loss = 0.767435478\n",
      "Epoka 80: Loss = 0.756993590\n",
      "Epoka 90: Loss = 0.747898491\n",
      "Epoka 100: Loss = 0.764841225\n",
      "Epoka 110: Loss = 0.752435039\n",
      "Epoka 120: Loss = 0.727706785\n",
      "Epoka 130: Loss = 0.765986890\n",
      "Epoka 140: Loss = 0.767329762\n",
      "Epoka 150: Loss = 0.773779728\n",
      "Epoka 160: Loss = 0.758736200\n",
      "Epoka 170: Loss = 0.776054942\n",
      "Epoka 180: Loss = 0.770091730\n",
      "Epoka 190: Loss = 0.753353437\n",
      "Epoka 200: Loss = 0.765977037\n",
      "Epoka 210: Loss = 0.772630696\n",
      "Epoka 220: Loss = 0.768965870\n",
      "Epoka 230: Loss = 0.763424759\n",
      "Epoka 240: Loss = 0.752779242\n",
      "Epoka 250: Loss = 0.754758608\n",
      "Epoka 260: Loss = 0.776746311\n",
      "Epoka 270: Loss = 0.755728269\n",
      "Epoka 280: Loss = 0.777781209\n",
      "Epoka 290: Loss = 0.768085660\n",
      "Epoka 300: Loss = 0.775374228\n",
      "Epoka 310: Loss = 0.780560796\n",
      "Epoka 320: Loss = 0.751912275\n",
      "Epoka 330: Loss = 0.771663214\n",
      "Epoka 340: Loss = 0.770100008\n",
      "Epoka 350: Loss = 0.764994806\n",
      "Epoka 360: Loss = 0.776710352\n",
      "Epoka 370: Loss = 0.767502183\n",
      "Epoka 380: Loss = 0.777848149\n",
      "Epoka 390: Loss = 0.768178261\n",
      "Epoka 400: Loss = 0.767938617\n",
      "Epoka 410: Loss = 0.768530971\n",
      "Epoka 420: Loss = 0.778524549\n",
      "Epoka 430: Loss = 0.753129386\n",
      "Epoka 440: Loss = 0.773757658\n",
      "Epoka 450: Loss = 0.776418032\n",
      "Epoka 460: Loss = 0.776148259\n",
      "Epoka 470: Loss = 0.759395735\n",
      "Epoka 480: Loss = 0.771027223\n",
      "Epoka 490: Loss = 0.753707920\n",
      "Epoka 500: Loss = 0.771575328\n",
      "Epoka 510: Loss = 0.778710515\n",
      "Epoka 520: Loss = 0.772661055\n",
      "Epoka 530: Loss = 0.767681094\n",
      "Epoka 540: Loss = 0.764061792\n",
      "Epoka 550: Loss = 0.757801967\n",
      "Epoka 560: Loss = 0.771200953\n",
      "Epoka 570: Loss = 0.767493180\n",
      "Epoka 580: Loss = 0.773229567\n",
      "Epoka 590: Loss = 0.744934840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 600: Loss = 0.778290504\n",
      "Epoka 610: Loss = 0.765893593\n",
      "Epoka 620: Loss = 0.740068646\n",
      "Epoka 630: Loss = 0.779541072\n",
      "Epoka 640: Loss = 0.760347103\n",
      "Epoka 650: Loss = 0.767065041\n",
      "Epoka 660: Loss = 0.757625064\n",
      "Epoka 670: Loss = 0.765889023\n",
      "Epoka 680: Loss = 0.749657440\n",
      "Epoka 690: Loss = 0.760206196\n",
      "Epoka 700: Loss = 0.759413917\n",
      "Epoka 710: Loss = 0.780131310\n",
      "Epoka 720: Loss = 0.736095452\n",
      "Epoka 730: Loss = 0.756619702\n",
      "Epoka 740: Loss = 0.770295490\n",
      "Epoka 750: Loss = 0.767161662\n",
      "Epoka 760: Loss = 0.774096158\n",
      "Epoka 770: Loss = 0.765877078\n",
      "Epoka 780: Loss = 0.752137122\n",
      "Epoka 790: Loss = 0.777262674\n",
      "Epoka 800: Loss = 0.764392560\n",
      "Epoka 810: Loss = 0.767642068\n",
      "Epoka 820: Loss = 0.779192733\n",
      "Epoka 830: Loss = 0.777702474\n",
      "Epoka 840: Loss = 0.756956485\n",
      "Epoka 850: Loss = 0.774853360\n",
      "Epoka 860: Loss = 0.770443245\n",
      "Epoka 870: Loss = 0.756618249\n",
      "Epoka 880: Loss = 0.752008168\n",
      "Epoka 890: Loss = 0.769936788\n",
      "Epoka 900: Loss = 0.761628885\n",
      "Epoka 910: Loss = 0.773199239\n",
      "Epoka 920: Loss = 0.770429392\n",
      "Epoka 930: Loss = 0.770529791\n",
      "Epoka 940: Loss = 0.773374907\n",
      "Epoka 950: Loss = 0.774559416\n",
      "Epoka 960: Loss = 0.773560308\n",
      "Epoka 970: Loss = 0.776465575\n",
      "Epoka 980: Loss = 0.766577088\n",
      "Epoka 990: Loss = 0.768085026\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 7.871230 sekundy dla relu w warstwie ukrytej i 5 neuronów\n",
      "f1 score:\n",
      "0.7581027491154447\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.361245161\n",
      "Epoka 10: Loss = 0.687627163\n",
      "Epoka 20: Loss = 0.868588704\n",
      "Epoka 30: Loss = 0.889773276\n",
      "Epoka 40: Loss = 0.876175674\n",
      "Epoka 50: Loss = 0.876987643\n",
      "Epoka 60: Loss = 0.890590025\n",
      "Epoka 70: Loss = 0.887549295\n",
      "Epoka 80: Loss = 0.895017122\n",
      "Epoka 90: Loss = 0.898030546\n",
      "Epoka 100: Loss = 0.894679398\n",
      "Epoka 110: Loss = 0.897689371\n",
      "Epoka 120: Loss = 0.911663776\n",
      "Epoka 130: Loss = 0.915157211\n",
      "Epoka 140: Loss = 0.901975581\n",
      "Epoka 150: Loss = 0.906082009\n",
      "Epoka 160: Loss = 0.910650076\n",
      "Epoka 170: Loss = 0.916621102\n",
      "Epoka 180: Loss = 0.907234782\n",
      "Epoka 190: Loss = 0.885180108\n",
      "Epoka 200: Loss = 0.912411736\n",
      "Epoka 210: Loss = 0.879908464\n",
      "Epoka 220: Loss = 0.883974170\n",
      "Epoka 230: Loss = 0.896905241\n",
      "Epoka 240: Loss = 0.873059909\n",
      "Epoka 250: Loss = 0.909179206\n",
      "Epoka 260: Loss = 0.920089028\n",
      "Epoka 270: Loss = 0.910936936\n",
      "Epoka 280: Loss = 0.909844494\n",
      "Epoka 290: Loss = 0.914697243\n",
      "Epoka 300: Loss = 0.906861584\n",
      "Epoka 310: Loss = 0.902945652\n",
      "Epoka 320: Loss = 0.908265201\n",
      "Epoka 330: Loss = 0.904204402\n",
      "Epoka 340: Loss = 0.917346070\n",
      "Epoka 350: Loss = 0.927355129\n",
      "Epoka 360: Loss = 0.921787378\n",
      "Epoka 370: Loss = 0.900040281\n",
      "Epoka 380: Loss = 0.915529934\n",
      "Epoka 390: Loss = 0.913488326\n",
      "Epoka 400: Loss = 0.923563599\n",
      "Epoka 410: Loss = 0.922430141\n",
      "Epoka 420: Loss = 0.894241854\n",
      "Epoka 430: Loss = 0.910522142\n",
      "Epoka 440: Loss = 0.931466059\n",
      "Epoka 450: Loss = 0.929205264\n",
      "Epoka 460: Loss = 0.931257041\n",
      "Epoka 470: Loss = 0.908700677\n",
      "Epoka 480: Loss = 0.911982258\n",
      "Epoka 490: Loss = 0.910637613\n",
      "Epoka 500: Loss = 0.882403113\n",
      "Epoka 510: Loss = 0.932239079\n",
      "Epoka 520: Loss = 0.885932427\n",
      "Epoka 530: Loss = 0.914811638\n",
      "Epoka 540: Loss = 0.920053888\n",
      "Epoka 550: Loss = 0.915419609\n",
      "Epoka 560: Loss = 0.919611743\n",
      "Epoka 570: Loss = 0.921197058\n",
      "Epoka 580: Loss = 0.916151538\n",
      "Epoka 590: Loss = 0.925793105\n",
      "Epoka 600: Loss = 0.916938237\n",
      "Epoka 610: Loss = 0.904144445\n",
      "Epoka 620: Loss = 0.928663059\n",
      "Epoka 630: Loss = 0.926835076\n",
      "Epoka 640: Loss = 0.920461194\n",
      "Epoka 650: Loss = 0.924152841\n",
      "Epoka 660: Loss = 0.920710213\n",
      "Epoka 670: Loss = 0.895123032\n",
      "Epoka 680: Loss = 0.868972562\n",
      "Epoka 690: Loss = 0.905358950\n",
      "Epoka 700: Loss = 0.913688109\n",
      "Epoka 710: Loss = 0.917341983\n",
      "Epoka 720: Loss = 0.908392352\n",
      "Epoka 730: Loss = 0.911217661\n",
      "Epoka 740: Loss = 0.901606442\n",
      "Epoka 750: Loss = 0.919364913\n",
      "Epoka 760: Loss = 0.920251169\n",
      "Epoka 770: Loss = 0.924743782\n",
      "Epoka 780: Loss = 0.912897895\n",
      "Epoka 790: Loss = 0.915333605\n",
      "Epoka 800: Loss = 0.927249030\n",
      "Epoka 810: Loss = 0.908556335\n",
      "Epoka 820: Loss = 0.926496699\n",
      "Epoka 830: Loss = 0.913436278\n",
      "Epoka 840: Loss = 0.926007702\n",
      "Epoka 850: Loss = 0.918471179\n",
      "Epoka 860: Loss = 0.917425503\n",
      "Epoka 870: Loss = 0.916729719\n",
      "Epoka 880: Loss = 0.921602838\n",
      "Epoka 890: Loss = 0.914655805\n",
      "Epoka 900: Loss = 0.927381829\n",
      "Epoka 910: Loss = 0.927514402\n",
      "Epoka 920: Loss = 0.910483302\n",
      "Epoka 930: Loss = 0.894853677\n",
      "Epoka 940: Loss = 0.926784304\n",
      "Epoka 950: Loss = 0.906018501\n",
      "Epoka 960: Loss = 0.931626796\n",
      "Epoka 970: Loss = 0.919694882\n",
      "Epoka 980: Loss = 0.899020883\n",
      "Epoka 990: Loss = 0.908287057\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 8.026364 sekundy dla relu w warstwie ukrytej i 10 neuronów\n",
      "f1 score:\n",
      "0.9002165822525008\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.458302789\n",
      "Epoka 10: Loss = 0.724872592\n",
      "Epoka 20: Loss = 0.877152625\n",
      "Epoka 30: Loss = 0.876516183\n",
      "Epoka 40: Loss = 0.903915716\n",
      "Epoka 50: Loss = 0.896020048\n",
      "Epoka 60: Loss = 0.921848189\n",
      "Epoka 70: Loss = 0.922427710\n",
      "Epoka 80: Loss = 0.910008302\n",
      "Epoka 90: Loss = 0.887054989\n",
      "Epoka 100: Loss = 0.895349066\n",
      "Epoka 110: Loss = 0.907572490\n",
      "Epoka 120: Loss = 0.868056010\n",
      "Epoka 130: Loss = 0.939758317\n",
      "Epoka 140: Loss = 0.912386451\n",
      "Epoka 150: Loss = 0.928683845\n",
      "Epoka 160: Loss = 0.937569956\n",
      "Epoka 170: Loss = 0.949248485\n",
      "Epoka 180: Loss = 0.934829423\n",
      "Epoka 190: Loss = 0.930113871\n",
      "Epoka 200: Loss = 0.905837358\n",
      "Epoka 210: Loss = 0.931079656\n",
      "Epoka 220: Loss = 0.947151133\n",
      "Epoka 230: Loss = 0.918853136\n",
      "Epoka 240: Loss = 0.908373431\n",
      "Epoka 250: Loss = 0.932227721\n",
      "Epoka 260: Loss = 0.931645432\n",
      "Epoka 270: Loss = 0.937699987\n",
      "Epoka 280: Loss = 0.928275997\n",
      "Epoka 290: Loss = 0.921741862\n",
      "Epoka 300: Loss = 0.924037699\n",
      "Epoka 310: Loss = 0.914294321\n",
      "Epoka 320: Loss = 0.919136178\n",
      "Epoka 330: Loss = 0.938034895\n",
      "Epoka 340: Loss = 0.958009784\n",
      "Epoka 350: Loss = 0.923708550\n",
      "Epoka 360: Loss = 0.949938057\n",
      "Epoka 370: Loss = 0.938858132\n",
      "Epoka 380: Loss = 0.943605844\n",
      "Epoka 390: Loss = 0.898969459\n",
      "Epoka 400: Loss = 0.933880628\n",
      "Epoka 410: Loss = 0.941256641\n",
      "Epoka 420: Loss = 0.942002334\n",
      "Epoka 430: Loss = 0.951945351\n",
      "Epoka 440: Loss = 0.952498948\n",
      "Epoka 450: Loss = 0.934820511\n",
      "Epoka 460: Loss = 0.916433098\n",
      "Epoka 470: Loss = 0.960087961\n",
      "Epoka 480: Loss = 0.912652535\n",
      "Epoka 490: Loss = 0.932490404\n",
      "Epoka 500: Loss = 0.933158514\n",
      "Epoka 510: Loss = 0.926235559\n",
      "Epoka 520: Loss = 0.927756938\n",
      "Epoka 530: Loss = 0.960694831\n",
      "Epoka 540: Loss = 0.954694180\n",
      "Epoka 550: Loss = 0.936776319\n",
      "Epoka 560: Loss = 0.938914381\n",
      "Epoka 570: Loss = 0.941074307\n",
      "Epoka 580: Loss = 0.906004170\n",
      "Epoka 590: Loss = 0.951435829\n",
      "Epoka 600: Loss = 0.950033192\n",
      "Epoka 610: Loss = 0.892871825\n",
      "Epoka 620: Loss = 0.955362525\n",
      "Epoka 630: Loss = 0.906037131\n",
      "Epoka 640: Loss = 0.954013536\n",
      "Epoka 650: Loss = 0.955991133\n",
      "Epoka 660: Loss = 0.941864860\n",
      "Epoka 670: Loss = 0.947316057\n",
      "Epoka 680: Loss = 0.959344775\n",
      "Epoka 690: Loss = 0.962036731\n",
      "Epoka 700: Loss = 0.959253517\n",
      "Epoka 710: Loss = 0.922547232\n",
      "Epoka 720: Loss = 0.918390880\n",
      "Epoka 730: Loss = 0.944049048\n",
      "Epoka 740: Loss = 0.953945048\n",
      "Epoka 750: Loss = 0.924224312\n",
      "Epoka 760: Loss = 0.933095456\n",
      "Epoka 770: Loss = 0.950009632\n",
      "Epoka 780: Loss = 0.952681600\n",
      "Epoka 790: Loss = 0.911685887\n",
      "Epoka 800: Loss = 0.905022603\n",
      "Epoka 810: Loss = 0.904578556\n",
      "Epoka 820: Loss = 0.945454395\n",
      "Epoka 830: Loss = 0.959919461\n",
      "Epoka 840: Loss = 0.963194514\n",
      "Epoka 850: Loss = 0.953308586\n",
      "Epoka 860: Loss = 0.952091143\n",
      "Epoka 870: Loss = 0.951288723\n",
      "Epoka 880: Loss = 0.891087609\n",
      "Epoka 890: Loss = 0.955285432\n",
      "Epoka 900: Loss = 0.944605174\n",
      "Epoka 910: Loss = 0.959266647\n",
      "Epoka 920: Loss = 0.946948395\n",
      "Epoka 930: Loss = 0.925179064\n",
      "Epoka 940: Loss = 0.956030722\n",
      "Epoka 950: Loss = 0.941063666\n",
      "Epoka 960: Loss = 0.963408574\n",
      "Epoka 970: Loss = 0.941327700\n",
      "Epoka 980: Loss = 0.956078397\n",
      "Epoka 990: Loss = 0.964628123\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 8.448322 sekundy dla relu w warstwie ukrytej i 15 neuronów\n",
      "f1 score:\n",
      "0.9216565094653015\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.469042800\n",
      "Epoka 10: Loss = 0.659424301\n",
      "Epoka 20: Loss = 0.800064531\n",
      "Epoka 30: Loss = 0.821264762\n",
      "Epoka 40: Loss = 0.866035246\n",
      "Epoka 50: Loss = 0.916232737\n",
      "Epoka 60: Loss = 0.867211192\n",
      "Epoka 70: Loss = 0.917820600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 80: Loss = 0.919229217\n",
      "Epoka 90: Loss = 0.928819533\n",
      "Epoka 100: Loss = 0.901539152\n",
      "Epoka 110: Loss = 0.932672617\n",
      "Epoka 120: Loss = 0.930852166\n",
      "Epoka 130: Loss = 0.894338214\n",
      "Epoka 140: Loss = 0.930897581\n",
      "Epoka 150: Loss = 0.928491707\n",
      "Epoka 160: Loss = 0.923122525\n",
      "Epoka 170: Loss = 0.919864374\n",
      "Epoka 180: Loss = 0.930678139\n",
      "Epoka 190: Loss = 0.900613557\n",
      "Epoka 200: Loss = 0.938979842\n",
      "Epoka 210: Loss = 0.925636659\n",
      "Epoka 220: Loss = 0.891455546\n",
      "Epoka 230: Loss = 0.913089428\n",
      "Epoka 240: Loss = 0.902817982\n",
      "Epoka 250: Loss = 0.941366454\n",
      "Epoka 260: Loss = 0.851325059\n",
      "Epoka 270: Loss = 0.947345910\n",
      "Epoka 280: Loss = 0.959987553\n",
      "Epoka 290: Loss = 0.928816032\n",
      "Epoka 300: Loss = 0.950510612\n",
      "Epoka 310: Loss = 0.938268348\n",
      "Epoka 320: Loss = 0.947976899\n",
      "Epoka 330: Loss = 0.951978529\n",
      "Epoka 340: Loss = 0.918520906\n",
      "Epoka 350: Loss = 0.921508256\n",
      "Epoka 360: Loss = 0.942252139\n",
      "Epoka 370: Loss = 0.958627662\n",
      "Epoka 380: Loss = 0.930293012\n",
      "Epoka 390: Loss = 0.853419703\n",
      "Epoka 400: Loss = 0.912782615\n",
      "Epoka 410: Loss = 0.932763818\n",
      "Epoka 420: Loss = 0.920095816\n",
      "Epoka 430: Loss = 0.923625841\n",
      "Epoka 440: Loss = 0.951925239\n",
      "Epoka 450: Loss = 0.959385744\n",
      "Epoka 460: Loss = 0.959274513\n",
      "Epoka 470: Loss = 0.809794818\n",
      "Epoka 480: Loss = 0.944453360\n",
      "Epoka 490: Loss = 0.959870638\n",
      "Epoka 500: Loss = 0.920066585\n",
      "Epoka 510: Loss = 0.909057688\n",
      "Epoka 520: Loss = 0.910554256\n",
      "Epoka 530: Loss = 0.933432824\n",
      "Epoka 540: Loss = 0.951886270\n",
      "Epoka 550: Loss = 0.915057184\n",
      "Epoka 560: Loss = 0.921020221\n",
      "Epoka 570: Loss = 0.964676584\n",
      "Epoka 580: Loss = 0.940788801\n",
      "Epoka 590: Loss = 0.949990516\n",
      "Epoka 600: Loss = 0.962620523\n",
      "Epoka 610: Loss = 0.963994627\n",
      "Epoka 620: Loss = 0.966674988\n",
      "Epoka 630: Loss = 0.961336268\n",
      "Epoka 640: Loss = 0.937405594\n",
      "Epoka 650: Loss = 0.936647531\n",
      "Epoka 660: Loss = 0.965299470\n",
      "Epoka 670: Loss = 0.968694436\n",
      "Epoka 680: Loss = 0.903016637\n",
      "Epoka 690: Loss = 0.950592690\n",
      "Epoka 700: Loss = 0.933418451\n",
      "Epoka 710: Loss = 0.964590448\n",
      "Epoka 720: Loss = 0.957112510\n",
      "Epoka 730: Loss = 0.944749678\n",
      "Epoka 740: Loss = 0.951340053\n",
      "Epoka 750: Loss = 0.962642645\n",
      "Epoka 760: Loss = 0.957339137\n",
      "Epoka 770: Loss = 0.957994334\n",
      "Epoka 780: Loss = 0.893600178\n",
      "Epoka 790: Loss = 0.920363342\n",
      "Epoka 800: Loss = 0.954716723\n",
      "Epoka 810: Loss = 0.961236368\n",
      "Epoka 820: Loss = 0.960095961\n",
      "Epoka 830: Loss = 0.941090834\n",
      "Epoka 840: Loss = 0.937213579\n",
      "Epoka 850: Loss = 0.958663044\n",
      "Epoka 860: Loss = 0.942756261\n",
      "Epoka 870: Loss = 0.963919998\n",
      "Epoka 880: Loss = 0.959941508\n",
      "Epoka 890: Loss = 0.917430108\n",
      "Epoka 900: Loss = 0.944217246\n",
      "Epoka 910: Loss = 0.939089497\n",
      "Epoka 920: Loss = 0.959979965\n",
      "Epoka 930: Loss = 0.963356121\n",
      "Epoka 940: Loss = 0.949902444\n",
      "Epoka 950: Loss = 0.966696401\n",
      "Epoka 960: Loss = 0.968629241\n",
      "Epoka 970: Loss = 0.959988613\n",
      "Epoka 980: Loss = 0.951937221\n",
      "Epoka 990: Loss = 0.943202261\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 9.258886 sekundy dla relu w warstwie ukrytej i 20 neuronów\n",
      "f1 score:\n",
      "0.9164073848943387\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "activation_functions =['sigmoid', 'linear', 'tanh', 'relu']\n",
    "num_neurons = [5, 10, 15, 20]\n",
    "for el in activation_functions:\n",
    "    for neurons in num_neurons:\n",
    "        mlp_ringsR = MLPNoBackprop(layer_sizes = [X_ringsR_train.shape[1], neurons, len(np.unique(Y_ringsR_train))], \n",
    "                                   output_activation='softmax', hidden_activation = el)\n",
    "        start_time = time.time()\n",
    "        mlp_ringsR.classifiaction_train(X_ringsR_train_normalized, Y_ringsR_train, epochs = 1000, learning_rate=0.01, batch_size=10)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print('--------------------------------------------------------------------------------------------')\n",
    "        print(f\"Czas wykonania: {execution_time:.6f} sekundy dla {el} w warstwie ukrytej i {neurons} neuronów\")\n",
    "        ypred = mlp_ringsR.predict_classification(X_ringsR_test_normalized)\n",
    "        print('f1 score:')\n",
    "        print(mlp_ringsR.f1_score(Y_ringsR_test, ypred))\n",
    "        print('--------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec05913",
   "metadata": {},
   "source": [
    " najlepiej pordział sobie tanh, sigmoid, relu tez wypada nie najgorzej, najgorzej linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388945f4",
   "metadata": {},
   "source": [
    "## Rings5-regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08caa18b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0: Loss = 0.210162206\n",
      "Epoka 10: Loss = 0.305835164\n",
      "Epoka 20: Loss = 0.394082362\n",
      "Epoka 30: Loss = 0.562739107\n",
      "Epoka 40: Loss = 0.497999253\n",
      "Epoka 50: Loss = 0.481666138\n",
      "Epoka 60: Loss = 0.570567539\n",
      "Epoka 70: Loss = 0.665527401\n",
      "Epoka 80: Loss = 0.666709396\n",
      "Epoka 90: Loss = 0.654296339\n",
      "Epoka 100: Loss = 0.690149529\n",
      "Epoka 110: Loss = 0.692357182\n",
      "Epoka 120: Loss = 0.698592685\n",
      "Epoka 130: Loss = 0.691198487\n",
      "Epoka 140: Loss = 0.708581158\n",
      "Epoka 150: Loss = 0.703337484\n",
      "Epoka 160: Loss = 0.703756433\n",
      "Epoka 170: Loss = 0.698410095\n",
      "Epoka 180: Loss = 0.708805933\n",
      "Epoka 190: Loss = 0.706997884\n",
      "Epoka 200: Loss = 0.715938503\n",
      "Epoka 210: Loss = 0.710910710\n",
      "Epoka 220: Loss = 0.717891493\n",
      "Epoka 230: Loss = 0.715382930\n",
      "Epoka 240: Loss = 0.724840199\n",
      "Epoka 250: Loss = 0.719167885\n",
      "Epoka 260: Loss = 0.712473757\n",
      "Epoka 270: Loss = 0.717422628\n",
      "Epoka 280: Loss = 0.729631283\n",
      "Epoka 290: Loss = 0.723472570\n",
      "Epoka 300: Loss = 0.727757871\n",
      "Epoka 310: Loss = 0.731403966\n",
      "Epoka 320: Loss = 0.728956009\n",
      "Epoka 330: Loss = 0.728039596\n",
      "Epoka 340: Loss = 0.735851124\n",
      "Epoka 350: Loss = 0.722321912\n",
      "Epoka 360: Loss = 0.728967549\n",
      "Epoka 370: Loss = 0.728029658\n",
      "Epoka 380: Loss = 0.733419848\n",
      "Epoka 390: Loss = 0.733798569\n",
      "Epoka 400: Loss = 0.734785843\n",
      "Epoka 410: Loss = 0.735789780\n",
      "Epoka 420: Loss = 0.727570493\n",
      "Epoka 430: Loss = 0.723208674\n",
      "Epoka 440: Loss = 0.739504893\n",
      "Epoka 450: Loss = 0.748755243\n",
      "Epoka 460: Loss = 0.736924211\n",
      "Epoka 470: Loss = 0.739538831\n",
      "Epoka 480: Loss = 0.739466027\n",
      "Epoka 490: Loss = 0.732616549\n",
      "Epoka 500: Loss = 0.737403217\n",
      "Epoka 510: Loss = 0.732263639\n",
      "Epoka 520: Loss = 0.740953103\n",
      "Epoka 530: Loss = 0.737029300\n",
      "Epoka 540: Loss = 0.735924843\n",
      "Epoka 550: Loss = 0.740405627\n",
      "Epoka 560: Loss = 0.730429782\n",
      "Epoka 570: Loss = 0.741422301\n",
      "Epoka 580: Loss = 0.742877660\n",
      "Epoka 590: Loss = 0.742312063\n",
      "Epoka 600: Loss = 0.740553346\n",
      "Epoka 610: Loss = 0.745576778\n",
      "Epoka 620: Loss = 0.752543241\n",
      "Epoka 630: Loss = 0.717996911\n",
      "Epoka 640: Loss = 0.741344303\n",
      "Epoka 650: Loss = 0.749913626\n",
      "Epoka 660: Loss = 0.747514899\n",
      "Epoka 670: Loss = 0.752840188\n",
      "Epoka 680: Loss = 0.737909672\n",
      "Epoka 690: Loss = 0.741673615\n",
      "Epoka 700: Loss = 0.747051551\n",
      "Epoka 710: Loss = 0.748239722\n",
      "Epoka 720: Loss = 0.751089469\n",
      "Epoka 730: Loss = 0.749090270\n",
      "Epoka 740: Loss = 0.748029170\n",
      "Epoka 750: Loss = 0.750917284\n",
      "Epoka 760: Loss = 0.742613380\n",
      "Epoka 770: Loss = 0.751091313\n",
      "Epoka 780: Loss = 0.756669477\n",
      "Epoka 790: Loss = 0.754728878\n",
      "Epoka 800: Loss = 0.757227409\n",
      "Epoka 810: Loss = 0.750061295\n",
      "Epoka 820: Loss = 0.755788668\n",
      "Epoka 830: Loss = 0.756211281\n",
      "Epoka 840: Loss = 0.754560932\n",
      "Epoka 850: Loss = 0.754088097\n",
      "Epoka 860: Loss = 0.758239639\n",
      "Epoka 870: Loss = 0.753348753\n",
      "Epoka 880: Loss = 0.755005419\n",
      "Epoka 890: Loss = 0.756151562\n",
      "Epoka 900: Loss = 0.759797075\n",
      "Epoka 910: Loss = 0.757531943\n",
      "Epoka 920: Loss = 0.756516569\n",
      "Epoka 930: Loss = 0.752866636\n",
      "Epoka 940: Loss = 0.764088931\n",
      "Epoka 950: Loss = 0.764371558\n",
      "Epoka 960: Loss = 0.764181864\n",
      "Epoka 970: Loss = 0.754199107\n",
      "Epoka 980: Loss = 0.758196413\n",
      "Epoka 990: Loss = 0.766036237\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 7.399022 sekundy dla sigmoid w warstwie ukrytej i 5 neuronów\n",
      "f1 score:\n",
      "0.7171954624458696\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.254694413\n",
      "Epoka 10: Loss = 0.354793321\n",
      "Epoka 20: Loss = 0.462749763\n",
      "Epoka 30: Loss = 0.494430711\n",
      "Epoka 40: Loss = 0.550813197\n",
      "Epoka 50: Loss = 0.667259283\n",
      "Epoka 60: Loss = 0.706875610\n",
      "Epoka 70: Loss = 0.762617293\n",
      "Epoka 80: Loss = 0.801807132\n",
      "Epoka 90: Loss = 0.797242749\n",
      "Epoka 100: Loss = 0.814100530\n",
      "Epoka 110: Loss = 0.828593260\n",
      "Epoka 120: Loss = 0.822850999\n",
      "Epoka 130: Loss = 0.833554215\n",
      "Epoka 140: Loss = 0.838530949\n",
      "Epoka 150: Loss = 0.839985721\n",
      "Epoka 160: Loss = 0.847537976\n",
      "Epoka 170: Loss = 0.849300209\n",
      "Epoka 180: Loss = 0.851534555\n",
      "Epoka 190: Loss = 0.854585771\n",
      "Epoka 200: Loss = 0.857493172\n",
      "Epoka 210: Loss = 0.855278289\n",
      "Epoka 220: Loss = 0.864946497\n",
      "Epoka 230: Loss = 0.852311244\n",
      "Epoka 240: Loss = 0.864754122\n",
      "Epoka 250: Loss = 0.865717622\n",
      "Epoka 260: Loss = 0.866564738\n",
      "Epoka 270: Loss = 0.870515680\n",
      "Epoka 280: Loss = 0.876387760\n",
      "Epoka 290: Loss = 0.875591220\n",
      "Epoka 300: Loss = 0.878789658\n",
      "Epoka 310: Loss = 0.878617956\n",
      "Epoka 320: Loss = 0.878750863\n",
      "Epoka 330: Loss = 0.887171920\n",
      "Epoka 340: Loss = 0.885966866\n",
      "Epoka 350: Loss = 0.886637031\n",
      "Epoka 360: Loss = 0.886798591\n",
      "Epoka 370: Loss = 0.886109298\n",
      "Epoka 380: Loss = 0.891557646\n",
      "Epoka 390: Loss = 0.894806882\n",
      "Epoka 400: Loss = 0.893906346\n",
      "Epoka 410: Loss = 0.885305473\n",
      "Epoka 420: Loss = 0.887156062\n",
      "Epoka 430: Loss = 0.900347740\n",
      "Epoka 440: Loss = 0.891645553\n",
      "Epoka 450: Loss = 0.898907639\n",
      "Epoka 460: Loss = 0.893078303\n",
      "Epoka 470: Loss = 0.897904268\n",
      "Epoka 480: Loss = 0.898223048\n",
      "Epoka 490: Loss = 0.893199880\n",
      "Epoka 500: Loss = 0.899576354\n",
      "Epoka 510: Loss = 0.901855639\n",
      "Epoka 520: Loss = 0.903484758\n",
      "Epoka 530: Loss = 0.899279598\n",
      "Epoka 540: Loss = 0.905136920\n",
      "Epoka 550: Loss = 0.896427060\n",
      "Epoka 560: Loss = 0.904371396\n",
      "Epoka 570: Loss = 0.900920710\n",
      "Epoka 580: Loss = 0.905906713\n",
      "Epoka 590: Loss = 0.908416490\n",
      "Epoka 600: Loss = 0.905419977\n",
      "Epoka 610: Loss = 0.911699672\n",
      "Epoka 620: Loss = 0.912633244\n",
      "Epoka 630: Loss = 0.909046308\n",
      "Epoka 640: Loss = 0.911444495\n",
      "Epoka 650: Loss = 0.911748020\n",
      "Epoka 660: Loss = 0.912289569\n",
      "Epoka 670: Loss = 0.912374488\n",
      "Epoka 680: Loss = 0.910032089\n",
      "Epoka 690: Loss = 0.912229496\n",
      "Epoka 700: Loss = 0.917248923\n",
      "Epoka 710: Loss = 0.911493265\n",
      "Epoka 720: Loss = 0.910580144\n",
      "Epoka 730: Loss = 0.910611836\n",
      "Epoka 740: Loss = 0.914570269\n",
      "Epoka 750: Loss = 0.914590249\n",
      "Epoka 760: Loss = 0.918146301\n",
      "Epoka 770: Loss = 0.918062663\n",
      "Epoka 780: Loss = 0.918222536\n",
      "Epoka 790: Loss = 0.912147242\n",
      "Epoka 800: Loss = 0.915458758\n",
      "Epoka 810: Loss = 0.911354964\n",
      "Epoka 820: Loss = 0.919082938\n",
      "Epoka 830: Loss = 0.917156035\n",
      "Epoka 840: Loss = 0.917026217\n",
      "Epoka 850: Loss = 0.911374718\n",
      "Epoka 860: Loss = 0.920444340\n",
      "Epoka 870: Loss = 0.919004928\n",
      "Epoka 880: Loss = 0.922793757\n",
      "Epoka 890: Loss = 0.923779446\n",
      "Epoka 900: Loss = 0.918680932\n",
      "Epoka 910: Loss = 0.918032213\n",
      "Epoka 920: Loss = 0.921190174\n",
      "Epoka 930: Loss = 0.919448239\n",
      "Epoka 940: Loss = 0.920244589\n",
      "Epoka 950: Loss = 0.924482802\n",
      "Epoka 960: Loss = 0.927615738\n",
      "Epoka 970: Loss = 0.923869744\n",
      "Epoka 980: Loss = 0.917048229\n",
      "Epoka 990: Loss = 0.918038391\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 8.043105 sekundy dla sigmoid w warstwie ukrytej i 10 neuronów\n",
      "f1 score:\n",
      "0.8857327539373484\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.214774444\n",
      "Epoka 10: Loss = 0.321217086\n",
      "Epoka 20: Loss = 0.321292378\n",
      "Epoka 30: Loss = 0.510635669\n",
      "Epoka 40: Loss = 0.672340246\n",
      "Epoka 50: Loss = 0.743901297\n",
      "Epoka 60: Loss = 0.734191302\n",
      "Epoka 70: Loss = 0.759242842\n",
      "Epoka 80: Loss = 0.769514466\n",
      "Epoka 90: Loss = 0.787279714\n",
      "Epoka 100: Loss = 0.816620156\n",
      "Epoka 110: Loss = 0.822803115\n",
      "Epoka 120: Loss = 0.833186219\n",
      "Epoka 130: Loss = 0.838877068\n",
      "Epoka 140: Loss = 0.843706231\n",
      "Epoka 150: Loss = 0.866712104\n",
      "Epoka 160: Loss = 0.864972214\n",
      "Epoka 170: Loss = 0.872389369\n",
      "Epoka 180: Loss = 0.868018020\n",
      "Epoka 190: Loss = 0.873672434\n",
      "Epoka 200: Loss = 0.879338502\n",
      "Epoka 210: Loss = 0.879000325\n",
      "Epoka 220: Loss = 0.877072026\n",
      "Epoka 230: Loss = 0.883683631\n",
      "Epoka 240: Loss = 0.888453446\n",
      "Epoka 250: Loss = 0.888977853\n",
      "Epoka 260: Loss = 0.892205829\n",
      "Epoka 270: Loss = 0.890159354\n",
      "Epoka 280: Loss = 0.900888577\n",
      "Epoka 290: Loss = 0.898222755\n",
      "Epoka 300: Loss = 0.902185388\n",
      "Epoka 310: Loss = 0.899871392\n",
      "Epoka 320: Loss = 0.898020133\n",
      "Epoka 330: Loss = 0.903460194\n",
      "Epoka 340: Loss = 0.905137914\n",
      "Epoka 350: Loss = 0.907859413\n",
      "Epoka 360: Loss = 0.911908321\n",
      "Epoka 370: Loss = 0.901934697\n",
      "Epoka 380: Loss = 0.906746651\n",
      "Epoka 390: Loss = 0.912321813\n",
      "Epoka 400: Loss = 0.905182801\n",
      "Epoka 410: Loss = 0.911083004\n",
      "Epoka 420: Loss = 0.909341303\n",
      "Epoka 430: Loss = 0.914967158\n",
      "Epoka 440: Loss = 0.911799861\n",
      "Epoka 450: Loss = 0.908251684\n",
      "Epoka 460: Loss = 0.917405823\n",
      "Epoka 470: Loss = 0.914837326\n",
      "Epoka 480: Loss = 0.917551079\n",
      "Epoka 490: Loss = 0.921701604\n",
      "Epoka 500: Loss = 0.911550280\n",
      "Epoka 510: Loss = 0.921072637\n",
      "Epoka 520: Loss = 0.917645855\n",
      "Epoka 530: Loss = 0.918271962\n",
      "Epoka 540: Loss = 0.923890830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 550: Loss = 0.918147194\n",
      "Epoka 560: Loss = 0.920622079\n",
      "Epoka 570: Loss = 0.920560335\n",
      "Epoka 580: Loss = 0.922283428\n",
      "Epoka 590: Loss = 0.918798766\n",
      "Epoka 600: Loss = 0.918717162\n",
      "Epoka 610: Loss = 0.925522768\n",
      "Epoka 620: Loss = 0.924493931\n",
      "Epoka 630: Loss = 0.918952047\n",
      "Epoka 640: Loss = 0.926268589\n",
      "Epoka 650: Loss = 0.921410658\n",
      "Epoka 660: Loss = 0.927821356\n",
      "Epoka 670: Loss = 0.926824841\n",
      "Epoka 680: Loss = 0.926929321\n",
      "Epoka 690: Loss = 0.929473053\n",
      "Epoka 700: Loss = 0.930255042\n",
      "Epoka 710: Loss = 0.931774433\n",
      "Epoka 720: Loss = 0.933516492\n",
      "Epoka 730: Loss = 0.934112397\n",
      "Epoka 740: Loss = 0.931108978\n",
      "Epoka 750: Loss = 0.930119936\n",
      "Epoka 760: Loss = 0.935196345\n",
      "Epoka 770: Loss = 0.933428412\n",
      "Epoka 780: Loss = 0.931876234\n",
      "Epoka 790: Loss = 0.935895965\n",
      "Epoka 800: Loss = 0.934366190\n",
      "Epoka 810: Loss = 0.934967261\n",
      "Epoka 820: Loss = 0.935943920\n",
      "Epoka 830: Loss = 0.939827484\n",
      "Epoka 840: Loss = 0.932553843\n",
      "Epoka 850: Loss = 0.937389083\n",
      "Epoka 860: Loss = 0.935032401\n",
      "Epoka 870: Loss = 0.938200794\n",
      "Epoka 880: Loss = 0.938188147\n",
      "Epoka 890: Loss = 0.936722408\n",
      "Epoka 900: Loss = 0.940607877\n",
      "Epoka 910: Loss = 0.939161786\n",
      "Epoka 920: Loss = 0.938184669\n",
      "Epoka 930: Loss = 0.942314133\n",
      "Epoka 940: Loss = 0.936415791\n",
      "Epoka 950: Loss = 0.942420697\n",
      "Epoka 960: Loss = 0.942523814\n",
      "Epoka 970: Loss = 0.939192506\n",
      "Epoka 980: Loss = 0.940682602\n",
      "Epoka 990: Loss = 0.941581373\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 8.028427 sekundy dla sigmoid w warstwie ukrytej i 15 neuronów\n",
      "f1 score:\n",
      "0.8995958613001924\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.160404691\n",
      "Epoka 10: Loss = 0.265619823\n",
      "Epoka 20: Loss = 0.424634039\n",
      "Epoka 30: Loss = 0.587350937\n",
      "Epoka 40: Loss = 0.678837834\n",
      "Epoka 50: Loss = 0.677237494\n",
      "Epoka 60: Loss = 0.739464149\n",
      "Epoka 70: Loss = 0.782507213\n",
      "Epoka 80: Loss = 0.793317120\n",
      "Epoka 90: Loss = 0.808014530\n",
      "Epoka 100: Loss = 0.822606526\n",
      "Epoka 110: Loss = 0.844650826\n",
      "Epoka 120: Loss = 0.851510606\n",
      "Epoka 130: Loss = 0.858014307\n",
      "Epoka 140: Loss = 0.867608955\n",
      "Epoka 150: Loss = 0.868560620\n",
      "Epoka 160: Loss = 0.859917270\n",
      "Epoka 170: Loss = 0.884579527\n",
      "Epoka 180: Loss = 0.884718093\n",
      "Epoka 190: Loss = 0.880251064\n",
      "Epoka 200: Loss = 0.885385700\n",
      "Epoka 210: Loss = 0.892060601\n",
      "Epoka 220: Loss = 0.890218512\n",
      "Epoka 230: Loss = 0.888915533\n",
      "Epoka 240: Loss = 0.896385672\n",
      "Epoka 250: Loss = 0.895470017\n",
      "Epoka 260: Loss = 0.892993310\n",
      "Epoka 270: Loss = 0.881873723\n",
      "Epoka 280: Loss = 0.893877796\n",
      "Epoka 290: Loss = 0.877246713\n",
      "Epoka 300: Loss = 0.894274506\n",
      "Epoka 310: Loss = 0.895530602\n",
      "Epoka 320: Loss = 0.903732176\n",
      "Epoka 330: Loss = 0.905329281\n",
      "Epoka 340: Loss = 0.905018260\n",
      "Epoka 350: Loss = 0.904371958\n",
      "Epoka 360: Loss = 0.906957939\n",
      "Epoka 370: Loss = 0.911074900\n",
      "Epoka 380: Loss = 0.896853697\n",
      "Epoka 390: Loss = 0.910958899\n",
      "Epoka 400: Loss = 0.903657367\n",
      "Epoka 410: Loss = 0.910187761\n",
      "Epoka 420: Loss = 0.914425112\n",
      "Epoka 430: Loss = 0.909418642\n",
      "Epoka 440: Loss = 0.909958145\n",
      "Epoka 450: Loss = 0.915903575\n",
      "Epoka 460: Loss = 0.918338497\n",
      "Epoka 470: Loss = 0.918928520\n",
      "Epoka 480: Loss = 0.916163991\n",
      "Epoka 490: Loss = 0.914991030\n",
      "Epoka 500: Loss = 0.917517736\n",
      "Epoka 510: Loss = 0.914296330\n",
      "Epoka 520: Loss = 0.915839084\n",
      "Epoka 530: Loss = 0.920008875\n",
      "Epoka 540: Loss = 0.913900377\n",
      "Epoka 550: Loss = 0.921780142\n",
      "Epoka 560: Loss = 0.908163225\n",
      "Epoka 570: Loss = 0.918150152\n",
      "Epoka 580: Loss = 0.921535445\n",
      "Epoka 590: Loss = 0.924816726\n",
      "Epoka 600: Loss = 0.923002299\n",
      "Epoka 610: Loss = 0.922151426\n",
      "Epoka 620: Loss = 0.923994283\n",
      "Epoka 630: Loss = 0.921606815\n",
      "Epoka 640: Loss = 0.926298243\n",
      "Epoka 650: Loss = 0.927150222\n",
      "Epoka 660: Loss = 0.927211551\n",
      "Epoka 670: Loss = 0.923937144\n",
      "Epoka 680: Loss = 0.924866562\n",
      "Epoka 690: Loss = 0.925884649\n",
      "Epoka 700: Loss = 0.928519432\n",
      "Epoka 710: Loss = 0.933631126\n",
      "Epoka 720: Loss = 0.932001481\n",
      "Epoka 730: Loss = 0.929558441\n",
      "Epoka 740: Loss = 0.930386599\n",
      "Epoka 750: Loss = 0.929577161\n",
      "Epoka 760: Loss = 0.933533802\n",
      "Epoka 770: Loss = 0.932002990\n",
      "Epoka 780: Loss = 0.932567028\n",
      "Epoka 790: Loss = 0.934399414\n",
      "Epoka 800: Loss = 0.933518153\n",
      "Epoka 810: Loss = 0.936032275\n",
      "Epoka 820: Loss = 0.935058125\n",
      "Epoka 830: Loss = 0.934450880\n",
      "Epoka 840: Loss = 0.931763050\n",
      "Epoka 850: Loss = 0.936048550\n",
      "Epoka 860: Loss = 0.924587213\n",
      "Epoka 870: Loss = 0.931752470\n",
      "Epoka 880: Loss = 0.938110637\n",
      "Epoka 890: Loss = 0.936760164\n",
      "Epoka 900: Loss = 0.935935545\n",
      "Epoka 910: Loss = 0.936071426\n",
      "Epoka 920: Loss = 0.943196874\n",
      "Epoka 930: Loss = 0.935103388\n",
      "Epoka 940: Loss = 0.935150908\n",
      "Epoka 950: Loss = 0.941581399\n",
      "Epoka 960: Loss = 0.938227169\n",
      "Epoka 970: Loss = 0.936708207\n",
      "Epoka 980: Loss = 0.943046646\n",
      "Epoka 990: Loss = 0.939152473\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 8.980338 sekundy dla sigmoid w warstwie ukrytej i 20 neuronów\n",
      "f1 score:\n",
      "0.89872862352185\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.309749055\n",
      "Epoka 10: Loss = 0.335182206\n",
      "Epoka 20: Loss = 0.278270696\n",
      "Epoka 30: Loss = 0.252037354\n",
      "Epoka 40: Loss = 0.257856855\n",
      "Epoka 50: Loss = 0.295870989\n",
      "Epoka 60: Loss = 0.274646517\n",
      "Epoka 70: Loss = 0.286690364\n",
      "Epoka 80: Loss = 0.278744343\n",
      "Epoka 90: Loss = 0.299103815\n",
      "Epoka 100: Loss = 0.293937114\n",
      "Epoka 110: Loss = 0.240423387\n",
      "Epoka 120: Loss = 0.286251206\n",
      "Epoka 130: Loss = 0.294569006\n",
      "Epoka 140: Loss = 0.296787495\n",
      "Epoka 150: Loss = 0.271523735\n",
      "Epoka 160: Loss = 0.281594046\n",
      "Epoka 170: Loss = 0.284525295\n",
      "Epoka 180: Loss = 0.248386142\n",
      "Epoka 190: Loss = 0.256889406\n",
      "Epoka 200: Loss = 0.286106077\n",
      "Epoka 210: Loss = 0.236435592\n",
      "Epoka 220: Loss = 0.246080389\n",
      "Epoka 230: Loss = 0.287607737\n",
      "Epoka 240: Loss = 0.239772259\n",
      "Epoka 250: Loss = 0.273563550\n",
      "Epoka 260: Loss = 0.306275470\n",
      "Epoka 270: Loss = 0.300749802\n",
      "Epoka 280: Loss = 0.283297801\n",
      "Epoka 290: Loss = 0.287343504\n",
      "Epoka 300: Loss = 0.249873687\n",
      "Epoka 310: Loss = 0.296750194\n",
      "Epoka 320: Loss = 0.294542657\n",
      "Epoka 330: Loss = 0.276833453\n",
      "Epoka 340: Loss = 0.254948187\n",
      "Epoka 350: Loss = 0.265074967\n",
      "Epoka 360: Loss = 0.304781276\n",
      "Epoka 370: Loss = 0.317033364\n",
      "Epoka 380: Loss = 0.334207828\n",
      "Epoka 390: Loss = 0.273924105\n",
      "Epoka 400: Loss = 0.309901809\n",
      "Epoka 410: Loss = 0.255411026\n",
      "Epoka 420: Loss = 0.282867387\n",
      "Epoka 430: Loss = 0.281202895\n",
      "Epoka 440: Loss = 0.296453266\n",
      "Epoka 450: Loss = 0.299139971\n",
      "Epoka 460: Loss = 0.297201247\n",
      "Epoka 470: Loss = 0.290765402\n",
      "Epoka 480: Loss = 0.299388454\n",
      "Epoka 490: Loss = 0.280943737\n",
      "Epoka 500: Loss = 0.266600827\n",
      "Epoka 510: Loss = 0.232842389\n",
      "Epoka 520: Loss = 0.316405138\n",
      "Epoka 530: Loss = 0.282039564\n",
      "Epoka 540: Loss = 0.252261670\n",
      "Epoka 550: Loss = 0.299133370\n",
      "Epoka 560: Loss = 0.274936127\n",
      "Epoka 570: Loss = 0.255493102\n",
      "Epoka 580: Loss = 0.300950657\n",
      "Epoka 590: Loss = 0.310563056\n",
      "Epoka 600: Loss = 0.339153238\n",
      "Epoka 610: Loss = 0.289143449\n",
      "Epoka 620: Loss = 0.278334265\n",
      "Epoka 630: Loss = 0.249248591\n",
      "Epoka 640: Loss = 0.335603298\n",
      "Epoka 650: Loss = 0.280749150\n",
      "Epoka 660: Loss = 0.233630903\n",
      "Epoka 670: Loss = 0.254657221\n",
      "Epoka 680: Loss = 0.292497648\n",
      "Epoka 690: Loss = 0.276215814\n",
      "Epoka 700: Loss = 0.254451692\n",
      "Epoka 710: Loss = 0.328819398\n",
      "Epoka 720: Loss = 0.287722431\n",
      "Epoka 730: Loss = 0.259904674\n",
      "Epoka 740: Loss = 0.232312366\n",
      "Epoka 750: Loss = 0.243690599\n",
      "Epoka 760: Loss = 0.268718299\n",
      "Epoka 770: Loss = 0.286494891\n",
      "Epoka 780: Loss = 0.331624389\n",
      "Epoka 790: Loss = 0.287984338\n",
      "Epoka 800: Loss = 0.284939017\n",
      "Epoka 810: Loss = 0.300497575\n",
      "Epoka 820: Loss = 0.271323996\n",
      "Epoka 830: Loss = 0.236522546\n",
      "Epoka 840: Loss = 0.306864507\n",
      "Epoka 850: Loss = 0.312646919\n",
      "Epoka 860: Loss = 0.264586979\n",
      "Epoka 870: Loss = 0.295715808\n",
      "Epoka 880: Loss = 0.331244567\n",
      "Epoka 890: Loss = 0.270502317\n",
      "Epoka 900: Loss = 0.294582940\n",
      "Epoka 910: Loss = 0.301523255\n",
      "Epoka 920: Loss = 0.236836463\n",
      "Epoka 930: Loss = 0.287953674\n",
      "Epoka 940: Loss = 0.289780573\n",
      "Epoka 950: Loss = 0.249522301\n",
      "Epoka 960: Loss = 0.316461164\n",
      "Epoka 970: Loss = 0.265362244\n",
      "Epoka 980: Loss = 0.239489727\n",
      "Epoka 990: Loss = 0.289382076\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 5.910547 sekundy dla linear w warstwie ukrytej i 5 neuronów\n",
      "f1 score:\n",
      "0.2597627875130152\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.284174370\n",
      "Epoka 10: Loss = 0.282324943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 20: Loss = 0.298498173\n",
      "Epoka 30: Loss = 0.288298166\n",
      "Epoka 40: Loss = 0.267627508\n",
      "Epoka 50: Loss = 0.320464108\n",
      "Epoka 60: Loss = 0.329552809\n",
      "Epoka 70: Loss = 0.294482866\n",
      "Epoka 80: Loss = 0.288761580\n",
      "Epoka 90: Loss = 0.306756265\n",
      "Epoka 100: Loss = 0.332353302\n",
      "Epoka 110: Loss = 0.315068240\n",
      "Epoka 120: Loss = 0.274103928\n",
      "Epoka 130: Loss = 0.325874690\n",
      "Epoka 140: Loss = 0.311914235\n",
      "Epoka 150: Loss = 0.299706247\n",
      "Epoka 160: Loss = 0.288378020\n",
      "Epoka 170: Loss = 0.281311267\n",
      "Epoka 180: Loss = 0.311231219\n",
      "Epoka 190: Loss = 0.242737566\n",
      "Epoka 200: Loss = 0.248550935\n",
      "Epoka 210: Loss = 0.246265086\n",
      "Epoka 220: Loss = 0.303709970\n",
      "Epoka 230: Loss = 0.301303567\n",
      "Epoka 240: Loss = 0.279203249\n",
      "Epoka 250: Loss = 0.315677193\n",
      "Epoka 260: Loss = 0.315932415\n",
      "Epoka 270: Loss = 0.320371527\n",
      "Epoka 280: Loss = 0.289592344\n",
      "Epoka 290: Loss = 0.251603488\n",
      "Epoka 300: Loss = 0.309452372\n",
      "Epoka 310: Loss = 0.314191294\n",
      "Epoka 320: Loss = 0.234898542\n",
      "Epoka 330: Loss = 0.269543103\n",
      "Epoka 340: Loss = 0.281381763\n",
      "Epoka 350: Loss = 0.285824693\n",
      "Epoka 360: Loss = 0.300758238\n",
      "Epoka 370: Loss = 0.278312628\n",
      "Epoka 380: Loss = 0.247214074\n",
      "Epoka 390: Loss = 0.302001986\n",
      "Epoka 400: Loss = 0.228754176\n",
      "Epoka 410: Loss = 0.282287090\n",
      "Epoka 420: Loss = 0.301605503\n",
      "Epoka 430: Loss = 0.330447279\n",
      "Epoka 440: Loss = 0.307157485\n",
      "Epoka 450: Loss = 0.253990114\n",
      "Epoka 460: Loss = 0.284768681\n",
      "Epoka 470: Loss = 0.265269878\n",
      "Epoka 480: Loss = 0.314800018\n",
      "Epoka 490: Loss = 0.252155940\n",
      "Epoka 500: Loss = 0.246926632\n",
      "Epoka 510: Loss = 0.256628265\n",
      "Epoka 520: Loss = 0.254040367\n",
      "Epoka 530: Loss = 0.311636339\n",
      "Epoka 540: Loss = 0.288880730\n",
      "Epoka 550: Loss = 0.299355480\n",
      "Epoka 560: Loss = 0.290412358\n",
      "Epoka 570: Loss = 0.294389962\n",
      "Epoka 580: Loss = 0.285742389\n",
      "Epoka 590: Loss = 0.257437761\n",
      "Epoka 600: Loss = 0.301982959\n",
      "Epoka 610: Loss = 0.294500934\n",
      "Epoka 620: Loss = 0.267196289\n",
      "Epoka 630: Loss = 0.285714743\n",
      "Epoka 640: Loss = 0.286423940\n",
      "Epoka 650: Loss = 0.295415814\n",
      "Epoka 660: Loss = 0.232809899\n",
      "Epoka 670: Loss = 0.275802024\n",
      "Epoka 680: Loss = 0.282696178\n",
      "Epoka 690: Loss = 0.329223723\n",
      "Epoka 700: Loss = 0.290511391\n",
      "Epoka 710: Loss = 0.272628988\n",
      "Epoka 720: Loss = 0.286220031\n",
      "Epoka 730: Loss = 0.307986449\n",
      "Epoka 740: Loss = 0.229322796\n",
      "Epoka 750: Loss = 0.299931504\n",
      "Epoka 760: Loss = 0.278718513\n",
      "Epoka 770: Loss = 0.295942899\n",
      "Epoka 780: Loss = 0.315229874\n",
      "Epoka 790: Loss = 0.256236966\n",
      "Epoka 800: Loss = 0.321027897\n",
      "Epoka 810: Loss = 0.301264731\n",
      "Epoka 820: Loss = 0.309731696\n",
      "Epoka 830: Loss = 0.313849783\n",
      "Epoka 840: Loss = 0.240143743\n",
      "Epoka 850: Loss = 0.281100320\n",
      "Epoka 860: Loss = 0.321234753\n",
      "Epoka 870: Loss = 0.307024539\n",
      "Epoka 880: Loss = 0.294593701\n",
      "Epoka 890: Loss = 0.279329137\n",
      "Epoka 900: Loss = 0.295570718\n",
      "Epoka 910: Loss = 0.306229559\n",
      "Epoka 920: Loss = 0.298566367\n",
      "Epoka 930: Loss = 0.256900547\n",
      "Epoka 940: Loss = 0.304392837\n",
      "Epoka 950: Loss = 0.279909862\n",
      "Epoka 960: Loss = 0.312883042\n",
      "Epoka 970: Loss = 0.268496649\n",
      "Epoka 980: Loss = 0.294100093\n",
      "Epoka 990: Loss = 0.286117162\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 6.105161 sekundy dla linear w warstwie ukrytej i 10 neuronów\n",
      "f1 score:\n",
      "0.24997977054067713\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.299223748\n",
      "Epoka 10: Loss = 0.274026053\n",
      "Epoka 20: Loss = 0.306374650\n",
      "Epoka 30: Loss = 0.337889222\n",
      "Epoka 40: Loss = 0.242561539\n",
      "Epoka 50: Loss = 0.255568093\n",
      "Epoka 60: Loss = 0.244293728\n",
      "Epoka 70: Loss = 0.278276874\n",
      "Epoka 80: Loss = 0.291085967\n",
      "Epoka 90: Loss = 0.301979024\n",
      "Epoka 100: Loss = 0.257774997\n",
      "Epoka 110: Loss = 0.274283950\n",
      "Epoka 120: Loss = 0.290653023\n",
      "Epoka 130: Loss = 0.282165451\n",
      "Epoka 140: Loss = 0.316410271\n",
      "Epoka 150: Loss = 0.242573293\n",
      "Epoka 160: Loss = 0.233650115\n",
      "Epoka 170: Loss = 0.269637853\n",
      "Epoka 180: Loss = 0.289835185\n",
      "Epoka 190: Loss = 0.275430712\n",
      "Epoka 200: Loss = 0.313621628\n",
      "Epoka 210: Loss = 0.315039217\n",
      "Epoka 220: Loss = 0.301303369\n",
      "Epoka 230: Loss = 0.311198403\n",
      "Epoka 240: Loss = 0.262826104\n",
      "Epoka 250: Loss = 0.306046639\n",
      "Epoka 260: Loss = 0.279437254\n",
      "Epoka 270: Loss = 0.311501244\n",
      "Epoka 280: Loss = 0.292962673\n",
      "Epoka 290: Loss = 0.275298753\n",
      "Epoka 300: Loss = 0.265641164\n",
      "Epoka 310: Loss = 0.330270442\n",
      "Epoka 320: Loss = 0.265011041\n",
      "Epoka 330: Loss = 0.314181348\n",
      "Epoka 340: Loss = 0.293223555\n",
      "Epoka 350: Loss = 0.257053359\n",
      "Epoka 360: Loss = 0.277872963\n",
      "Epoka 370: Loss = 0.275219312\n",
      "Epoka 380: Loss = 0.256303031\n",
      "Epoka 390: Loss = 0.296827722\n",
      "Epoka 400: Loss = 0.262891489\n",
      "Epoka 410: Loss = 0.251919659\n",
      "Epoka 420: Loss = 0.269982810\n",
      "Epoka 430: Loss = 0.289270950\n",
      "Epoka 440: Loss = 0.309015249\n",
      "Epoka 450: Loss = 0.296115237\n",
      "Epoka 460: Loss = 0.295314816\n",
      "Epoka 470: Loss = 0.272572013\n",
      "Epoka 480: Loss = 0.292348596\n",
      "Epoka 490: Loss = 0.250266735\n",
      "Epoka 500: Loss = 0.275108601\n",
      "Epoka 510: Loss = 0.277461403\n",
      "Epoka 520: Loss = 0.231118029\n",
      "Epoka 530: Loss = 0.294556589\n",
      "Epoka 540: Loss = 0.309950511\n",
      "Epoka 550: Loss = 0.300748561\n",
      "Epoka 560: Loss = 0.259673695\n",
      "Epoka 570: Loss = 0.255265250\n",
      "Epoka 580: Loss = 0.283901675\n",
      "Epoka 590: Loss = 0.282590587\n",
      "Epoka 600: Loss = 0.281919599\n",
      "Epoka 610: Loss = 0.289851842\n",
      "Epoka 620: Loss = 0.327219850\n",
      "Epoka 630: Loss = 0.257724503\n",
      "Epoka 640: Loss = 0.255037715\n",
      "Epoka 650: Loss = 0.238126827\n",
      "Epoka 660: Loss = 0.281530545\n",
      "Epoka 670: Loss = 0.239386472\n",
      "Epoka 680: Loss = 0.278952079\n",
      "Epoka 690: Loss = 0.328149552\n",
      "Epoka 700: Loss = 0.306027660\n",
      "Epoka 710: Loss = 0.305912106\n",
      "Epoka 720: Loss = 0.348035999\n",
      "Epoka 730: Loss = 0.280279695\n",
      "Epoka 740: Loss = 0.314497145\n",
      "Epoka 750: Loss = 0.285242775\n",
      "Epoka 760: Loss = 0.322986518\n",
      "Epoka 770: Loss = 0.259013256\n",
      "Epoka 780: Loss = 0.296040415\n",
      "Epoka 790: Loss = 0.266374854\n",
      "Epoka 800: Loss = 0.298305821\n",
      "Epoka 810: Loss = 0.246904451\n",
      "Epoka 820: Loss = 0.353922422\n",
      "Epoka 830: Loss = 0.273573522\n",
      "Epoka 840: Loss = 0.237752680\n",
      "Epoka 850: Loss = 0.311331522\n",
      "Epoka 860: Loss = 0.336526104\n",
      "Epoka 870: Loss = 0.242235648\n",
      "Epoka 880: Loss = 0.252550209\n",
      "Epoka 890: Loss = 0.287776492\n",
      "Epoka 900: Loss = 0.278646884\n",
      "Epoka 910: Loss = 0.317392201\n",
      "Epoka 920: Loss = 0.266701191\n",
      "Epoka 930: Loss = 0.263705469\n",
      "Epoka 940: Loss = 0.277177892\n",
      "Epoka 950: Loss = 0.291526570\n",
      "Epoka 960: Loss = 0.302571689\n",
      "Epoka 970: Loss = 0.347719429\n",
      "Epoka 980: Loss = 0.275970052\n",
      "Epoka 990: Loss = 0.264481669\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 6.249600 sekundy dla linear w warstwie ukrytej i 15 neuronów\n",
      "f1 score:\n",
      "0.317399388555082\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.267397278\n",
      "Epoka 10: Loss = 0.322632210\n",
      "Epoka 20: Loss = 0.310309597\n",
      "Epoka 30: Loss = 0.252153408\n",
      "Epoka 40: Loss = 0.296583928\n",
      "Epoka 50: Loss = 0.289304649\n",
      "Epoka 60: Loss = 0.296843970\n",
      "Epoka 70: Loss = 0.310716058\n",
      "Epoka 80: Loss = 0.280706127\n",
      "Epoka 90: Loss = 0.299885892\n",
      "Epoka 100: Loss = 0.288630366\n",
      "Epoka 110: Loss = 0.284556490\n",
      "Epoka 120: Loss = 0.248589359\n",
      "Epoka 130: Loss = 0.354057688\n",
      "Epoka 140: Loss = 0.294122543\n",
      "Epoka 150: Loss = 0.245074657\n",
      "Epoka 160: Loss = 0.299656937\n",
      "Epoka 170: Loss = 0.308032603\n",
      "Epoka 180: Loss = 0.309544993\n",
      "Epoka 190: Loss = 0.286499895\n",
      "Epoka 200: Loss = 0.265675000\n",
      "Epoka 210: Loss = 0.280781108\n",
      "Epoka 220: Loss = 0.269773815\n",
      "Epoka 230: Loss = 0.265223060\n",
      "Epoka 240: Loss = 0.263586517\n",
      "Epoka 250: Loss = 0.267377504\n",
      "Epoka 260: Loss = 0.236437435\n",
      "Epoka 270: Loss = 0.275715717\n",
      "Epoka 280: Loss = 0.273625245\n",
      "Epoka 290: Loss = 0.246120467\n",
      "Epoka 300: Loss = 0.236291686\n",
      "Epoka 310: Loss = 0.322998631\n",
      "Epoka 320: Loss = 0.284569995\n",
      "Epoka 330: Loss = 0.221497240\n",
      "Epoka 340: Loss = 0.302812270\n",
      "Epoka 350: Loss = 0.286765858\n",
      "Epoka 360: Loss = 0.255719770\n",
      "Epoka 370: Loss = 0.284782726\n",
      "Epoka 380: Loss = 0.278766911\n",
      "Epoka 390: Loss = 0.259700521\n",
      "Epoka 400: Loss = 0.293509582\n",
      "Epoka 410: Loss = 0.300164523\n",
      "Epoka 420: Loss = 0.316602531\n",
      "Epoka 430: Loss = 0.312611772\n",
      "Epoka 440: Loss = 0.288019324\n",
      "Epoka 450: Loss = 0.269557490\n",
      "Epoka 460: Loss = 0.269236287\n",
      "Epoka 470: Loss = 0.233955673\n",
      "Epoka 480: Loss = 0.244280735\n",
      "Epoka 490: Loss = 0.316263560\n",
      "Epoka 500: Loss = 0.266404411\n",
      "Epoka 510: Loss = 0.289670351\n",
      "Epoka 520: Loss = 0.323020084\n",
      "Epoka 530: Loss = 0.285515885\n",
      "Epoka 540: Loss = 0.321005622\n",
      "Epoka 550: Loss = 0.255212653\n",
      "Epoka 560: Loss = 0.235013121\n",
      "Epoka 570: Loss = 0.268090689\n",
      "Epoka 580: Loss = 0.269383188\n",
      "Epoka 590: Loss = 0.290177558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 600: Loss = 0.264899738\n",
      "Epoka 610: Loss = 0.267957769\n",
      "Epoka 620: Loss = 0.290458037\n",
      "Epoka 630: Loss = 0.324903035\n",
      "Epoka 640: Loss = 0.276385174\n",
      "Epoka 650: Loss = 0.279645045\n",
      "Epoka 660: Loss = 0.303455008\n",
      "Epoka 670: Loss = 0.259067015\n",
      "Epoka 680: Loss = 0.293046181\n",
      "Epoka 690: Loss = 0.300889661\n",
      "Epoka 700: Loss = 0.243567076\n",
      "Epoka 710: Loss = 0.281292335\n",
      "Epoka 720: Loss = 0.313036825\n",
      "Epoka 730: Loss = 0.301339421\n",
      "Epoka 740: Loss = 0.275308134\n",
      "Epoka 750: Loss = 0.311688813\n",
      "Epoka 760: Loss = 0.284130183\n",
      "Epoka 770: Loss = 0.297481864\n",
      "Epoka 780: Loss = 0.316952434\n",
      "Epoka 790: Loss = 0.294803106\n",
      "Epoka 800: Loss = 0.311886079\n",
      "Epoka 810: Loss = 0.289254188\n",
      "Epoka 820: Loss = 0.287242955\n",
      "Epoka 830: Loss = 0.297823594\n",
      "Epoka 840: Loss = 0.269098168\n",
      "Epoka 850: Loss = 0.283425048\n",
      "Epoka 860: Loss = 0.308681001\n",
      "Epoka 870: Loss = 0.302183395\n",
      "Epoka 880: Loss = 0.303774884\n",
      "Epoka 890: Loss = 0.311836898\n",
      "Epoka 900: Loss = 0.284895626\n",
      "Epoka 910: Loss = 0.299282068\n",
      "Epoka 920: Loss = 0.270403153\n",
      "Epoka 930: Loss = 0.296206414\n",
      "Epoka 940: Loss = 0.251579246\n",
      "Epoka 950: Loss = 0.278380152\n",
      "Epoka 960: Loss = 0.310525364\n",
      "Epoka 970: Loss = 0.268221448\n",
      "Epoka 980: Loss = 0.272690531\n",
      "Epoka 990: Loss = 0.251436777\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 6.835177 sekundy dla linear w warstwie ukrytej i 20 neuronów\n",
      "f1 score:\n",
      "0.27212655640660194\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.263986099\n",
      "Epoka 10: Loss = 0.488953150\n",
      "Epoka 20: Loss = 0.612146601\n",
      "Epoka 30: Loss = 0.603595843\n",
      "Epoka 40: Loss = 0.650789859\n",
      "Epoka 50: Loss = 0.703515905\n",
      "Epoka 60: Loss = 0.721830015\n",
      "Epoka 70: Loss = 0.746552383\n",
      "Epoka 80: Loss = 0.765098589\n",
      "Epoka 90: Loss = 0.771134853\n",
      "Epoka 100: Loss = 0.770839978\n",
      "Epoka 110: Loss = 0.757638492\n",
      "Epoka 120: Loss = 0.774531219\n",
      "Epoka 130: Loss = 0.793223397\n",
      "Epoka 140: Loss = 0.780799128\n",
      "Epoka 150: Loss = 0.776001203\n",
      "Epoka 160: Loss = 0.773831477\n",
      "Epoka 170: Loss = 0.777693187\n",
      "Epoka 180: Loss = 0.791458858\n",
      "Epoka 190: Loss = 0.802583231\n",
      "Epoka 200: Loss = 0.786114170\n",
      "Epoka 210: Loss = 0.778241714\n",
      "Epoka 220: Loss = 0.800190063\n",
      "Epoka 230: Loss = 0.780074550\n",
      "Epoka 240: Loss = 0.803238918\n",
      "Epoka 250: Loss = 0.804170720\n",
      "Epoka 260: Loss = 0.803887453\n",
      "Epoka 270: Loss = 0.810682470\n",
      "Epoka 280: Loss = 0.801793392\n",
      "Epoka 290: Loss = 0.810311166\n",
      "Epoka 300: Loss = 0.815968296\n",
      "Epoka 310: Loss = 0.775320009\n",
      "Epoka 320: Loss = 0.808486794\n",
      "Epoka 330: Loss = 0.773368928\n",
      "Epoka 340: Loss = 0.816158107\n",
      "Epoka 350: Loss = 0.786041482\n",
      "Epoka 360: Loss = 0.808147493\n",
      "Epoka 370: Loss = 0.792142959\n",
      "Epoka 380: Loss = 0.797852031\n",
      "Epoka 390: Loss = 0.760583522\n",
      "Epoka 400: Loss = 0.780248559\n",
      "Epoka 410: Loss = 0.772169314\n",
      "Epoka 420: Loss = 0.787518448\n",
      "Epoka 430: Loss = 0.804111827\n",
      "Epoka 440: Loss = 0.806539602\n",
      "Epoka 450: Loss = 0.778742779\n",
      "Epoka 460: Loss = 0.814009862\n",
      "Epoka 470: Loss = 0.803122026\n",
      "Epoka 480: Loss = 0.800132657\n",
      "Epoka 490: Loss = 0.782840880\n",
      "Epoka 500: Loss = 0.795246026\n",
      "Epoka 510: Loss = 0.797205191\n",
      "Epoka 520: Loss = 0.808014150\n",
      "Epoka 530: Loss = 0.804427353\n",
      "Epoka 540: Loss = 0.812441871\n",
      "Epoka 550: Loss = 0.805849649\n",
      "Epoka 560: Loss = 0.800346385\n",
      "Epoka 570: Loss = 0.790441705\n",
      "Epoka 580: Loss = 0.816416689\n",
      "Epoka 590: Loss = 0.805150596\n",
      "Epoka 600: Loss = 0.797759041\n",
      "Epoka 610: Loss = 0.817695488\n",
      "Epoka 620: Loss = 0.803732700\n",
      "Epoka 630: Loss = 0.789840579\n",
      "Epoka 640: Loss = 0.794269122\n",
      "Epoka 650: Loss = 0.821714730\n",
      "Epoka 660: Loss = 0.797442062\n",
      "Epoka 670: Loss = 0.807328689\n",
      "Epoka 680: Loss = 0.815850014\n",
      "Epoka 690: Loss = 0.805897730\n",
      "Epoka 700: Loss = 0.798280437\n",
      "Epoka 710: Loss = 0.806414388\n",
      "Epoka 720: Loss = 0.819176749\n",
      "Epoka 730: Loss = 0.810805768\n",
      "Epoka 740: Loss = 0.791223939\n",
      "Epoka 750: Loss = 0.795369863\n",
      "Epoka 760: Loss = 0.804948891\n",
      "Epoka 770: Loss = 0.817702555\n",
      "Epoka 780: Loss = 0.815895996\n",
      "Epoka 790: Loss = 0.799240646\n",
      "Epoka 800: Loss = 0.796944128\n",
      "Epoka 810: Loss = 0.809329926\n",
      "Epoka 820: Loss = 0.783204270\n",
      "Epoka 830: Loss = 0.784093556\n",
      "Epoka 840: Loss = 0.785422831\n",
      "Epoka 850: Loss = 0.801157909\n",
      "Epoka 860: Loss = 0.805909505\n",
      "Epoka 870: Loss = 0.805050925\n",
      "Epoka 880: Loss = 0.789817778\n",
      "Epoka 890: Loss = 0.816377476\n",
      "Epoka 900: Loss = 0.776396292\n",
      "Epoka 910: Loss = 0.801258186\n",
      "Epoka 920: Loss = 0.806962302\n",
      "Epoka 930: Loss = 0.763133783\n",
      "Epoka 940: Loss = 0.803646860\n",
      "Epoka 950: Loss = 0.802025557\n",
      "Epoka 960: Loss = 0.806323683\n",
      "Epoka 970: Loss = 0.791782533\n",
      "Epoka 980: Loss = 0.814532699\n",
      "Epoka 990: Loss = 0.811941050\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 6.541003 sekundy dla tanh w warstwie ukrytej i 5 neuronów\n",
      "f1 score:\n",
      "0.7890381265275925\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.300365046\n",
      "Epoka 10: Loss = 0.622952366\n",
      "Epoka 20: Loss = 0.719086777\n",
      "Epoka 30: Loss = 0.781378616\n",
      "Epoka 40: Loss = 0.811519886\n",
      "Epoka 50: Loss = 0.834757867\n",
      "Epoka 60: Loss = 0.828199565\n",
      "Epoka 70: Loss = 0.835435874\n",
      "Epoka 80: Loss = 0.854086688\n",
      "Epoka 90: Loss = 0.858986978\n",
      "Epoka 100: Loss = 0.852450491\n",
      "Epoka 110: Loss = 0.864433484\n",
      "Epoka 120: Loss = 0.868587114\n",
      "Epoka 130: Loss = 0.869238078\n",
      "Epoka 140: Loss = 0.880908448\n",
      "Epoka 150: Loss = 0.875367588\n",
      "Epoka 160: Loss = 0.871698098\n",
      "Epoka 170: Loss = 0.887033807\n",
      "Epoka 180: Loss = 0.879204345\n",
      "Epoka 190: Loss = 0.874471467\n",
      "Epoka 200: Loss = 0.879310379\n",
      "Epoka 210: Loss = 0.882114390\n",
      "Epoka 220: Loss = 0.861390112\n",
      "Epoka 230: Loss = 0.888772414\n",
      "Epoka 240: Loss = 0.873678319\n",
      "Epoka 250: Loss = 0.877895668\n",
      "Epoka 260: Loss = 0.898107628\n",
      "Epoka 270: Loss = 0.886443035\n",
      "Epoka 280: Loss = 0.880855844\n",
      "Epoka 290: Loss = 0.894599396\n",
      "Epoka 300: Loss = 0.896462367\n",
      "Epoka 310: Loss = 0.893988058\n",
      "Epoka 320: Loss = 0.891896464\n",
      "Epoka 330: Loss = 0.881801669\n",
      "Epoka 340: Loss = 0.886278689\n",
      "Epoka 350: Loss = 0.892571991\n",
      "Epoka 360: Loss = 0.887624131\n",
      "Epoka 370: Loss = 0.890204342\n",
      "Epoka 380: Loss = 0.884324008\n",
      "Epoka 390: Loss = 0.890059548\n",
      "Epoka 400: Loss = 0.893397711\n",
      "Epoka 410: Loss = 0.891154597\n",
      "Epoka 420: Loss = 0.889751662\n",
      "Epoka 430: Loss = 0.890457443\n",
      "Epoka 440: Loss = 0.884729128\n",
      "Epoka 450: Loss = 0.886219836\n",
      "Epoka 460: Loss = 0.898836377\n",
      "Epoka 470: Loss = 0.897604840\n",
      "Epoka 480: Loss = 0.877413019\n",
      "Epoka 490: Loss = 0.893756737\n",
      "Epoka 500: Loss = 0.893773328\n",
      "Epoka 510: Loss = 0.886990894\n",
      "Epoka 520: Loss = 0.894014866\n",
      "Epoka 530: Loss = 0.895868314\n",
      "Epoka 540: Loss = 0.888107225\n",
      "Epoka 550: Loss = 0.889868542\n",
      "Epoka 560: Loss = 0.888773514\n",
      "Epoka 570: Loss = 0.889418447\n",
      "Epoka 580: Loss = 0.890611242\n",
      "Epoka 590: Loss = 0.895570841\n",
      "Epoka 600: Loss = 0.890735346\n",
      "Epoka 610: Loss = 0.904646018\n",
      "Epoka 620: Loss = 0.891969488\n",
      "Epoka 630: Loss = 0.887714081\n",
      "Epoka 640: Loss = 0.887770296\n",
      "Epoka 650: Loss = 0.874210600\n",
      "Epoka 660: Loss = 0.889429974\n",
      "Epoka 670: Loss = 0.902140639\n",
      "Epoka 680: Loss = 0.897365408\n",
      "Epoka 690: Loss = 0.887102558\n",
      "Epoka 700: Loss = 0.891999578\n",
      "Epoka 710: Loss = 0.896304610\n",
      "Epoka 720: Loss = 0.869109003\n",
      "Epoka 730: Loss = 0.896107916\n",
      "Epoka 740: Loss = 0.887094012\n",
      "Epoka 750: Loss = 0.897767080\n",
      "Epoka 760: Loss = 0.898539307\n",
      "Epoka 770: Loss = 0.897917352\n",
      "Epoka 780: Loss = 0.889108727\n",
      "Epoka 790: Loss = 0.901538760\n",
      "Epoka 800: Loss = 0.895751698\n",
      "Epoka 810: Loss = 0.903826888\n",
      "Epoka 820: Loss = 0.902918661\n",
      "Epoka 830: Loss = 0.899495399\n",
      "Epoka 840: Loss = 0.894234832\n",
      "Epoka 850: Loss = 0.906476966\n",
      "Epoka 860: Loss = 0.880954353\n",
      "Epoka 870: Loss = 0.891932637\n",
      "Epoka 880: Loss = 0.898184513\n",
      "Epoka 890: Loss = 0.896012078\n",
      "Epoka 900: Loss = 0.880787932\n",
      "Epoka 910: Loss = 0.903940849\n",
      "Epoka 920: Loss = 0.898554048\n",
      "Epoka 930: Loss = 0.897582332\n",
      "Epoka 940: Loss = 0.897213357\n",
      "Epoka 950: Loss = 0.900319681\n",
      "Epoka 960: Loss = 0.895333255\n",
      "Epoka 970: Loss = 0.896739669\n",
      "Epoka 980: Loss = 0.879527494\n",
      "Epoka 990: Loss = 0.888051450\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 6.948058 sekundy dla tanh w warstwie ukrytej i 10 neuronów\n",
      "f1 score:\n",
      "0.8493364069173159\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.302241751\n",
      "Epoka 10: Loss = 0.671307455\n",
      "Epoka 20: Loss = 0.785400943\n",
      "Epoka 30: Loss = 0.823726255\n",
      "Epoka 40: Loss = 0.854953473\n",
      "Epoka 50: Loss = 0.884419403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 60: Loss = 0.899750598\n",
      "Epoka 70: Loss = 0.892317332\n",
      "Epoka 80: Loss = 0.906758011\n",
      "Epoka 90: Loss = 0.913121538\n",
      "Epoka 100: Loss = 0.924073653\n",
      "Epoka 110: Loss = 0.920126587\n",
      "Epoka 120: Loss = 0.928502787\n",
      "Epoka 130: Loss = 0.928687850\n",
      "Epoka 140: Loss = 0.933949684\n",
      "Epoka 150: Loss = 0.937818477\n",
      "Epoka 160: Loss = 0.938312097\n",
      "Epoka 170: Loss = 0.937372822\n",
      "Epoka 180: Loss = 0.941374378\n",
      "Epoka 190: Loss = 0.940400858\n",
      "Epoka 200: Loss = 0.946234654\n",
      "Epoka 210: Loss = 0.946317149\n",
      "Epoka 220: Loss = 0.946981881\n",
      "Epoka 230: Loss = 0.923757449\n",
      "Epoka 240: Loss = 0.947048106\n",
      "Epoka 250: Loss = 0.955961075\n",
      "Epoka 260: Loss = 0.950213325\n",
      "Epoka 270: Loss = 0.957632822\n",
      "Epoka 280: Loss = 0.961647290\n",
      "Epoka 290: Loss = 0.952620809\n",
      "Epoka 300: Loss = 0.960746537\n",
      "Epoka 310: Loss = 0.951923305\n",
      "Epoka 320: Loss = 0.959138028\n",
      "Epoka 330: Loss = 0.956016407\n",
      "Epoka 340: Loss = 0.967982012\n",
      "Epoka 350: Loss = 0.960566520\n",
      "Epoka 360: Loss = 0.960772477\n",
      "Epoka 370: Loss = 0.965526436\n",
      "Epoka 380: Loss = 0.959998304\n",
      "Epoka 390: Loss = 0.963950619\n",
      "Epoka 400: Loss = 0.947719252\n",
      "Epoka 410: Loss = 0.959261689\n",
      "Epoka 420: Loss = 0.958302326\n",
      "Epoka 430: Loss = 0.963027374\n",
      "Epoka 440: Loss = 0.964000483\n",
      "Epoka 450: Loss = 0.966387809\n",
      "Epoka 460: Loss = 0.965518603\n",
      "Epoka 470: Loss = 0.959124086\n",
      "Epoka 480: Loss = 0.957505036\n",
      "Epoka 490: Loss = 0.967979515\n",
      "Epoka 500: Loss = 0.962378430\n",
      "Epoka 510: Loss = 0.961530465\n",
      "Epoka 520: Loss = 0.959984455\n",
      "Epoka 530: Loss = 0.963212991\n",
      "Epoka 540: Loss = 0.967171671\n",
      "Epoka 550: Loss = 0.969498968\n",
      "Epoka 560: Loss = 0.964845204\n",
      "Epoka 570: Loss = 0.967971663\n",
      "Epoka 580: Loss = 0.955111908\n",
      "Epoka 590: Loss = 0.966409891\n",
      "Epoka 600: Loss = 0.967978789\n",
      "Epoka 610: Loss = 0.965619846\n",
      "Epoka 620: Loss = 0.960770138\n",
      "Epoka 630: Loss = 0.968807881\n",
      "Epoka 640: Loss = 0.961464776\n",
      "Epoka 650: Loss = 0.966456031\n",
      "Epoka 660: Loss = 0.964858431\n",
      "Epoka 670: Loss = 0.969568678\n",
      "Epoka 680: Loss = 0.961605016\n",
      "Epoka 690: Loss = 0.964708300\n",
      "Epoka 700: Loss = 0.967155114\n",
      "Epoka 710: Loss = 0.971199866\n",
      "Epoka 720: Loss = 0.973575037\n",
      "Epoka 730: Loss = 0.971953179\n",
      "Epoka 740: Loss = 0.973587901\n",
      "Epoka 750: Loss = 0.967151405\n",
      "Epoka 760: Loss = 0.965616158\n",
      "Epoka 770: Loss = 0.965578378\n",
      "Epoka 780: Loss = 0.967134955\n",
      "Epoka 790: Loss = 0.972750594\n",
      "Epoka 800: Loss = 0.968815427\n",
      "Epoka 810: Loss = 0.953493856\n",
      "Epoka 820: Loss = 0.973566949\n",
      "Epoka 830: Loss = 0.968010402\n",
      "Epoka 840: Loss = 0.970372681\n",
      "Epoka 850: Loss = 0.962359148\n",
      "Epoka 860: Loss = 0.970360357\n",
      "Epoka 870: Loss = 0.971984359\n",
      "Epoka 880: Loss = 0.956751813\n",
      "Epoka 890: Loss = 0.954382615\n",
      "Epoka 900: Loss = 0.968798293\n",
      "Epoka 910: Loss = 0.971120642\n",
      "Epoka 920: Loss = 0.972777301\n",
      "Epoka 930: Loss = 0.970375016\n",
      "Epoka 940: Loss = 0.971186365\n",
      "Epoka 950: Loss = 0.967976972\n",
      "Epoka 960: Loss = 0.974334666\n",
      "Epoka 970: Loss = 0.959202650\n",
      "Epoka 980: Loss = 0.968776134\n",
      "Epoka 990: Loss = 0.956677413\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 7.617101 sekundy dla tanh w warstwie ukrytej i 15 neuronów\n",
      "f1 score:\n",
      "0.9200244904914797\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.330485433\n",
      "Epoka 10: Loss = 0.723468388\n",
      "Epoka 20: Loss = 0.759350303\n",
      "Epoka 30: Loss = 0.807167925\n",
      "Epoka 40: Loss = 0.837793691\n",
      "Epoka 50: Loss = 0.858172907\n",
      "Epoka 60: Loss = 0.880210022\n",
      "Epoka 70: Loss = 0.888872227\n",
      "Epoka 80: Loss = 0.896593575\n",
      "Epoka 90: Loss = 0.897595934\n",
      "Epoka 100: Loss = 0.902671570\n",
      "Epoka 110: Loss = 0.904557130\n",
      "Epoka 120: Loss = 0.923880922\n",
      "Epoka 130: Loss = 0.922844296\n",
      "Epoka 140: Loss = 0.913688447\n",
      "Epoka 150: Loss = 0.927671527\n",
      "Epoka 160: Loss = 0.932043718\n",
      "Epoka 170: Loss = 0.937468507\n",
      "Epoka 180: Loss = 0.934809493\n",
      "Epoka 190: Loss = 0.933403773\n",
      "Epoka 200: Loss = 0.941625878\n",
      "Epoka 210: Loss = 0.934811325\n",
      "Epoka 220: Loss = 0.944797126\n",
      "Epoka 230: Loss = 0.944845044\n",
      "Epoka 240: Loss = 0.948048568\n",
      "Epoka 250: Loss = 0.946409039\n",
      "Epoka 260: Loss = 0.947169883\n",
      "Epoka 270: Loss = 0.944548535\n",
      "Epoka 280: Loss = 0.951176310\n",
      "Epoka 290: Loss = 0.950330336\n",
      "Epoka 300: Loss = 0.939586358\n",
      "Epoka 310: Loss = 0.951156161\n",
      "Epoka 320: Loss = 0.951988121\n",
      "Epoka 330: Loss = 0.948095064\n",
      "Epoka 340: Loss = 0.948494911\n",
      "Epoka 350: Loss = 0.955920530\n",
      "Epoka 360: Loss = 0.958325493\n",
      "Epoka 370: Loss = 0.950308548\n",
      "Epoka 380: Loss = 0.952782698\n",
      "Epoka 390: Loss = 0.958308616\n",
      "Epoka 400: Loss = 0.943091147\n",
      "Epoka 410: Loss = 0.959893642\n",
      "Epoka 420: Loss = 0.960001929\n",
      "Epoka 430: Loss = 0.952700204\n",
      "Epoka 440: Loss = 0.954362168\n",
      "Epoka 450: Loss = 0.964746257\n",
      "Epoka 460: Loss = 0.963194849\n",
      "Epoka 470: Loss = 0.959183183\n",
      "Epoka 480: Loss = 0.962339239\n",
      "Epoka 490: Loss = 0.962364330\n",
      "Epoka 500: Loss = 0.963134472\n",
      "Epoka 510: Loss = 0.963922188\n",
      "Epoka 520: Loss = 0.958172082\n",
      "Epoka 530: Loss = 0.967986299\n",
      "Epoka 540: Loss = 0.969545477\n",
      "Epoka 550: Loss = 0.962355657\n",
      "Epoka 560: Loss = 0.963918484\n",
      "Epoka 570: Loss = 0.954381952\n",
      "Epoka 580: Loss = 0.967191275\n",
      "Epoka 590: Loss = 0.968766848\n",
      "Epoka 600: Loss = 0.967243730\n",
      "Epoka 610: Loss = 0.967128166\n",
      "Epoka 620: Loss = 0.971171772\n",
      "Epoka 630: Loss = 0.963943299\n",
      "Epoka 640: Loss = 0.964720915\n",
      "Epoka 650: Loss = 0.971176163\n",
      "Epoka 660: Loss = 0.963188773\n",
      "Epoka 670: Loss = 0.971938073\n",
      "Epoka 680: Loss = 0.963173572\n",
      "Epoka 690: Loss = 0.970330500\n",
      "Epoka 700: Loss = 0.965576923\n",
      "Epoka 710: Loss = 0.969553620\n",
      "Epoka 720: Loss = 0.971200650\n",
      "Epoka 730: Loss = 0.973590174\n",
      "Epoka 740: Loss = 0.967055906\n",
      "Epoka 750: Loss = 0.974368946\n",
      "Epoka 760: Loss = 0.969579910\n",
      "Epoka 770: Loss = 0.970357896\n",
      "Epoka 780: Loss = 0.970421557\n",
      "Epoka 790: Loss = 0.974390124\n",
      "Epoka 800: Loss = 0.974354218\n",
      "Epoka 810: Loss = 0.974351149\n",
      "Epoka 820: Loss = 0.971167762\n",
      "Epoka 830: Loss = 0.977591483\n",
      "Epoka 840: Loss = 0.975180994\n",
      "Epoka 850: Loss = 0.977594612\n",
      "Epoka 860: Loss = 0.973586788\n",
      "Epoka 870: Loss = 0.977585387\n",
      "Epoka 880: Loss = 0.969516892\n",
      "Epoka 890: Loss = 0.969481530\n",
      "Epoka 900: Loss = 0.979981321\n",
      "Epoka 910: Loss = 0.972773241\n",
      "Epoka 920: Loss = 0.979983859\n",
      "Epoka 930: Loss = 0.975196372\n",
      "Epoka 940: Loss = 0.969562138\n",
      "Epoka 950: Loss = 0.975166876\n",
      "Epoka 960: Loss = 0.975968670\n",
      "Epoka 970: Loss = 0.971939001\n",
      "Epoka 980: Loss = 0.970346767\n",
      "Epoka 990: Loss = 0.977597995\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 9.126709 sekundy dla tanh w warstwie ukrytej i 20 neuronów\n",
      "f1 score:\n",
      "0.9286593542972472\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.325311353\n",
      "Epoka 10: Loss = 0.595642660\n",
      "Epoka 20: Loss = 0.689408148\n",
      "Epoka 30: Loss = 0.759247795\n",
      "Epoka 40: Loss = 0.764844041\n",
      "Epoka 50: Loss = 0.759470458\n",
      "Epoka 60: Loss = 0.729576497\n",
      "Epoka 70: Loss = 0.785162212\n",
      "Epoka 80: Loss = 0.781746706\n",
      "Epoka 90: Loss = 0.773577156\n",
      "Epoka 100: Loss = 0.785658453\n",
      "Epoka 110: Loss = 0.790423559\n",
      "Epoka 120: Loss = 0.782181708\n",
      "Epoka 130: Loss = 0.772536503\n",
      "Epoka 140: Loss = 0.793832977\n",
      "Epoka 150: Loss = 0.782247872\n",
      "Epoka 160: Loss = 0.775975907\n",
      "Epoka 170: Loss = 0.769238608\n",
      "Epoka 180: Loss = 0.782906623\n",
      "Epoka 190: Loss = 0.775915160\n",
      "Epoka 200: Loss = 0.783194998\n",
      "Epoka 210: Loss = 0.789497272\n",
      "Epoka 220: Loss = 0.775025415\n",
      "Epoka 230: Loss = 0.789078849\n",
      "Epoka 240: Loss = 0.783844490\n",
      "Epoka 250: Loss = 0.792773981\n",
      "Epoka 260: Loss = 0.805928130\n",
      "Epoka 270: Loss = 0.793992768\n",
      "Epoka 280: Loss = 0.742324556\n",
      "Epoka 290: Loss = 0.787972022\n",
      "Epoka 300: Loss = 0.805071316\n",
      "Epoka 310: Loss = 0.789799154\n",
      "Epoka 320: Loss = 0.781592465\n",
      "Epoka 330: Loss = 0.792617267\n",
      "Epoka 340: Loss = 0.796403799\n",
      "Epoka 350: Loss = 0.771335127\n",
      "Epoka 360: Loss = 0.798365765\n",
      "Epoka 370: Loss = 0.786632825\n",
      "Epoka 380: Loss = 0.803693548\n",
      "Epoka 390: Loss = 0.794653666\n",
      "Epoka 400: Loss = 0.795105132\n",
      "Epoka 410: Loss = 0.775761286\n",
      "Epoka 420: Loss = 0.776551858\n",
      "Epoka 430: Loss = 0.792921385\n",
      "Epoka 440: Loss = 0.767462355\n",
      "Epoka 450: Loss = 0.787540612\n",
      "Epoka 460: Loss = 0.758209205\n",
      "Epoka 470: Loss = 0.792841137\n",
      "Epoka 480: Loss = 0.804267274\n",
      "Epoka 490: Loss = 0.798580129\n",
      "Epoka 500: Loss = 0.773006812\n",
      "Epoka 510: Loss = 0.793059840\n",
      "Epoka 520: Loss = 0.797950291\n",
      "Epoka 530: Loss = 0.765010278\n",
      "Epoka 540: Loss = 0.798140798\n",
      "Epoka 550: Loss = 0.801255745\n",
      "Epoka 560: Loss = 0.798744513\n",
      "Epoka 570: Loss = 0.796983472\n",
      "Epoka 580: Loss = 0.811928364\n",
      "Epoka 590: Loss = 0.803019955\n",
      "Epoka 600: Loss = 0.763121472\n",
      "Epoka 610: Loss = 0.789747753\n",
      "Epoka 620: Loss = 0.792453721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 630: Loss = 0.767910327\n",
      "Epoka 640: Loss = 0.788805983\n",
      "Epoka 650: Loss = 0.734214671\n",
      "Epoka 660: Loss = 0.793032165\n",
      "Epoka 670: Loss = 0.792138061\n",
      "Epoka 680: Loss = 0.785650590\n",
      "Epoka 690: Loss = 0.800810324\n",
      "Epoka 700: Loss = 0.799630346\n",
      "Epoka 710: Loss = 0.777482941\n",
      "Epoka 720: Loss = 0.779630221\n",
      "Epoka 730: Loss = 0.801980747\n",
      "Epoka 740: Loss = 0.794358841\n",
      "Epoka 750: Loss = 0.759454760\n",
      "Epoka 760: Loss = 0.808759282\n",
      "Epoka 770: Loss = 0.792977672\n",
      "Epoka 780: Loss = 0.793631160\n",
      "Epoka 790: Loss = 0.794520143\n",
      "Epoka 800: Loss = 0.780880942\n",
      "Epoka 810: Loss = 0.799978439\n",
      "Epoka 820: Loss = 0.805588270\n",
      "Epoka 830: Loss = 0.797909071\n",
      "Epoka 840: Loss = 0.784509122\n",
      "Epoka 850: Loss = 0.789342487\n",
      "Epoka 860: Loss = 0.782006428\n",
      "Epoka 870: Loss = 0.779422291\n",
      "Epoka 880: Loss = 0.797786283\n",
      "Epoka 890: Loss = 0.771782876\n",
      "Epoka 900: Loss = 0.789924714\n",
      "Epoka 910: Loss = 0.779833699\n",
      "Epoka 920: Loss = 0.794420150\n",
      "Epoka 930: Loss = 0.794649106\n",
      "Epoka 940: Loss = 0.782207748\n",
      "Epoka 950: Loss = 0.777079873\n",
      "Epoka 960: Loss = 0.778281067\n",
      "Epoka 970: Loss = 0.796145103\n",
      "Epoka 980: Loss = 0.779388083\n",
      "Epoka 990: Loss = 0.794091683\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 6.650104 sekundy dla relu w warstwie ukrytej i 5 neuronów\n",
      "f1 score:\n",
      "0.7705515371869728\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.348712502\n",
      "Epoka 10: Loss = 0.674564285\n",
      "Epoka 20: Loss = 0.715763153\n",
      "Epoka 30: Loss = 0.774767098\n",
      "Epoka 40: Loss = 0.790001753\n",
      "Epoka 50: Loss = 0.807061208\n",
      "Epoka 60: Loss = 0.793427934\n",
      "Epoka 70: Loss = 0.761741910\n",
      "Epoka 80: Loss = 0.766463596\n",
      "Epoka 90: Loss = 0.815177257\n",
      "Epoka 100: Loss = 0.828798030\n",
      "Epoka 110: Loss = 0.839992599\n",
      "Epoka 120: Loss = 0.775597867\n",
      "Epoka 130: Loss = 0.839279146\n",
      "Epoka 140: Loss = 0.844491094\n",
      "Epoka 150: Loss = 0.842255413\n",
      "Epoka 160: Loss = 0.833333978\n",
      "Epoka 170: Loss = 0.860341666\n",
      "Epoka 180: Loss = 0.849827697\n",
      "Epoka 190: Loss = 0.829397392\n",
      "Epoka 200: Loss = 0.803121805\n",
      "Epoka 210: Loss = 0.814597806\n",
      "Epoka 220: Loss = 0.848037707\n",
      "Epoka 230: Loss = 0.836436089\n",
      "Epoka 240: Loss = 0.846980707\n",
      "Epoka 250: Loss = 0.852176003\n",
      "Epoka 260: Loss = 0.849853067\n",
      "Epoka 270: Loss = 0.850937675\n",
      "Epoka 280: Loss = 0.854032675\n",
      "Epoka 290: Loss = 0.807100400\n",
      "Epoka 300: Loss = 0.854054359\n",
      "Epoka 310: Loss = 0.869128901\n",
      "Epoka 320: Loss = 0.823578964\n",
      "Epoka 330: Loss = 0.837939191\n",
      "Epoka 340: Loss = 0.859824584\n",
      "Epoka 350: Loss = 0.854404717\n",
      "Epoka 360: Loss = 0.864023745\n",
      "Epoka 370: Loss = 0.864689826\n",
      "Epoka 380: Loss = 0.837710043\n",
      "Epoka 390: Loss = 0.855546325\n",
      "Epoka 400: Loss = 0.887694300\n",
      "Epoka 410: Loss = 0.881978675\n",
      "Epoka 420: Loss = 0.854396351\n",
      "Epoka 430: Loss = 0.861915346\n",
      "Epoka 440: Loss = 0.892432104\n",
      "Epoka 450: Loss = 0.876073465\n",
      "Epoka 460: Loss = 0.811051969\n",
      "Epoka 470: Loss = 0.838893955\n",
      "Epoka 480: Loss = 0.882375605\n",
      "Epoka 490: Loss = 0.880113079\n",
      "Epoka 500: Loss = 0.879920078\n",
      "Epoka 510: Loss = 0.890153571\n",
      "Epoka 520: Loss = 0.889586519\n",
      "Epoka 530: Loss = 0.807440868\n",
      "Epoka 540: Loss = 0.768724785\n",
      "Epoka 550: Loss = 0.809345314\n",
      "Epoka 560: Loss = 0.892279124\n",
      "Epoka 570: Loss = 0.891181985\n",
      "Epoka 580: Loss = 0.867956758\n",
      "Epoka 590: Loss = 0.807622249\n",
      "Epoka 600: Loss = 0.894317275\n",
      "Epoka 610: Loss = 0.857690327\n",
      "Epoka 620: Loss = 0.834014795\n",
      "Epoka 630: Loss = 0.834443521\n",
      "Epoka 640: Loss = 0.868067404\n",
      "Epoka 650: Loss = 0.875377088\n",
      "Epoka 660: Loss = 0.902255342\n",
      "Epoka 670: Loss = 0.886861727\n",
      "Epoka 680: Loss = 0.901882387\n",
      "Epoka 690: Loss = 0.865468433\n",
      "Epoka 700: Loss = 0.850322805\n",
      "Epoka 710: Loss = 0.833829987\n",
      "Epoka 720: Loss = 0.854345682\n",
      "Epoka 730: Loss = 0.879114583\n",
      "Epoka 740: Loss = 0.899399281\n",
      "Epoka 750: Loss = 0.812812523\n",
      "Epoka 760: Loss = 0.887070293\n",
      "Epoka 770: Loss = 0.888991667\n",
      "Epoka 780: Loss = 0.835003342\n",
      "Epoka 790: Loss = 0.902350676\n",
      "Epoka 800: Loss = 0.894988822\n",
      "Epoka 810: Loss = 0.874095596\n",
      "Epoka 820: Loss = 0.881585179\n",
      "Epoka 830: Loss = 0.886507265\n",
      "Epoka 840: Loss = 0.897448891\n",
      "Epoka 850: Loss = 0.883377996\n",
      "Epoka 860: Loss = 0.841363235\n",
      "Epoka 870: Loss = 0.836044781\n",
      "Epoka 880: Loss = 0.889003395\n",
      "Epoka 890: Loss = 0.879346357\n",
      "Epoka 900: Loss = 0.800499310\n",
      "Epoka 910: Loss = 0.846514122\n",
      "Epoka 920: Loss = 0.841492085\n",
      "Epoka 930: Loss = 0.873362657\n",
      "Epoka 940: Loss = 0.841496681\n",
      "Epoka 950: Loss = 0.847599053\n",
      "Epoka 960: Loss = 0.894680469\n",
      "Epoka 970: Loss = 0.884848327\n",
      "Epoka 980: Loss = 0.900204575\n",
      "Epoka 990: Loss = 0.867443020\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 6.831291 sekundy dla relu w warstwie ukrytej i 10 neuronów\n",
      "f1 score:\n",
      "0.8008046411350526\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.328687218\n",
      "Epoka 10: Loss = 0.720625549\n",
      "Epoka 20: Loss = 0.763602583\n",
      "Epoka 30: Loss = 0.797003728\n",
      "Epoka 40: Loss = 0.834122297\n",
      "Epoka 50: Loss = 0.842920793\n",
      "Epoka 60: Loss = 0.835020088\n",
      "Epoka 70: Loss = 0.827819428\n",
      "Epoka 80: Loss = 0.882252608\n",
      "Epoka 90: Loss = 0.896870369\n",
      "Epoka 100: Loss = 0.897182928\n",
      "Epoka 110: Loss = 0.901498669\n",
      "Epoka 120: Loss = 0.866638335\n",
      "Epoka 130: Loss = 0.855138250\n",
      "Epoka 140: Loss = 0.864054500\n",
      "Epoka 150: Loss = 0.903059633\n",
      "Epoka 160: Loss = 0.902942900\n",
      "Epoka 170: Loss = 0.889401917\n",
      "Epoka 180: Loss = 0.868265070\n",
      "Epoka 190: Loss = 0.902722882\n",
      "Epoka 200: Loss = 0.880339220\n",
      "Epoka 210: Loss = 0.892326033\n",
      "Epoka 220: Loss = 0.870170517\n",
      "Epoka 230: Loss = 0.896758474\n",
      "Epoka 240: Loss = 0.884468252\n",
      "Epoka 250: Loss = 0.838194333\n",
      "Epoka 260: Loss = 0.887038211\n",
      "Epoka 270: Loss = 0.898327185\n",
      "Epoka 280: Loss = 0.903697234\n",
      "Epoka 290: Loss = 0.913687487\n",
      "Epoka 300: Loss = 0.907713083\n",
      "Epoka 310: Loss = 0.879943633\n",
      "Epoka 320: Loss = 0.906018203\n",
      "Epoka 330: Loss = 0.895120103\n",
      "Epoka 340: Loss = 0.885840103\n",
      "Epoka 350: Loss = 0.899809343\n",
      "Epoka 360: Loss = 0.908492848\n",
      "Epoka 370: Loss = 0.891714260\n",
      "Epoka 380: Loss = 0.852952612\n",
      "Epoka 390: Loss = 0.902891052\n",
      "Epoka 400: Loss = 0.899780067\n",
      "Epoka 410: Loss = 0.904850171\n",
      "Epoka 420: Loss = 0.893193567\n",
      "Epoka 430: Loss = 0.910247858\n",
      "Epoka 440: Loss = 0.888327786\n",
      "Epoka 450: Loss = 0.909435398\n",
      "Epoka 460: Loss = 0.849836028\n",
      "Epoka 470: Loss = 0.891442418\n",
      "Epoka 480: Loss = 0.904695038\n",
      "Epoka 490: Loss = 0.858544269\n",
      "Epoka 500: Loss = 0.888002673\n",
      "Epoka 510: Loss = 0.914736465\n",
      "Epoka 520: Loss = 0.900174455\n",
      "Epoka 530: Loss = 0.901833473\n",
      "Epoka 540: Loss = 0.917626667\n",
      "Epoka 550: Loss = 0.889352777\n",
      "Epoka 560: Loss = 0.884821531\n",
      "Epoka 570: Loss = 0.913259967\n",
      "Epoka 580: Loss = 0.913986700\n",
      "Epoka 590: Loss = 0.903216563\n",
      "Epoka 600: Loss = 0.888941681\n",
      "Epoka 610: Loss = 0.915913242\n",
      "Epoka 620: Loss = 0.907594153\n",
      "Epoka 630: Loss = 0.915483747\n",
      "Epoka 640: Loss = 0.909378617\n",
      "Epoka 650: Loss = 0.923895136\n",
      "Epoka 660: Loss = 0.922579751\n",
      "Epoka 670: Loss = 0.913225743\n",
      "Epoka 680: Loss = 0.910527848\n",
      "Epoka 690: Loss = 0.922646514\n",
      "Epoka 700: Loss = 0.917906087\n",
      "Epoka 710: Loss = 0.836247015\n",
      "Epoka 720: Loss = 0.909601544\n",
      "Epoka 730: Loss = 0.930147489\n",
      "Epoka 740: Loss = 0.897806494\n",
      "Epoka 750: Loss = 0.910495195\n",
      "Epoka 760: Loss = 0.914761489\n",
      "Epoka 770: Loss = 0.911537754\n",
      "Epoka 780: Loss = 0.891309300\n",
      "Epoka 790: Loss = 0.930971452\n",
      "Epoka 800: Loss = 0.916892146\n",
      "Epoka 810: Loss = 0.910895995\n",
      "Epoka 820: Loss = 0.918496520\n",
      "Epoka 830: Loss = 0.909136250\n",
      "Epoka 840: Loss = 0.926013397\n",
      "Epoka 850: Loss = 0.895212350\n",
      "Epoka 860: Loss = 0.927727101\n",
      "Epoka 870: Loss = 0.896983974\n",
      "Epoka 880: Loss = 0.900218184\n",
      "Epoka 890: Loss = 0.911740471\n",
      "Epoka 900: Loss = 0.913257132\n",
      "Epoka 910: Loss = 0.890869793\n",
      "Epoka 920: Loss = 0.901796205\n",
      "Epoka 930: Loss = 0.901304773\n",
      "Epoka 940: Loss = 0.894021042\n",
      "Epoka 950: Loss = 0.903547638\n",
      "Epoka 960: Loss = 0.902918026\n",
      "Epoka 970: Loss = 0.925146466\n",
      "Epoka 980: Loss = 0.900925163\n",
      "Epoka 990: Loss = 0.923129530\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 7.079635 sekundy dla relu w warstwie ukrytej i 15 neuronów\n",
      "f1 score:\n",
      "0.8661804354679539\n",
      "--------------------------------------------------------------------------------------------\n",
      "Epoka 0: Loss = 0.385685464\n",
      "Epoka 10: Loss = 0.680903770\n",
      "Epoka 20: Loss = 0.788340970\n",
      "Epoka 30: Loss = 0.802794812\n",
      "Epoka 40: Loss = 0.838812598\n",
      "Epoka 50: Loss = 0.859068559\n",
      "Epoka 60: Loss = 0.861634031\n",
      "Epoka 70: Loss = 0.859643902\n",
      "Epoka 80: Loss = 0.885675466\n",
      "Epoka 90: Loss = 0.864333590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 100: Loss = 0.897670664\n",
      "Epoka 110: Loss = 0.891148528\n",
      "Epoka 120: Loss = 0.883763013\n",
      "Epoka 130: Loss = 0.887653322\n",
      "Epoka 140: Loss = 0.910244061\n",
      "Epoka 150: Loss = 0.912813695\n",
      "Epoka 160: Loss = 0.872394492\n",
      "Epoka 170: Loss = 0.896018148\n",
      "Epoka 180: Loss = 0.868681694\n",
      "Epoka 190: Loss = 0.898573841\n",
      "Epoka 200: Loss = 0.891089009\n",
      "Epoka 210: Loss = 0.859318826\n",
      "Epoka 220: Loss = 0.878964979\n",
      "Epoka 230: Loss = 0.874180290\n",
      "Epoka 240: Loss = 0.884414667\n",
      "Epoka 250: Loss = 0.830923408\n",
      "Epoka 260: Loss = 0.904462166\n",
      "Epoka 270: Loss = 0.874789416\n",
      "Epoka 280: Loss = 0.890748853\n",
      "Epoka 290: Loss = 0.825879236\n",
      "Epoka 300: Loss = 0.886824833\n",
      "Epoka 310: Loss = 0.903990624\n",
      "Epoka 320: Loss = 0.891271564\n",
      "Epoka 330: Loss = 0.902256275\n",
      "Epoka 340: Loss = 0.866569427\n",
      "Epoka 350: Loss = 0.891022300\n",
      "Epoka 360: Loss = 0.884657942\n",
      "Epoka 370: Loss = 0.883549943\n",
      "Epoka 380: Loss = 0.902688093\n",
      "Epoka 390: Loss = 0.902123159\n",
      "Epoka 400: Loss = 0.904279363\n",
      "Epoka 410: Loss = 0.901922485\n",
      "Epoka 420: Loss = 0.867741140\n",
      "Epoka 430: Loss = 0.884608189\n",
      "Epoka 440: Loss = 0.900617610\n",
      "Epoka 450: Loss = 0.856471987\n",
      "Epoka 460: Loss = 0.912448138\n",
      "Epoka 470: Loss = 0.880029250\n",
      "Epoka 480: Loss = 0.905662237\n",
      "Epoka 490: Loss = 0.892034567\n",
      "Epoka 500: Loss = 0.898896144\n",
      "Epoka 510: Loss = 0.897038499\n",
      "Epoka 520: Loss = 0.900196811\n",
      "Epoka 530: Loss = 0.880200753\n",
      "Epoka 540: Loss = 0.898804680\n",
      "Epoka 550: Loss = 0.916308477\n",
      "Epoka 560: Loss = 0.912456434\n",
      "Epoka 570: Loss = 0.907392487\n",
      "Epoka 580: Loss = 0.912034543\n",
      "Epoka 590: Loss = 0.874958847\n",
      "Epoka 600: Loss = 0.907895416\n",
      "Epoka 610: Loss = 0.901716898\n",
      "Epoka 620: Loss = 0.906981828\n",
      "Epoka 630: Loss = 0.909802552\n",
      "Epoka 640: Loss = 0.921870631\n",
      "Epoka 650: Loss = 0.918278033\n",
      "Epoka 660: Loss = 0.900319673\n",
      "Epoka 670: Loss = 0.916836821\n",
      "Epoka 680: Loss = 0.877948895\n",
      "Epoka 690: Loss = 0.910889695\n",
      "Epoka 700: Loss = 0.914473889\n",
      "Epoka 710: Loss = 0.905390068\n",
      "Epoka 720: Loss = 0.888331478\n",
      "Epoka 730: Loss = 0.899173210\n",
      "Epoka 740: Loss = 0.894113649\n",
      "Epoka 750: Loss = 0.906820695\n",
      "Epoka 760: Loss = 0.892725886\n",
      "Epoka 770: Loss = 0.898744928\n",
      "Epoka 780: Loss = 0.901096832\n",
      "Epoka 790: Loss = 0.924124580\n",
      "Epoka 800: Loss = 0.906450866\n",
      "Epoka 810: Loss = 0.917488334\n",
      "Epoka 820: Loss = 0.866105948\n",
      "Epoka 830: Loss = 0.896113101\n",
      "Epoka 840: Loss = 0.924813088\n",
      "Epoka 850: Loss = 0.929407110\n",
      "Epoka 860: Loss = 0.933898420\n",
      "Epoka 870: Loss = 0.904605813\n",
      "Epoka 880: Loss = 0.911499380\n",
      "Epoka 890: Loss = 0.900870651\n",
      "Epoka 900: Loss = 0.903992507\n",
      "Epoka 910: Loss = 0.926191450\n",
      "Epoka 920: Loss = 0.888435181\n",
      "Epoka 930: Loss = 0.905426603\n",
      "Epoka 940: Loss = 0.870531007\n",
      "Epoka 950: Loss = 0.896222353\n",
      "Epoka 960: Loss = 0.916302549\n",
      "Epoka 970: Loss = 0.928848431\n",
      "Epoka 980: Loss = 0.925092570\n",
      "Epoka 990: Loss = 0.923227405\n",
      "--------------------------------------------------------------------------------------------\n",
      "Czas wykonania: 7.683947 sekundy dla relu w warstwie ukrytej i 20 neuronów\n",
      "f1 score:\n",
      "0.8957368156017853\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "activation_functions =['sigmoid', 'linear', 'tanh', 'relu']\n",
    "num_neurons = [5, 10, 15, 20]\n",
    "for el in activation_functions:\n",
    "    for neurons in num_neurons:\n",
    "        mlp_ringsR = MLPNoBackprop(layer_sizes = [X_ringsR5_train.shape[1], neurons, len(np.unique(Y_ringsR5_train))], \n",
    "                                   output_activation='softmax', hidden_activation = el)\n",
    "        start_time = time.time()\n",
    "        mlp_ringsR.classifiaction_train(X_ringsR5_train_normalized, Y_ringsR5_train, epochs = 1000, learning_rate=0.01, batch_size=10)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print('--------------------------------------------------------------------------------------------')\n",
    "        print(f\"Czas wykonania: {execution_time:.6f} sekundy dla {el} w warstwie ukrytej i {neurons} neuronów\")\n",
    "        ypred = mlp_ringsR.predict_classification(X_ringsR5_test_normalized)\n",
    "        print('f1 score:')\n",
    "        print(mlp_ringsR.f1_score(Y_ringsR5_test, ypred))\n",
    "        print('--------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2075bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "najlepiej tanh i 20 neuronów, znów najgorzej linear - wniosek: linear niw n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
